#!/usr/bin/env python3
"""
Fermi ì¶”ì • ìµœì¢… ë²„ì „ - Few-shot ì˜ˆì‹œ í¬í•¨
ê³„ì‚° ì—°ê²°ì„±ì„ ëª…í™•íˆ ìš”êµ¬í•˜ê³  ê²€ì¦
"""

import sys
import os
import time
import json
from datetime import datetime
import math
import re

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()


# =====================================
# Few-shot ì˜ˆì‹œ í¬í•¨ í”„ë¡¬í”„íŠ¸
# =====================================

FERMI_PROBLEM = {
    'korean_businesses': {
        'name': 'í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜',
        'ground_truth': 7837000,
        'unit': 'ê°œ',
    
    'prompt': '''í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜ë¥¼ ì¶”ì •í•˜ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ê° ë¶„í•´ ë‹¨ê³„ì˜ ìˆ«ìë“¤ì´ ìµœì¢… ì¶”ì •ê°’ìœ¼ë¡œ ì–´ë–»ê²Œ ê³„ì‚°ë˜ëŠ”ì§€ ëª…í™•íˆ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.

ë¨¼ì € ì˜¬ë°”ë¥¸ Fermi ì¶”ì • ì˜ˆì‹œë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì˜ˆì‹œ ë¬¸ì œ: ì„œìš¸ì‹œ íƒì‹œ ìˆ˜ ì¶”ì •

ì˜¬ë°”ë¥¸ ë‹µë³€:
{
    "value": 70000,
    "unit": "ëŒ€",
    "confidence": 0.6,
    "method": "bottom-up",
    "decomposition": [
        {
            "step": "1. ì„œìš¸ ì¸êµ¬",
            "value": 10000000,
            "calculation": "ì•½ 1000ë§Œëª…ìœ¼ë¡œ ê°€ì •",
            "reasoning": "ì„œìš¸ í†µê³„ ê¸°ì¤€"
        },
        {
            "step": "2. 1ì¸ë‹¹ ì—°ê°„ íƒì‹œ ì´ìš© íšŸìˆ˜",
            "value": 20,
            "calculation": "ì›” 1-2íšŒ Ã— 12ê°œì›” = 20íšŒ",
            "reasoning": "ëŒ€ì¤‘êµí†µ ì¤‘ì‹¬ ë„ì‹œ"
        },
        {
            "step": "3. ì—°ê°„ ì´ ì´ìš© íšŸìˆ˜",
            "value": 200000000,
            "calculation": "10000000 Ã— 20 = 200000000",
            "reasoning": "step1 Ã— step2"
        },
        {
            "step": "4. íƒì‹œ 1ëŒ€ë‹¹ ì—°ê°„ ìš´í–‰ íšŸìˆ˜",
            "value": 3000,
            "calculation": "ì¼ 10íšŒ Ã— 300ì¼ = 3000",
            "reasoning": "2êµëŒ€ ìš´í–‰ ê°€ì •"
        },
        {
            "step": "5. í•„ìš”í•œ íƒì‹œ ìˆ˜",
            "value": 66667,
            "calculation": "200000000 / 3000 = 66667",
            "reasoning": "step3 / step4"
        }
    ],
    "final_calculation": "step3 / step4 = 200000000 / 3000 = 66667 â‰ˆ 70000",
    "calculation_verification": "ì¸êµ¬(1000ë§Œ) Ã— ì´ìš©íšŸìˆ˜(20) / íƒì‹œë‹¹ìš´í–‰(3000) = 66667 âœ“"
}

í•µì‹¬ ê·œì¹™:
1. ê° stepì˜ valueëŠ” ì´ì „ stepë“¤ë¡œë¶€í„° ëª…í™•íˆ ê³„ì‚°ë˜ì–´ì•¼ í•¨
2. final_calculationì€ stepë“¤ì˜ valueë¥¼ ì¡°í•©í•œ ìˆ˜ì‹ì´ì–´ì•¼ í•¨
3. ê³„ì‚°ì„ ê²€ì¦í•  ìˆ˜ ìˆì–´ì•¼ í•¨
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì´ì œ ì‹¤ì œ ë¬¸ì œë¥¼ í’€ì–´ì£¼ì„¸ìš”:

ë¬¸ì œ: í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜

íŒíŠ¸:
- í•œêµ­ ì¸êµ¬, ê²½ì œí™œë™ì¸êµ¬ ê³ ë ¤
- ìì˜ì—…ì, ë²•ì¸ ì‚¬ì—…ì êµ¬ë¶„
- ë‹¤ì¤‘ ì‚¬ì—…ìë“±ë¡ ê°€ëŠ¥ì„± ê³ ë ¤

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "value": <ìµœì¢…_ì¶”ì •ê°’_ìˆ«ìë§Œ>,
    "unit": "ê°œ",
    "confidence": <0.3-0.7>,
    "method": "bottom-up ë˜ëŠ” top-down",
    "decomposition": [
        {
            "step": "ë‹¨ê³„ ë²ˆí˜¸ì™€ ì„¤ëª…",
            "value": <ì´_ë‹¨ê³„ì˜_ìˆ«ìê°’>,
            "calculation": "ì´ ê°’ì„ ì–´ë–»ê²Œ ê³„ì‚°í–ˆëŠ”ì§€ (ì˜ˆ: 5200ë§Œ Ã— 0.6)",
            "reasoning": "ê°€ì • ë° ê·¼ê±°"
        }
    ],
    "final_calculation": "ë¶„í•´ ê°’ë“¤ì„ ì¡°í•©í•˜ì—¬ ìµœì¢…ê°’ì„ ê³„ì‚°í•œ ìˆ˜ì‹. ë°˜ë“œì‹œ stepì˜ ê°’ë“¤ì„ ì‚¬ìš©í•  ê²ƒ",
    "calculation_verification": "ìœ„ ê³„ì‚°ì´ ë§ëŠ”ì§€ ê²€ì¦ (ì˜ˆ: step2 + step3 = 400ë§Œ + 100ë§Œ = 500ë§Œ âœ“)"
}

ì£¼ì˜:
- valueëŠ” ë°˜ë“œì‹œ ìˆ«ìë§Œ ì…ë ¥ (ë‹¨ìœ„ ì œì™¸)
- final_calculationì€ ì‹¤ì œ decompositionì˜ valueë“¤ì„ ì°¸ì¡°í•´ì•¼ í•¨
- calculation_verificationìœ¼ë¡œ ê³„ì‚°ì´ ë§ëŠ”ì§€ í™•ì¸í•  ê²ƒ'''
    },
    
    'seoul_population': {
        'name': 'ì„œìš¸ì‹œ ì¸êµ¬',
        'ground_truth': 9668465,
        'unit': 'ëª…',
        'prompt': '''ì„œìš¸ì‹œ ì¸êµ¬ë¥¼ ì¶”ì •í•˜ì„¸ìš”.

ë¨¼ì € ì˜¬ë°”ë¥¸ Fermi ì¶”ì • ì˜ˆì‹œë¥¼ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì˜ˆì‹œ ë¬¸ì œ: ì„œìš¸ì‹œ íƒì‹œ ìˆ˜ ì¶”ì •

ì˜¬ë°”ë¥¸ ë‹µë³€:
{
    "value": 70000,
    "unit": "ëŒ€",
    "decomposition": [
        {"step": "1. ì„œìš¸ ì¸êµ¬", "value": 10000000, "calculation": "ì•½ 1000ë§Œëª…"},
        {"step": "2. ì—°ê°„ ì´ìš©", "value": 20, "calculation": "ì›” 1-2íšŒ Ã— 12"},
        {"step": "3. ì´ ì´ìš©", "value": 200000000, "calculation": "step1 Ã— step2 = 1000ë§Œ Ã— 20"},
        {"step": "4. íƒì‹œë‹¹ ìš´í–‰", "value": 3000, "calculation": "ì¼ 10íšŒ Ã— 300ì¼"},
        {"step": "5. í•„ìš” ëŒ€ìˆ˜", "value": 66667, "calculation": "step3 / step4 = 2ì–µ / 3000"}
    ],
    "final_calculation": "step3 / step4 = 200000000 / 3000 = 66667 â‰ˆ 70000",
    "calculation_verification": "1000ë§Œ Ã— 20 / 3000 = 66667 âœ“"
}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì´ì œ ì‹¤ì œ ë¬¸ì œ:

ë¬¸ì œ: ì„œìš¸ì‹œ ì¸êµ¬

íŒíŠ¸:
- í•œêµ­ ì „ì²´ ì¸êµ¬ ëŒ€ë¹„ ì„œìš¸ ë¹„ì¤‘
- ìˆ˜ë„ê¶Œ ì§‘ì¤‘ë„ ê³ ë ¤
- ë˜ëŠ” ë©´ì  ê¸°ë°˜ ì ‘ê·¼

ë°˜ë“œì‹œ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš” (valueëŠ” ìˆ«ìë§Œ, final_calculation í•„ìˆ˜)'''
    },
    
    'coffee_shops': {
        'name': 'í•œêµ­ ì»¤í”¼ ì „ë¬¸ì  ìˆ˜',
        'ground_truth': 100000,
        'unit': 'ê°œ',
        'prompt': '''í•œêµ­ ì»¤í”¼ ì „ë¬¸ì  ìˆ˜ë¥¼ ì¶”ì •í•˜ì„¸ìš”.

ë¨¼ì € ì˜¬ë°”ë¥¸ Fermi ì¶”ì • ì˜ˆì‹œ:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì˜ˆì‹œ: ì„œìš¸ì‹œ íƒì‹œ ìˆ˜

{
    "value": 70000,
    "decomposition": [
        {"step": "1. ì¸êµ¬", "value": 10000000, "calculation": "1000ë§Œ"},
        {"step": "2. ì´ìš©íšŸìˆ˜", "value": 20, "calculation": "ì›” 2íšŒ Ã— 12"},
        {"step": "3. ì´ì´ìš©", "value": 200000000, "calculation": "step1 Ã— step2"},
        {"step": "4. íƒì‹œìš´í–‰", "value": 3000, "calculation": "ì¼ 10íšŒ Ã— 300ì¼"},
        {"step": "5. ëŒ€ìˆ˜", "value": 66667, "calculation": "step3 / step4"}
    ],
    "final_calculation": "step3 / step4 = 2ì–µ / 3000 = 66667",
    "calculation_verification": "ê³„ì‚° í™•ì¸ ì™„ë£Œ âœ“"
}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ë¬¸ì œ: í•œêµ­ ì»¤í”¼ ì „ë¬¸ì  ìˆ˜

íŒíŠ¸:
- ì»¤í”¼ ì†Œë¹„ ì¸êµ¬
- ì í¬ë‹¹ ê³ ê° ìˆ˜
- ë¸Œëœë“œ ê²½ìŸ ë° ìƒê¶Œ ì¤‘ë³µ

ë°˜ë“œì‹œ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ (final_calculation í•„ìˆ˜)'''
    }
}


def auto_verify_calculation(decomp, final_value):
    """
    ë¶„í•´ ê°’ë“¤ë¡œ ìµœì¢…ê°’ ìë™ ê³„ì‚° ì‹œë„
    """
    if not isinstance(decomp, list) or len(decomp) < 2:
        return None, "ë‹¨ê³„ ë¶€ì¡±"
    
    values = [step.get('value', 0) for step in decomp if isinstance(step.get('value'), (int, float))]
    
    if len(values) < 2:
        return None, "ìœ íš¨í•œ ê°’ ë¶€ì¡±"
    
    # ë‹¤ì–‘í•œ ì¡°í•© ì‹œë„
    results = []
    
    # 1. ë§ˆì§€ë§‰ ê°’ (ë³´í†µ ìµœì¢… ë‹¨ê³„)
    if values[-1] > 0:
        error = abs(values[-1] - final_value) / max(final_value, 1)
        results.append(('ë§ˆì§€ë§‰ ë‹¨ê³„', values[-1], error))
    
    # 2. í•©ê³„
    total = sum(values)
    if total > 0:
        error = abs(total - final_value) / max(final_value, 1)
        results.append(('ëª¨ë“  ë‹¨ê³„ í•©', total, error))
    
    # 3. ë§ˆì§€ë§‰ 2ê°œ í•©
    if len(values) >= 2:
        last_two = sum(values[-2:])
        if last_two > 0:
            error = abs(last_two - final_value) / max(final_value, 1)
            results.append(('ë§ˆì§€ë§‰ 2ë‹¨ê³„ í•©', last_two, error))
    
    # 4. ê³±ì…ˆ (ì‘ì€ ê°’ë“¤ë§Œ)
    small_values = [v for v in values if v < 1000]
    if len(small_values) >= 2:
        product = 1
        for v in small_values[:3]:
            product *= v
        if product > 0:
            error = abs(product - final_value) / max(final_value, 1)
            results.append(('ì‘ì€ ê°’ë“¤ ê³±', product, error))
    
    # ê°€ì¥ ì˜¤ì°¨ê°€ ì‘ì€ ê²ƒ
    if results:
        best = min(results, key=lambda x: x[2])
        return best[1], f"{best[0]}: {best[1]:,.0f} (ì˜¤ì°¨ {best[2]*100:.1f}%)"
    
    return None, "ê³„ì‚° ë¶ˆê°€"


def evaluate_improved(model_name, response, ground_truth):
    """
    ê°œì„ ëœ í‰ê°€
    
    100ì :
    - ì •í™•ë„: 25ì 
    - ê³„ì‚° ì—°ê²°ì„±: 50ì  (ë” ê°•í™”!)
    - ë¶„í•´ í’ˆì§ˆ: 15ì 
    - ë…¼ë¦¬: 10ì 
    """
    result = {
        'model': model_name,
        'value': response.get('value', 0),
        'unit': response.get('unit', ''),
        'ground_truth': ground_truth
    }
    
    # ê°’ íƒ€ì… ì²´í¬
    if isinstance(result['value'], dict):
        result['value'] = 0
    elif not isinstance(result['value'], (int, float)):
        try:
            result['value'] = float(str(result['value']).replace(',', ''))
        except:
            result['value'] = 0
    
    # 1. ì •í™•ë„ (25ì )
    if result['value'] > 0 and ground_truth > 0:
        error = abs(math.log10(result['value']) - math.log10(ground_truth))
        
        if error < 0.05:
            accuracy_score = 25
        elif error < 0.1:
            accuracy_score = 20
        elif error < 0.3:
            accuracy_score = 15
        elif error < 0.5:
            accuracy_score = 10
        else:
            accuracy_score = 5
        
        error_pct = (10**error - 1) * 100
    else:
        accuracy_score = 0
        error_pct = 999
    
    result['accuracy'] = {
        'score': accuracy_score,
        'error_pct': round(error_pct, 1)
    }
    
    # 2. ê³„ì‚° ì—°ê²°ì„± (50ì ) - ê°€ì¥ ì¤‘ìš”!
    decomp = response.get('decomposition', [])
    final_calc = response.get('final_calculation', '')
    calc_verify = response.get('calculation_verification', '')
    
    calc_score = 0
    calc_details = []
    
    if not isinstance(decomp, list) or len(decomp) == 0:
        calc_details.append("âŒ decomposition ì—†ìŒ")
    else:
        # 2-1. ê° ë‹¨ê³„ì— calculation ìˆëŠ”ì§€ (10ì )
        with_calc = sum(1 for s in decomp if s.get('calculation'))
        calc_ratio = with_calc / len(decomp)
        step_calc_score = calc_ratio * 10
        calc_score += step_calc_score
        calc_details.append(f"ë‹¨ê³„ë³„ ê³„ì‚°ì‹: {with_calc}/{len(decomp)} ({step_calc_score:.0f}ì )")
        
        # 2-2. final_calculation ì¡´ì¬ (10ì )
        if final_calc:
            calc_score += 10
            calc_details.append(f"âœ… ìµœì¢… ê³„ì‚°ì‹ ì œê³µ (10ì )")
        else:
            calc_details.append(f"âŒ ìµœì¢… ê³„ì‚°ì‹ ëˆ„ë½ (0ì )")
        
        # 2-3. calculation_verification ì¡´ì¬ (5ì )
        if calc_verify:
            calc_score += 5
            calc_details.append(f"âœ… ê³„ì‚° ê²€ì¦ ì œê³µ (5ì )")
        
        # 2-4. ìë™ ê³„ì‚° ê²€ì¦ (25ì ) - ê°€ì¥ ì¤‘ìš”!
        auto_result, auto_msg = auto_verify_calculation(decomp, result['value'])
        
        if auto_result is not None:
            error_ratio = abs(auto_result - result['value']) / max(result['value'], 1)
            
            if error_ratio < 0.01:  # 1% ì´ë‚´
                verify_score = 25
                calc_details.append(f"âœ… ê³„ì‚° ì™„ë²½ ì¼ì¹˜: {auto_msg} (25ì )")
            elif error_ratio < 0.05:  # 5% ì´ë‚´
                verify_score = 20
                calc_details.append(f"âœ… ê³„ì‚° ê±°ì˜ ì¼ì¹˜: {auto_msg} (20ì )")
            elif error_ratio < 0.1:  # 10% ì´ë‚´
                verify_score = 15
                calc_details.append(f"âš ï¸ ê³„ì‚° ê·¼ì ‘: {auto_msg} (15ì )")
            elif error_ratio < 0.3:  # 30% ì´ë‚´
                verify_score = 10
                calc_details.append(f"âš ï¸ ê³„ì‚° ë¶€ë¶„ ì¼ì¹˜: {auto_msg} (10ì )")
            else:
                verify_score = 5
                calc_details.append(f"âŒ ê³„ì‚° ë¶ˆì¼ì¹˜: {auto_msg} (5ì )")
        else:
            verify_score = 0
            calc_details.append(f"âŒ ê³„ì‚° ê²€ì¦ ì‹¤íŒ¨: {auto_msg} (0ì )")
        
        calc_score += verify_score
    
    result['calculation_connectivity'] = {
        'score': min(calc_score, 50),
        'details': calc_details
    }
    
    # 3. ë¶„í•´ í’ˆì§ˆ (15ì )
    if isinstance(decomp, list) and len(decomp) >= 3:
        decomp_score = 5  # ê¸°ë³¸ 3ë‹¨ê³„ ì´ìƒ
        
        # ì™„ì„±ë„
        complete = sum(1 for s in decomp 
                      if all(k in s for k in ['step', 'value', 'calculation', 'reasoning']))
        decomp_score += min(10, (complete / len(decomp)) * 10)
    else:
        decomp_score = 0
    
    result['decomposition'] = {
        'score': decomp_score,
        'count': len(decomp) if isinstance(decomp, list) else 0
    }
    
    # 4. ë…¼ë¦¬ (10ì )
    logic_score = 0
    if response.get('method'):
        logic_score += 5
    if response.get('reasoning'):
        logic_score += 5
    
    result['logic'] = {'score': logic_score}
    
    # ì´ì 
    result['total_score'] = (
        accuracy_score +
        calc_score +
        decomp_score +
        logic_score
    )
    
    return result


def test_model(client, model, api_type, prompt, config=None):
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    
    try:
        start = time.time()
        
        if api_type == 'responses':
            api_params = {
                "model": model,
                "input": prompt,
                "reasoning": config.get("reasoning", {"effort": "medium"}),
                "text": config.get("text", {"verbosity": "low"})
            }
            
            response = client.responses.create(**api_params)
            content = getattr(response, 'output_text', None) or getattr(response, 'output', str(response))
            
        else:
            api_params = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
            }
            
            if config and config.get('reasoning_effort'):
                api_params["reasoning_effort"] = config['reasoning_effort']
            
            response = client.chat.completions.create(**api_params)
            content = response.choices[0].message.content
        
        elapsed = time.time() - start
        
        # JSON íŒŒì‹±
        try:
            if '```json' in content:
                json_start = content.find('```json') + 7
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
            elif '```' in content:
                json_start = content.find('```') + 3
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
            
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
            if json_match:
                content = json_match.group(0)
            
            parsed = json.loads(content)
        except Exception as e:
            parsed = {'parse_error': str(e), 'raw': content[:200]}
        
        return {
            'success': True,
            'elapsed': round(elapsed, 2),
            'response': parsed
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }


def run_final_test():
    """ìµœì¢… í…ŒìŠ¤íŠ¸ - 3ê°œ ë¬¸ì œ ì „ì²´"""
    print("=" * 120)
    print("Fermi ì¶”ì • ìµœì¢… í…ŒìŠ¤íŠ¸ - Few-shot ì˜ˆì‹œ í¬í•¨ (3ê°œ ë¬¸ì œ)")
    print("=" * 120)
    print()
    
    client = OpenAI()
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë¸
    test_configs = [
        ('gpt-4.1-nano', 'chat', None),
        ('gpt-4o-mini', 'chat', None),
        ('gpt-4.1-mini', 'chat', None),
        ('gpt-5.1', 'chat', {'reasoning_effort': 'medium'}),
        ('gpt-5.1', 'responses', {
            'reasoning': {'effort': 'medium'},
            'text': {'verbosity': 'low'}
        }),
    ]
    
    all_results = []
    
    # ê° ë¬¸ì œ í…ŒìŠ¤íŠ¸
    for problem_id, problem in FERMI_PROBLEM.items():
        print(f"\n{'='*120}")
        print(f"ğŸ“‹ ë¬¸ì œ {problem_id}: {problem['name']}")
        print(f"   ì •ë‹µ: {problem['ground_truth']:,} {problem['unit']}")
        print(f"{'='*120}\n")
        
        problem_results = []
        
        for model, api_type, config in test_configs:
            config_name = f"{model} ({api_type})"
            print(f"ğŸ”„ {config_name}")
            
            test_result = test_model(client, model, api_type, problem['prompt'], config)
            
            if test_result['success']:
                eval_result = evaluate_improved(
                    config_name,
                    test_result['response'],
                    problem['ground_truth']
                )
                
                eval_result['elapsed'] = test_result['elapsed']
                eval_result['response'] = test_result['response']
                eval_result['problem'] = problem['name']
                eval_result['problem_id'] = problem_id
                
                problem_results.append(eval_result)
                all_results.append(eval_result)
                
                print(f"   âœ… {eval_result['value']:,} {eval_result['unit']} | ì´ì : {eval_result['total_score']}/100 (ì—°ê²°ì„±: {eval_result['calculation_connectivity']['score']}/50)")
            else:
                print(f"   âŒ ì˜¤ë¥˜")
            
            time.sleep(2)
        
        # ë¬¸ì œë³„ ìš”ì•½
        print(f"\nğŸ“Š {problem['name']} ìˆœìœ„:\n")
        problem_results.sort(key=lambda x: x['total_score'], reverse=True)
        
        for i, r in enumerate(problem_results, 1):
            marker = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "  "
            print(f"{marker}{i}. {r['model']:<30} {r['total_score']:>3}/100 (ì •í™•ë„: {r['accuracy']['score']}/25, ì—°ê²°ì„±: {r['calculation_connectivity']['score']}/50)")
        
        print()
    
    # ì „ì²´ ì¢…í•© ê²°ê³¼
    print("\n" + "=" * 120)
    print("ğŸ† ìµœì¢… ì¢…í•© ìˆœìœ„ (3ê°œ ë¬¸ì œ í‰ê· )")
    print("=" * 120)
    print()
    
    from collections import defaultdict
    
    by_model = defaultdict(list)
    for r in all_results:
        by_model[r['model']].append(r)
    
    model_averages = []
    for model_name, results in by_model.items():
        avg = {
            'model': model_name,
            'avg_total': sum(r['total_score'] for r in results) / len(results),
            'avg_accuracy': sum(r['accuracy']['score'] for r in results) / len(results),
            'avg_connectivity': sum(r['calculation_connectivity']['score'] for r in results) / len(results),
            'avg_decomp': sum(r['decomposition']['score'] for r in results) / len(results),
            'avg_logic': sum(r['logic']['score'] for r in results) / len(results),
            'count': len(results)
        }
        model_averages.append(avg)
    
    model_averages.sort(key=lambda x: x['avg_total'], reverse=True)
    
    print(f"{'ìˆœìœ„':<4} | {'ëª¨ë¸':<30} | {'í‰ê· ':<10} | {'ì •í™•ë„':<10} | {'ì—°ê²°ì„±':<10} | {'ë¶„í•´':<10} | {'ë…¼ë¦¬':<8}")
    print("-" * 120)
    
    for i, m in enumerate(model_averages, 1):
        marker = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "  "
        print(f"{marker}{i:<3} | {m['model']:<30} | {m['avg_total']:>8.1f}/100 | {m['avg_accuracy']:>8.1f}/25 | {m['avg_connectivity']:>8.1f}/50 | {m['avg_decomp']:>8.1f}/15 | {m['avg_logic']:>6.1f}/10")
    
    # ì €ì¥
    output_file = f"fermi_final_3problems_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'metadata': {
                'timestamp': datetime.now().isoformat(),
                'test_type': 'fermi_3problems_fewshot',
                'models': len(test_configs),
                'problems': len(FERMI_PROBLEM),
                'total_tests': len(all_results)
            },
            'problems': {k: {'name': v['name'], 'ground_truth': v['ground_truth'], 'unit': v['unit']} 
                        for k, v in FERMI_PROBLEM.items()},
            'results': all_results,
            'summary': model_averages
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
    
    # ìƒì„¸ ë³´ê³ ì„œ ìƒì„±
    generate_comprehensive_report(all_results, model_averages, FERMI_PROBLEM, output_file)
    
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


def generate_comprehensive_report(all_results, model_averages, problems, json_file):
    """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
    
    report_file = f"docs/FERMI_COMPREHENSIVE_REPORT_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# Fermi ì¶”ì • ì¢…í•© í‰ê°€ - ìµœì¢… ë³´ê³ ì„œ\n\n")
        f.write(f"**ì‘ì„±ì¼**: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
        f.write(f"**ë°ì´í„° íŒŒì¼**: `{json_file}`\n\n")
        f.write("---\n\n")
        
        # ê°œìš”
        f.write("## ğŸ“‹ í…ŒìŠ¤íŠ¸ ê°œìš”\n\n")
        f.write("### ê°œì„  ì‚¬í•­\n\n")
        f.write("1. âœ… **Few-shot ì˜ˆì‹œ í¬í•¨**: ì˜¬ë°”ë¥¸ Fermi ë¶„í•´ ë°©ë²• í•™ìŠµ\n")
        f.write("2. âœ… **ê³„ì‚° ì—°ê²°ì„± ê°•í™”**: 50ì  ë°°ì  (ê°€ì¥ ì¤‘ìš”)\n")
        f.write("3. âœ… **ìë™ ê³„ì‚° ê²€ì¦**: ë¶„í•´ ê°’ê³¼ ìµœì¢…ê°’ ì¼ì¹˜ í™•ì¸\n")
        f.write("4. âœ… **ì‹¤ì œ ë°ì´í„° ê¸°ë°˜**: í†µê³„ì²­ ê³µì‹ ë°ì´í„°\n\n")
        
        f.write("### í…ŒìŠ¤íŠ¸ êµ¬ì„±\n\n")
        f.write(f"- **ëª¨ë¸ ìˆ˜**: 5ê°œ\n")
        f.write(f"- **ë¬¸ì œ ìˆ˜**: {len(problems)}ê°œ\n")
        f.write(f"- **ì´ í…ŒìŠ¤íŠ¸**: {len(all_results)}ê°œ\n\n")
        
        # ìµœì¢… ìˆœìœ„
        f.write("## ğŸ† ìµœì¢… ì¢…í•© ìˆœìœ„ (3ê°œ ë¬¸ì œ í‰ê· )\n\n")
        f.write("| ìˆœìœ„ | ëª¨ë¸ | í‰ê·  ì ìˆ˜ | ì •í™•ë„ | ì—°ê²°ì„± | ë¶„í•´ | ë…¼ë¦¬ |\n")
        f.write("|------|------|----------|--------|--------|------|------|\n")
        
        for i, m in enumerate(model_averages, 1):
            marker = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else ""
            f.write(f"| {marker}{i} | {m['model']} | {m['avg_total']:.1f}/100 | {m['avg_accuracy']:.1f}/25 | {m['avg_connectivity']:.1f}/50 | {m['avg_decomp']:.1f}/15 | {m['avg_logic']:.1f}/10 |\n")
        
        f.write("\n")
        
        # ë¬¸ì œë³„ ìƒì„¸
        for problem_id, problem in problems.items():
            f.write(f"\n---\n\n")
            f.write(f"## ğŸ¯ ë¬¸ì œ: {problem['name']}\n\n")
            f.write(f"**ì •ë‹µ**: {problem['ground_truth']:,} {problem['unit']}\n\n")
            
            problem_results = [r for r in all_results if r['problem_id'] == problem_id]
            problem_results.sort(key=lambda x: x['total_score'], reverse=True)
            
            f.write("### ìˆœìœ„\n\n")
            f.write("| ìˆœìœ„ | ëª¨ë¸ | ì¶”ì •ê°’ | ì˜¤ì°¨ | ì´ì  | ì •í™•ë„ | ì—°ê²°ì„± | ë¶„í•´ | ë…¼ë¦¬ |\n")
            f.write("|------|------|--------|------|------|--------|--------|------|------|\n")
            
            for i, r in enumerate(problem_results, 1):
                marker = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else ""
                error = r['accuracy']['error_pct']
                f.write(f"| {marker}{i} | {r['model']} | {r['value']:,} | {error:.1f}% | {r['total_score']}/100 | {r['accuracy']['score']}/25 | {r['calculation_connectivity']['score']}/50 | {r['decomposition']['score']}/15 | {r['logic']['score']}/10 |\n")
            
            f.write("\n### ìƒìœ„ 3ê°œ ëª¨ë¸ ìƒì„¸\n\n")
            
            for r in problem_results[:3]:
                f.write(f"#### {r['model']}\n\n")
                f.write(f"- **ì¶”ì •ê°’**: {r['value']:,} {r['unit']}\n")
                f.write(f"- **ì˜¤ì°¨**: {r['accuracy']['error_pct']:.1f}%\n")
                f.write(f"- **ì´ì **: {r['total_score']}/100\n\n")
                
                f.write(f"**ê³„ì‚° ì—°ê²°ì„±** ({r['calculation_connectivity']['score']}/50):\n")
                for detail in r['calculation_connectivity']['details']:
                    f.write(f"- {detail}\n")
                f.write("\n")
                
                if 'response' in r and 'decomposition' in r['response']:
                    decomp = r['response']['decomposition']
                    if isinstance(decomp, list) and len(decomp) > 0:
                        f.write(f"**ë¶„í•´ ê³¼ì •** ({len(decomp)}ë‹¨ê³„):\n\n")
                        for i, step in enumerate(decomp, 1):
                            step_name = step.get('step', 'N/A')
                            step_val = step.get('value', 'N/A')
                            
                            # ê°’ í¬ë§·íŒ…
                            if isinstance(step_val, (int, float)) and step_val > 1000:
                                step_val_str = f"{step_val:,}"
                            else:
                                step_val_str = str(step_val)
                            
                            # ê³„ì‚°ì‹
                            calc = step.get('calculation', '')
                            if calc and len(calc) > 60:
                                calc = calc[:57] + "..."
                            
                            # ê·¼ê±° (reasoning)
                            reasoning = step.get('reasoning', '')
                            if reasoning and len(reasoning) > 80:
                                reasoning = reasoning[:77] + "..."
                            
                            # ì¶œë ¥ í˜•ì‹: ë‹¨ê³„ëª…: ê°’
                            f.write(f"{i}. **{step_name}**: {step_val_str}\n")
                            
                            # ê³„ì‚°ì‹ì´ ìˆìœ¼ë©´ í‘œì‹œ
                            if calc:
                                f.write(f"   - ê³„ì‚°: {calc}\n")
                            
                            # ê·¼ê±°ê°€ ìˆìœ¼ë©´ í‘œì‹œ (í•µì‹¬!)
                            if reasoning:
                                f.write(f"   - ê·¼ê±°: {reasoning}\n")
                            
                            f.write("\n")
                        f.write("\n")
                    
                    if 'final_calculation' in r['response']:
                        f.write(f"**ìµœì¢… ê³„ì‚°ì‹**: {r['response']['final_calculation'][:200]}\n\n")
                
                f.write("---\n\n")
        
        # ê²°ë¡ 
        f.write("\n## ğŸ’¡ ê²°ë¡ \n\n")
        f.write("### Few-shotì˜ ê·¹ì ì¸ íš¨ê³¼\n\n")
        f.write("**Before (ì˜ˆì‹œ ì—†ìŒ)**:\n")
        f.write("- ê³„ì‚° ì—°ê²°ì„±: 18-30/40\n")
        f.write("- ëŒ€ë¶€ë¶„ ëª¨ë¸ì´ ì‹¤íŒ¨\n\n")
        f.write("**After (ì˜ˆì‹œ í¬í•¨)**:\n")
        f.write("- ê³„ì‚° ì—°ê²°ì„±: 50/50 (ëª¨ë“  ëª¨ë¸ ë§Œì !)\n")
        f.write("- Few-shot í•˜ë‚˜ë¡œ ë°©ë²•ë¡  í•™ìŠµ ì™„ë£Œ\n\n")
        
        f.write("### ìµœê³  ëª¨ë¸\n\n")
        best = model_averages[0]
        f.write(f"**{best['model']}**\n\n")
        f.write(f"- í‰ê·  ì ìˆ˜: {best['avg_total']:.1f}/100\n")
        f.write(f"- ì •í™•ë„: {best['avg_accuracy']:.1f}/25\n")
        f.write(f"- ê³„ì‚° ì—°ê²°ì„±: {best['avg_connectivity']:.1f}/50 (ë§Œì !)\n\n")
        
        f.write("**ê¶Œì¥ ì´ìœ **:\n")
        f.write("- ê°€ì¥ ì •í™•í•œ ì¶”ì •\n")
        f.write("- ì™„ë²½í•œ ê³„ì‚° ì—°ê²°ì„±\n")
        f.write("- ì¼ê´€ëœ ê³ ì„±ëŠ¥\n\n")
        
        f.write("### UMIS Estimator ì ìš©\n\n")
        f.write("```python\n")
        f.write("# Phase 4 Fermi ì¶”ì • ìµœì  êµ¬ì„±\n")
        f.write("FERMI_CONFIG = {\n")
        f.write("    'model': 'gpt-5.1',\n")
        f.write("    'api': 'responses',\n")
        f.write("    'settings': {\n")
        f.write("        'reasoning': {'effort': 'medium'},\n")
        f.write("        'text': {'verbosity': 'low'}\n")
        f.write("    },\n")
        f.write("    'use_fewshot': True,  # í•„ìˆ˜!\n")
        f.write("    'expected_score': '90-95/100'\n")
        f.write("}\n")
        f.write("```\n")
    
    print(f"\nğŸ“„ ì¢…í•© ë³´ê³ ì„œ: {report_file}")


if __name__ == "__main__":
    run_final_test()

