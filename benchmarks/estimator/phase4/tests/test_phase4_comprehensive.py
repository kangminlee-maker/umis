#!/usr/bin/env python3
"""
Phase 4 ì¢…í•© ëª¨ë¸ í…ŒìŠ¤íŠ¸ - Few-shot Fermi ì¶”ì •
ì‹¤ì œ í†µê³„ ê¸°ë°˜ 3ê°œ ë¬¸ì œ (í•œêµ­ ì‚¬ì—…ì ìˆ˜, ì„œìš¸ ì¸êµ¬, ì»¤í”¼ì „ë¬¸ì )
"""

import os
import json
import time
import math
import re
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()


def get_phase4_scenarios():
    """Phase 4 Fermi ì‹œë‚˜ë¦¬ì˜¤ - Few-shot ì˜ˆì‹œ í¬í•¨"""
    
    # Few-shot ì˜ˆì‹œ
    fewshot_example = '''
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì˜¬ë°”ë¥¸ Fermi ì¶”ì • ì˜ˆì‹œ: ì„œìš¸ì‹œ íƒì‹œ ìˆ˜

{
    "value": 70000,
    "unit": "ëŒ€",
    "confidence": 0.6,
    "method": "bottom-up",
    "decomposition": [
        {
            "step": "1. ì„œìš¸ ì¸êµ¬",
            "value": 10000000,
            "calculation": "ì•½ 1000ë§Œëª…ìœ¼ë¡œ ê°€ì •",
            "reasoning": "ì„œìš¸ í†µê³„ ê¸°ì¤€"
        },
        {
            "step": "2. 1ì¸ë‹¹ ì—°ê°„ íƒì‹œ ì´ìš© íšŸìˆ˜",
            "value": 20,
            "calculation": "ì›” 1-2íšŒ Ã— 12ê°œì›” = 20íšŒ",
            "reasoning": "ëŒ€ì¤‘êµí†µ ì¤‘ì‹¬ ë„ì‹œ"
        },
        {
            "step": "3. ì—°ê°„ ì´ ì´ìš© íšŸìˆ˜",
            "value": 200000000,
            "calculation": "10000000 Ã— 20 = 200000000",
            "reasoning": "step1 Ã— step2"
        },
        {
            "step": "4. íƒì‹œ 1ëŒ€ë‹¹ ì—°ê°„ ìš´í–‰ íšŸìˆ˜",
            "value": 3000,
            "calculation": "ì¼ 10íšŒ Ã— 300ì¼ = 3000",
            "reasoning": "2êµëŒ€ ìš´í–‰ ê°€ì •"
        },
        {
            "step": "5. í•„ìš”í•œ íƒì‹œ ìˆ˜",
            "value": 66667,
            "calculation": "200000000 / 3000 = 66667",
            "reasoning": "step3 / step4"
        }
    ],
    "final_calculation": "step3 / step4 = 200000000 / 3000 = 66667 â‰ˆ 70000",
    "calculation_verification": "ì¸êµ¬(1000ë§Œ) Ã— ì´ìš©íšŸìˆ˜(20) / íƒì‹œë‹¹ìš´í–‰(3000) = 66667 âœ“"
}

í•µì‹¬ ê·œì¹™:
1. ê° stepì˜ valueëŠ” ì´ì „ stepë“¤ë¡œë¶€í„° ëª…í™•íˆ ê³„ì‚°ë˜ì–´ì•¼ í•¨
2. final_calculationì€ stepë“¤ì˜ valueë¥¼ ì¡°í•©í•œ ìˆ˜ì‹ì´ì–´ì•¼ í•¨
3. ê³„ì‚°ì„ ê²€ì¦í•  ìˆ˜ ìˆì–´ì•¼ í•¨
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
'''
    
    return [
        {
            'id': 'phase4_korean_businesses',
            'name': 'Phase 4 - í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜',
            'phase': 4,
            'prompt': f'''{fewshot_example}

ì´ì œ ì‹¤ì œ ë¬¸ì œë¥¼ í’€ì–´ì£¼ì„¸ìš”:

ë¬¸ì œ: í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜ë¥¼ ì¶”ì •í•˜ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ê° ë¶„í•´ ë‹¨ê³„ì˜ ìˆ«ìë“¤ì´ ìµœì¢… ì¶”ì •ê°’ìœ¼ë¡œ ì–´ë–»ê²Œ ê³„ì‚°ë˜ëŠ”ì§€ ëª…í™•íˆ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.

íŒíŠ¸:
- í•œêµ­ ì¸êµ¬, ê²½ì œí™œë™ì¸êµ¬ ê³ ë ¤
- ìì˜ì—…ì, ë²•ì¸ ì‚¬ì—…ì êµ¬ë¶„
- ë‹¤ì¤‘ ì‚¬ì—…ìë“±ë¡ ê°€ëŠ¥ì„± ê³ ë ¤

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "value": <ìµœì¢…_ì¶”ì •ê°’_ìˆ«ìë§Œ>,
    "unit": "ê°œ",
    "confidence": <0.3-0.7>,
    "method": "bottom-up ë˜ëŠ” top-down",
    "decomposition": [
        {{
            "step": "ë‹¨ê³„ ë²ˆí˜¸ì™€ ì„¤ëª…",
            "value": <ì´_ë‹¨ê³„ì˜_ìˆ«ìê°’>,
            "calculation": "ì´ ê°’ì„ ì–´ë–»ê²Œ ê³„ì‚°í–ˆëŠ”ì§€ (ì˜ˆ: 5200ë§Œ Ã— 0.6)",
            "reasoning": "ê°€ì • ë° ê·¼ê±°"
        }}
    ],
    "final_calculation": "ë¶„í•´ ê°’ë“¤ì„ ì¡°í•©í•˜ì—¬ ìµœì¢…ê°’ì„ ê³„ì‚°í•œ ìˆ˜ì‹. ë°˜ë“œì‹œ stepì˜ ê°’ë“¤ì„ ì‚¬ìš©í•  ê²ƒ",
    "calculation_verification": "ìœ„ ê³„ì‚°ì´ ë§ëŠ”ì§€ ê²€ì¦ (ì˜ˆ: step2 + step3 = 400ë§Œ + 100ë§Œ = 500ë§Œ âœ“)"
}}

ì£¼ì˜:
- valueëŠ” ë°˜ë“œì‹œ ìˆ«ìë§Œ ì…ë ¥ (ë‹¨ìœ„ ì œì™¸)
- final_calculationì€ ì‹¤ì œ decompositionì˜ valueë“¤ì„ ì°¸ì¡°í•´ì•¼ í•¨
- calculation_verificationìœ¼ë¡œ ê³„ì‚°ì´ ë§ëŠ”ì§€ í™•ì¸í•  ê²ƒ''',
            'expected_value': 7837000,
            'expected_unit': 'ê°œ',
        },
        {
            'id': 'phase4_seoul_population',
            'name': 'Phase 4 - ì„œìš¸ì‹œ ì¸êµ¬',
            'phase': 4,
            'prompt': f'''{fewshot_example}

ì´ì œ ì‹¤ì œ ë¬¸ì œ:

ë¬¸ì œ: ì„œìš¸ì‹œ ì¸êµ¬ë¥¼ ì¶”ì •í•˜ì„¸ìš”.

íŒíŠ¸:
- í•œêµ­ ì „ì²´ ì¸êµ¬ ëŒ€ë¹„ ì„œìš¸ ë¹„ì¤‘
- ìˆ˜ë„ê¶Œ ì§‘ì¤‘ë„ ê³ ë ¤
- ë˜ëŠ” ë©´ì  ê¸°ë°˜ ì ‘ê·¼

ë°˜ë“œì‹œ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš” (valueëŠ” ìˆ«ìë§Œ, final_calculation í•„ìˆ˜)''',
            'expected_value': 9668465,
            'expected_unit': 'ëª…',
        },
        {
            'id': 'phase4_coffee_shops',
            'name': 'Phase 4 - í•œêµ­ ì»¤í”¼ ì „ë¬¸ì  ìˆ˜',
            'phase': 4,
            'prompt': f'''ë¨¼ì € ì˜¬ë°”ë¥¸ Fermi ì¶”ì • ì˜ˆì‹œ:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì˜ˆì‹œ: ì„œìš¸ì‹œ íƒì‹œ ìˆ˜

{{
    "value": 70000,
    "decomposition": [
        {{"step": "1. ì¸êµ¬", "value": 10000000, "calculation": "1000ë§Œ"}},
        {{"step": "2. ì´ìš©íšŸìˆ˜", "value": 20, "calculation": "ì›” 2íšŒ Ã— 12"}},
        {{"step": "3. ì´ì´ìš©", "value": 200000000, "calculation": "step1 Ã— step2"}},
        {{"step": "4. íƒì‹œìš´í–‰", "value": 3000, "calculation": "ì¼ 10íšŒ Ã— 300ì¼"}},
        {{"step": "5. ëŒ€ìˆ˜", "value": 66667, "calculation": "step3 / step4"}}
    ],
    "final_calculation": "step3 / step4 = 2ì–µ / 3000 = 66667",
    "calculation_verification": "ê³„ì‚° í™•ì¸ ì™„ë£Œ âœ“"
}}
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ë¬¸ì œ: í•œêµ­ ì»¤í”¼ ì „ë¬¸ì  ìˆ˜ë¥¼ ì¶”ì •í•˜ì„¸ìš”.

íŒíŠ¸:
- ì»¤í”¼ ì†Œë¹„ ì¸êµ¬
- ì í¬ë‹¹ ê³ ê° ìˆ˜
- ë¸Œëœë“œ ê²½ìŸ ë° ìƒê¶Œ ì¤‘ë³µ

ë°˜ë“œì‹œ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ (final_calculation í•„ìˆ˜)''',
            'expected_value': 100000,
            'expected_unit': 'ê°œ',
        }
    ]


def auto_verify_calculation(decomp, final_value):
    """ë¶„í•´ ê°’ë“¤ë¡œ ìµœì¢…ê°’ ìë™ ê³„ì‚° ì‹œë„"""
    if not isinstance(decomp, list) or len(decomp) < 2:
        return None, "ë‹¨ê³„ ë¶€ì¡±"
    
    values = [step.get('value', 0) for step in decomp if isinstance(step.get('value'), (int, float))]
    
    if len(values) < 2:
        return None, "ìœ íš¨í•œ ê°’ ë¶€ì¡±"
    
    # ë‹¤ì–‘í•œ ì¡°í•© ì‹œë„
    results = []
    
    # 1. ë§ˆì§€ë§‰ ê°’ (ë³´í†µ ìµœì¢… ë‹¨ê³„)
    if values[-1] > 0:
        error = abs(values[-1] - final_value) / max(final_value, 1)
        results.append(('ë§ˆì§€ë§‰ ë‹¨ê³„', values[-1], error))
    
    # 2. í•©ê³„
    total = sum(values)
    if total > 0:
        error = abs(total - final_value) / max(final_value, 1)
        results.append(('ëª¨ë“  ë‹¨ê³„ í•©', total, error))
    
    # 3. ë§ˆì§€ë§‰ 2ê°œ í•©
    if len(values) >= 2:
        last_two = sum(values[-2:])
        if last_two > 0:
            error = abs(last_two - final_value) / max(final_value, 1)
            results.append(('ë§ˆì§€ë§‰ 2ë‹¨ê³„ í•©', last_two, error))
    
    # ê°€ì¥ ì˜¤ì°¨ê°€ ì‘ì€ ê²ƒ
    if results:
        best = min(results, key=lambda x: x[2])
        return best[1], f"{best[0]}: {best[1]:,.0f} (ì˜¤ì°¨ {best[2]*100:.1f}%)"
    
    return None, "ê³„ì‚° ë¶ˆê°€"


def evaluate_fermi_response(model_name, response, expected_value):
    """
    Fermi ì¶”ì • í‰ê°€
    
    100ì  ë§Œì :
    - ì •í™•ë„: 25ì 
    - ê³„ì‚° ì—°ê²°ì„±: 50ì  (ê°€ì¥ ì¤‘ìš”!)
    - ë¶„í•´ í’ˆì§ˆ: 15ì 
    - ë…¼ë¦¬: 10ì 
    """
    result = {
        'model': model_name,
        'value': response.get('value', 0),
        'unit': response.get('unit', ''),
        'expected_value': expected_value
    }
    
    # ê°’ íƒ€ì… ì²´í¬
    if isinstance(result['value'], dict):
        result['value'] = 0
    elif not isinstance(result['value'], (int, float)):
        try:
            result['value'] = float(str(result['value']).replace(',', ''))
        except:
            result['value'] = 0
    
    # 1. ì •í™•ë„ (25ì )
    if result['value'] > 0 and expected_value > 0:
        error = abs(math.log10(result['value']) - math.log10(expected_value))
        
        if error < 0.05:
            accuracy_score = 25
        elif error < 0.1:
            accuracy_score = 20
        elif error < 0.3:
            accuracy_score = 15
        elif error < 0.5:
            accuracy_score = 10
        else:
            accuracy_score = 5
        
        error_pct = (10**error - 1) * 100
    else:
        accuracy_score = 0
        error_pct = 999
    
    result['accuracy'] = {
        'score': accuracy_score,
        'error_pct': round(error_pct, 1)
    }
    
    # 2. ê³„ì‚° ì—°ê²°ì„± (50ì )
    decomp = response.get('decomposition', [])
    final_calc = response.get('final_calculation', '')
    calc_verify = response.get('calculation_verification', '')
    
    calc_score = 0
    calc_details = []
    
    if not isinstance(decomp, list) or len(decomp) == 0:
        calc_details.append("âŒ decomposition ì—†ìŒ")
    else:
        # 2-1. ê° ë‹¨ê³„ì— calculation ìˆëŠ”ì§€ (10ì )
        with_calc = sum(1 for s in decomp if s.get('calculation'))
        calc_ratio = with_calc / len(decomp)
        step_calc_score = calc_ratio * 10
        calc_score += step_calc_score
        calc_details.append(f"ë‹¨ê³„ë³„ ê³„ì‚°ì‹: {with_calc}/{len(decomp)} ({step_calc_score:.0f}ì )")
        
        # 2-2. final_calculation ì¡´ì¬ (10ì )
        if final_calc:
            calc_score += 10
            calc_details.append(f"âœ… ìµœì¢… ê³„ì‚°ì‹ ì œê³µ (10ì )")
        else:
            calc_details.append(f"âŒ ìµœì¢… ê³„ì‚°ì‹ ëˆ„ë½ (0ì )")
        
        # 2-3. calculation_verification ì¡´ì¬ (5ì )
        if calc_verify:
            calc_score += 5
            calc_details.append(f"âœ… ê³„ì‚° ê²€ì¦ ì œê³µ (5ì )")
        
        # 2-4. ìë™ ê³„ì‚° ê²€ì¦ (25ì )
        auto_result, auto_msg = auto_verify_calculation(decomp, result['value'])
        
        if auto_result is not None:
            error_ratio = abs(auto_result - result['value']) / max(result['value'], 1)
            
            if error_ratio < 0.01:
                verify_score = 25
                calc_details.append(f"âœ… ê³„ì‚° ì™„ë²½ ì¼ì¹˜: {auto_msg} (25ì )")
            elif error_ratio < 0.05:
                verify_score = 20
                calc_details.append(f"âœ… ê³„ì‚° ê±°ì˜ ì¼ì¹˜: {auto_msg} (20ì )")
            elif error_ratio < 0.1:
                verify_score = 15
                calc_details.append(f"âš ï¸ ê³„ì‚° ê·¼ì ‘: {auto_msg} (15ì )")
            elif error_ratio < 0.3:
                verify_score = 10
                calc_details.append(f"âš ï¸ ê³„ì‚° ë¶€ë¶„ ì¼ì¹˜: {auto_msg} (10ì )")
            else:
                verify_score = 5
                calc_details.append(f"âŒ ê³„ì‚° ë¶ˆì¼ì¹˜: {auto_msg} (5ì )")
        else:
            verify_score = 0
            calc_details.append(f"âŒ ê³„ì‚° ê²€ì¦ ì‹¤íŒ¨: {auto_msg} (0ì )")
        
        calc_score += verify_score
    
    result['calculation_connectivity'] = {
        'score': min(calc_score, 50),
        'details': calc_details
    }
    
    # 3. ë¶„í•´ í’ˆì§ˆ (15ì )
    if isinstance(decomp, list) and len(decomp) >= 3:
        decomp_score = 5
        complete = sum(1 for s in decomp 
                      if all(k in s for k in ['step', 'value', 'calculation', 'reasoning']))
        decomp_score += min(10, (complete / len(decomp)) * 10)
    else:
        decomp_score = 0
    
    result['decomposition'] = {
        'score': decomp_score,
        'count': len(decomp) if isinstance(decomp, list) else 0
    }
    
    # 4. ë…¼ë¦¬ (10ì )
    logic_score = 0
    if response.get('method'):
        logic_score += 5
    if response.get('reasoning'):
        logic_score += 5
    
    result['logic'] = {'score': logic_score}
    
    # ì´ì 
    result['total_score'] = (
        accuracy_score +
        calc_score +
        decomp_score +
        logic_score
    )
    
    return result


def test_model_responses_api(client, model_name, scenario, reasoning_effort='medium'):
    """Responses APIë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    
    try:
        start = time.time()
        
        api_params = {
            "model": model_name,
            "input": scenario['prompt'],
            "reasoning": {"effort": reasoning_effort},
            "text": {"verbosity": "low"}
        }
        
        response = client.responses.create(**api_params)
        content = getattr(response, 'output_text', None) or getattr(response, 'output', str(response))
        
        elapsed = time.time() - start
        
        # JSON íŒŒì‹±
        try:
            if '```json' in content:
                json_start = content.find('```json') + 7
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
            elif '```' in content:
                json_start = content.find('```') + 3
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
            
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
            if json_match:
                content = json_match.group(0)
            
            parsed = json.loads(content)
        except Exception as e:
            parsed = {'parse_error': str(e), 'raw': content[:200]}
        
        return {
            'success': True,
            'elapsed': round(elapsed, 2),
            'response': parsed
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }


def run_phase4_comprehensive_test():
    """Phase 4 ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 120)
    print("Phase 4 ì¢…í•© ëª¨ë¸ í…ŒìŠ¤íŠ¸ - Few-shot Fermi ì¶”ì •")
    print("=" * 120)
    print()
    
    client = OpenAI()
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë¸ (Tier 1, 2 + gpt-5-pro, gpt-5.1)
    test_config = [
        # Tier 1 (o-series)
        {'model': 'o1', 'effort': 'high', 'tier': 'Tier 1'},
        {'model': 'o1-2024-12-17', 'effort': 'high', 'tier': 'Tier 1'},
        {'model': 'o1-pro', 'effort': 'high', 'tier': 'Pro'},
        {'model': 'o1-pro-2025-03-19', 'effort': 'high', 'tier': 'Pro'},
        {'model': 'o3', 'effort': 'high', 'tier': 'Tier 1'},
        {'model': 'o3-2025-04-16', 'effort': 'high', 'tier': 'Tier 1'},
        {'model': 'o3-mini', 'effort': 'high', 'tier': 'Tier 1'},
        {'model': 'o3-mini-2025-01-31', 'effort': 'high', 'tier': 'Tier 1'},
        {'model': 'o4-mini', 'effort': 'high', 'tier': 'Tier 1'},
        {'model': 'o4-mini-2025-04-16', 'effort': 'high', 'tier': 'Tier 1'},
        
        # Tier 2 (gpt-4.1)
        {'model': 'gpt-4.1', 'effort': 'high', 'tier': 'Tier 2'},
        {'model': 'gpt-4.1-mini', 'effort': 'high', 'tier': 'Tier 2'},
        
        # Premium
        {'model': 'gpt-5-pro', 'effort': 'high', 'tier': 'Premium'},
        {'model': 'gpt-5.1', 'effort': 'high', 'tier': 'Premium'},
    ]
    
    all_results = []
    scenarios = get_phase4_scenarios()
    
    # ê° ë¬¸ì œ í…ŒìŠ¤íŠ¸
    for scenario in scenarios:
        print(f"\n{'='*120}")
        print(f"ğŸ“‹ {scenario['name']}")
        print(f"   ì •ë‹µ: {scenario['expected_value']:,} {scenario['expected_unit']}")
        print(f"{'='*120}\n")
        
        problem_results = []
        
        for config in test_config:
            model_name = config['model']
            effort = config['effort']
            tier = config['tier']
            
            print(f"ğŸ”„ {model_name} ({tier}, effort={effort})")
            
            test_result = test_model_responses_api(client, model_name, scenario, effort)
            
            if test_result['success']:
                eval_result = evaluate_fermi_response(
                    f"{model_name} ({tier})",
                    test_result['response'],
                    scenario['expected_value']
                )
                
                eval_result['elapsed'] = test_result['elapsed']
                eval_result['response'] = test_result['response']
                eval_result['problem'] = scenario['name']
                eval_result['problem_id'] = scenario['id']
                eval_result['tier'] = tier
                eval_result['reasoning_effort'] = effort
                
                problem_results.append(eval_result)
                all_results.append(eval_result)
                
                print(f"   âœ… {eval_result['value']:,} {eval_result['unit']} | ì´ì : {eval_result['total_score']}/100 (ì—°ê²°ì„±: {eval_result['calculation_connectivity']['score']}/50)")
            else:
                print(f"   âŒ ì˜¤ë¥˜: {test_result['error'][:80]}")
            
            time.sleep(2)
        
        # ë¬¸ì œë³„ ìš”ì•½
        print(f"\nğŸ“Š {scenario['name']} ìˆœìœ„:\n")
        problem_results.sort(key=lambda x: x['total_score'], reverse=True)
        
        for i, r in enumerate(problem_results, 1):
            marker = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "  "
            print(f"{marker}{i}. {r['model']:<35} {r['total_score']:>3}/100 (ì •í™•ë„: {r['accuracy']['score']}/25, ì—°ê²°ì„±: {r['calculation_connectivity']['score']}/50)")
        
        print()
    
    # ì „ì²´ ì¢…í•© ê²°ê³¼
    print("\n" + "=" * 120)
    print("ğŸ† ìµœì¢… ì¢…í•© ìˆœìœ„ (3ê°œ ë¬¸ì œ í‰ê· )")
    print("=" * 120)
    print()
    
    from collections import defaultdict
    
    by_model = defaultdict(list)
    for r in all_results:
        by_model[r['model']].append(r)
    
    model_averages = []
    for model_name, results in by_model.items():
        avg = {
            'model': model_name,
            'avg_total': sum(r['total_score'] for r in results) / len(results),
            'avg_accuracy': sum(r['accuracy']['score'] for r in results) / len(results),
            'avg_connectivity': sum(r['calculation_connectivity']['score'] for r in results) / len(results),
            'avg_decomp': sum(r['decomposition']['score'] for r in results) / len(results),
            'avg_logic': sum(r['logic']['score'] for r in results) / len(results),
            'count': len(results)
        }
        model_averages.append(avg)
    
    model_averages.sort(key=lambda x: x['avg_total'], reverse=True)
    
    print(f"{'ìˆœìœ„':<4} | {'ëª¨ë¸':<35} | {'í‰ê· ':<10} | {'ì •í™•ë„':<10} | {'ì—°ê²°ì„±':<10} | {'ë¶„í•´':<10} | {'ë…¼ë¦¬':<8}")
    print("-" * 120)
    
    for i, m in enumerate(model_averages, 1):
        marker = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "  "
        print(f"{marker}{i:<3} | {m['model']:<35} | {m['avg_total']:>8.1f}/100 | {m['avg_accuracy']:>8.1f}/25 | {m['avg_connectivity']:>8.1f}/50 | {m['avg_decomp']:>8.1f}/15 | {m['avg_logic']:>6.1f}/10")
    
    # ì €ì¥
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f"phase4_comprehensive_test_{timestamp}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'metadata': {
                'timestamp': datetime.now().isoformat(),
                'test_type': 'phase4_comprehensive_fewshot',
                'models': len(test_config),
                'problems': len(scenarios),
                'total_tests': len(all_results)
            },
            'problems': {
                s['id']: {
                    'name': s['name'],
                    'expected_value': s['expected_value'],
                    'expected_unit': s['expected_unit']
                } for s in scenarios
            },
            'results': all_results,
            'summary': model_averages
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    run_phase4_comprehensive_test()
