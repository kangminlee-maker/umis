#!/usr/bin/env python3
"""
ê°œì„ ëœ Fermi ì¶”ì • í‰ê°€ - ê³„ì‚°ì‹ ì—°ê²° í•„ìˆ˜
ë¶„í•´ ê°’ë“¤ì´ ìµœì¢… ì¶”ì •ê°’ìœ¼ë¡œ ì–´ë–»ê²Œ ê³„ì‚°ë˜ëŠ”ì§€ ëª…í™•íˆ ìš”êµ¬
"""

import sys
import os
import time
import json
from datetime import datetime
import math
import re

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from openai import OpenAI
from dotenv import load_dotenv
load_dotenv()


# =====================================
# ê°œì„ ëœ Fermi ë¬¸ì œ (ê³„ì‚°ì‹ í¬í•¨)
# =====================================

FERMI_PROBLEM = {
    'name': 'í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜',
    'ground_truth': 7837000,
    'unit': 'ê°œ',
    
    # AIì˜ ì˜¬ë°”ë¥¸ Fermi ë¶„í•´ (ê³„ì‚°ì‹ ëª…ì‹œ)
    'ai_baseline': {
        'estimate': 6036000,
        'decomposition': [
            {
                'step': '1. ê²½ì œí™œë™ì¸êµ¬',
                'value': 20300000,
                'calculation': '5200ë§Œ Ã— 0.60 Ã— 0.65',
                'reasoning': 'í•œêµ­ ì¸êµ¬ 5200ë§Œ, ê²½ì œí™œë™ê°€ëŠ¥ì¸êµ¬ 60%, ì°¸ê°€ìœ¨ 65%'
            },
            {
                'step': '2. ìì˜ì—…ì ìˆ˜',
                'value': 4060000,
                'calculation': '20300000 Ã— 0.20',
                'reasoning': 'ê²½ì œí™œë™ì¸êµ¬ì˜ 20%ê°€ ìì˜ì—…'
            },
            {
                'step': '3. ë²•ì¸ ì‚¬ì—…ì ìˆ˜',
                'value': 970000,
                'calculation': '(20300000 - 4060000) / 20 Ã— 1.2',
                'reasoning': 'ê·¼ë¡œì 1624ë§Œëª… / í‰ê·  20ëª… Ã— ë‹¤ì¤‘ì‚¬ì—…ì¥ ë³´ì • 1.2'
            },
            {
                'step': '4. ì´ ì‚¬ì—…ì ìˆ˜',
                'value': 6036000,
                'calculation': '(4060000 + 970000) Ã— 1.2',
                'reasoning': 'ìì˜ì—… + ë²•ì¸ Ã— íœ´ì—…/ë‹¤ì¤‘ë“±ë¡ ë³´ì •'
            }
        ],
        'final_formula': '[(ì¸êµ¬ Ã— ê²½í™œë¹„ìœ¨ Ã— ì°¸ê°€ìœ¨ Ã— ìì˜ë¹„ìœ¨) + (ê·¼ë¡œì / ê¸°ì—…ê·œëª¨ Ã— ë³´ì •)] Ã— íœ´ì—…ë³´ì •',
        'calculation_chain': [
            '5200ë§Œ Ã— 0.6 Ã— 0.65 = 2030ë§Œ (ê²½ì œí™œë™ì¸êµ¬)',
            '2030ë§Œ Ã— 0.2 = 406ë§Œ (ìì˜ì—…ì)',
            '(2030ë§Œ - 406ë§Œ) / 20 Ã— 1.2 = 97ë§Œ (ë²•ì¸)',
            '(406ë§Œ + 97ë§Œ) Ã— 1.2 = 603.6ë§Œ â‰ˆ 600ë§Œ'
        ]
    },
    
    'prompt': '''í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜ë¥¼ ì¶”ì •í•˜ì„¸ìš”.

âš ï¸ ì¤‘ìš”: ê° ë¶„í•´ ë‹¨ê³„ì˜ ìˆ«ìë“¤ì´ ìµœì¢… ì¶”ì •ê°’ìœ¼ë¡œ ì–´ë–»ê²Œ ê³„ì‚°ë˜ëŠ”ì§€ ëª…í™•íˆ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.

íŒíŠ¸:
- í•œêµ­ ì¸êµ¬, ê²½ì œí™œë™ì¸êµ¬ ê³ ë ¤
- ìì˜ì—…ì, ë²•ì¸ ì‚¬ì—…ì êµ¬ë¶„
- ë‹¤ì¤‘ ì‚¬ì—…ìë“±ë¡ ê°€ëŠ¥ì„± ê³ ë ¤

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
    "value": <ìµœì¢…_ì¶”ì •ê°’>,
    "unit": "ê°œ",
    "confidence": <0.3-0.7>,
    "method": "ì ‘ê·¼ ë°©ë²•",
    "decomposition": [
        {
            "step": "ë‹¨ê³„ëª…",
            "value": <ì´ ë‹¨ê³„ì˜ ê°’>,
            "calculation": "ì´ ê°’ì„ ê³„ì‚°í•œ ìˆ˜ì‹ (ì˜ˆ: 5200ë§Œ Ã— 0.6)",
            "reasoning": "ê°€ì • ë° ê·¼ê±°"
        }
    ],
    "final_calculation": "ë¶„í•´ ê°’ë“¤ì„ ì¡°í•©í•˜ì—¬ ìµœì¢…ê°’ì„ ê³„ì‚°í•œ ìˆ˜ì‹ (ì˜ˆ: step2 + step3)",
    "calculation_verification": "ìµœì¢… ê³„ì‚° ê²€ì¦ (ì˜ˆ: 406ë§Œ + 97ë§Œ = 503ë§Œ â‰ˆ 500ë§Œ)"
}

ì˜ˆì‹œ:
{
    "value": 500,
    "decomposition": [
        {"step": "A", "value": 100, "calculation": "1000 / 10"},
        {"step": "B", "value": 5, "calculation": "10 / 2"}
    ],
    "final_calculation": "A Ã— B = 100 Ã— 5 = 500",
    "calculation_verification": "100 Ã— 5 = 500 âœ“"
}'''
}


def verify_calculation_chain(decomp, final_value, final_calc, calc_verify):
    """
    ë¶„í•´ ê°’ë“¤ê³¼ ìµœì¢…ê°’ì˜ ê³„ì‚° ì—°ê²°ì„± ê²€ì¦
    ë°˜í™˜: (ì ìˆ˜, ê²€ì¦ ê²°ê³¼ ì„¤ëª…)
    """
    if not isinstance(decomp, list) or len(decomp) == 0:
        return 0, "ë¶„í•´ ì—†ìŒ"
    
    if not final_calc:
        return 0, "ìµœì¢… ê³„ì‚°ì‹ ëˆ„ë½"
    
    score = 0
    details = []
    
    # 1. ê° ë‹¨ê³„ì— calculation í•„ë“œ ìˆëŠ”ì§€ (10ì )
    calc_present = sum(1 for step in decomp if 'calculation' in step and step['calculation'])
    calc_score = min(10, (calc_present / len(decomp)) * 10)
    score += calc_score
    details.append(f"ë‹¨ê³„ë³„ ê³„ì‚°ì‹: {calc_present}/{len(decomp)} ì¡´ì¬ ({calc_score:.0f}ì )")
    
    # 2. final_calculationì— step ê°’ë“¤ì´ ì°¸ì¡°ë˜ëŠ”ì§€ (10ì )
    final_calc_lower = final_calc.lower()
    step_values = [step.get('value', 0) for step in decomp if 'value' in step]
    
    referenced_count = 0
    for val in step_values:
        if val and (str(val) in final_calc or str(int(val)) in final_calc):
            referenced_count += 1
    
    if referenced_count >= 2:  # ìµœì†Œ 2ê°œ ë‹¨ê³„ ê°’ ì°¸ì¡°
        ref_score = 10
        details.append(f"âœ… ìµœì¢… ê³„ì‚°ì‹ì´ ë¶„í•´ ê°’ ì°¸ì¡° ({referenced_count}ê°œ)")
    else:
        ref_score = 3
        details.append(f"âŒ ìµœì¢… ê³„ì‚°ì‹ì´ ë¶„í•´ ê°’ ë¯¸ì°¸ì¡°")
    
    score += ref_score
    
    # 3. ê³„ì‚° ê²€ì¦ ì‹œë„ (20ì )
    try:
        # ë‹¨ìˆœ ì‚°ìˆ ì‹ í‰ê°€ ì‹œë„
        # ìœ„í—˜: eval ì‚¬ìš©, ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ë” ì•ˆì „í•œ ë°©ë²• í•„ìš”
        
        # ë¶„í•´ ê°’ë“¤ë¡œ ìµœì¢…ê°’ ì¬ê³„ì‚° ì‹œë„
        values = [step.get('value', 0) for step in decomp if 'value' in step]
        
        if len(values) >= 2 and final_value > 0:
            # ë‹¤ì–‘í•œ ì¡°í•© ì‹œë„
            combinations = [
                sum(values),  # í•©
                sum(values[:-1]) if len(values) > 1 else 0,  # ë§ˆì§€ë§‰ ì œì™¸ í•©
                values[-1] if values else 0,  # ë§ˆì§€ë§‰ ê°’
            ]
            
            # ê³±ì…ˆ ì¡°í•©
            if len(values) >= 2:
                product = 1
                for v in values[:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
                    if v > 0 and v < 1000000000:  # ë„ˆë¬´ í° ìˆ˜ ì œì™¸
                        product *= v
                combinations.append(product)
            
            # ê°€ì¥ ê°€ê¹Œìš´ ì¡°í•© ì°¾ê¸°
            best_match = min(combinations, key=lambda x: abs(x - final_value) if x > 0 else float('inf'))
            
            if best_match > 0:
                error_ratio = abs(best_match - final_value) / final_value
                
                if error_ratio < 0.01:  # 1% ì´ë‚´
                    calc_score = 20
                    details.append(f"âœ… ê³„ì‚° ì¼ì¹˜: {best_match:,.0f} â‰ˆ {final_value:,.0f}")
                elif error_ratio < 0.1:  # 10% ì´ë‚´
                    calc_score = 15
                    details.append(f"âœ… ê³„ì‚° ê·¼ì ‘: {best_match:,.0f} â‰ˆ {final_value:,.0f} (ì˜¤ì°¨ {error_ratio*100:.1f}%)")
                elif error_ratio < 0.5:  # 50% ì´ë‚´
                    calc_score = 10
                    details.append(f"âš ï¸ ê³„ì‚° ë¶€ë¶„ ì¼ì¹˜: {best_match:,.0f} vs {final_value:,.0f}")
                else:
                    calc_score = 5
                    details.append(f"âŒ ê³„ì‚° ë¶ˆì¼ì¹˜: {best_match:,.0f} vs {final_value:,.0f}")
            else:
                calc_score = 0
                details.append("âŒ ê³„ì‚° ê²€ì¦ ì‹¤íŒ¨")
        else:
            calc_score = 0
            details.append("âŒ ê²€ì¦ ë¶ˆê°€ (ê°’ ë¶€ì¡±)")
        
        score += calc_score
        
    except Exception as e:
        details.append(f"âš ï¸ ê³„ì‚° ê²€ì¦ ì˜¤ë¥˜: {str(e)[:50]}")
    
    return min(score, 40), details


def evaluate_model_response(model_name, response, ground_truth, ai_baseline):
    """
    ê°œì„ ëœ í‰ê°€: ê³„ì‚° ì—°ê²°ì„± ì¤‘ì‹¬
    
    100ì  ë§Œì :
    - ì •í™•ë„: 30ì 
    - ê³„ì‚° ì—°ê²°ì„±: 40ì  (í•µì‹¬!)
    - ë¶„í•´ í•©ë¦¬ì„±: 20ì 
    - ë…¼ë¦¬ ì¼ê´€ì„±: 10ì 
    """
    result = {
        'model': model_name,
        'value': response.get('value', 0),
        'unit': response.get('unit', ''),
        'ground_truth': ground_truth
    }
    
    # ê°’ íƒ€ì… ì²´í¬
    if isinstance(result['value'], dict):
        result['value'] = 0
    elif not isinstance(result['value'], (int, float)):
        result['value'] = 0
    
    # 1. ì •í™•ë„ (30ì )
    if result['value'] > 0 and ground_truth > 0:
        error = abs(math.log10(result['value']) - math.log10(ground_truth))
        
        if error < 0.05:  # 5% ì´ë‚´
            accuracy_score = 30
        elif error < 0.1:  # 25% ì´ë‚´
            accuracy_score = 25
        elif error < 0.3:  # 2ë°° ì´ë‚´
            accuracy_score = 20
        elif error < 0.5:  # 3ë°° ì´ë‚´
            accuracy_score = 15
        elif error < 1.0:  # 10ë°° ì´ë‚´
            accuracy_score = 10
        else:
            accuracy_score = 5
        
        error_pct = (10**error - 1) * 100
    else:
        accuracy_score = 0
        error_pct = 999
    
    result['accuracy'] = {
        'score': accuracy_score,
        'error_pct': error_pct
    }
    
    # 2. ê³„ì‚° ì—°ê²°ì„± (40ì ) - ê°€ì¥ ì¤‘ìš”!
    calc_score, calc_details = verify_calculation_chain(
        response.get('decomposition', []),
        result['value'],
        response.get('final_calculation', ''),
        response.get('calculation_verification', '')
    )
    
    result['calculation_connectivity'] = {
        'score': calc_score,
        'details': calc_details
    }
    
    # 3. ë¶„í•´ í•©ë¦¬ì„± (20ì )
    decomp = response.get('decomposition', [])
    if isinstance(decomp, list) and len(decomp) >= 3:
        decomp_score = 10
        
        # ê° ë‹¨ê³„ ì™„ì„±ë„
        complete_count = sum(1 for step in decomp 
                           if all(k in step for k in ['step', 'value', 'calculation', 'reasoning']))
        decomp_score += min(10, (complete_count / len(decomp)) * 10)
    else:
        decomp_score = 0
    
    result['decomposition_quality'] = {
        'score': decomp_score,
        'step_count': len(decomp) if isinstance(decomp, list) else 0
    }
    
    # 4. ë…¼ë¦¬ ì¼ê´€ì„± (10ì )
    logic_score = 0
    if response.get('method'):
        logic_score += 5
    if response.get('reasoning'):
        logic_score += 5
    
    result['logic'] = {
        'score': logic_score
    }
    
    # ì´ì 
    result['total_score'] = (
        accuracy_score +
        calc_score +
        decomp_score +
        logic_score
    )
    
    return result


def test_model_on_fermi(client, model, api_type, problem_def, config=None):
    """ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    
    prompt = problem_def['prompt']
    
    try:
        start = time.time()
        
        if api_type == 'responses':
            api_params = {
                "model": model,
                "input": prompt,
            }
            
            if config:
                api_params["reasoning"] = config.get("reasoning", {"effort": "medium"})
                api_params["text"] = config.get("text", {"verbosity": "low"})
            
            response = client.responses.create(**api_params)
            
            if hasattr(response, 'output_text'):
                content = response.output_text
            elif hasattr(response, 'output'):
                content = response.output
            else:
                content = str(response)
            
        else:
            api_params = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
            }
            
            if config and config.get('reasoning_effort'):
                api_params["reasoning_effort"] = config['reasoning_effort']
            
            response = client.chat.completions.create(**api_params)
            content = response.choices[0].message.content
        
        elapsed = time.time() - start
        
        # JSON íŒŒì‹±
        try:
            if '```json' in content:
                json_start = content.find('```json') + 7
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
            elif '```' in content:
                json_start = content.find('```') + 3
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
            
            json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
            if json_match:
                content = json_match.group(0)
            
            parsed = json.loads(content)
        except Exception as e:
            parsed = {'parse_error': str(e)}
        
        return {
            'success': True,
            'elapsed': round(elapsed, 2),
            'response': parsed
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }


def run_improved_fermi_test():
    """ê°œì„ ëœ Fermi í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("=" * 120)
    print("ê°œì„ ëœ Fermi ì¶”ì • í‰ê°€ - ê³„ì‚°ì‹ ì—°ê²° í•„ìˆ˜")
    print("=" * 120)
    print()
    
    client = OpenAI()
    
    problem_def = FERMI_PROBLEM
    
    print(f"ğŸ“‹ ë¬¸ì œ: {problem_def['name']}")
    print(f"   ì •ë‹µ: {problem_def['ground_truth']:,} {problem_def['unit']}")
    print()
    
    print("ğŸ” AI ê¸°ì¤€ì„  (ì˜¬ë°”ë¥¸ Fermi ë¶„í•´):\n")
    print(f"ì¶”ì •ê°’: {problem_def['ai_baseline']['estimate']:,}")
    print("\nê³„ì‚° ê³¼ì •:")
    for calc in problem_def['ai_baseline']['calculation_chain']:
        print(f"  {calc}")
    print(f"\nìµœì¢… ê³µì‹: {problem_def['ai_baseline']['final_formula']}")
    print()
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë¸
    test_configs = [
        ('gpt-4.1-nano', 'chat', None),
        ('gpt-4o-mini', 'chat', None),
        ('gpt-4.1-mini', 'chat', None),
        ('gpt-5.1', 'chat', {'reasoning_effort': 'medium'}),
        ('gpt-5.1', 'responses', {
            'reasoning': {'effort': 'medium'},
            'text': {'verbosity': 'low'}
        }),
    ]
    
    results = []
    
    print("=" * 120)
    print("ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 120)
    print()
    
    for model, api_type, config in test_configs:
        config_name = f"{model} ({api_type})"
        print(f"í…ŒìŠ¤íŠ¸: {config_name}")
        
        test_result = test_model_on_fermi(client, model, api_type, problem_def, config)
        
        if test_result['success']:
            eval_result = evaluate_model_response(
                config_name,
                test_result['response'],
                problem_def['ground_truth'],
                problem_def['ai_baseline']
            )
            
            eval_result['response'] = test_result['response']
            results.append(eval_result)
            
            print(f"  âœ… ì™„ë£Œ ({test_result['elapsed']}ì´ˆ)")
            print(f"     ì¶”ì •ê°’: {eval_result['value']:,}")
            print(f"     ì •í™•ë„: {eval_result['accuracy']['score']}/30")
            print(f"     ğŸ”— ê³„ì‚° ì—°ê²°ì„±: {eval_result['calculation_connectivity']['score']}/40")
            print(f"     ë¶„í•´ í’ˆì§ˆ: {eval_result['decomposition_quality']['score']}/20")
            print(f"     ë…¼ë¦¬: {eval_result['logic']['score']}/10")
            print(f"     ì´ì : {eval_result['total_score']}/100")
        else:
            print(f"  âŒ ì˜¤ë¥˜: {test_result['error'][:50]}")
        
        print()
        time.sleep(2)
    
    # ê²°ê³¼ ë¶„ì„
    print("=" * 120)
    print("ğŸ† ìµœì¢… ê²°ê³¼")
    print("=" * 120)
    print()
    
    results.sort(key=lambda x: x['total_score'], reverse=True)
    
    print(f"{'ìˆœìœ„':<4} | {'ëª¨ë¸':<30} | {'ì¶”ì •ê°’':<15} | {'ì´ì ':<8} | {'ì •í™•ë„':<8} | {'ì—°ê²°ì„±':<8} | {'ë¶„í•´':<8} | {'ë…¼ë¦¬':<8}")
    print("-" * 120)
    
    for i, r in enumerate(results, 1):
        marker = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰" if i == 3 else "  "
        print(f"{marker}{i:<3} | {r['model']:<30} | {r['value']:>13,}{r['unit']:<2} | {r['total_score']:>6}/100 | {r['accuracy']['score']:>6}/30 | {r['calculation_connectivity']['score']:>6}/40 | {r['decomposition_quality']['score']:>6}/20 | {r['logic']['score']:>6}/10")
    
    # ìƒì„¸ ë¶„ì„
    print("\n\n" + "=" * 120)
    print("ğŸ“‹ ìƒì„¸ ë¶„ì„")
    print("=" * 120)
    
    for r in results:
        print(f"\n{'='*120}")
        print(f"{r['model']}")
        print(f"{'='*120}\n")
        
        print(f"**ì¶”ì •ê°’**: {r['value']:,} {r['unit']}")
        print(f"**ì´ì **: {r['total_score']}/100\n")
        
        # ì •í™•ë„
        print(f"**ì •í™•ë„** ({r['accuracy']['score']}/30):")
        if r['accuracy']['score'] > 0:
            print(f"  ì˜¤ì°¨: {r['accuracy']['error_pct']:.1f}%\n")
        else:
            print("  ê°’ ì—†ìŒ\n")
        
        # ê³„ì‚° ì—°ê²°ì„± (í•µì‹¬!)
        print(f"**ğŸ”— ê³„ì‚° ì—°ê²°ì„±** ({r['calculation_connectivity']['score']}/40):")
        for detail in r['calculation_connectivity']['details']:
            print(f"  {detail}")
        print()
        
        # ë¶„í•´
        print(f"**ë¶„í•´ í’ˆì§ˆ** ({r['decomposition_quality']['score']}/20):")
        print(f"  ë‹¨ê³„ ìˆ˜: {r['decomposition_quality']['step_count']}\n")
        
        # ì‹¤ì œ ì‘ë‹µ
        if 'response' in r:
            resp = r['response']
            
            if 'decomposition' in resp and isinstance(resp['decomposition'], list):
                print("**ë¶„í•´ ê³¼ì •**:")
                for i, step in enumerate(resp['decomposition'][:4], 1):
                    print(f"  {i}. {step.get('step', 'N/A')}")
                    print(f"     ê°’: {step.get('value', 'N/A')}")
                    print(f"     ê³„ì‚°: {step.get('calculation', 'N/A')}")
                print()
            
            if 'final_calculation' in resp:
                print(f"**ìµœì¢… ê³„ì‚°ì‹**: {resp['final_calculation']}")
            else:
                print("**ìµœì¢… ê³„ì‚°ì‹**: âŒ ëˆ„ë½")
            print()
    
    # ì €ì¥
    output_file = f"fermi_improved_evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            'metadata': {
                'timestamp': datetime.now().isoformat(),
                'evaluation_focus': 'ê³„ì‚°ì‹ ì—°ê²°ì„±',
                'scoring': {
                    'accuracy': '30ì ',
                    'calculation_connectivity': '40ì  (í•µì‹¬!)',
                    'decomposition': '20ì ',
                    'logic': '10ì '
                }
            },
            'problem': problem_def,
            'results': results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
    print("\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    run_improved_fermi_test()


