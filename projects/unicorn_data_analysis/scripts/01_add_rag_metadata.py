#!/usr/bin/env python3
"""
ìœ ë‹ˆì½˜ ë°ì´í„°ì— RAG Canonical Index ë©”íƒ€ë°ì´í„° ìë™ ì¶”ê°€

ì‘ì„±ì¼: 2025-11-04
ëª©ì : unicorn_companies_structured.jsonì„ UMIS RAG í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
"""

import json
import hashlib
from datetime import datetime
from typing import Dict, List, Any
import re


# ========================================
# Category â†’ Pattern Type ë§¤í•‘
# ========================================

CATEGORY_TO_PATTERN = {
    # Fintech
    "Fintech": "fintech_platform",
    
    # E-commerce & Marketplace
    "E-commerce & direct-to-consumer": "marketplace",
    "Supply chain, logistics, & delivery": "marketplace",
    
    # SaaS & Software
    "Internet software & services": "saas_platform",
    "Data management & analytics": "saas_tool",
    "Cybersecurity": "saas_security",
    
    # Platform Models
    "Artificial intelligence": "ai_platform",
    "Mobile & telecommunications": "platform",
    
    # Subscription/Service
    "Health": "healthcare_service",
    "Edtech": "education_service",
    "Travel": "travel_service",
    
    # Hardware/Manufacturing
    "Auto & transportation": "hardware_mobility",
    "Hardware": "hardware",
    "Consumer & retail": "retail",
    
    # Other
    "Other": "other",
}


# ========================================
# Helper Functions
# ========================================

def generate_canonical_id(company_name: str) -> str:
    """
    íšŒì‚¬ëª…ìœ¼ë¡œ Canonical ID ìƒì„±
    
    Format: CAN-{hash8}
    Example: CAN-byteda01
    """
    # íšŒì‚¬ëª…ì„ ì†Œë¬¸ì ì•ŒíŒŒë²³+ìˆ«ìë§Œ ë‚¨ê¹€
    clean_name = re.sub(r'[^a-z0-9]', '', company_name.lower())
    
    # ì• 6ì + 01 (ë²„ì „)
    if len(clean_name) >= 6:
        base = clean_name[:6]
    else:
        base = clean_name.ljust(6, '0')
    
    return f"CAN-{base}01"


def generate_source_id(company_name: str) -> str:
    """
    Source ID ìƒì„±
    
    Format: {company_name}_case
    Example: bytedance_case
    """
    clean_name = re.sub(r'[^a-z0-9]', '_', company_name.lower())
    clean_name = re.sub(r'_+', '_', clean_name)  # ì—°ì† ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°
    clean_name = clean_name.strip('_')
    
    return f"{clean_name}_case"


def generate_content_hash(content: str) -> str:
    """
    ì»¨í…ì¸  SHA-256 í•´ì‹œ ìƒì„±
    
    Returns: sha256:{hash}
    """
    hash_obj = hashlib.sha256(content.encode('utf-8'))
    return f"sha256:{hash_obj.hexdigest()}"


def estimate_tokens(text: str) -> int:
    """
    í† í° ìˆ˜ ì¶”ì • (ê°„ë‹¨í•œ ë°©ì‹: ë‹¨ì–´ ìˆ˜ * 1.3)
    """
    words = len(text.split())
    return int(words * 1.3)


def get_pattern_type(category: str) -> str:
    """
    ì¹´í…Œê³ ë¦¬ë¡œ íŒ¨í„´ íƒ€ì… ì¶”ë¡ 
    """
    return CATEGORY_TO_PATTERN.get(category, "platform")


def estimate_launch_year(unicorn_date: str, company_name: str) -> str:
    """
    ìœ ë‹ˆì½˜ ë“±ì¬ì¼ë¡œ ì°½ì—… ì—°ë„ ì¶”ì •
    
    Strategy: ìœ ë‹ˆì½˜ - 7ë…„ (í‰ê· )
    """
    try:
        # "2017.4.7" â†’ 2017
        year = int(unicorn_date.split('.')[0])
        launch_year = year - 7  # í‰ê·  7ë…„
        
        # 2000ë…„ ì´ì „ì€ 2000ìœ¼ë¡œ ì„¤ì •
        if launch_year < 2000:
            launch_year = 2000
            
        return str(launch_year)
    except:
        return "2010"  # ê¸°ë³¸ê°’


def calculate_funding_total(funding_history: List[Dict]) -> float:
    """
    ì´ í€ë”© ê¸ˆì•¡ ê³„ì‚° (ë°±ë§Œ ë‹¬ëŸ¬ ë‹¨ìœ„)
    """
    total = 0.0
    for round in funding_history:
        amount_str = round.get('amount', '')
        if 'M' in amount_str:
            value = float(amount_str.replace('M', '').replace(',', ''))
            total += value
        elif 'B' in amount_str:
            value = float(amount_str.replace('B', '').replace(',', ''))
            total += value * 1000
    
    return total


def extract_funding_rounds(funding_history: List[Dict]) -> List[str]:
    """
    í€ë”© ë¼ìš´ë“œ ë‚ ì§œ ì¶”ì¶œ
    """
    dates = []
    for round in funding_history:
        date = round.get('date', '')
        if date:
            dates.append(date)
    return dates


# ========================================
# Main Transformation Function
# ========================================

def add_rag_metadata(company: Dict[str, Any]) -> Dict[str, Any]:
    """
    ê°œë³„ íšŒì‚¬ ë°ì´í„°ì— RAG ë©”íƒ€ë°ì´í„° ì¶”ê°€
    """
    company_name = company.get('company', 'unknown')
    category = company.get('category', 'Other')
    
    # === 1. RAG Core Metadata ===
    canonical_id = generate_canonical_id(company_name)
    source_id = generate_source_id(company_name)
    
    # === 2. Content for hashing ===
    content_parts = [
        company_name,
        company.get('business', {}).get('summary', ''),
        category,
        str(company.get('valuation', {})),
    ]
    content_text = ' '.join(filter(None, content_parts))
    content_hash = generate_content_hash(content_text)
    
    # === 3. Timestamps ===
    now = datetime.utcnow().isoformat() + 'Z'
    
    # === 4. Pattern Type ===
    pattern_type = get_pattern_type(category)
    
    # === 5. Growth Info ===
    unicorn_date = company.get('valuation', {}).get('date_added', '2020.1.1')
    launch_year = estimate_launch_year(unicorn_date, company_name)
    
    # === 6. Funding Info ===
    funding_history = company.get('funding_history', [])
    total_funding = calculate_funding_total(funding_history)
    funding_rounds = extract_funding_rounds(funding_history)
    
    # === 7. Token Count ===
    total_tokens = estimate_tokens(content_text)
    
    # === RAG Metadata Structure ===
    rag_metadata = {
        # Core Identity
        "source_id": source_id,
        "canonical_chunk_id": canonical_id,
        "domain": "case_study",
        "content_type": "normalized_full",
        "version": "7.0.0",
        
        # Lineage
        "lineage": {
            "from": canonical_id,
            "via": [],
            "evidence_ids": [],
            "created_by": {
                "agent": "Explorer",
                "overlay_layer": "core",
                "tenant_id": None
            }
        },
        
        # Content Sections
        "sections": [
            {
                "agent_view": "explorer",
                "anchor_path": f"{source_id}.business_model",
                "content_hash": content_hash,
                "span_hint": {
                    "tokens": total_tokens
                }
            }
        ],
        
        # Metadata
        "total_tokens": total_tokens,
        "quality_grade": "B",  # ê¸°ë³¸ê°’, ì¶”í›„ ê²€ì¦ í•„ìš”
        "validation_status": "pending",
        
        # Timestamps
        "created_at": now,
        "updated_at": now,
        
        # Embedding (ì„ íƒ)
        "embedding": {
            "model": "text-embedding-3-large",
            "dimension": 3072,
            "space": "cosine"
        }
    }
    
    # === Business Model Enhancement ===
    business_enhancement = {
        "business_model": {
            "pattern_type": pattern_type,
            "pattern_id": f"{pattern_type}_pattern",
            "revenue_model": []  # ë¦¬ì„œì¹˜ í•„ìš”
        },
        
        "problem_solution": {
            "problem": None,  # ë¦¬ì„œì¹˜ í•„ìš”
            "solution": company.get('business', {}).get('summary', ''),
            "unique_value": None  # ë¦¬ì„œì¹˜ í•„ìš”
        },
        
        "performance_metrics": {
            "_note": "í™•ì¸ ê°€ëŠ¥í•œ ì¬ë¬´/ìš´ì˜ ì§€í‘œë§Œ ê¸°ì¬ (ìƒì¥ì‚¬, IR ìë£Œ ë“±)",
            
            "financial": {
                "revenue": {
                    "year_1": {"year": None, "amount_usd_million": None, "source": None},
                    "year_2": {"year": None, "amount_usd_million": None, "source": None},
                    "year_3": {"year": None, "amount_usd_million": None, "source": None}
                },
                "operating_profit": {
                    "year_1": {"year": None, "amount_usd_million": None, "source": None},
                    "year_2": {"year": None, "amount_usd_million": None, "source": None},
                    "year_3": {"year": None, "amount_usd_million": None, "source": None}
                },
                "gross_margin": None,
                "ebitda": None,
                "_note": "ìµœê·¼ 3ê°œë…„ ë°ì´í„° ìš°ì„ "
            },
            
            "operational": {
                "users": None,
                "mau": None,
                "dau": None,
                "transactions": None,
                "gmv_usd_million": None,
                "arr_usd_million": None,
                "subscribers": None,
                "_note": "í™•ì¸ ê°€ëŠ¥í•œ ì§€í‘œë§Œ ì„ íƒì ìœ¼ë¡œ ê¸°ì¬"
            },
            
            "unit_economics": {
                "arpu_usd": None,
                "cac_usd": None,
                "ltv_usd": None,
                "ltv_cac_ratio": None,
                "churn_rate_percent": None,
                "payback_period_months": None,
                "_note": "ê³µê°œëœ ê²½ìš°ì—ë§Œ ê¸°ì¬ (ìƒì¥ì‚¬, ì¸í„°ë·° ë“±)"
            }
        },
        
        "market_dynamics": {
            "market_size": None,
            "market_growth": None,
            "target_segment": None,
            "geographic_focus": [company.get('location', {}).get('country', 'Unknown')]
        },
        
        "competitive_advantage": [],  # ë¦¬ì„œì¹˜ í•„ìš”
        
        "critical_success_factors": [],  # ë¦¬ì„œì¹˜ í•„ìš”
        
        "growth_trajectory": {
            "launch_date": launch_year,
            "unicorn_date": unicorn_date,
            "total_funding_usd_million": total_funding,
            "funding_rounds": len(funding_rounds),
            "major_milestones": []  # ë¦¬ì„œì¹˜ í•„ìš”
        }
    }
    
    # === ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€ ===
    enhanced_company = company.copy()
    enhanced_company['rag_metadata'] = rag_metadata
    
    # business í•„ë“œ í™•ì¥
    if 'business' in enhanced_company:
        enhanced_company['business'].update(business_enhancement)
    else:
        enhanced_company['business'] = {
            'summary': '',
            'details': [],
            **business_enhancement
        }
    
    return enhanced_company


# ========================================
# Main Execution
# ========================================

def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    import os
    
    # íŒŒì¼ ê²½ë¡œ
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    
    input_file = os.path.join(project_dir, 'unicorn_companies_structured.json')
    output_file = os.path.join(project_dir, 'unicorn_companies_rag_enhanced.json')
    
    print("="*80)
    print("ğŸ¦„ ìœ ë‹ˆì½˜ ë°ì´í„° RAG ë©”íƒ€ë°ì´í„° ìë™ ì¶”ê°€")
    print("="*80)
    print()
    
    # ë°ì´í„° ë¡œë“œ
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {os.path.basename(input_file)}")
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    companies = data.get('companies', [])
    print(f"ğŸ“Š ì´ ê¸°ì—… ìˆ˜: {len(companies)}ê°œ")
    print()
    
    # ë³€í™˜ ì‹¤í–‰
    print("ğŸ”„ RAG ë©”íƒ€ë°ì´í„° ì¶”ê°€ ì¤‘...")
    enhanced_companies = []
    
    for i, company in enumerate(companies, 1):
        enhanced = add_rag_metadata(company)
        enhanced_companies.append(enhanced)
        
        if i % 100 == 0:
            print(f"   ì§„í–‰: {i}/{len(companies)} ({i/len(companies)*100:.1f}%)")
    
    print(f"âœ… ë³€í™˜ ì™„ë£Œ: {len(enhanced_companies)}ê°œ")
    print()
    
    # ê²°ê³¼ ì €ì¥
    output_data = {
        "metadata": {
            "total_companies": len(enhanced_companies),
            "data_version": "3.0",  # RAG í˜¸í™˜ ë²„ì „
            "last_updated": datetime.utcnow().isoformat() + 'Z',
            "rag_schema_version": "7.0.0",
            "structure": {
                "rag_metadata": "UMIS Canonical Index í˜¸í™˜ ë©”íƒ€ë°ì´í„°",
                "business": "í™•ì¥ëœ ë¹„ì¦ˆë‹ˆìŠ¤ ì •ë³´ (ì¼ë¶€ ë¦¬ì„œì¹˜ í•„ìš”)",
                "valuation": "ë°¸ë¥˜ì—ì´ì…˜ ì •ë³´",
                "funding_history": "í€ë”© íˆìŠ¤í† ë¦¬",
                "location": "ìœ„ì¹˜ ì •ë³´"
            },
            "notes": [
                "RAG ë©”íƒ€ë°ì´í„°ëŠ” ìë™ ìƒì„±ë¨",
                "business_model, problem_solution ë“±ì€ ì¼ë¶€ ë¦¬ì„œì¹˜ í•„ìš”",
                "unit_economics, key_metricsëŠ” ëŒ€ë¶€ë¶„ ë¹„ê³µê°œ ì •ë³´"
            ]
        },
        "companies": enhanced_companies
    }
    
    print(f"ğŸ’¾ ì €ì¥ ì¤‘: {os.path.basename(output_file)}")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print("âœ… ì €ì¥ ì™„ë£Œ!")
    print()
    
    # í†µê³„ ì¶œë ¥
    print("="*80)
    print("ğŸ“Š ë³€í™˜ í†µê³„")
    print("="*80)
    print()
    
    # Pattern Type ë¶„í¬
    pattern_counts = {}
    for company in enhanced_companies:
        pattern = company['business']['business_model']['pattern_type']
        pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1
    
    print("Pattern Type ë¶„í¬:")
    for pattern, count in sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True):
        print(f"  - {pattern}: {count}ê°œ ({count/len(enhanced_companies)*100:.1f}%)")
    
    print()
    
    # ìƒ˜í”Œ ì¶œë ¥
    print("="*80)
    print("ğŸ“ ìƒ˜í”Œ ì¶œë ¥ (ì²« ë²ˆì§¸ ê¸°ì—…)")
    print("="*80)
    print()
    
    sample = enhanced_companies[0]
    print(f"íšŒì‚¬: {sample['company']}")
    print(f"Canonical ID: {sample['rag_metadata']['canonical_chunk_id']}")
    print(f"Source ID: {sample['rag_metadata']['source_id']}")
    print(f"Pattern Type: {sample['business']['business_model']['pattern_type']}")
    print(f"Total Tokens: {sample['rag_metadata']['total_tokens']}")
    print()
    
    print("="*80)
    print("âœ… ì‘ì—… ì™„ë£Œ!")
    print("="*80)
    print()
    print(f"ì¶œë ¥ íŒŒì¼: {output_file}")
    print()
    print("ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. unicorn_companies_rag_enhanced.json í™•ì¸")
    print("  2. íŒŒì¼ëŸ¿ 10ê°œ ê¸°ì—… ì„ ì •")
    print("  3. ë¦¬ì„œì¹˜ë¥¼ í†µí•œ ìƒì„¸ ì •ë³´ ë³´ì™„")


if __name__ == "__main__":
    main()

