#!/usr/bin/env python3
"""
SEC ìˆ˜ì§‘ ë°ì´í„°ë¥¼ ë©”ì¸ JSONì— ìë™ ë°˜ì˜

ì‘ì„±ì¼: 2025-11-05
ëª©ì : SEC_*_final.json ë°ì´í„°ë¥¼ unicorn_companies_rag_enhanced.jsonì— ì—…ë°ì´íŠ¸
"""

import json
import os
import glob
from datetime import datetime


def update_company_performance(main_data: dict, sec_data: dict) -> bool:
    """
    SEC ë°ì´í„°ë¡œ ë©”ì¸ JSONì˜ Performance Metrics ì—…ë°ì´íŠ¸
    """
    company_name = sec_data['company']
    
    # í•´ë‹¹ ê¸°ì—… ì°¾ê¸°
    company = None
    for comp in main_data['companies']:
        if comp['company'] == company_name:
            company = comp
            break
    
    if not company:
        print(f"  âš ï¸ {company_name}ë¥¼ ë©”ì¸ JSONì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    # Performance Metrics ì—…ë°ì´íŠ¸
    sec_metrics = sec_data['performance_metrics']['financial']
    
    company['business']['performance_metrics']['financial'] = {
        'revenue': sec_metrics.get('revenue', {}),
        'operating_profit': sec_metrics.get('operating_profit', {}),
        'gross_profit': sec_metrics.get('gross_profit', {}),
        'net_income': sec_metrics.get('net_income', {}),
        'gross_margin': sec_metrics.get('gross_margin'),
        'operating_margin': sec_metrics.get('operating_margin'),
        'net_margin': sec_metrics.get('net_margin'),
        'ebitda': sec_metrics.get('ebitda'),
        '_note': 'ìµœê·¼ 3ê°œë…„ ë°ì´í„° ìš°ì„ '
    }
    
    # Cash ì—…ë°ì´íŠ¸
    if sec_metrics.get('cash_and_equivalents'):
        company['business']['performance_metrics']['financial']['cash_and_equivalents'] = sec_metrics['cash_and_equivalents']
    
    # RAG ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    company['rag_metadata']['updated_at'] = datetime.utcnow().isoformat() + 'Z'
    company['rag_metadata']['quality_grade'] = 'A'  # SEC ë°ì´í„°ëŠ” Aë“±ê¸‰
    company['rag_metadata']['validation_status'] = 'verified'
    
    return True


def main():
    print("="*80)
    print("ğŸ“Š SEC ë°ì´í„° â†’ ë©”ì¸ JSON ìë™ ë°˜ì˜")
    print("="*80)
    print()
    
    # ê²½ë¡œ ì„¤ì •
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    
    # ë©”ì¸ JSON ë¡œë“œ
    main_file = os.path.join(project_dir, 'unicorn_companies_rag_enhanced.json')
    print(f"ğŸ“‚ ë©”ì¸ íŒŒì¼: unicorn_companies_rag_enhanced.json")
    
    with open(main_file, 'r', encoding='utf-8') as f:
        main_data = json.load(f)
    
    print(f"   ì´ ê¸°ì—…: {len(main_data['companies'])}ê°œ")
    print()
    
    # SEC ë°ì´í„° íŒŒì¼ ì°¾ê¸°
    sec_files = glob.glob(os.path.join(project_dir, 'research', 'SEC_*_final.json'))
    print(f"ğŸ” SEC ë°ì´í„° íŒŒì¼: {len(sec_files)}ê°œ")
    print()
    
    # ê° SEC íŒŒì¼ ì²˜ë¦¬
    updated_count = 0
    failed_count = 0
    
    for sec_file in sorted(sec_files):
        company_name = os.path.basename(sec_file).replace('SEC_', '').replace('_final.json', '')
        
        print(f"ğŸ“Š {company_name}...")
        
        # SEC ë°ì´í„° ë¡œë“œ
        with open(sec_file, 'r', encoding='utf-8') as f:
            sec_data = json.load(f)
        
        # ì—…ë°ì´íŠ¸
        success = update_company_performance(main_data, sec_data)
        
        if success:
            updated_count += 1
            print(f"   âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            # ê°„ë‹¨íˆ í™•ì¸
            for comp in main_data['companies']:
                if comp['company'] == sec_data['company']:
                    rev = comp['business']['performance_metrics']['financial']['revenue']
                    if 'year_1' in rev:
                        y1 = rev['year_1']
                        print(f"   â†’ {y1['year']}: ${y1['amount_usd_million']}M")
                    break
        else:
            failed_count += 1
    
    print()
    print("="*80)
    print("ğŸ’¾ ë©”ì¸ JSON ì €ì¥ ì¤‘...")
    print("="*80)
    
    # ë°±ì—… ìƒì„±
    backup_file = os.path.join(
        project_dir,
        f"unicorn_companies_rag_enhanced_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    )
    
    with open(main_file, 'r', encoding='utf-8') as f:
        backup_data = f.read()
    with open(backup_file, 'w', encoding='utf-8') as f:
        f.write(backup_data)
    
    print(f"âœ… ë°±ì—… ìƒì„±: {os.path.basename(backup_file)}")
    
    # ë©”ì¸ íŒŒì¼ ì—…ë°ì´íŠ¸
    with open(main_file, 'w', encoding='utf-8') as f:
        json.dump(main_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ë©”ì¸ íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
    print()
    
    # ìš”ì•½
    print("="*80)
    print("ğŸ“Š ì—…ë°ì´íŠ¸ ìš”ì•½")
    print("="*80)
    print()
    print(f"  ì´ ì²˜ë¦¬: {len(sec_files)}ê°œ")
    print(f"  ì„±ê³µ: {updated_count}ê°œ")
    print(f"  ì‹¤íŒ¨: {failed_count}ê°œ")
    print()
    
    # ì—…ë°ì´íŠ¸ëœ ê¸°ì—… ë¦¬ìŠ¤íŠ¸
    print("âœ… ì—…ë°ì´íŠ¸ëœ ê¸°ì—…:")
    updated_companies = []
    for comp in main_data['companies']:
        if comp['rag_metadata'].get('quality_grade') == 'A' and comp['rag_metadata'].get('validation_status') == 'verified':
            rev = comp['business']['performance_metrics']['financial']['revenue']
            if rev and 'year_1' in rev:
                y1 = rev['year_1']
                updated_companies.append({
                    'name': comp['company'],
                    'year': y1['year'],
                    'revenue': y1['amount_usd_million']
                })
    
    for i, comp in enumerate(sorted(updated_companies, key=lambda x: x['revenue'], reverse=True), 1):
        print(f"  {i:2d}. {comp['name']:15s} - {comp['year']}: ${comp['revenue']:>8,.0f}M")
    
    print()
    print("="*80)
    print("âœ… ì‘ì—… ì™„ë£Œ!")
    print("="*80)
    print()
    print("ğŸ“ íŒŒì¼ ìœ„ì¹˜:")
    print(f"  - ë©”ì¸: unicorn_companies_rag_enhanced.json (ì—…ë°ì´íŠ¸ë¨)")
    print(f"  - ë°±ì—…: {os.path.basename(backup_file)}")
    print()
    print("ğŸ¯ ë‹¤ìŒ ë‹¨ê³„:")
    print("  1. ë©”ì¸ JSON í™•ì¸")
    print("  2. ì‹¤íŒ¨ 5ê°œ CIK ì¬í™•ì¸")
    print("  3. íŒŒì¼ëŸ¿ ë‚˜ë¨¸ì§€ 8ê°œ ì§„í–‰")


if __name__ == "__main__":
    main()



