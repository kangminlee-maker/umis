#!/usr/bin/env python3
"""
ë¦¬ì„œì¹˜ í—¬í¼ - ê²€ìƒ‰ ì¿¼ë¦¬ ìë™ ìƒì„± ë° ë¦¬ì„œì¹˜ ì§„í–‰ ì§€ì›

ì‘ì„±ì¼: 2025-11-04
ëª©ì : íŒŒì¼ëŸ¿ ë¦¬ì„œì¹˜ íš¨ìœ¨í™”
"""

import json
import webbrowser
from typing import Dict, List


# ========================================
# ê²€ìƒ‰ ì¿¼ë¦¬ í…œí”Œë¦¿
# ========================================

SEARCH_QUERIES = {
    "revenue_financial": [
        '"{company}" revenue "$" billion million 2023 2024',
        '"{company}" annual revenue growth rate financial performance',
        '"{company}" profitability operating margin EBITDA',
    ],
    
    "operational_metrics": [
        '"{company}" MAU million users 2024 statistics',
        '"{company}" announces XX million customers subscribers',
        '"{company}" GMV gross merchandise value',
        '"{company}" ARR annual recurring revenue',
    ],
    
    "business_model": [
        '"{company}" business model how does make money',
        '"{company}" revenue model pricing strategy',
        '"{company}" fee structure commission rate',
    ],
    
    "problem_solution": [
        '"{company}" problem solving value proposition',
        '"{company}" why customers choose competitive advantage',
        '"{company}" founder story startup journey',
    ],
    
    "competitive": [
        '"{company}" vs {competitor} market share comparison',
        '"{company}" competitive advantage moat network effects',
        '"{company}" differentiation unique features',
    ],
}


SITE_SPECIFIC_QUERIES = {
    "techcrunch": 'site:techcrunch.com "{company}" revenue OR funding OR metrics',
    "bloomberg": 'site:bloomberg.com "{company}" financial OR revenue',
    "wsj": 'site:wsj.com "{company}" valuation OR financial',
    "theinformation": 'site:theinformation.com "{company}"',
    "sec": '"{company}" site:sec.gov 10-K OR S-1',
}


# ========================================
# URL ìƒì„±
# ========================================

def generate_google_search_url(query: str) -> str:
    """
    Google ê²€ìƒ‰ URL ìƒì„±
    """
    import urllib.parse
    encoded = urllib.parse.quote(query)
    return f"https://www.google.com/search?q={encoded}"


def generate_crunchbase_url(company_name: str) -> str:
    """
    Crunchbase í”„ë¡œí•„ URL ìƒì„±
    """
    import urllib.parse
    slug = company_name.lower().replace(' ', '-').replace('.', '')
    return f"https://www.crunchbase.com/organization/{slug}"


def generate_sec_search_url(company_name: str) -> str:
    """
    SEC EDGAR ê²€ìƒ‰ URL ìƒì„±
    """
    import urllib.parse
    encoded = urllib.parse.quote(company_name)
    return f"https://www.sec.gov/cgi-bin/browse-edgar?company={encoded}&action=getcompany"


# ========================================
# ë¦¬ì„œì¹˜ ê°€ì´ë“œ ìƒì„±
# ========================================

def generate_research_guide(company: Dict) -> Dict:
    """
    ê°œë³„ ê¸°ì—…ì˜ ë¦¬ì„œì¹˜ ê°€ì´ë“œ ìƒì„±
    """
    company_name = company['company']
    category = company['category']
    country = company['location']['country']
    
    # ê²½ìŸì‚¬ ì¶”ë¡ 
    competitors = {
        "Stripe": ["PayPal", "Square", "Adyen", "Checkout.com"],
        "SpaceX": ["Blue Origin", "Rocket Lab", "Virgin Galactic"],
        "Databricks": ["Snowflake", "Google BigQuery", "Amazon Redshift"],
        "Klarna": ["Affirm", "Afterpay", "PayPal Credit"],
        "Instacart": ["DoorDash", "Uber Eats", "Amazon Fresh"],
    }
    
    competitor_list = competitors.get(company_name, [])
    
    # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    queries = {}
    for category, templates in SEARCH_QUERIES.items():
        queries[category] = []
        for template in templates:
            query = template.replace("{company}", company_name)
            if "{competitor}" in template and competitor_list:
                query = query.replace("{competitor}", competitor_list[0])
            queries[category].append({
                "query": query,
                "url": generate_google_search_url(query)
            })
    
    # ì‚¬ì´íŠ¸ë³„ ì¿¼ë¦¬
    site_queries = {}
    for site, template in SITE_SPECIFIC_QUERIES.items():
        query = template.replace("{company}", company_name)
        site_queries[site] = {
            "query": query,
            "url": generate_google_search_url(query)
        }
    
    # ì§ì ‘ URL
    direct_urls = {
        "crunchbase": generate_crunchbase_url(company_name),
        "sec": generate_sec_search_url(company_name),
        "google_company": generate_google_search_url(f'"{company_name}" official website'),
    }
    
    return {
        "company": company_name,
        "category": category,
        "country": country,
        "competitors": competitor_list,
        "search_queries": queries,
        "site_specific": site_queries,
        "direct_urls": direct_urls,
    }


# ========================================
# ë¦¬ì„œì¹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
# ========================================

def create_research_checklist(company_name: str) -> str:
    """
    ë¦¬ì„œì¹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ Markdown ìƒì„±
    """
    checklist = f"""# âœ… {company_name} ë¦¬ì„œì¹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

## Phase 1: ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘ (10ë¶„)

- [ ] Crunchbase í”„ë¡œí•„ í™•ì¸
- [ ] ê³µì‹ ì›¹ì‚¬ì´íŠ¸ ë°©ë¬¸
- [ ] ìµœì‹  ë‰´ìŠ¤ í™•ì¸ (Google News)
- [ ] ìƒì¥ ì—¬ë¶€ í™•ì¸ (SEC ê²€ìƒ‰)

## Phase 2: ì¬ë¬´ ì •ë³´ (20-30ë¶„)

### ìƒì¥ì‚¬ì¸ ê²½ìš°:
- [ ] SEC EDGARì—ì„œ ìµœì‹  10-K ë‹¤ìš´ë¡œë“œ
- [ ] Revenue (3ë…„) ì¶”ì¶œ
- [ ] Operating Profit (3ë…„) ì¶”ì¶œ
- [ ] Key Metrics í™•ì¸ (MD&A ì„¹ì…˜)
- [ ] ì†ŒìŠ¤: 10-K, Page ___

### ë¹„ìƒì¥ì¸ ê²½ìš°:
- [ ] TechCrunch í€ë”© ê¸°ì‚¬ ê²€ìƒ‰
- [ ] Bloomberg/WSJ ë¶„ì„ ê¸°ì‚¬
- [ ] ê³µì‹ ë°œí‘œì—ì„œ ì–¸ê¸‰ëœ ì§€í‘œ í™•ì¸
- [ ] The Information ê¸°ì‚¬ (ìœ ë£Œ ì‹œ)

## Phase 3: ìš´ì˜ ì§€í‘œ (15-20ë¶„)

- [ ] Users/MAU ê³µì‹ ë°œí‘œ í™•ì¸
- [ ] GMV/ARR ë°œí‘œ í™•ì¸
- [ ] ì»¨í¼ëŸ°ìŠ¤ ë°œí‘œ ìë£Œ ê²€ìƒ‰
- [ ] CEO ì¸í„°ë·°ì—ì„œ ì–¸ê¸‰ëœ ì§€í‘œ

## Phase 4: ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ (20-30ë¶„)

- [ ] Problem/Solution ì •ë¦¬
- [ ] Revenue Model í™•ì¸
- [ ] Competitive Advantage ë¶„ì„ (3-5ê°œ)
- [ ] Critical Success Factors ë„ì¶œ (3-5ê°œ)

## Phase 5: ê²€ì¦ & ë¬¸ì„œí™” (10ë¶„)

- [ ] ëª¨ë“  ì†ŒìŠ¤ URL ê¸°ë¡
- [ ] ì‹ ë¢°ë„ í‰ê°€ (â­â­â­â­â­)
- [ ] Quality Grade ë¶€ì—¬ (A/B/C/D)
- [ ] JSON ì—…ë°ì´íŠ¸ ì¤€ë¹„

---

**ì˜ˆìƒ ì´ ì†Œìš”ì‹œê°„:** 75-110ë¶„
**ëª©í‘œ Quality Grade:** A ë˜ëŠ” B
"""
    return checklist


# ========================================
# Main - ë¦¬ì„œì¹˜ ê°€ì´ë“œ ì¶œë ¥
# ========================================

def main():
    """
    íŒŒì¼ëŸ¿ 10ê°œ ê¸°ì—…ì˜ ë¦¬ì„œì¹˜ ê°€ì´ë“œ ìƒì„±
    """
    import os
    
    # íŒŒì¼ ê²½ë¡œ
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    
    # íŒŒì¼ëŸ¿ ë°ì´í„° ë¡œë“œ
    pilot_file = os.path.join(project_dir, 'pilot_companies.json')
    with open(pilot_file, 'r', encoding='utf-8') as f:
        pilot = json.load(f)
    
    companies = pilot['pilot_companies']
    
    print("="*80)
    print("ğŸ” ë¦¬ì„œì¹˜ í—¬í¼ - ê²€ìƒ‰ ì¿¼ë¦¬ ìë™ ìƒì„±")
    print("="*80)
    print()
    
    # ë¦¬ì„œì¹˜ ê°€ì´ë“œ í´ë” ìƒì„±
    research_dir = os.path.join(project_dir, 'research')
    os.makedirs(research_dir, exist_ok=True)
    
    print(f"ğŸ“ ë¦¬ì„œì¹˜ ê°€ì´ë“œ í´ë”: {research_dir}")
    print()
    
    # ê° ê¸°ì—…ë³„ ê°€ì´ë“œ ìƒì„±
    for i, company in enumerate(companies, 1):
        company_name = company['company']
        
        print(f"{i}. {company_name} ë¦¬ì„œì¹˜ ê°€ì´ë“œ ìƒì„± ì¤‘...")
        
        # ë¦¬ì„œì¹˜ ê°€ì´ë“œ ìƒì„±
        guide = generate_research_guide(company)
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
        checklist = create_research_checklist(company_name)
        
        # íŒŒì¼ëª… ì•ˆì „í•˜ê²Œ ë§Œë“¤ê¸°
        safe_name = company_name.replace('/', '_').replace(' ', '_')
        
        # JSON ê°€ì´ë“œ ì €ì¥
        guide_file = os.path.join(research_dir, f"{i:02d}_{safe_name}_guide.json")
        with open(guide_file, 'w', encoding='utf-8') as f:
            json.dump(guide, f, ensure_ascii=False, indent=2)
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì €ì¥
        checklist_file = os.path.join(research_dir, f"{i:02d}_{safe_name}_checklist.md")
        with open(checklist_file, 'w', encoding='utf-8') as f:
            f.write(checklist)
        
        print(f"   âœ… {guide_file}")
        print(f"   âœ… {checklist_file}")
    
    print()
    print("="*80)
    print("âœ… ë¦¬ì„œì¹˜ ê°€ì´ë“œ ìƒì„± ì™„ë£Œ!")
    print("="*80)
    print()
    
    # ì²« ë²ˆì§¸ ê¸°ì—… ìƒ˜í”Œ ì¶œë ¥
    print("ğŸ“ ìƒ˜í”Œ: Stripe ë¦¬ì„œì¹˜ ê°€ì´ë“œ")
    print("="*80)
    print()
    
    stripe_guide = generate_research_guide(companies[0])
    
    print("ğŸ” Revenue & Financial ê²€ìƒ‰ ì¿¼ë¦¬:")
    for q in stripe_guide['search_queries']['revenue_financial'][:2]:
        print(f"   - {q['query']}")
    
    print()
    print("ğŸ“Š Operational Metrics ê²€ìƒ‰ ì¿¼ë¦¬:")
    for q in stripe_guide['search_queries']['operational_metrics'][:2]:
        print(f"   - {q['query']}")
    
    print()
    print("ğŸŒ ì§ì ‘ ì ‘ê·¼ URL:")
    for name, url in stripe_guide['direct_urls'].items():
        print(f"   - {name}: {url}")
    
    print()
    print("="*80)
    print("ğŸ’¡ ì‚¬ìš© ë°©ë²•:")
    print("="*80)
    print()
    print("1. research/ í´ë”ì˜ ê°€ì´ë“œ íŒŒì¼ ì—´ê¸°")
    print("2. JSON íŒŒì¼ì—ì„œ ê²€ìƒ‰ ì¿¼ë¦¬ ë³µì‚¬")
    print("3. URL í´ë¦­í•˜ì—¬ ìë™ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤í–‰")
    print("4. ì²´í¬ë¦¬ìŠ¤íŠ¸ ë”°ë¼ê°€ë©° ì •ë³´ ìˆ˜ì§‘")
    print("5. ë¦¬ì„œì¹˜ í…œí”Œë¦¿ì— ì •ë³´ ì…ë ¥")


if __name__ == "__main__":
    main()

