"""
v7.11.0 EstimatorRAG - 10ê°œ Fermi ë¬¸ì œ í…ŒìŠ¤íŠ¸

ê¸°ì¡´ Phase 4 Extended í…ŒìŠ¤íŠ¸ì˜ 10ê°œ ë¬¸í•­ì„ v7.11.0 Fusion Architectureë¡œ í…ŒìŠ¤íŠ¸
"""

import sys
from pathlib import Path
import time
import json
from datetime import datetime

project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from umis_rag.agents.estimator import EstimatorRAG
from umis_rag.agents.estimator.models import Context
from umis_rag.utils.logger import logger


# 10ê°œ Fermi ë¬¸ì œ ì •ì˜
FERMI_PROBLEMS = [
    {
        'id': 'extended_delivery_riders',
        'question': 'í•œêµ­ ì „ì²´ ë°°ë‹¬ ê¸°ì‚¬(ë¼ì´ë”) ìˆ˜ëŠ”?',
        'name': 'í•œêµ­ ì „ì²´ ë°°ë‹¬ ê¸°ì‚¬(ë¼ì´ë”) ìˆ˜',
        'expected_value': 400000,
        'unit': 'ëª…',
        'context': {
            'domain': 'Platform Economy',
            'region': 'Korea',
            'industry': 'Food Delivery'
        }
    },
    {
        'id': 'extended_chicken_delivery',
        'question': 'í•œêµ­ ì—°ê°„ ì¹˜í‚¨ ë°°ë‹¬ ì£¼ë¬¸ ê±´ìˆ˜ëŠ”?',
        'name': 'í•œêµ­ ì—°ê°„ ì¹˜í‚¨ ë°°ë‹¬ ì£¼ë¬¸ ê±´ìˆ˜',
        'expected_value': 1100000000,
        'unit': 'ê±´',
        'context': {
            'domain': 'Food Delivery',
            'region': 'Korea',
            'industry': 'Restaurant'
        }
    },
    {
        'id': 'extended_taxi_passengers',
        'question': 'ì„œìš¸ì‹œ í•˜ë£¨ í‰ê·  íƒì‹œ ìŠ¹ê° ìˆ˜ëŠ”?',
        'name': 'ì„œìš¸ì‹œ í•˜ë£¨ í‰ê·  íƒì‹œ ìŠ¹ê° ìˆ˜',
        'expected_value': 1500000,
        'unit': 'ëª…',
        'context': {
            'domain': 'Transportation',
            'region': 'Seoul',
            'industry': 'Taxi'
        }
    },
    {
        'id': 'extended_credit_card',
        'question': 'í•œêµ­ ì—°ê°„ ì‹ ìš©ì¹´ë“œ ìŠ¹ì¸ ê±´ìˆ˜ëŠ”?',
        'name': 'í•œêµ­ ì—°ê°„ ì‹ ìš©ì¹´ë“œ ìŠ¹ì¸ ê±´ìˆ˜',
        'expected_value': 30000000000,
        'unit': 'ê±´',
        'context': {
            'domain': 'FinTech',
            'region': 'Korea',
            'industry': 'Payment'
        }
    },
    {
        'id': 'extended_hospital_visits',
        'question': 'í•œêµ­ ì—°ê°„ ë³‘ì› ì™¸ë˜ ì§„ë£Œ ê±´ìˆ˜ëŠ”?',
        'name': 'í•œêµ­ ì—°ê°„ ë³‘ì› ì™¸ë˜ ì§„ë£Œ ê±´ìˆ˜',
        'expected_value': 1700000000,
        'unit': 'ê±´',
        'context': {
            'domain': 'Healthcare',
            'region': 'Korea',
            'industry': 'Hospital'
        }
    },
    {
        'id': 'extended_private_education',
        'question': 'í•œêµ­ ì´ˆì¤‘ê³  í•™ìƒ ì—°ê°„ ì‚¬êµìœ¡ë¹„ ì´ì•¡ì€?',
        'name': 'í•œêµ­ ì´ˆì¤‘ê³  í•™ìƒ ì—°ê°„ ì‚¬êµìœ¡ë¹„ ì´ì•¡',
        'expected_value': 26000000000000,
        'unit': 'ì›',
        'context': {
            'domain': 'Education',
            'region': 'Korea',
            'industry': 'Private Education'
        }
    },
    {
        'id': 'extended_jeonse_contracts',
        'question': 'ì„œìš¸ì‹œ ì—°ê°„ ì „ì„¸ ê³„ì•½ ê±´ìˆ˜ëŠ”?',
        'name': 'ì„œìš¸ì‹œ ì—°ê°„ ì „ì„¸ ê³„ì•½ ê±´ìˆ˜',
        'expected_value': 400000,
        'unit': 'ê±´',
        'context': {
            'domain': 'Real Estate',
            'region': 'Seoul',
            'industry': 'Rental'
        }
    },
    {
        'id': 'extended_ott_subscribers',
        'question': 'í•œêµ­ ìœ ë£Œ OTT êµ¬ë…ì ìˆ˜ëŠ”?',
        'name': 'í•œêµ­ ìœ ë£Œ OTT êµ¬ë…ì ìˆ˜',
        'expected_value': 25000000,
        'unit': 'ëª…',
        'context': {
            'domain': 'Media',
            'region': 'Korea',
            'industry': 'Streaming'
        }
    },
    {
        'id': 'extended_coupang_boxes',
        'question': 'ì¿ íŒ¡ ì¼í‰ê·  ë°°ì†¡ ë¬¼ëŸ‰ì€?',
        'name': 'ì¿ íŒ¡ ì¼í‰ê·  ë°°ì†¡ ë¬¼ëŸ‰',
        'expected_value': 12000000,
        'unit': 'ë°•ìŠ¤',
        'context': {
            'domain': 'E-commerce',
            'region': 'Korea',
            'industry': 'Logistics'
        }
    },
    {
        'id': 'extended_disposable_cups',
        'question': 'í•œêµ­ ì—°ê°„ ì¼íšŒìš© ì»µ ì‚¬ìš©ëŸ‰ì€?',
        'name': 'í•œêµ­ ì—°ê°„ ì¼íšŒìš© ì»µ ì‚¬ìš©ëŸ‰',
        'expected_value': 33000000000,
        'unit': 'ê°œ',
        'context': {
            'domain': 'Environment',
            'region': 'Korea',
            'industry': 'Cafe'
        }
    }
]


def calculate_error_percentage(estimated: float, expected: float) -> float:
    """ì˜¤ì°¨ìœ¨ ê³„ì‚°"""
    if expected == 0:
        return 0.0
    return abs(estimated - expected) / expected * 100


def evaluate_result(problem: dict, result) -> dict:
    """ê²°ê³¼ í‰ê°€"""
    estimated_value = result.value
    expected_value = problem['expected_value']
    
    error_pct = calculate_error_percentage(estimated_value, expected_value)
    
    # ì •í™•ë„ ì ìˆ˜ (50ì  ë§Œì )
    if error_pct <= 10:
        accuracy_score = 50
    elif error_pct <= 20:
        accuracy_score = 40
    elif error_pct <= 30:
        accuracy_score = 30
    elif error_pct <= 50:
        accuracy_score = 20
    elif error_pct <= 100:
        accuracy_score = 10
    else:
        accuracy_score = 5
    
    # Certainty ì ìˆ˜ (20ì  ë§Œì )
    certainty_map = {'high': 20, 'medium': 15, 'low': 10}
    certainty_score = certainty_map.get(result.certainty, 10)
    
    # ì‚¬ìš©í•œ Stage ì ìˆ˜ (20ì  ë§Œì )
    stage_score = 0
    if 'Evidence' in result.source:
        stage_score = 20  # í™•ì • ê°’
    elif 'Prior' in result.source:
        stage_score = 15  # Generative Prior
    elif 'Fermi' in result.source:
        stage_score = 18  # êµ¬ì¡°ì  ì„¤ëª…
    elif 'Fusion' in result.source:
        stage_score = 17  # í†µí•©
    else:
        stage_score = 10
    
    # íš¨ìœ¨ì„± ì ìˆ˜ (10ì  ë§Œì )
    cost_summary = result.cost
    llm_calls = cost_summary.get('llm_calls', 0)
    
    if llm_calls == 0:
        efficiency_score = 10  # Phase 0 ì¦‰ì‹œ ë°˜í™˜
    elif llm_calls <= 3:
        efficiency_score = 9
    elif llm_calls <= 6:
        efficiency_score = 8
    elif llm_calls <= 10:
        efficiency_score = 7
    else:
        efficiency_score = 5
    
    total_score = accuracy_score + certainty_score + stage_score + efficiency_score
    
    return {
        'estimated_value': estimated_value,
        'expected_value': expected_value,
        'error_pct': error_pct,
        'accuracy_score': accuracy_score,
        'certainty_score': certainty_score,
        'stage_score': stage_score,
        'efficiency_score': efficiency_score,
        'total_score': total_score,
        'max_score': 100
    }


def run_test():
    """10ê°œ ë¬¸ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    print("=" * 120)
    print("ğŸš€ v7.11.0 EstimatorRAG - 10ê°œ Fermi ë¬¸ì œ í…ŒìŠ¤íŠ¸")
    print("=" * 120)
    print()
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ êµ¬ì„±:")
    print("  â€¢ ì•„í‚¤í…ì²˜: v7.11.0 Fusion Architecture (4-Stage)")
    print("  â€¢ ë¬¸ì œ ìˆ˜: 10ê°œ")
    print("  â€¢ íŠ¹ì§•:")
    print("    - âœ… ì¬ê·€ ì™„ì „ ì œê±° (Recursion FORBIDDEN)")
    print("    - âœ… Budget ê¸°ë°˜ íƒìƒ‰ (max_llm_calls=10, max_depth=2)")
    print("    - âœ… Evidence â†’ Prior â†’ Fermi â†’ Fusion")
    print("    - âœ… Phase 0 (Literal) + Guardrail Engine")
    print()
    
    # EstimatorRAG ì´ˆê¸°í™”
    estimator = EstimatorRAG()
    
    all_results = []
    
    for i, problem in enumerate(FERMI_PROBLEMS, 1):
        print("\n" + "=" * 120)
        print(f"ğŸ“‹ ë¬¸ì œ {i}/10: {problem['name']}")
        print(f"   ì§ˆë¬¸: {problem['question']}")
        print(f"   ì •ë‹µ: {problem['expected_value']:,} {problem['unit']}")
        print("=" * 120)
        
        try:
            start_time = time.time()
            
            # Context ìƒì„±
            context = problem['context']
            
            # ì¶”ì • ì‹¤í–‰
            logger.info(f"\n[Test {i}] {problem['name']}")
            result = estimator.estimate(
                question=problem['question'],
                context=context
            )
            
            elapsed = time.time() - start_time
            
            # í‰ê°€
            evaluation = evaluate_result(problem, result)
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\nâœ… ê²°ê³¼:")
            print(f"   ì¶”ì •ê°’: {result.value:,.0f} {problem['unit']}")
            print(f"   ì •ë‹µ: {evaluation['expected_value']:,} {problem['unit']}")
            print(f"   ì˜¤ì°¨ìœ¨: {evaluation['error_pct']:.1f}%")
            print(f"   Certainty: {result.certainty}")
            print(f"   Source: {result.source}")
            print(f"   ì‹¤í–‰ ì‹œê°„: {elapsed:.2f}ì´ˆ")
            print(f"\nğŸ“Š ì ìˆ˜:")
            print(f"   ì •í™•ë„: {evaluation['accuracy_score']}/50")
            print(f"   Certainty: {evaluation['certainty_score']}/20")
            print(f"   Stage: {evaluation['stage_score']}/20")
            print(f"   íš¨ìœ¨ì„±: {evaluation['efficiency_score']}/10")
            print(f"   ì´ì : {evaluation['total_score']}/100")
            
            # ë¹„ìš© ì •ë³´
            cost_summary = result.cost
            if cost_summary and isinstance(cost_summary, dict):
                print(f"\nğŸ’° ë¹„ìš©:")
                print(f"   LLM Calls: {cost_summary.get('llm_calls', 0)}")
                print(f"   Variables: {cost_summary.get('variables', 0)}")
                print(f"   Time: {cost_summary.get('time', 0):.2f}ì´ˆ")
            
            # Decomposition ì •ë³´
            if result.decomposition:
                print(f"\nğŸ” ë¶„í•´:")
                formula = result.decomposition.get('formula', '')
                variables = result.decomposition.get('variables', {})
                print(f"   Formula: {formula}")
                if variables:
                    print(f"   Variables: {len(variables)}ê°œ")
                    for var, val in list(variables.items())[:3]:
                        print(f"     - {var}: {val:,.0f}")
            
            # ê²°ê³¼ ì €ì¥
            all_results.append({
                'problem_id': problem['id'],
                'problem_name': problem['name'],
                'question': problem['question'],
                'estimated_value': result.value,
                'expected_value': problem['expected_value'],
                'unit': problem['unit'],
                'error_pct': evaluation['error_pct'],
                'certainty': result.certainty,
                'source': result.source,
                'elapsed_time': elapsed,
                'cost': cost_summary,
                'evaluation': evaluation,
                'decomposition': result.decomposition,
                'metadata': result.metadata
            })
        
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            logger.error(f"Problem {i} failed: {e}", exc_info=True)
            
            all_results.append({
                'problem_id': problem['id'],
                'problem_name': problem['name'],
                'question': problem['question'],
                'error': str(e),
                'status': 'failed'
            })
    
    # ìµœì¢… í†µê³„
    print("\n" + "=" * 120)
    print("ğŸ† ìµœì¢… ê²°ê³¼")
    print("=" * 120)
    print()
    
    successful_results = [r for r in all_results if 'evaluation' in r]
    
    if successful_results:
        avg_total_score = sum(r['evaluation']['total_score'] for r in successful_results) / len(successful_results)
        avg_accuracy_score = sum(r['evaluation']['accuracy_score'] for r in successful_results) / len(successful_results)
        avg_certainty_score = sum(r['evaluation']['certainty_score'] for r in successful_results) / len(successful_results)
        avg_stage_score = sum(r['evaluation']['stage_score'] for r in successful_results) / len(successful_results)
        avg_efficiency_score = sum(r['evaluation']['efficiency_score'] for r in successful_results) / len(successful_results)
        avg_error_pct = sum(r['error_pct'] for r in successful_results) / len(successful_results)
        avg_time = sum(r['elapsed_time'] for r in successful_results) / len(successful_results)
        
        total_llm_calls = sum(r['cost'].get('llm_calls', 0) for r in successful_results if 'cost' in r and r['cost'])
        avg_llm_calls = total_llm_calls / len(successful_results) if successful_results else 0
        
        print(f"ì„±ê³µí•œ ë¬¸ì œ: {len(successful_results)}/{len(FERMI_PROBLEMS)}")
        print()
        print(f"í‰ê·  ì´ì : {avg_total_score:.1f}/100")
        print(f"  - ì •í™•ë„: {avg_accuracy_score:.1f}/50")
        print(f"  - Certainty: {avg_certainty_score:.1f}/20")
        print(f"  - Stage: {avg_stage_score:.1f}/20")
        print(f"  - íš¨ìœ¨ì„±: {avg_efficiency_score:.1f}/10")
        print()
        print(f"í‰ê·  ì˜¤ì°¨ìœ¨: {avg_error_pct:.1f}%")
        print(f"í‰ê·  ì‹¤í–‰ ì‹œê°„: {avg_time:.2f}ì´ˆ")
        print(f"í‰ê·  LLM Calls: {avg_llm_calls:.1f}íšŒ")
        
        # ìˆœìœ„
        print("\n" + "-" * 120)
        print("ğŸ“Š ë¬¸ì œë³„ ìˆœìœ„:")
        print("-" * 120)
        print()
        
        sorted_results = sorted(successful_results, key=lambda x: x['evaluation']['total_score'], reverse=True)
        
        print(f"{'ìˆœìœ„':<6} | {'ë¬¸ì œ':<40} | {'ì˜¤ì°¨ìœ¨':<10} | {'ì´ì ':<10} | {'ì‹œê°„':<10}")
        print("-" * 120)
        
        for rank, r in enumerate(sorted_results, 1):
            medal = "ğŸ¥‡" if rank == 1 else "ğŸ¥ˆ" if rank == 2 else "ğŸ¥‰" if rank == 3 else "  "
            print(f"{medal}{rank:<4} | {r['problem_name']:<40} | {r['error_pct']:>7.1f}% | "
                  f"{r['evaluation']['total_score']:>7.1f}/100 | {r['elapsed_time']:>7.2f}ì´ˆ")
    
    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = f'v7_11_0_fermi_10problems_{timestamp}.json'
    
    output_data = {
        'timestamp': timestamp,
        'test_name': 'v7.11.0 EstimatorRAG - 10 Fermi Problems',
        'architecture': 'v7.11.0 Fusion Architecture (4-Stage)',
        'features': [
            'Recursion FORBIDDEN',
            'Budget-based Exploration',
            'Evidence â†’ Prior â†’ Fermi â†’ Fusion',
            'Phase 0 (Literal)',
            'Guardrail Engine'
        ],
        'problems': FERMI_PROBLEMS,
        'results': all_results,
        'summary': {
            'total_problems': len(FERMI_PROBLEMS),
            'successful': len(successful_results),
            'failed': len(FERMI_PROBLEMS) - len(successful_results),
            'avg_total_score': avg_total_score if successful_results else 0,
            'avg_accuracy_score': avg_accuracy_score if successful_results else 0,
            'avg_error_pct': avg_error_pct if successful_results else 0,
            'avg_time': avg_time if successful_results else 0,
            'avg_llm_calls': avg_llm_calls if successful_results else 0
        }
    }
    
    output_path = project_root / output_file
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
    print("\nğŸ‰ ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    return all_results


if __name__ == '__main__':
    run_test()
