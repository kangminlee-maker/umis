#!/usr/bin/env python3
"""
Model Config ì‹¤ì „ ì‹œë®¬ë ˆì´ì…˜

ì‹¤ì œ Phase 4 ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹œë®¬ë ˆì´ì…˜
"""

import sys
from pathlib import Path

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from umis_rag.core.model_router import select_model_with_config
from umis_rag.core.model_configs import is_pro_model


def simulate_phase4_estimation():
    """Phase 4 ì¶”ì • ì‹œë®¬ë ˆì´ì…˜"""
    print("\n" + "="*60)
    print("ğŸ¯ Phase 4 Fermi Estimation ì‹œë®¬ë ˆì´ì…˜")
    print("="*60)
    
    # 1. ëª¨ë¸ + ì„¤ì • ì„ íƒ
    model_name, config = select_model_with_config(phase=4)
    
    print(f"\nğŸ“Œ Phase 4 ëª¨ë¸ ì„ íƒ:")
    print(f"   ëª¨ë¸: {model_name}")
    print(f"   API: {config.api_type}")
    print(f"   Max tokens: {config.max_output_tokens}")
    
    # 2. Fast Mode ì²´í¬
    if is_pro_model(model_name):
        print(f"\nğŸš€ Fast Mode ì ìš© ëŒ€ìƒ (pro ëª¨ë¸)")
        fast_mode_prompt = """
ğŸ”´ SPEED OPTIMIZATION MODE
â±ï¸ ëª©í‘œ ì‘ë‹µ ì‹œê°„: 60ì´ˆ ì´ë‚´
ğŸ“ ìµœëŒ€ ì¶œë ¥ ê¸¸ì´: 2,000ì ì´ë‚´
"""
        print(f"   Fast Mode í”„ë¡¬í”„íŠ¸ ì¶”ê°€ë¨")
    else:
        print(f"\nâœ… ì¼ë°˜ ëª¨ë¸ (Fast Mode ë¯¸ì ìš©)")
        fast_mode_prompt = ""
    
    # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    base_prompt = "ì„œìš¸ í•˜ë£¨ íƒì‹œ ìŠ¹ê° ìˆ˜ëŠ”?"
    full_prompt = fast_mode_prompt + base_prompt if fast_mode_prompt else base_prompt
    
    print(f"\nğŸ“ í”„ë¡¬í”„íŠ¸:")
    print(f"   - Fast Mode: {'ì ìš©' if fast_mode_prompt else 'ë¯¸ì ìš©'}")
    print(f"   - ê¸¸ì´: {len(full_prompt)}ì")
    
    # 4. API íŒŒë¼ë¯¸í„° êµ¬ì„±
    api_params = config.build_api_params(
        prompt=full_prompt,
        reasoning_effort='medium'
    )
    
    print(f"\nâš™ï¸ API íŒŒë¼ë¯¸í„°:")
    for key, value in api_params.items():
        if key == 'input':
            print(f"   - {key}: {value[:30]}...")
        elif key == 'messages':
            print(f"   - {key}: {len(value)}ê°œ ë©”ì‹œì§€")
        elif isinstance(value, dict):
            print(f"   - {key}: {value}")
        else:
            print(f"   - {key}: {value}")
    
    print(f"\nâœ… API í˜¸ì¶œ ì¤€ë¹„ ì™„ë£Œ")
    print(f"   ì‹¤ì œ í˜¸ì¶œ: client.{config.api_type}.create(**api_params)")
    
    return True


def test_multiple_models():
    """ì—¬ëŸ¬ ëª¨ë¸ ì„¤ì • ë¹„êµ"""
    print("\n" + "="*60)
    print("ğŸ“Š ëª¨ë¸ë³„ API ì„¤ì • ë¹„êµ")
    print("="*60)
    
    from umis_rag.core.model_configs import get_model_config
    
    test_models = [
        'o1-mini',      # Phase 4 ê¸°ë³¸
        'o3-mini-2025-01-31',  # ë²¤ì¹˜ë§ˆí¬ ìµœìš°ì„ 
        'gpt-5.1',      # ë†’ì€ ì¶”ë¡ , ë‚®ì€ í˜•ì‹
        'gpt-5-pro',    # Pro ëª¨ë¸
        'gpt-4.1-nano'  # Phase 0-2
    ]
    
    print("\nëª¨ë¸ ë¹„êµí‘œ:")
    print("-" * 100)
    print(f"{'ëª¨ë¸':<25} {'API':<12} {'Max Tokens':<12} {'Reasoning':<12} {'Pro':<8} {'ë¹„ê³ '}")
    print("-" * 100)
    
    for model_name in test_models:
        config = get_model_config(model_name)
        reasoning = 'Yes' if config.reasoning_effort_support else 'No'
        if config.reasoning_effort_fixed:
            reasoning += f" (fixed)"
        pro = 'Yes' if is_pro_model(model_name) else 'No'
        notes = config.notes[:30]
        
        print(f"{model_name:<25} {config.api_type:<12} {config.max_output_tokens:<12} {reasoning:<12} {pro:<8} {notes}")
    
    print("-" * 100)
    
    return True


def test_reasoning_effort_variations():
    """Reasoning effort ë ˆë²¨ë³„ íŒŒë¼ë¯¸í„° í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("ğŸ”§ Reasoning Effort ë ˆë²¨ë³„ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    from umis_rag.core.model_configs import get_model_config
    
    config = get_model_config('o1-mini')
    
    efforts = ['low', 'medium', 'high']
    
    print(f"\nëª¨ë¸: o1-mini")
    print(f"ì§€ì› ë ˆë²¨: {config.reasoning_effort_levels}")
    
    for effort in efforts:
        params = config.build_api_params(
            prompt="í…ŒìŠ¤íŠ¸",
            reasoning_effort=effort
        )
        
        if 'reasoning' in params:
            actual_effort = params['reasoning']['effort']
            status = "âœ…" if actual_effort == effort else "âŒ"
            print(f"{status} {effort} â†’ reasoning.effort={actual_effort}")
        else:
            print(f"âŒ {effort} â†’ reasoning í•„ë“œ ì—†ìŒ")
    
    # Pro ëª¨ë¸ í…ŒìŠ¤íŠ¸ (high ê³ ì •)
    print(f"\nëª¨ë¸: gpt-5-pro (high ê³ ì •)")
    config_pro = get_model_config('gpt-5-pro')
    print(f"ì§€ì› ë ˆë²¨: {config_pro.reasoning_effort_levels}")
    print(f"ê³ ì •ê°’: {config_pro.reasoning_effort_fixed}")
    
    for effort in efforts:
        params = config_pro.build_api_params(
            prompt="í…ŒìŠ¤íŠ¸",
            reasoning_effort=effort
        )
        
        if 'reasoning' in params:
            actual_effort = params['reasoning']['effort']
            expected = 'high'  # ê³ ì •
            status = "âœ…" if actual_effort == expected else "âŒ"
            print(f"{status} {effort} ìš”ì²­ â†’ reasoning.effort={actual_effort} (ê³ ì •)")
    
    return True


def test_environment_model_change():
    """í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ ëª¨ë¸ ë³€ê²½ ì‹œë®¬ë ˆì´ì…˜"""
    print("\n" + "="*60)
    print("ğŸ”„ .env ëª¨ë¸ ë³€ê²½ ì‹œë®¬ë ˆì´ì…˜")
    print("="*60)
    
    # ì‹œë‚˜ë¦¬ì˜¤: .envì—ì„œ LLM_MODEL_PHASE4ë¥¼ ë³€ê²½
    scenarios = [
        ('o1-mini', 'ê¸°ë³¸ ëª¨ë¸ (Phase 4 ê¸°ë³¸)'),
        ('gpt-5.1', 'Advanced reasoning ëª¨ë¸'),
        ('o3-mini-2025-01-31', 'ë²¤ì¹˜ë§ˆí¬ ìµœìš°ì„  í›„ë³´'),
        ('gpt-5-pro', 'Pro ëª¨ë¸ (Fast Mode)'),
    ]
    
    print("\nì‹œë®¬ë ˆì´ì…˜: .envì—ì„œ LLM_MODEL_PHASE4 ë³€ê²½")
    print("-" * 80)
    
    for model_name, description in scenarios:
        print(f"\nğŸ“ LLM_MODEL_PHASE4={model_name}")
        print(f"   ì„¤ëª…: {description}")
        
        from umis_rag.core.model_configs import get_model_config
        config = get_model_config(model_name)
        
        print(f"   ìë™ ì ìš©:")
        print(f"   - API íƒ€ì…: {config.api_type}")
        print(f"   - Max tokens: {config.max_output_tokens}")
        print(f"   - Reasoning: {config.reasoning_effort_support}")
        if config.reasoning_effort_support:
            print(f"   - Default effort: {config.reasoning_effort_default}")
        
        if is_pro_model(model_name):
            print(f"   - â­ Fast Mode ìë™ ì ìš©")
        
        # API íŒŒë¼ë¯¸í„° ë¯¸ë¦¬ë³´ê¸°
        params = config.build_api_params(
            prompt="í…ŒìŠ¤íŠ¸",
            reasoning_effort='medium'
        )
        print(f"   - API keys: {list(params.keys())}")
    
    print("\nâœ… ëª¨ë“  ëª¨ë¸ ë³€ê²½ ì‹œë‚˜ë¦¬ì˜¤ ê²€ì¦ ì™„ë£Œ")
    return True


def main():
    """ì‹¤ì „ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"""
    print("\n" + "â”"*60)
    print("ğŸ® Model Config System ì‹¤ì „ ì‹œë®¬ë ˆì´ì…˜")
    print("â”"*60)
    
    tests = [
        ("Phase 4 ì¶”ì • ì‹œë®¬ë ˆì´ì…˜", simulate_phase4_estimation),
        ("ëª¨ë¸ë³„ ì„¤ì • ë¹„êµ", test_multiple_models),
        ("Reasoning Effort ë ˆë²¨ í…ŒìŠ¤íŠ¸", test_reasoning_effort_variations),
        ("í™˜ê²½ë³€ìˆ˜ ëª¨ë¸ ë³€ê²½", test_environment_model_change),
    ]
    
    results = []
    
    for name, test_func in tests:
        try:
            result = test_func()
            results.append((name, result))
        except Exception as e:
            print(f"\nâŒ {name} ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "â”"*60)
    print("ğŸ“Š ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")
    print("â”"*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status}: {name}")
    
    print(f"\nì´ ê²°ê³¼: {passed}/{total} í†µê³¼ ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("\nğŸ‰ ëª¨ë“  ì‹œë®¬ë ˆì´ì…˜ ì„±ê³µ!")
        print("\nâœ… ì‹¤ì œ Phase 4 í†µí•© ì¤€ë¹„ ì™„ë£Œ!")
        return 0
    else:
        print(f"\nâš ï¸ {total - passed}ê°œ ì‹œë®¬ë ˆì´ì…˜ ì‹¤íŒ¨")
        return 1


if __name__ == "__main__":
    sys.exit(main())

