# UMIS Model API Configurations
# 
# 모델별 API 파라미터 설정
# Phase 4 Fermi Decomposition 벤치마크 기반 (v7.8.0)
#
# 사용법:
#   .env에서 LLM_MODEL_PHASE4=o1-mini 설정하면
#   자동으로 해당 모델의 API 설정 적용

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 기본값 (미지원 모델 폴백)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
defaults:
  api_type: chat
  max_output_tokens: 4096
  temperature: 0.7
  reasoning_effort:
    support: false
    default: medium

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 모델별 설정
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
models:
  
  # ===== o-series (OpenAI Reasoning Models) =====
  
  o1-mini:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    temperature_support: false
    context_window: 128000
    notes: "STEM 최적화, 80% 저렴, Phase 4 기본 모델"
  
  o1:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    temperature_support: false
    context_window: 200000
    notes: "기본 reasoning 모델, function calling 지원"
  
  o1-2024-12-17:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    temperature_support: false
    context_window: 200000
    notes: "o1의 특정 버전"
  
  o1-pro:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [high]  # high 고정
      fixed: high
      default: high
    temperature_support: false
    context_window: 200000
    notes: "Responses API only, 최고 성능, 비용 높음 ($150/1M input)"
  
  o1-pro-2025-03-19:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [high]
      fixed: high
      default: high
    temperature_support: false
    context_window: 200000
    notes: "o1-pro의 특정 버전"
  
  o3:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    temperature_support: false
    context_window: 200000
    notes: "o3 시리즈"
  
  o3-2025-04-16:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    temperature_support: false
    context_window: 200000
    notes: "o3의 특정 버전"
  
  o3-mini:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    temperature_support: false
    context_window: 200000
    notes: "o3 mini 버전"
  
  o3-mini-2025-01-31:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    temperature_support: false
    context_window: 200000
    notes: "o3-mini의 특정 버전, 벤치마크 최우선 후보"
  
  o4-mini:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    temperature_support: false
    context_window: 200000
    notes: "o4 mini 버전"
  
  o4-mini-2025-04-16:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    temperature_support: false
    context_window: 200000
    notes: "o4-mini의 특정 버전, 벤치마크 최우선 후보"
  
  # ===== gpt-5 series =====
  
  gpt-5.1:
    api_type: responses  # Chat Completions도 지원
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [none, low, medium, high]
      default: high
    temperature_support: true  # reasoning.effort=none일 때만
    temperature_condition: reasoning_effort_none
    context_window: 196000
    notes: "Advanced reasoning, JSON 형식 약함, temperature는 reasoning.effort=none일 때만"
  
  gpt-5-pro:
    api_type: responses  # Responses API only
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      levels: [high]  # high 고정
      fixed: high
      default: high
    temperature_support: false
    context_window: 400000
    notes: "Responses API only, reasoning.effort=high 고정, temperature 미지원, Fast Mode 권장"
  
  # ===== gpt-4.1 series =====
  
  gpt-4.1:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: false
    temperature_support: false  # Responses API에서는 미지원
    context_window: 128000
    notes: "reasoning 미지원"
  
  gpt-4.1-mini:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: false
    temperature_support: false
    context_window: 128000
    notes: "reasoning 미지원"
  
  # ===== Phase 0-3 최적화 모델 (참고용) =====
  
  gpt-4.1-nano:
    api_type: chat
    max_output_tokens: 4096
    reasoning_effort:
      support: false
    temperature_support: true
    temperature: 0.7
    context_window: 16000
    notes: "Phase 0-2 최적화, $0.000033/작업, 정확도 100%"
  
  gpt-4o-mini:
    api_type: chat
    max_output_tokens: 16000
    reasoning_effort:
      support: false
    temperature_support: true
    temperature: 0.7
    context_window: 128000
    notes: "Phase 3 최적화, $0.000121/작업, 정확도 100%"

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Pro 모델 (Fast Mode 대상)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
pro_models:
  - gpt-5-pro
  - o1-pro
  - o1-pro-2025-03-19

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 벤치마크 결과 (참고용)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 
# 최우선 후보 (Phase 4):
#   - o3-mini-2025-01-31: 계산 연결성 50/50, 개념 일관성 15/15
#   - o4-mini-2025-04-16: 계산 연결성 50/50, 개념 일관성 15/15
#
# 프리미엄:
#   - o3-2025-04-16: 최고 품질
#   - o1-pro-2025-03-19: 최고 성능
#
# 실험적:
#   - gpt-5.1: 높은 추론 능력, JSON 형식 약함 (형식 점수 0-2/5)
#
# 상세: benchmarks/estimator/phase4/analysis/model_recommendations.md

