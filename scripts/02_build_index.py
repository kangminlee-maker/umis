#!/usr/bin/env python3
"""
ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸

ì²­í¬ íŒŒì¼(.jsonl)ì„ ì½ì–´ì„œ ë²¡í„° DB(Chroma)ì— ì„ë² ë”© í›„ ì €ì¥í•©ë‹ˆë‹¤.

ê°œë…:
------
1. **Embeddings**: í…ìŠ¤íŠ¸ë¥¼ 1536ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
   - OpenAI text-embedding-3-small ì‚¬ìš©
   - ë¹„ìš© íš¨ìœ¨ì  (ada-002 ëŒ€ë¹„ 5ë°° ì €ë ´)

2. **Chroma DB**: ë¡œì»¬ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤
   - í”„ë¡œí† íƒ€ì…ìš© (ë¬´ë£Œ, ë¡œì»¬)
   - í”„ë¡œë•ì…˜ì—ì„œëŠ” Pinecone ì‚¬ìš© ê¶Œì¥

3. **Agentë³„ Collection**: 
   - Explorerìš© ì»¬ë ‰ì…˜ ë”°ë¡œ ê´€ë¦¬
   - í–¥í›„ Observer, Quantifier, Validator ì»¬ë ‰ì…˜ ì¶”ê°€

ì‚¬ìš©ë²•:
    python scripts/02_build_index.py --agent explorer
    python scripts/02_build_index.py --agent all
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Any, Dict, List

from rich.console import Console
from rich.progress import track, Progress
from rich.table import Table

# LangChain imports
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.vectorstores.utils import filter_complex_metadata
from langchain_core.documents import Document

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from umis_rag.core.config import settings
from umis_rag.utils.logger import logger

console = Console()


class UMISIndexBuilder:
    """
    UMIS RAG ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶•ê¸°
    
    ì—­í• :
    ------
    1. JSON Lines ì²­í¬ íŒŒì¼ ë¡œë“œ
    2. OpenAI Embeddingsë¡œ ë²¡í„°í™”
    3. Chroma DBì— ì €ì¥
    4. ì—ì´ì „íŠ¸ë³„ ì»¬ë ‰ì…˜ ê´€ë¦¬
    
    ê°œë…:
    ------
    - **Document**: LangChainì˜ ê¸°ë³¸ ë‹¨ìœ„
      {page_content: str, metadata: dict}
    
    - **Embeddings**: í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜ê¸°
      OpenAI API ì‚¬ìš© (ì¸í„°ë„· í•„ìš”)
    
    - **VectorStore**: ë²¡í„° ì €ì¥ì†Œ (Chroma)
      ìœ ì‚¬ë„ ê²€ìƒ‰ ì œê³µ
    """
    
    def __init__(self):
        self.data_dir = settings.project_root / "data"
        self.chunks_dir = self.data_dir / "chunks"
        self.chroma_dir = settings.chroma_persist_dir
        
        # OpenAI Embeddings ì´ˆê¸°í™”
        logger.info(f"OpenAI Embeddings ì´ˆê¸°í™”: {settings.embedding_model}")
        self.embeddings = OpenAIEmbeddings(
            model=settings.embedding_model,
            openai_api_key=settings.openai_api_key
        )
        
        logger.info(f"Chroma DB ê²½ë¡œ: {self.chroma_dir}")
    
    def load_chunks(self, filename: str) -> List[Dict[str, Any]]:
        """
        JSON Lines ì²­í¬ íŒŒì¼ ë¡œë“œ
        
        JSON Lines í˜•ì‹:
        - í•œ ì¤„ì— í•˜ë‚˜ì˜ JSON ê°ì²´
        - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  (í•œ ì¤„ì”© ì½ê¸° ê°€ëŠ¥)
        """
        filepath = self.chunks_dir / filename
        logger.info(f"ì²­í¬ íŒŒì¼ ë¡œë”©: {filepath}")
        
        if not filepath.exists():
            logger.error(f"  âŒ íŒŒì¼ ì—†ìŒ: {filepath}")
            return []
        
        chunks = []
        with open(filepath, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    chunk = json.loads(line)
                    chunks.append(chunk)
                except json.JSONDecodeError as e:
                    logger.warning(f"  âš ï¸  ë¼ì¸ {line_num} íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        logger.info(f"  âœ… {len(chunks)}ê°œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
        return chunks
    
    def chunks_to_documents(self, chunks: List[Dict[str, Any]]) -> List[Document]:
        """
        ì²­í¬ë¥¼ LangChain Documentë¡œ ë³€í™˜
        
        Document êµ¬ì¡°:
        - page_content: ì‹¤ì œ í…ìŠ¤íŠ¸ ë‚´ìš©
        - metadata: ê²€ìƒ‰ í•„í„°ë§ìš© ë©”íƒ€ë°ì´í„°
        
        ê°œë…:
        ------
        LangChainì˜ ëª¨ë“  ë„êµ¬ëŠ” Document ê°ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        ìš°ë¦¬ì˜ ì²­í¬ë¥¼ ì´ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
        """
        logger.info(f"ì²­í¬ â†’ Document ë³€í™˜ ì¤‘...")
        
        documents = []
        for chunk in chunks:
            doc = Document(
                page_content=chunk["content"],
                metadata=chunk["metadata"]
            )
            documents.append(doc)
        
        logger.info(f"  âœ… {len(documents)}ê°œ Document ìƒì„±")
        return documents
    
    def build_explorer_index(self) -> None:
        """
        Explorer ì—ì´ì „íŠ¸ìš© ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶•
        
        í”„ë¡œì„¸ìŠ¤:
        1. Business Model ì²­í¬ ë¡œë“œ
        2. Disruption ì²­í¬ ë¡œë“œ
        3. í•©ì¹˜ê¸°
        4. ë²¡í„°í™” (OpenAI API í˜¸ì¶œ!)
        5. Chroma DB ì €ì¥
        
        ì°¸ê³ :
        ------
        - API í˜¸ì¶œ ë¹„ìš© ë°œìƒ (54ê°œ ì²­í¬ Ã— $0.00002 â‰ˆ $0.001)
        - 1-2ë¶„ ì†Œìš” (API ì†ë„ ì˜ì¡´)
        """
        console.print("\n[bold blue]ğŸ“Š Explorer ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œì‘[/bold blue]\n")
        
        # 1. ì²­í¬ ë¡œë“œ
        console.print("[yellow]Step 1/4: ì²­í¬ íŒŒì¼ ë¡œë”©...[/yellow]")
        bm_chunks = self.load_chunks("explorer_business_models.jsonl")
        dp_chunks = self.load_chunks("explorer_disruption_patterns.jsonl")
        all_chunks = bm_chunks + dp_chunks
        
        if not all_chunks:
            logger.error("ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 01_convert_yaml.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        console.print(f"  â†’ ì´ {len(all_chunks)}ê°œ ì²­í¬ ë¡œë“œë¨\n")
        
        # 2. Document ë³€í™˜
        console.print("[yellow]Step 2/4: LangChain Document ë³€í™˜...[/yellow]")
        documents = self.chunks_to_documents(all_chunks)
        console.print(f"  â†’ {len(documents)}ê°œ Document ìƒì„±\n")
        
        # 2.5. ë©”íƒ€ë°ì´í„° í•„í„°ë§ (Chroma DB í˜¸í™˜ì„±)
        console.print("[yellow]Step 2.5/4: ë©”íƒ€ë°ì´í„° í•„í„°ë§...[/yellow]")
        documents = filter_complex_metadata(documents)
        console.print(f"  â†’ list/dict íƒ€ì… JSON ë¬¸ìì—´ë¡œ ë³€í™˜\n")
        
        # 3. ë²¡í„°í™” ë° ì €ì¥
        console.print("[yellow]Step 3/4: ë²¡í„° ì„ë² ë”© ìƒì„± (OpenAI API í˜¸ì¶œ)...[/yellow]")
        console.print("  â³ 1-2ë¶„ ì†Œìš” ì˜ˆìƒ... (API ì†ë„ ì˜ì¡´)\n")
        
        # Chroma DB ìƒì„± (ìë™ìœ¼ë¡œ ì„ë² ë”© + ì €ì¥)
        collection_name = "explorer_knowledge_base"
        
        logger.info(f"Chroma Collection ìƒì„±: {collection_name}")
        vectorstore = Chroma.from_documents(
            documents=documents,
            embedding=self.embeddings,
            collection_name=collection_name,
            persist_directory=str(self.chroma_dir)
        )
        
        console.print(f"  âœ… ë²¡í„° DB ì €ì¥ ì™„ë£Œ!\n")
        
        # 4. ê²€ì¦
        console.print("[yellow]Step 4/4: ì¸ë±ìŠ¤ ê²€ì¦...[/yellow]")
        self._validate_index(vectorstore, documents)
        
        # í†µê³„ ì¶œë ¥
        self._print_statistics(all_chunks)
        
        console.print("\n[bold green]âœ… Explorer ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ![/bold green]\n")
        console.print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.chroma_dir}")
        console.print(f"ğŸ“Š Collection: {collection_name}")
        console.print(f"ğŸ“ Document ìˆ˜: {len(documents)}")
        console.print("\në‹¤ìŒ ë‹¨ê³„:")
        console.print("  python scripts/03_test_search.py --agent explorer")
    
    def _validate_index(self, vectorstore: Chroma, documents: List[Document]) -> None:
        """
        ì¸ë±ìŠ¤ ê²€ì¦: ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        
        ê°œë…:
        ------
        ë²¡í„° DBê°€ ì œëŒ€ë¡œ êµ¬ì¶•ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´
        í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•´ë´…ë‹ˆë‹¤.
        """
        logger.info("ì¸ë±ìŠ¤ ê²€ì¦ ì¤‘...")
        
        # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_queries = [
            "í”Œë«í¼ ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸",
            "êµ¬ë… ì„œë¹„ìŠ¤",
            "1ë“± ì¶”ì›” ì „ëµ"
        ]
        
        for query in test_queries:
            results = vectorstore.similarity_search(query, k=1)
            if results:
                logger.info(f"  âœ… '{query}' â†’ {results[0].metadata.get('chunk_id', 'unknown')}")
            else:
                logger.warning(f"  âš ï¸  '{query}' â†’ ê²°ê³¼ ì—†ìŒ")
        
        console.print("  âœ… ì¸ë±ìŠ¤ ê²€ì¦ ì™„ë£Œ\n")
    
    def _print_statistics(self, chunks: List[Dict[str, Any]]) -> None:
        """í†µê³„ ì •ë³´ ì¶œë ¥"""
        # ì²­í¬ íƒ€ì…ë³„ ì§‘ê³„
        from collections import Counter
        
        chunk_types = Counter(c["metadata"]["chunk_type"] for c in chunks)
        pattern_types = Counter(c["metadata"]["pattern_type"] for c in chunks)
        
        # í…Œì´ë¸” ìƒì„±
        table = Table(title="ğŸ“Š Explorer ì¸ë±ìŠ¤ í†µê³„")
        table.add_column("êµ¬ë¶„", style="cyan")
        table.add_column("ê°œìˆ˜", style="magenta")
        
        table.add_row("ì´ ì²­í¬ ìˆ˜", str(len(chunks)))
        table.add_row("Business Model", str(sum(1 for c in chunks if c["metadata"]["pattern_type"] == "business_model")))
        table.add_row("Disruption", str(sum(1 for c in chunks if c["metadata"]["pattern_type"] == "disruption")))
        
        console.print(table)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="UMIS RAG ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶•")
    parser.add_argument(
        "--agent",
        choices=["explorer", "observer", "quantifier", "validator", "all"],
        default="explorer",
        help="êµ¬ì¶•í•  ì—ì´ì „íŠ¸ ì¸ë±ìŠ¤"
    )
    args = parser.parse_args()
    
    console.print("\n[bold blue]ğŸš€ UMIS RAG ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶•[/bold blue]")
    console.print(f"Agent: {args.agent}\n")
    
    # í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
    if not settings.openai_api_key:
        console.print("[bold red]âŒ OpenAI API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤![/bold red]")
        console.print("\n.env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:")
        console.print("  OPENAI_API_KEY=sk-your-api-key-here\n")
        sys.exit(1)
    
    # ì¸ë±ìŠ¤ ë¹Œë” ì´ˆê¸°í™”
    builder = UMISIndexBuilder()
    
    # ì—ì´ì „íŠ¸ë³„ ì‹¤í–‰
    if args.agent == "explorer":
        builder.build_explorer_index()
    elif args.agent == "all":
        builder.build_explorer_index()
        # TODO: í–¥í›„ ë‹¤ë¥¸ ì—ì´ì „íŠ¸ ì¶”ê°€
    else:
        console.print(f"[yellow]âš ï¸  {args.agent} ì¸ë±ìŠ¤ëŠ” ì•„ì§ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.[/yellow]")
        console.print("í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥: explorer")


if __name__ == "__main__":
    main()

