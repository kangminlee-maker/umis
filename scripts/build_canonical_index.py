#!/usr/bin/env python3
"""
Canonical Index êµ¬ì¶• (v3.0)

data/raw/*.yaml â†’ canonical_index Collection
- ID: CAN-xxxxxxxx
- sections: anchor_path + content_hash
- Lineage ì¶”ì 
- config/schema_registry.yaml 100% ì¤€ìˆ˜
"""

import sys
from pathlib import Path
from datetime import datetime
import hashlib

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from umis_rag.core.schema import SchemaRegistry, generate_id, calculate_content_hash
from umis_rag.core.config import settings
from umis_rag.utils.logger import logger
import yaml
import json
import chromadb
from langchain_openai import OpenAIEmbeddings

class CanonicalIndexBuilder:
    """
    Canonical Index ë¹Œë”
    
    ê¸°ëŠ¥:
    - YAML ì‚¬ë¡€ â†’ ì •ê·œí™” ì²­í¬
    - ID: CAN-xxxxxxxx
    - sections: anchor_path + content_hash
    - Lineage ìƒì„±
    """
    
    def __init__(self):
        self.schema = SchemaRegistry()
        self.data_dir = Path("data/raw")
        
        # Chroma
        self.client = chromadb.PersistentClient(path="data/chroma")
        
        # Embeddings
        self.embeddings = OpenAIEmbeddings(
            model=settings.embedding_model,
            openai_api_key=settings.openai_api_key
        )
        
        logger.info("CanonicalIndexBuilder ì´ˆê¸°í™”")
    
    def load_yaml(self, filename: str):
        """YAML íŒŒì¼ ë¡œë“œ"""
        filepath = self.data_dir / filename
        
        with open(filepath, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def extract_sections(self, pattern_data: dict, pattern_id: str):
        """
        íŒ¨í„´ì—ì„œ Agentë³„ ì„¹ì…˜ ì¶”ì¶œ
        â†’ anchor_path + content_hash ë°©ì‹
        """
        sections = []
        
        # Explorer ì„¹ì…˜
        if 'opportunity_structure' in pattern_data:
            content = yaml.dump(pattern_data['opportunity_structure'])
            sections.append({
                'agent_view': 'explorer',
                'anchor_path': f"{pattern_id}.opportunity_structure",
                'content_hash': calculate_content_hash(content),
                'span_hint': {
                    'tokens': len(content.split())
                }
            })
        
        # Observer ì„¹ì…˜ (í–¥í›„)
        # Quantifier ì„¹ì…˜ (í–¥í›„)
        
        return sections
    
    def build_canonical_chunk(self, pattern_id: str, pattern_data: dict, domain: str):
        """
        Canonical ì²­í¬ ìƒì„± (schema ì¤€ìˆ˜!)
        """
        
        # ID ìƒì„±
        canonical_id = generate_id("CAN", pattern_id)
        
        # ì „ì²´ ë‚´ìš©
        content = yaml.dump(pattern_data, allow_unicode=True)
        
        # Sections
        sections = self.extract_sections(pattern_data, pattern_id)
        
        # Lineage
        lineage = {
            'from': f"yaml:{pattern_id}",  # YAML ì›ë³¸
            'via': [],  # ìµœì´ˆ ìƒì„±
            'evidence_ids': [],
            'created_by': {
                'agent': 'system',
                'overlay_layer': 'core',
                'tenant_id': None
            }
        }
        
        # Chunk (ChromaëŠ” ë³µì¡í•œ ê°ì²´ë¥¼ JSON ë¬¸ìì—´ë¡œ ì €ì¥)
        chunk = {
            'canonical_chunk_id': canonical_id,
            'source_id': pattern_id,
            'domain': domain,
            'version': '6.3.0-alpha',
            'content_type': 'normalized_full',
            'sections': json.dumps(sections),  # list â†’ JSON string
            'total_tokens': len(content.split()),
            'lineage': json.dumps(lineage),  # dict â†’ JSON string
            'embedding_model': 'text-embedding-3-large',
            'embedding_dimension': 3072,
            'embedding_space': 'cosine',
            'created_at': datetime.now().isoformat(),
            'updated_at': datetime.now().isoformat()
        }
        
        return {
            'id': canonical_id,
            'content': content,
            'metadata': chunk
        }
    
    def build(self):
        """Canonical Index ì „ì²´ êµ¬ì¶•"""
        
        logger.info("ğŸ”¨ Canonical Index êµ¬ì¶• ì‹œì‘")
        
        # Collection ìƒì„±
        try:
            self.client.delete_collection("canonical_index")
        except:
            pass
        
        collection = self.client.create_collection(
            name="canonical_index",
            metadata={
                "hnsw:space": "cosine",
                "version": "1.0",
                "architecture": "v3.0"
            }
        )
        
        logger.info("  âœ… canonical_index Collection ìƒì„±")
        
        # Business Model Patterns
        bm_data = self.load_yaml("umis_business_model_patterns.yaml")
        
        chunks = []
        for pattern_id, pattern_data in bm_data.items():
            if pattern_id.startswith('_'):
                continue
            
            chunk = self.build_canonical_chunk(
                pattern_id,
                pattern_data,
                domain='pattern'
            )
            chunks.append(chunk)
        
        logger.info(f"  âœ… Business Model: {len(chunks)}ê°œ ì²­í¬")
        
        # Disruption Patterns
        dp_data = self.load_yaml("umis_disruption_patterns.yaml")
        
        for pattern_id, pattern_data in dp_data.items():
            if pattern_id.startswith('_'):
                continue
            
            chunk = self.build_canonical_chunk(
                pattern_id,
                pattern_data,
                domain='pattern'
            )
            chunks.append(chunk)
        
        logger.info(f"  âœ… Disruption: ì´ {len(chunks)}ê°œ ì²­í¬")
        
        # Embedding ë° ì €ì¥
        logger.info("  ğŸ”„ Embedding ìƒì„± ì¤‘...")
        
        texts = [c['content'] for c in chunks]
        embeddings = self.embeddings.embed_documents(texts)
        
        collection.add(
            ids=[c['id'] for c in chunks],
            documents=texts,
            metadatas=[c['metadata'] for c in chunks],
            embeddings=embeddings
        )
        
        logger.info(f"  âœ… {len(chunks)}ê°œ Canonical ì²­í¬ ì €ì¥ ì™„ë£Œ!")
        
        # ê²€ì¦
        count = collection.count()
        logger.info(f"\nğŸ“Š Canonical Index: {count}ê°œ")
        
        return count


if __name__ == "__main__":
    builder = CanonicalIndexBuilder()
    count = builder.build()
    
    print(f"\nâœ… Canonical Index êµ¬ì¶• ì™„ë£Œ!")
    print(f"ğŸ“Š Collection: canonical_index")
    print(f"ğŸ“ Documents: {count}ê°œ")
    print(f"ğŸ”‘ ID: CAN-xxxxxxxx")
    print(f"âš“ Sections: anchor_path + content_hash")

