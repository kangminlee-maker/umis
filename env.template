# ========================================
# UMIS 환경 변수 설정 (v7.7.0)
# ========================================
#
# 사용법:
#   1. 이 파일을 .env로 복사
#   2. 아래 설정 입력
#   3. 저장
#
# ========================================

# ========================================
# 🎯 UMIS 전역 설정 (6-Agent System)
# ========================================

# LLM 제공자 설정 (전체 시스템 적용)
UMIS_MODE=native
# 옵션:
#   native   - Cursor Agent LLM 사용 (권장, 비용 $0, 최고 품질) ✅ v7.7.0 진짜 구현!
#            
#            Agent별 동작:
#            → Explorer: RAG 검색 → Cursor LLM이 가설 생성 (LLM API 호출 없음)
#            → Observer: RAG 검색만 (시장 구조 패턴 매칭)
#            → Quantifier: RAG 검색만 (계산 방법론 검색)
#            → Validator: RAG 검색 (데이터 소스 85% 커버)
#            → Estimator: 5-Phase (RAG + Web Search, LLM API 없음)
#            → Guardian: 목표/순환/품질 모니터링
#            
#            비용: $0 (RAG 임베딩만, ~$0.0001/요청)
#            워크플로우: Python RAG → Cursor Composer 분석
#
#   external - External API LLM 사용 (자동화, 비용 발생)
#            
#            Agent별 동작:
#            → Explorer: RAG + OpenAI API 호출 → 완성된 가설
#            → 나머지 Agent: native와 동일 (RAG만)
#            
#            비용: ~$0.10/요청 (100회 시 $10)
#            워크플로우: Python RAG + API → 완성된 결과
#            사용 시나리오: 완전 자동화, 배치 처리, cron job
#
# v7.7.0 변경사항:
#   - 이전 (v7.4.0): Native 모드 개념만 존재, 실제로는 External 동작
#   - 현재 (v7.7.0): Native 모드 실제 구현 완료! ✅
#   - LLMProvider 클래스 추가
#   - Explorer Native/External 분기 처리
#   - 테스트: python scripts/test_native_mode.py

# ========================================
# 참고: Estimator (Fermi) Agent - 5-Phase Architecture (v7.7.0)
# ========================================
#
# Estimator는 5-Phase Architecture로 작동합니다.
# Native/External 모드 모두에서 LLM API 호출 없이 동작 (비용 $0)
#
# 용어 정의:
#   - Phase: Estimator 전체 프로세스 단계 (0-4)
#   - Step: Phase 4 (Fermi) 내부 세부 단계 (1-4)
#
# Phase 0: Literal (프로젝트 명시 데이터, 즉시 반환)
# Phase 1: Direct RAG (Tier 1 학습 규칙, <0.5초, 95%+ 커버)
# Phase 2: Validator (확정 데이터 검색, <1초, 85% 처리)
# Phase 3: Guestimation (Tier 2 추정, 3-8초, 80%+ 신뢰도)
# Phase 4: Fermi Decomposition (Tier 3 분해, 10-30초)
#   └─ Step 1: 초기 스캔 (가용 데이터 파악)
#   └─ Step 2: 모형 생성 (3-5개 후보)
#   └─ Step 3: 실행 가능성 체크 (재귀 추정)
#   └─ Step 4: 모형 실행 (Backtracking)
#
# 특징:
#   - 100% 커버리지 (LLM API 없이)
#   - Web Search 자동화 (DuckDuckGo/Google)
#   - 단위 자동 변환, Relevance/Boundary 검증
#
# ⚠️ Deprecated:
#   - 3-Tier Architecture (v7.5.0 이전) → 5-Phase로 대체
#
# 상세: umis_core.yaml (Line 603-693)
#
# ========================================

# ========================================
# 🔑 API Keys
# ========================================

# OpenAI API 키 (필수!)
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic (Claude) API 키 (선택, 벤치마크용)
# 발급: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ========================================
# 🏢 한국 공공 데이터 API (Gap #2 실제 데이터)
# ========================================

# DART (전자공시) API 키
# 발급: https://opendart.fss.or.kr → 인증키 신청/관리
# 무료, 즉시 발급
# 형식: 40자 영숫자
DART_API_KEY=your-dart-api-key-here

# KOSIS (통계청) API 키
# 발급: https://kosis.kr/openapi/index/index.jsp → API 신청
# 무료, 승인 필요 (1-2일)
# ⚠️ 주의: Key에 '=' 문자 포함 시 따옴표로 감싸기!
#   예: KOSIS_API_KEY="abc123=def456=xyz"
KOSIS_API_KEY=your-kosis-api-key-here

# 참고: API Key에 특수문자 (=, &, # 등) 포함 시:
#   - 큰따옴표 사용: KEY="value=with=equals"
#   - 작은따옴표 사용: KEY='value=with=equals'
#   - 둘 다 가능, 큰따옴표 권장

# ========================================
# 🌐 Web Search 설정 (v7.6.2)
# ========================================

# 검색 엔진 선택: "duckduckgo" (무료, 기본) or "google" (유료, 고품질)
WEB_SEARCH_ENGINE=duckduckgo

# Web Search 활성화 여부
WEB_SEARCH_ENABLED=true

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 페이지 크롤링 설정 (v7.7.0+)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 검색 결과의 전체 페이지를 크롤링할지 여부
# true: URL을 방문해서 실제 페이지 내용 추출 (정확도 향상, snippet의 500자 제한 없음)
# false: snippet만 사용 (빠르지만 정보 제한적)
WEB_SEARCH_FETCH_FULL_PAGE=true

# 페이지당 최대 추출 문자 수 (기본 5000자)
WEB_SEARCH_MAX_CHARS=5000

# 페이지 크롤링 타임아웃 (초, 기본 10초)
WEB_SEARCH_TIMEOUT=10

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Google Custom Search (선택적 - google 사용 시만 필요)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# API 키: https://console.cloud.google.com/apis/credentials
# Engine ID: https://programmablesearchengine.google.com/
GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_SEARCH_ENGINE_ID=your-search-engine-id-here

# 비용: $5/1000 쿼리 (100/일 무료)
# 품질: 최고
# 권장: 프로덕션, 품질 중시

# ========================================
# 📦 RAG 설정
# ========================================

# Embedding 모델
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIMENSION=3072

# ========================================
# 🤖 LLM 최적화 전략 (v7.7.0+)
# ========================================
#
# ⚠️ 주의: 이 설정은 UMIS_MODE=external 일 때만 적용됩니다!
#
# UMIS_MODE=native (기본):
#   → Cursor LLM 사용, 아래 설정 무시
#   → 비용: $0 (RAG 임베딩만)
#   → 설정 불필요
#
# UMIS_MODE=external (완전 자동화):
#   → 외부 LLM API 사용
#   → 아래 Phase별 모델 설정 적용
#   → Phase별 최적 모델 자동 선택으로 98% 비용 절감!
#
# External 모드 효과:
#   기존: $15.00/1,000회 (Sonnet Think)
#   최적화: $0.30/1,000회
#   절감: 98% ⭐
#
# Phase별 모델 (External 모드만):
#   Phase 0-2 (45%): gpt-4.1-nano ($0.000033/작업, 1.02초, 100% 정확)
#   Phase 3 (48%): gpt-4o-mini ($0.000121/작업, 4.61초, 100% 정확)
#   Phase 4 (7%): o1-mini ($0.0033/작업, 5-15초, 90-95% 정확)
#
# ========================================

# Phase별 모델 자동 선택 활성화 (External 모드만 적용)
# Native 모드에서는 이 설정이 무시됩니다
USE_PHASE_BASED_ROUTING=true

# Phase 0-2: Literal, Inferred, Formula (45% 작업) - External 모드만
LLM_MODEL_PHASE0_2=gpt-4.1-nano

# Phase 3: Guestimation (48% 작업) - External 모드만
LLM_MODEL_PHASE3=gpt-4o-mini

# Phase 4: Fermi Decomposition (7% 작업) - External 모드만
LLM_MODEL_PHASE4=o1-mini

# Legacy 모델 (하위 호환성, Phase 라우팅 비활성화 시 사용) - External 모드만
LLM_MODEL=gpt-4-turbo-preview
LLM_TEMPERATURE=0.7

# Chroma DB 경로
CHROMA_PERSIST_DIR=./data/chroma

# ========================================
# 🔗 Neo4j 설정 (Knowledge Graph)
# ========================================

NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=umis_password
NEO4J_DATABASE=neo4j

# ========================================
# 🔍 LangSmith 설정 (선택적, 디버깅/모니터링)
# ========================================

# LangSmith Tracing 활성화 (기본: false)
# true로 설정 시 모든 LLM 호출이 LangSmith에 기록됨
LANGCHAIN_TRACING_V2=false

# LangSmith API 키 (활성화 시 필요)
# 받기: https://smith.langchain.com/
LANGCHAIN_API_KEY=your-langchain-api-key-here

# LangSmith 프로젝트명 (기본: umis-rag)
LANGCHAIN_PROJECT=umis-rag

# 용도:
#   - LLM 호출 추적 및 디버깅
#   - 성능 모니터링
#   - 비용 추적
#   - 품질 개선
#
# 권장:
#   - 개발 중: false (불필요)
#   - 디버깅: true (문제 해결 시)
#   - 프로덕션: false (개인정보 보호)

