# ========================================
# UMIS 환경 변수 설정 (v7.11.0)
# ========================================
#
# 사용법:
#   1. 이 파일을 .env로 복사
#   2. 아래 설정 입력
#   3. 저장
#
# ========================================

# ========================================
# 🎯 UMIS 전역 설정 (6-Agent System)
# ========================================

# ========================================
# LLM 모드 설정 (v7.11.0: LLM Complete Abstraction)
# ========================================
LLM_MODE=cursor
#
# 옵션 (2가지만):
#   cursor    - Cursor AI 사용 (무료, 대화형, 권장!) ✅
#   external  - External LLM API 사용 (자동화, Stage별 모델 선택)
#
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# cursor 모드 (기본값, 권장):
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
#   → Cursor AI 직접 사용, API 불필요
#   → 비용: $0 (RAG 임베딩만)
#   → 대화형 추정 (Composer/Chat에서)
#   → 아래 Stage별 모델 설정 무시
#
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# external 모드 (자동화 필요 시):
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
#   → OpenAI/Anthropic API 호출
#   → 아래 LLM_MODEL_STAGE1/2/3 설정 적용
#   → Stage별 최적 모델 자동 선택
#   → 비용: Stage별 차등 과금 (98% 절감)
#
# 참고:
#   - 설정: LLMProvider (Dependency Injection)
#   - 문서: dev_docs/improvements/LLM_COMPLETE_ABSTRACTION_SUMMARY_v7_11_0.md
#   - API 키: OPENAI_API_KEY, ANTHROPIC_API_KEY (아래 🔑 API Keys 섹션)
#
# v7.11.0 변경사항:
#   - LLM Complete Abstraction (LLMProvider 패턴)
#   - cursor/external 두 가지 모드만 존재
#   - Estimator: 4-Stage Fusion Architecture
#   - Agent별 LLM 사용은 아래 Stage별 설정 참조

# ========================================
# 참고: Estimator (Fermi) Agent - 4-Stage Fusion Architecture (v7.11.0)
# ========================================
#
# Estimator는 4-Stage Fusion Architecture로 작동합니다. ⭐ v7.11.0
# Native/External 모드 모두에서 LLM API 호출 없이 동작 (비용 $0)
#
# 용어 정의:
#   - Stage: Estimator 전체 프로세스 단계 (1-4)
#   - source: 추정 소스 (Literal/Prior/Fermi/Fusion)
#   - certainty: LLM 내부 확신도 (high/medium/low)
#
# Stage 1: Evidence Collection (증거 수집, <1초)
#   ├─ Literal: 프로젝트 명시 데이터
#   ├─ Direct RAG: 학습 규칙 (95%+ 커버)
#   ├─ Validator: 확정 데이터 (85% 처리!)
#   └─ Guardrail: 논리적/경험적 제약
#   → Early Return (확정값 발견 시 즉시 반환)
#
# Stage 2: Generative Prior (생성적 사전, ~3초)
#   └─ LLM 직접 값 요청 + certainty 평가
#   → certainty == high → 종료
#
# Stage 3: Structural Explanation (구조적 설명, 3-5초)
#   └─ Fermi 분해 (재귀 없음, max_depth=2)
#      - 변수 식별 → Stage 2로 추정 → 공식 계산
#
# Stage 4: Fusion & Validation (융합, <1초)
#   └─ 모든 Stage 결과 가중 합성 → 최종 값
#
# 주요 변경사항 (v7.11.0):
#   - Phase 0-4 (5단계) → Stage 1-4 (4단계)
#   - Phase 4 재귀 제거 → max_depth=2 고정
#   - confidence (0.0-1.0) → certainty (high/medium/low)
#   - PhaseConfig → Budget (자원 제어)
#   - 속도 향상: 3-10배 (10-30초 → 3-5초)
#
# 특징:
#   - 100% 커버리지 (LLM API 없이)
#   - Web Search 자동화 (DuckDuckGo/Google)
#   - Budget 기반 탐색 (max_llm_calls, max_runtime)
#   - 예측 가능한 실행 시간
#
# ⚠️ Deprecated:
#   - Phase 0-4 Architecture (v7.10.2) → Stage 1-4로 대체
#   - 하위 호환성: compat.py (DeprecationWarning)
#
# 상세: docs/api/ESTIMATOR_API_v7_11_0.md
#
# ========================================

# ========================================
# 🔑 API Keys
# ========================================

# OpenAI API 키 (필수!)
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic (Claude) API 키 (선택, 벤치마크용)
# 발급: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ========================================
# 🏢 한국 공공 데이터 API (Gap #2 실제 데이터)
# ========================================

# DART (전자공시) API 키
# 발급: https://opendart.fss.or.kr → 인증키 신청/관리
# 무료, 즉시 발급
# 형식: 40자 영숫자
DART_API_KEY=your-dart-api-key-here

# KOSIS (통계청) API 키
# 발급: https://kosis.kr/openapi/index/index.jsp → API 신청
# 무료, 승인 필요 (1-2일)
# ⚠️ 주의: Key에 '=' 문자 포함 시 따옴표로 감싸기!
#   예: KOSIS_API_KEY="abc123=def456=xyz"
KOSIS_API_KEY=your-kosis-api-key-here

# 참고: API Key에 특수문자 (=, &, # 등) 포함 시:
#   - 큰따옴표 사용: KEY="value=with=equals"
#   - 작은따옴표 사용: KEY='value=with=equals'
#   - 둘 다 가능, 큰따옴표 권장

# ========================================
# 🌐 Web Search 설정 (v7.6.2)
# ========================================

# 검색 엔진 선택: "duckduckgo" (무료, 기본) or "google" (유료, 고품질)
WEB_SEARCH_ENGINE=duckduckgo

# Web Search 활성화 여부
WEB_SEARCH_ENABLED=true

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 페이지 크롤링 설정 (v7.7.0+)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 검색 결과의 전체 페이지를 크롤링할지 여부
# true: URL을 방문해서 실제 페이지 내용 추출 (정확도 향상, snippet의 500자 제한 없음)
# false: snippet만 사용 (빠르지만 정보 제한적)
WEB_SEARCH_FETCH_FULL_PAGE=true

# 페이지당 최대 추출 문자 수 (기본 5000자)
WEB_SEARCH_MAX_CHARS=5000

# 페이지 크롤링 타임아웃 (초, 기본 10초)
WEB_SEARCH_TIMEOUT=10

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Google Custom Search (선택적 - google 사용 시만 필요)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# API 키: https://console.cloud.google.com/apis/credentials
# Engine ID: https://programmablesearchengine.google.com/
GOOGLE_API_KEY=your-google-api-key-here
GOOGLE_SEARCH_ENGINE_ID=your-search-engine-id-here

# 비용: $5/1000 쿼리 (100/일 무료)
# 품질: 최고
# 권장: 프로덕션, 품질 중시

# ========================================
# 📦 RAG 설정
# ========================================

# Embedding 모델
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIMENSION=3072

# ========================================
# 🤖 LLM 모델 설정 (v7.11.0)
# ========================================
# ⚠️ 주의: LLM_MODE=external일 때만 적용됩니다!
# ========================================
#
# LLM_MODE=cursor:
#   → 아래 설정 모두 무시
#   → Cursor AI 사용 (비용 $0)
#
# LLM_MODE=external:
#   → 아래 모델 설정 적용
#   → OpenAI/Anthropic API 호출
#   → Agent 및 Stage별 자동 라우팅
#
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Agent별 LLM 사용 (External 모드만)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
#
# Observer, Quantifier, Validator, Guardian:
#   - RAG 검색만 (LLM API 호출 없음)
#   - 비용: $0 (임베딩만)
#
# Explorer:
#   - RAG 검색 + LLM API 호출 (가설 생성)
#   - 모델: LLM_MODEL 사용 (아래 설정)
#   - 비용: ~$0.01/요청
#
# Estimator:
#   - 4-Stage Fusion Architecture
#   - Stage별 모델: LLM_MODEL_STAGE1/2/3 사용 (아래 설정)
#   - Stage 1 (Evidence): LLM 미사용
#   - Stage 2 (Prior): LLM_MODEL_STAGE2
#   - Stage 3 (Fermi): LLM_MODEL_STAGE3
#   - Stage 4 (Fusion): LLM 미사용
#
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Estimator Stage별 모델 전략 (External 모드만)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
#
# Stage 1 (Evidence Collection, 85%):
#   - 작업: Literal, RAG, Validator, Guardrail 검색 (LLM 미사용)
#
# Stage 2 (Generative Prior, 10%):
#   - 작업: LLM 직접 추정 + certainty 평가
#   - 권장 모델:
#     - gpt-4o-mini (기본, 빠름, 저렴)
#     - claude-3-5-sonnet-20241022 (Anthropic, 고품질)
#   - 비용: $0.000121/작업, ~3초
#
# Stage 3 (Structural Explanation, 5%):
#   - 작업: Fermi 분해 (재귀 없음, max_depth=2)
#   - 권장 모델:
#     - o1-mini (기본, STEM 최적화)
#     - o3-mini-2025-01-31 (최고 성능)
#     - claude-3-7-sonnet-20250219 (Anthropic Sonnet 3.7)
#   - 비용: $0.0033/작업, 3-5초
#
# Stage 4 (Fusion, <1%):
#   - 작업: 가중 합성 (계산만, LLM 미사용)
#
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 지원 모델 (config/model_configs.yaml)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
#
# OpenAI:
#   - o1: o1-mini, o1, o1-2024-12-17, o1-pro, o1-pro-2025-03-19
#   - o3: o3, o3-2025-04-16, o3-mini, o3-mini-2025-01-31
#   - o4: o4-mini, o4-mini-2025-04-16
#   - gpt-5: gpt-5.1, gpt-5-pro
#   - gpt-4: gpt-4.1, gpt-4.1-mini, gpt-4.1-nano, gpt-4o-mini
#
# Anthropic (Claude):
#   - claude-3-opus-20240229
#   - claude-3-5-sonnet-20241022 (Sonnet 3.5)
#   - claude-3-7-sonnet-20250219 (Sonnet 3.7, 최신)
#   - claude-3-5-haiku-20241022
#
# 신규 모델 추가:
#   1. OPENAI_API_KEY 또는 ANTHROPIC_API_KEY 설정 (위 🔑 섹션)
#   2. config/model_configs.yaml에 모델 정의 추가 (필요시)
#   3. 아래 LLM_MODEL_* 변수에 모델명 입력
#
# ========================================

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 일반 Agent 모델 (Explorer용, External 모드만)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# Explorer가 사용할 기본 LLM 모델
# OpenAI: gpt-4-turbo-preview, gpt-4o-mini, gpt-4o, gpt-5.1
# Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7

# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Estimator Stage별 모델 (External 모드만)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

# Stage별 모델 자동 선택 활성화
USE_STAGE_BASED_ROUTING=true

# Stage 1: Evidence Collection (LLM 미사용, 설정 불필요)

# Stage 2: Generative Prior
# 권장: gpt-4o-mini (OpenAI), claude-3-5-sonnet-20241022 (Anthropic)
LLM_MODEL_STAGE2=gpt-4o-mini

# Stage 3: Structural Explanation
# 권장: o1-mini (OpenAI), claude-3-7-sonnet-20250219 (Anthropic)
LLM_MODEL_STAGE3=o1-mini

# Stage 4: Fusion (LLM 미사용, 설정 불필요)

# Chroma DB 경로
CHROMA_PERSIST_DIR=./data/chroma

# ========================================
# 🔗 Neo4j 설정 (Knowledge Graph)
# ========================================

NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=umis_password
NEO4J_DATABASE=neo4j

# ========================================
# 🔍 LangSmith 설정 (선택적, 디버깅/모니터링)
# ========================================

# LangSmith Tracing 활성화 (기본: false)
# true로 설정 시 모든 LLM 호출이 LangSmith에 기록됨
LANGCHAIN_TRACING_V2=false

# LangSmith API 키 (활성화 시 필요)
# 받기: https://smith.langchain.com/
LANGCHAIN_API_KEY=your-langchain-api-key-here

# LangSmith 프로젝트명 (기본: umis-rag)
LANGCHAIN_PROJECT=umis-rag

# 용도:
#   - LLM 호출 추적 및 디버깅
#   - 성능 모니터링
#   - 비용 추적
#   - 품질 개선
#
# 권장:
#   - 개발 중: false (불필요)
#   - 디버깅: true (문제 해결 시)
#   - 프로덕션: false (개인정보 보호)

