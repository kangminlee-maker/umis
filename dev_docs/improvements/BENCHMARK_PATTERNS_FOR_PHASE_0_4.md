# ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤í¬ë¦½íŠ¸ â†’ Phase 0-4 ì ìš© ê°€ëŠ¥ íŒ¨í„´ ë¶„ì„

**ë‚ ì§œ**: 2025-11-25  
**ë²„ì „**: v7.8.1  
**ëŒ€ìƒ ìŠ¤í¬ë¦½íŠ¸**: `scripts/benchmark_llm_models_2025.py`

---

## ğŸ“‹ ìš”ì•½

ë²¤ì¹˜ë§ˆí‚¹ ê³¼ì •ì—ì„œ ë„ì…í•œ **ê²€ì¦ëœ íŒ¨í„´**ë“¤ì„ ì‹¤ì œ Phase 0-4 ì¶”ì • ê³¼ì •ì— ì ìš©í•˜ì—¬, **ì•ˆì •ì„±**, **ì •í™•ì„±**, **íš¨ìœ¨ì„±**ì„ ë†’ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ¯ ì ìš© ê°€ëŠ¥í•œ í•µì‹¬ íŒ¨í„´

### 1. **JSON íŒŒì‹± ê°•í™” (Robust Parsing)** â­ ìš°ì„ ìˆœìœ„ 1

**ë²¤ì¹˜ë§ˆí¬ì—ì„œ ë°œê²¬í•œ íŒ¨í„´**:

```python:422:436:scripts/benchmark_llm_models_2025.py
            # JSON ì¶”ì¶œ ì‹œë„ (```json ... ``` ë¸”ë¡ ë˜ëŠ” ì¼ë°˜ JSON)
            try:
                # ì½”ë“œ ë¸”ë¡ ë‚´ JSON ì¶”ì¶œ
                if '```json' in content:
                    json_start = content.find('```json') + 7
                    json_end = content.find('```', json_start)
                    content = content[json_start:json_end].strip()
                elif '```' in content:
                    json_start = content.find('```') + 3
                    json_end = content.find('```', json_start)
                    content = content[json_start:json_end].strip()
                
                parsed = json.loads(content)
            except json.JSONDecodeError:
                parsed = {'raw_response': content, 'parse_error': True}
```

**Phase 4ì— ì´ë¯¸ ì ìš©ë¨**:

```python:1268:1291:umis_rag/agents/estimator/phase4_fermi.py
            # 2. JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„ (```json ... ```)
            content = llm_output
            
            if '```json' in content:
                json_start = content.find('```json') + 7
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
                logger.info(f"{'  ' * depth}        [Parser] JSON ë¸”ë¡ ê°ì§€ (```json)")
            elif '```' in content:
                json_start = content.find('```') + 3
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
                logger.info(f"{'  ' * depth}        [Parser] JSON ë¸”ë¡ ê°ì§€ (```)")
            else:
                logger.info(f"{'  ' * depth}        [Parser] ì½”ë“œ ë¸”ë¡ ì—†ìŒ, ì „ì²´ íŒŒì‹± ì‹œë„")
            
            # 3. JSON íŒŒì‹± ì‹œë„
            try:
                data = json.loads(content)
                logger.info(f"{'  ' * depth}        [Parser] JSON íŒŒì‹± ì„±ê³µ")
            except json.JSONDecodeError:
                # 4. YAMLë¡œ ì „ì²´ íŒŒì‹± ì‹œë„ (Fallback)
                logger.info(f"{'  ' * depth}        [Parser] JSON ì‹¤íŒ¨, YAML ì‹œë„")
                data = yaml.safe_load(llm_output)
```

**ìƒíƒœ**: âœ… **ì´ë¯¸ ì ìš©ë¨** (v7.8.1 Structural Fixì—ì„œ êµ¬í˜„)

**ê°œì„  ì œì•ˆ**:
- Phase 3ì˜ `AIAugmentedEstimationSource`ì—ì„œ External API êµ¬í˜„ ì‹œ ë™ì¼í•œ íŒ¨í„´ ì ìš©
- ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”: `parse_error` í”Œë˜ê·¸ë¥¼ Phase 4ì—ì„œë„ í™œìš©

---

### 2. **Retry ë©”ì»¤ë‹ˆì¦˜ with Backoff** â­ ìš°ì„ ìˆœìœ„ 2

**ë²¤ì¹˜ë§ˆí¬ íŒ¨í„´**:

```python:367:376:scripts/benchmark_llm_models_2025.py
    @backoff.on_exception(
        backoff.expo,
        (Exception),
        max_tries=3,
        max_time=30,
        giveup=lambda e: "429" not in str(e) and "rate limit" not in str(e).lower() and "timeout" not in str(e).lower()
    )
    def _call_openai_with_retry(self, api_params: Dict) -> Any:
        """OpenAI API í˜¸ì¶œ with retry"""
        return self.openai_client.chat.completions.create(**api_params)
```

**ì ìš© ë°©ë²•**:

Phase 4ì˜ `_generate_llm_models`ì— Retry ë¡œì§ ì¶”ê°€:

```python
# umis_rag/agents/estimator/phase4_fermi.py

import backoff

class Phase4FermiDecomposition:
    
    @backoff.on_exception(
        backoff.expo,
        (Exception),
        max_tries=3,
        max_time=30,
        giveup=lambda e: "429" not in str(e) and "rate limit" not in str(e).lower()
    )
    def _call_llm_with_retry(self, api_params: Dict) -> Any:
        """LLM API í˜¸ì¶œ with retry"""
        model_config = self.model_config  # selfì—ì„œ ê°€ì ¸ì˜¤ê¸°
        
        if model_config.api_type == 'responses':
            return self.llm_client.responses.create(**api_params)
        elif model_config.api_type == 'chat':
            return self.llm_client.chat.completions.create(**api_params)
        else:
            raise ValueError(f"Unsupported api_type: {model_config.api_type}")
    
    def _generate_llm_models(self, question, context, depth):
        # ... ê¸°ì¡´ ì½”ë“œ ...
        
        # Retry ì ìš©
        try:
            response = self._call_llm_with_retry(api_params)
        except Exception as e:
            logger.error(f"{'  ' * depth}      âŒ LLM í˜¸ì¶œ ì‹¤íŒ¨ (ì¬ì‹œë„ ì†Œì§„): {e}")
            return []
```

**ì¥ì **:
- Rate Limit ì—ëŸ¬ ìë™ ì¬ì‹œë„
- Timeout ì—ëŸ¬ ë³µì›ë ¥ í–¥ìƒ
- ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ API ë¶€í•˜ ì™„í™”

**ìƒíƒœ**: â³ **ë¯¸ì ìš©**

**ìš°ì„ ìˆœìœ„**: **Phase 3 External API êµ¬í˜„ê³¼ í•¨ê»˜ ì ìš© ê¶Œì¥**

---

### 3. **API íƒ€ì…ë³„ ë¶„ê¸° ë¡œì§** âœ… ì´ë¯¸ ì ìš©ë¨

**ë²¤ì¹˜ë§ˆí¬ íŒ¨í„´**:

```python:383:413:scripts/benchmark_llm_models_2025.py
            # ëª¨ë¸ íƒ€ì… êµ¬ë¶„
            is_o_series = model.startswith(('o1', 'o3', 'o4'))  # o1/o3/o4 ì‹œë¦¬ì¦ˆ
            is_gpt5 = model.startswith('gpt-5')  # gpt-5 ì‹œë¦¬ì¦ˆ
            is_reasoning_model = is_o_series or is_gpt5
            
            messages = [{"role": "user", "content": scenario['prompt']}]
            
            if not is_reasoning_model:
                messages.insert(0, {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."
                })
            
            # API í˜¸ì¶œ íŒŒë¼ë¯¸í„° êµ¬ì„±
            api_params = {
                "model": model,
                "messages": messages
            }
            
            # íŒŒë¼ë¯¸í„° ì¶”ê°€ (ëª¨ë¸ë³„ ì°¨ë³„í™”)
            if is_reasoning_model:
                # o1/o3/o4: low/medium/high, gpt-5: minimal/low/medium/high
                if is_o_series:
                    api_params["reasoning_effort"] = "medium"  # o ì‹œë¦¬ì¦ˆ ê¸°ë³¸ê°’
                else:  # gpt-5
                    api_params["reasoning_effort"] = "low"  # gpt-5 ê· í˜•ì¡íŒ ì„¤ì •
            else:
                # ì¼ë°˜ ëª¨ë¸: temperature ì‚¬ìš©
                api_params["temperature"] = 0.2
                api_params["response_format"] = {"type": "json_object"}
```

**Phase 4ì— ì´ë¯¸ ì ìš©ë¨**:

`model_configs.yaml`ì—ì„œ ëª¨ë¸ë³„ ì„¤ì • ê´€ë¦¬:

```yaml:28:50:config/model_configs.yaml
  o1-mini:
    api_type: responses
    max_output_tokens: 16000
    reasoning_effort:
      support: true
      default: medium
    cost_per_1m_input: 1.10
    cost_per_1m_output: 4.40
  
  gpt-4o-mini:
    api_type: chat
    max_output_tokens: 16384
    temperature: 0.7
    cost_per_1m_input: 0.15
    cost_per_1m_output: 0.60
```

`ModelConfig.build_api_params()`ì—ì„œ ìë™ìœ¼ë¡œ ì ì ˆí•œ íŒŒë¼ë¯¸í„° êµ¬ì„±.

**ìƒíƒœ**: âœ… **ì´ë¯¸ ì ìš©ë¨** (Model Config System v7.8.0)

---

### 4. **í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ (Quality Scoring)** â­ ìš°ì„ ìˆœìœ„ 3

**ë²¤ì¹˜ë§ˆí¬ íŒ¨í„´**:

```python:609:648:scripts/benchmark_llm_models_2025.py
    def _evaluate_quality(self, response: Dict, expected: Dict) -> Dict[str, Any]:
        """í’ˆì§ˆ í‰ê°€"""
        score = {
            'has_value': 'value' in response,
            'has_confidence': 'confidence' in response,
            'has_reasoning': 'reasoning' in response or 'reasoning_detail' in response,
            'has_models': 'models' in response or 'decomposition' in response,
            'json_valid': 'parse_error' not in response,
            'value_in_range': False,
            'confidence_sufficient': False
        }
        
        # ê°’ ë²”ìœ„ ì²´í¬
        if score['has_value'] and 'value_range' in expected:
            value = response.get('value')
            if isinstance(value, (int, float)):
                min_val, max_val = expected['value_range']
                score['value_in_range'] = min_val <= value <= max_val
        elif score['has_value'] and 'value' in expected:
            score['value_in_range'] = response.get('value') == expected['value']
        
        # ì‹ ë¢°ë„ ì²´í¬
        if score['has_confidence'] and 'confidence_min' in expected:
            confidence = response.get('confidence', 0)
            score['confidence_sufficient'] = confidence >= expected['confidence_min']
        
        # ì´ì  ê³„ì‚° (0-100)
        total_score = 0
        if score['json_valid']: total_score += 20
        if score['has_value']: total_score += 20
        if score['has_confidence']: total_score += 15
        if score['has_reasoning']: total_score += 15
        if score['has_models']: total_score += 10
        if score['value_in_range']: total_score += 15
        if score['confidence_sufficient']: total_score += 5
        
        score['total_score'] = total_score
        
        return score
```

**Phase 4 ì ìš© ë°©ì•ˆ**:

```python
# umis_rag/agents/estimator/phase4_fermi.py

class Phase4FermiDecomposition:
    
    def _evaluate_model_quality(self, model: FermiModel, llm_output: str) -> Dict[str, Any]:
        """
        ìƒì„±ëœ ëª¨í˜•ì˜ í’ˆì§ˆ í‰ê°€
        
        Returns:
            {
                'has_formula': bool,
                'has_variables': bool,
                'variable_count_reasonable': bool,  # 2-6ê°œ
                'formula_parsable': bool,
                'total_score': int (0-100)
            }
        """
        score = {
            'has_formula': bool(model.formula),
            'has_variables': len(model.variables) > 0,
            'variable_count_reasonable': 2 <= len(model.variables) <= 6,
            'formula_parsable': False,
            'all_variables_defined': False
        }
        
        # ìˆ˜ì‹ íŒŒì‹± ê°€ëŠ¥ ì—¬ë¶€
        try:
            # ê°„ë‹¨í•œ ê²€ì¦: ë³€ìˆ˜ëª…ì´ ìˆ˜ì‹ì— í¬í•¨ë˜ëŠ”ì§€
            formula = model.formula.lower()
            for var in model.variables.values():
                if var.name.lower() not in formula:
                    score['formula_parsable'] = False
                    break
            else:
                score['formula_parsable'] = True
        except:
            score['formula_parsable'] = False
        
        # ëª¨ë“  ë³€ìˆ˜ê°€ ì •ì˜ë˜ì—ˆëŠ”ì§€
        score['all_variables_defined'] = all(
            var.available or var.need_estimate for var in model.variables.values()
        )
        
        # ì´ì  ê³„ì‚°
        total_score = 0
        if score['has_formula']: total_score += 25
        if score['has_variables']: total_score += 25
        if score['variable_count_reasonable']: total_score += 20
        if score['formula_parsable']: total_score += 20
        if score['all_variables_defined']: total_score += 10
        
        score['total_score'] = total_score
        
        return score
    
    def _step2_generate_models(self, question, context, depth):
        # ... ê¸°ì¡´ ë¡œì§ ...
        
        models = self._generate_default_models(question, context, depth)
        
        # í’ˆì§ˆ í‰ê°€ ì¶”ê°€
        for model in models:
            quality = self._evaluate_model_quality(model, "")
            logger.info(f"{'  ' * depth}        [Quality] {model.model_id}: {quality['total_score']}/100")
            
            # í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬ ì‹œ ê²½ê³ 
            if quality['total_score'] < 60:
                logger.warning(f"{'  ' * depth}        âš ï¸  ë‚®ì€ í’ˆì§ˆ: {model.model_id} ({quality['total_score']}/100)")
        
        return models
```

**ì¥ì **:
- ìƒì„±ëœ ëª¨í˜•ì˜ í’ˆì§ˆì„ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€
- í’ˆì§ˆ ê¸°ì¤€ ë¯¸ë‹¬ ëª¨í˜• ì¡°ê¸° í•„í„°ë§
- ë””ë²„ê¹… ë° ê°œì„  ìš©ì´

**ìƒíƒœ**: â³ **ë¯¸ì ìš©**

---

### 5. **ë¹„ìš© ì¶”ì  ì‹œìŠ¤í…œ (Cost Tracking)** â³ ìš°ì„ ìˆœìœ„ 4

**ë²¤ì¹˜ë§ˆí¬ íŒ¨í„´**:

```python:599:607:scripts/benchmark_llm_models_2025.py
    def _calculate_cost(self, model: str, input_tokens: int, output_tokens: int) -> float:
        """ë¹„ìš© ê³„ì‚°"""
        if model not in self.pricing:
            return 0.0
        
        rates = self.pricing[model]
        cost = (input_tokens / 1_000_000 * rates['input'] +
                output_tokens / 1_000_000 * rates['output'])
        return round(cost, 6)
```

**Phase 4 ì ìš© ë°©ì•ˆ**:

```python
# umis_rag/agents/estimator/phase4_fermi.py

class Phase4FermiDecomposition:
    
    def __init__(self, ...):
        # ... ê¸°ì¡´ ì´ˆê¸°í™” ...
        
        # ë¹„ìš© ì¶”ì 
        self.cost_tracker = {
            'total_cost': 0.0,
            'api_calls': 0,
            'total_tokens': {'input': 0, 'output': 0}
        }
    
    def _track_cost(self, model_name: str, usage: Any):
        """ë¹„ìš© ì¶”ì """
        from umis_rag.core.model_configs import get_model_config
        
        model_config = get_model_config(model_name)
        
        input_tokens = usage.prompt_tokens if hasattr(usage, 'prompt_tokens') else usage.input_tokens
        output_tokens = usage.completion_tokens if hasattr(usage, 'completion_tokens') else usage.output_tokens
        
        cost = (
            input_tokens / 1_000_000 * model_config.cost_per_1m_input +
            output_tokens / 1_000_000 * model_config.cost_per_1m_output
        )
        
        self.cost_tracker['total_cost'] += cost
        self.cost_tracker['api_calls'] += 1
        self.cost_tracker['total_tokens']['input'] += input_tokens
        self.cost_tracker['total_tokens']['output'] += output_tokens
        
        logger.info(f"[Cost] API í˜¸ì¶œ ë¹„ìš©: ${cost:.6f} (ëˆ„ì : ${self.cost_tracker['total_cost']:.6f})")
    
    def _generate_llm_models(self, question, context, depth):
        # ... API í˜¸ì¶œ ...
        
        response = self.llm_client.chat.completions.create(**api_params)
        
        # ë¹„ìš© ì¶”ì 
        self._track_cost(model_config.model_name, response.usage)
        
        # ... ë‚˜ë¨¸ì§€ ë¡œì§ ...
    
    def get_cost_summary(self) -> Dict:
        """ë¹„ìš© ìš”ì•½ ë°˜í™˜"""
        return {
            'total_cost_usd': round(self.cost_tracker['total_cost'], 6),
            'api_calls': self.cost_tracker['api_calls'],
            'total_tokens': self.cost_tracker['total_tokens'],
            'avg_cost_per_call': round(
                self.cost_tracker['total_cost'] / self.cost_tracker['api_calls'], 6
            ) if self.cost_tracker['api_calls'] > 0 else 0.0
        }
```

**ì¥ì **:
- ì‹¤ì‹œê°„ ë¹„ìš© ëª¨ë‹ˆí„°ë§
- API í˜¸ì¶œ íšŸìˆ˜ ì¶”ì 
- ë¹„ìš© ìµœì í™” ê·¼ê±° ë°ì´í„°

**ìƒíƒœ**: â³ **ë¯¸ì ìš©**

---

### 6. **Rate Limiting ìë™ ëŒ€ê¸°** â³ ìš°ì„ ìˆœìœ„ 5

**ë²¤ì¹˜ë§ˆí¬ íŒ¨í„´**:

```python:121:140:scripts/benchmark_llm_models_2025.py
                            # Rate limiting: ë” ê¸´ ëŒ€ê¸° ì‹œê°„ ì ìš©
                            if model.startswith('o'):  # thinking ëª¨ë¸ì€ ë” ê¸´ ëŒ€ê¸°
                                time.sleep(3)
                            else:
                                time.sleep(1.5)
                        
                        except Exception as e:
                            print(f"   âŒ {model}: ì˜¤ë¥˜ - {str(e)}")
                            self.results.append({
                                'provider': 'openai',
                                'model': model,
                                'scenario': scenario['name'],
                                'error': str(e),
                                'timestamp': datetime.now().isoformat(),
                                'success': False
                            })
                            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë” ê¸´ ëŒ€ê¸°
                            time.sleep(3)
```

**Phase 4 ì ìš© ë°©ì•ˆ**:

```python
# umis_rag/agents/estimator/phase4_fermi.py

import time

class Phase4FermiDecomposition:
    
    def _apply_rate_limiting(self, model_name: str, is_error: bool = False):
        """Rate Limiting ìë™ ëŒ€ê¸°"""
        
        if is_error:
            # ì—ëŸ¬ ë°œìƒ ì‹œ 3ì´ˆ ëŒ€ê¸°
            time.sleep(3)
            logger.info("[Rate Limit] ì—ëŸ¬ í›„ 3ì´ˆ ëŒ€ê¸° ì™„ë£Œ")
            return
        
        # ëª¨ë¸ íƒ€ì…ë³„ ëŒ€ê¸° ì‹œê°„
        if model_name.startswith('o1') or model_name.startswith('o3'):
            # Reasoning ëª¨ë¸: 3ì´ˆ
            time.sleep(3)
            logger.debug("[Rate Limit] Reasoning ëª¨ë¸ 3ì´ˆ ëŒ€ê¸° ì™„ë£Œ")
        elif model_name.startswith('gpt-5'):
            # GPT-5: 2ì´ˆ
            time.sleep(2)
            logger.debug("[Rate Limit] GPT-5 2ì´ˆ ëŒ€ê¸° ì™„ë£Œ")
        else:
            # ì¼ë°˜ ëª¨ë¸: 1.5ì´ˆ
            time.sleep(1.5)
            logger.debug("[Rate Limit] ì¼ë°˜ ëª¨ë¸ 1.5ì´ˆ ëŒ€ê¸° ì™„ë£Œ")
    
    def _estimate_variable(self, var_name, question, parent_depth):
        # ... Phase 3 ì‹œë„ ...
        
        try:
            phase3_result = self.phase3.estimate(question, context)
        except Exception as e:
            logger.error(f"Phase 3 ì‹¤íŒ¨: {e}")
            self._apply_rate_limiting(self.llm_mode, is_error=True)
        
        # ... Phase 4 ì¬ê·€ ...
        
        if parent_depth + 1 < self.max_depth:
            try:
                recursive_result = self.estimate(question, depth=parent_depth + 1)
                
                # ì„±ê³µ ì‹œ ì¼ë°˜ ëŒ€ê¸°
                self._apply_rate_limiting(self.llm_mode, is_error=False)
                
            except Exception as e:
                logger.error(f"ì¬ê·€ ì‹¤íŒ¨: {e}")
                self._apply_rate_limiting(self.llm_mode, is_error=True)
```

**ì¥ì **:
- Rate Limit ì—ëŸ¬ ì‚¬ì „ ë°©ì§€
- API ê³µê¸‰ì ì •ì±… ì¤€ìˆ˜
- ì•ˆì •ì ì¸ ëŒ€ìš©ëŸ‰ ì¶”ì •

**ìƒíƒœ**: â³ **ë¯¸ì ìš©**

---

## ğŸ“Š ìš°ì„ ìˆœìœ„ ì •ë¦¬

| ìˆœìœ„ | íŒ¨í„´ | ìƒíƒœ | ì ìš© ëŒ€ìƒ | ë‚œì´ë„ | íš¨ê³¼ |
|------|------|------|-----------|--------|------|
| 1 | JSON íŒŒì‹± ê°•í™” | âœ… ì™„ë£Œ | Phase 4 | ë‚®ìŒ | ë†’ìŒ |
| 2 | Retry ë©”ì»¤ë‹ˆì¦˜ | â³ ë¯¸ì ìš© | Phase 3, 4 | ì¤‘ê°„ | ë†’ìŒ |
| 3 | í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ | â³ ë¯¸ì ìš© | Phase 4 | ì¤‘ê°„ | ì¤‘ê°„ |
| 4 | ë¹„ìš© ì¶”ì  | â³ ë¯¸ì ìš© | Phase 3, 4 | ë‚®ìŒ | ì¤‘ê°„ |
| 5 | Rate Limiting | â³ ë¯¸ì ìš© | Phase 3, 4 | ë‚®ìŒ | ì¤‘ê°„ |
| - | API íƒ€ì… ë¶„ê¸° | âœ… ì™„ë£Œ | ì „ì²´ | - | - |

---

## ğŸš€ ì ìš© ë¡œë“œë§µ

### Phase 1 (ì¦‰ì‹œ): Phase 3 External API êµ¬í˜„

**ì‘ì—…**:
1. `AIAugmentedEstimationSource.collect()` External API êµ¬í˜„
2. JSON íŒŒì‹± ê°•í™” íŒ¨í„´ ì ìš© (ë²¤ì¹˜ë§ˆí¬ì™€ ë™ì¼)
3. Retry ë©”ì»¤ë‹ˆì¦˜ í†µí•©

**ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„

---

### Phase 2 (ë‹¨ê¸°): Phase 4 ì•ˆì •ì„± ê°•í™”

**ì‘ì—…**:
1. Retry ë©”ì»¤ë‹ˆì¦˜ ì¶”ê°€
2. í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ í†µí•©
3. Phase 4 íŒŒì‹± ì—ëŸ¬ ë””ë²„ê¹… ì™„ë£Œ

**ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„

---

### Phase 3 (ì¤‘ê¸°): ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”

**ì‘ì—…**:
1. ë¹„ìš© ì¶”ì  ì‹œìŠ¤í…œ êµ¬ì¶•
2. Rate Limiting ìë™í™”
3. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

**ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„

---

## ğŸ“ ì¶”ê°€ ì œì•ˆ

### 1. **í†µí•© íŒŒì‹± ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜**

ë²¤ì¹˜ë§ˆí¬ì™€ Phase 4ì—ì„œ ì¤‘ë³µëœ íŒŒì‹± ë¡œì§ì„ í†µí•©:

```python
# umis_rag/utils/llm_parsing.py

import json
import yaml
import re
from typing import Any, Optional, Dict

def parse_llm_response(
    content: str,
    prefer_format: str = 'json'  # 'json' or 'yaml'
) -> Optional[Dict[str, Any]]:
    """
    LLM ì‘ë‹µì—ì„œ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ
    
    ì§€ì› í˜•ì‹:
    - ```json ... ```
    - ```yaml ... ```
    - ``` ... ``` (ì¼ë°˜ ì½”ë“œ ë¸”ë¡)
    - Raw JSON/YAML
    
    Returns:
        íŒŒì‹±ëœ Dict ë˜ëŠ” None
    """
    try:
        # 1. JSON ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        if '```json' in content:
            json_start = content.find('```json') + 7
            json_end = content.find('```', json_start)
            content = content[json_start:json_end].strip()
            return json.loads(content)
        
        # 2. YAML ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
        elif '```yaml' in content:
            yaml_start = content.find('```yaml') + 7
            yaml_end = content.find('```', yaml_start)
            content = content[yaml_start:yaml_end].strip()
            return yaml.safe_load(content)
        
        # 3. ì¼ë°˜ ì½”ë“œ ë¸”ë¡
        elif '```' in content:
            block_start = content.find('```') + 3
            block_end = content.find('```', block_start)
            content = content[block_start:block_end].strip()
            
            # JSON ì‹œë„
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                pass
            
            # YAML ì‹œë„
            try:
                return yaml.safe_load(content)
            except yaml.YAMLError:
                pass
        
        # 4. Raw content íŒŒì‹±
        if prefer_format == 'json':
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                return yaml.safe_load(content)
        else:
            try:
                return yaml.safe_load(content)
            except yaml.YAMLError:
                return json.loads(content)
    
    except Exception as e:
        return None
```

**ì‚¬ìš©**:

```python
# Phase 4
llm_output = response.choices[0].message.content
parsed = parse_llm_response(llm_output, prefer_format='yaml')

# Phase 3
llm_output = response.choices[0].message.content
parsed = parse_llm_response(llm_output, prefer_format='json')

# ë²¤ì¹˜ë§ˆí¬
content = response.choices[0].message.content
parsed = parse_llm_response(content, prefer_format='json')
```

---

### 2. **í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì¬ì‚¬ìš©**

ë²¤ì¹˜ë§ˆí¬ì˜ Phase 0-4 ì‹œë‚˜ë¦¬ì˜¤ë¥¼ **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**ë¡œ í™œìš©:

```python
# tests/test_estimator_phases.py

import pytest
from umis_rag.agents.estimator import EstimatorRAG

class TestEstimatorPhases:
    
    @pytest.fixture
    def estimator(self):
        return EstimatorRAG(llm_mode='gpt-4o-mini')
    
    def test_phase0_literal_lookup(self, estimator):
        """Phase 0: Literal Lookup"""
        question = "í•œêµ­ B2B SaaS ì›” ARPUëŠ”?"
        
        # í”„ë¡œì íŠ¸ ë°ì´í„°ì— í¬í•¨
        estimator.project_data = {
            'korea_b2b_saas_monthly_arpu': 200000
        }
        
        result = estimator.estimate(question)
        
        assert result['phase'] == 0
        assert result['value'] == 200000
        assert result['confidence'] >= 0.9
    
    def test_phase1_direct_rag(self, estimator):
        """Phase 1: Direct RAG"""
        question = "ì½”ì›¨ì´ ë Œíƒˆ ARPUëŠ”?"
        
        result = estimator.estimate(question)
        
        assert result['phase'] in [1, 2]  # Phase 1 or 2
        assert 30000 <= result['value'] <= 35000
    
    # ... Phase 2, 3, 4 í…ŒìŠ¤íŠ¸ ...
```

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ ì‚¬í•­

### ì¦‰ì‹œ ì ìš© (High Priority)

1. âœ… **JSON íŒŒì‹± ê°•í™”** - ì´ë¯¸ ì™„ë£Œ
2. â³ **Phase 3 External API + Retry** - Phase 3 êµ¬í˜„ê³¼ í•¨ê»˜
3. â³ **í†µí•© íŒŒì‹± ìœ í‹¸ë¦¬í‹°** - ì½”ë“œ ì¤‘ë³µ ì œê±°

### ë‹¨ê¸° ì ìš© (Medium Priority)

4. â³ **í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ** - Phase 4 ëª¨í˜• í•„í„°ë§
5. â³ **ë¹„ìš© ì¶”ì  ì‹œìŠ¤í…œ** - ìš´ì˜ ìµœì í™”

### ì¥ê¸° ì ìš© (Low Priority)

6. â³ **Rate Limiting ìë™í™”** - ëŒ€ìš©ëŸ‰ ì¶”ì • ì‹œ
7. â³ **ë²¤ì¹˜ë§ˆí¬ ì‹œë‚˜ë¦¬ì˜¤ â†’ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸** - íšŒê·€ ë°©ì§€

---

**ë¬¸ì„œ ì¢…ë£Œ**


