# LLM Mode ì™„ì „ ì¶”ìƒí™” êµ¬í˜„ ê³„íš (ëŒ€ì•ˆ 1)

**ì‘ì„±ì¼**: 2025-11-26
**ë²„ì „**: v7.11.0
**ëª©í‘œ**: Native/External ë¶„ê¸°ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ë ˆì´ì–´ì—ì„œ **ì™„ì „íˆ** ì œê±°

---

## ğŸ¯ ìµœì¢… ëª©í‘œ ìƒíƒœ

### Estimator ì½”ë“œ (ë¹„ì¦ˆë‹ˆìŠ¤ ë ˆì´ì–´)

```python
class EstimatorRAG:
    def __init__(self, llm_provider: Optional[LLMProvider] = None):
        # âœ… LLMProvider ì¸í„°í˜ì´ìŠ¤ë§Œ ì˜ì¡´
        self.llm_provider = llm_provider or get_default_llm_provider()
        
        # âŒ ì œê±°: self.llm_mode, native_mode, external_mode
    
    def estimate(self, question: str, ...) -> EstimationResult:
        """4-Stage ì¶”ì • (ë¶„ê¸° ì—†ìŒ!)"""
        
        # Stage 1: Evidence Collection
        evidence = self.evidence_collector.collect(...)
        
        # Stage 2: Prior Estimation
        llm = self.llm_provider.get_llm("prior_estimation")
        prior_result = llm.estimate(question, context)
        
        # Early Return ì²´í¬
        if prior_result.certainty == "high":
            return prior_result
        
        # Stage 3: Fermi Decomposition
        llm = self.llm_provider.get_llm("fermi_decomposition")
        fermi_result = llm.decompose(question, budget)
        
        # Stage 4: Fusion
        return self._fuse_results(evidence, prior_result, fermi_result)
```

**í•µì‹¬**: `llm_provider.get_llm(task)` í˜¸ì¶œë§Œ ì¡´ì¬, ë¶„ê¸° **0ê°œ**

---

## ğŸ“ ì•„í‚¤í…ì²˜ ì„¤ê³„

### 1. ê³„ì¸µ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ë¹„ì¦ˆë‹ˆìŠ¤ ë ˆì´ì–´ (Estimator)                               â”‚
â”‚  - EstimatorRAG                                           â”‚
â”‚  - PriorEstimator                                         â”‚
â”‚  - FermiEstimator                                         â”‚
â”‚  - EvidenceCollector                                      â”‚
â”‚  âŒ llm_mode ëª¨ë¦„, ë¶„ê¸° ì—†ìŒ                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ LLMProvider Interface (ì˜ì¡´ì„± ì—­ì „)
                  â”‚
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì¶”ìƒí™” ë ˆì´ì–´ (Interface)                                 â”‚
â”‚  - LLMProvider (ABC)                                      â”‚
â”‚  - BaseLLM (ABC)                                          â”‚
â”‚  - TaskType (Enum)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CursorLLMProviderâ”‚  â”‚ExternalLLMProviderâ”‚
â”‚  (Native êµ¬í˜„)   â”‚  â”‚  (External êµ¬í˜„) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - CursorLLM      â”‚  â”‚ - ExternalLLM    â”‚
â”‚ - í¬ë§·ë§Œ ë°˜í™˜    â”‚  â”‚ - API ì‹¤ì œ í˜¸ì¶œ  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Infrastructure ë ˆì´ì–´                                     â”‚
â”‚  - ModelRouter (Task â†’ Stage â†’ Model ì„ íƒ)                â”‚
â”‚  - ModelConfig (model_configs.yaml)                       â”‚
â”‚  - Settings (.env)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Dependency Inversion

```
High-level (Estimator) â†’ Interface (LLMProvider) â† Low-level (CursorLLMProvider, ExternalLLMProvider)
                              â†‘
                         ì˜ì¡´ì„± ì—­ì „
```

---

## ğŸ”§ êµ¬í˜„ ì»´í¬ë„ŒíŠ¸

### Phase 1: ì¸í„°í˜ì´ìŠ¤ ì •ì˜

#### 1.1 LLM ì¸í„°í˜ì´ìŠ¤

```python
# umis_rag/core/llm_interface.py (ì‹ ê·œ)

from abc import ABC, abstractmethod
from typing import Optional, Dict, Any
from enum import Enum
from umis_rag.agents.estimator.models import EstimationResult, Context
from umis_rag.agents.estimator.common.budget import Budget


class TaskType(Enum):
    """LLM ì‘ì—… íƒ€ì… (Stage ê¸°ë°˜)"""
    
    # Stage 1 (LLM ë¶ˆí•„ìš”, í¬í•¨ì€ ì™„ì „ì„± ìœ„í•´)
    EVIDENCE_COLLECTION = "evidence_collection"
    
    # Stage 2
    PRIOR_ESTIMATION = "prior_estimation"
    CERTAINTY_EVALUATION = "certainty_evaluation"
    
    # Stage 3
    FERMI_DECOMPOSITION = "fermi_decomposition"
    FERMI_VARIABLE_ESTIMATION = "fermi_variable_estimation"  # = Stage 2 ì¬ì‚¬ìš©
    
    # Stage 4 (LLM ë¶ˆí•„ìš”, í¬í•¨ì€ ì™„ì „ì„± ìœ„í•´)
    FUSION_CALCULATION = "fusion_calculation"
    
    # ê¸°íƒ€
    BOUNDARY_VALIDATION = "boundary_validation"
    GUARDRAIL_ANALYSIS = "guardrail_analysis"


class BaseLLM(ABC):
    """
    LLM ì¶”ìƒ ì¸í„°í˜ì´ìŠ¤
    
    ëª¨ë“  LLM êµ¬í˜„ì²´(Cursor, External)ê°€ ì¤€ìˆ˜í•´ì•¼ í•  ì¸í„°í˜ì´ìŠ¤
    """
    
    @abstractmethod
    def estimate(
        self,
        question: str,
        context: Context,
        **kwargs
    ) -> Optional[EstimationResult]:
        """
        ê°’ ì¶”ì • (Stage 2: Prior Estimation)
        
        Args:
            question: ì¶”ì • ì§ˆë¬¸
            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
        
        Returns:
            EstimationResult ë˜ëŠ” None (Early Return ì‹¤íŒ¨ ì‹œ)
        """
        pass
    
    @abstractmethod
    def decompose(
        self,
        question: str,
        context: Context,
        budget: Budget,
        **kwargs
    ) -> Optional[Dict[str, Any]]:
        """
        Fermi ë¶„í•´ (Stage 3: Structural Explanation)
        
        Args:
            question: ë¶„í•´í•  ì§ˆë¬¸
            context: ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            budget: ì˜ˆì‚° ì œì•½
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°
        
        Returns:
            ë¶„í•´ ê²°ê³¼ (variables, formula, reasoning ë“±)
        """
        pass
    
    @abstractmethod
    def evaluate_certainty(
        self,
        question: str,
        value: Any,
        context: Context,
        **kwargs
    ) -> str:
        """
        í™•ì‹ ë„ í‰ê°€ (Stage 2)
        
        Args:
            question: ì§ˆë¬¸
            value: ì¶”ì •ê°’
            context: ì»¨í…ìŠ¤íŠ¸
        
        Returns:
            certainty: "high", "medium", "low"
        """
        pass
    
    @abstractmethod
    def validate_boundary(
        self,
        value: Any,
        context: Context,
        **kwargs
    ) -> Dict[str, Any]:
        """
        ê²½ê³„ ê²€ì¦
        
        Args:
            value: ê²€ì¦í•  ê°’
            context: ì»¨í…ìŠ¤íŠ¸
        
        Returns:
            ê²€ì¦ ê²°ê³¼ (is_valid, reason, suggested_range)
        """
        pass
    
    @abstractmethod
    def is_native(self) -> bool:
        """Native(Cursor) ëª¨ë“œ ì—¬ë¶€"""
        pass


class LLMProvider(ABC):
    """
    LLM Provider ì¸í„°í˜ì´ìŠ¤
    
    Taskë³„ ì ì ˆí•œ LLM ê°ì²´ë¥¼ ì œê³µí•˜ëŠ” íŒ©í† ë¦¬
    """
    
    @abstractmethod
    def get_llm(self, task: TaskType) -> BaseLLM:
        """
        Taskì— ë§ëŠ” LLM ê°ì²´ ë°˜í™˜
        
        Args:
            task: TaskType (prior_estimation, fermi_decomposition ë“±)
        
        Returns:
            BaseLLM êµ¬í˜„ì²´ (CursorLLM ë˜ëŠ” ExternalLLM)
        """
        pass
    
    @abstractmethod
    def is_native(self) -> bool:
        """Native(Cursor) Provider ì—¬ë¶€"""
        pass
    
    @abstractmethod
    def get_mode_info(self) -> Dict[str, Any]:
        """í˜„ì¬ ëª¨ë“œ ì •ë³´ ë°˜í™˜ (ë””ë²„ê¹…/ëª¨ë‹ˆí„°ë§ìš©)"""
        pass
```

---

### Phase 2: Cursor êµ¬í˜„

#### 2.1 CursorLLM (Native êµ¬í˜„)

```python
# umis_rag/core/llm_cursor.py (ì‹ ê·œ)

from typing import Optional, Dict, Any
from umis_rag.core.llm_interface import BaseLLM, TaskType
from umis_rag.agents.estimator.models import EstimationResult, Context
from umis_rag.agents.estimator.common.budget import Budget
import logging

logger = logging.getLogger(__name__)


class CursorLLM(BaseLLM):
    """
    Cursor Native LLM êµ¬í˜„
    
    íŠ¹ì§•:
    - ì‹¤ì œ LLM í˜¸ì¶œ ë¶ˆê°€ (Cursor Composerê°€ ì²˜ë¦¬)
    - í¬ë§·ëœ ë°ì´í„°ë§Œ ë°˜í™˜
    - ë¹„ìš© $0
    """
    
    def __init__(self, task: TaskType):
        self.task = task
        logger.info(f"[CursorLLM] ì´ˆê¸°í™”: {task.value}")
    
    def estimate(
        self,
        question: str,
        context: Context,
        **kwargs
    ) -> Optional[EstimationResult]:
        """
        Cursor ëª¨ë“œ: í¬ë§·ëœ ë°ì´í„° ë°˜í™˜ (ì‹¤ì œ ì¶”ì • ë¶ˆê°€)
        
        Returns:
            None (Cursorê°€ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ íŠ¹ìˆ˜ í¬ë§· ë¡œê¹…)
        """
        logger.info(f"[Cursor Prior] ì¶”ì • ë°ì´í„° ì¤€ë¹„")
        logger.info(f"  Question: {question}")
        logger.info(f"  Context: {context.to_dict()}")
        logger.info("  â†’ Cursor Composerì—ì„œ ìœ„ ë°ì´í„°ë¡œ ì¶”ì • ìˆ˜í–‰")
        
        # âš ï¸ None ë°˜í™˜ â†’ Estimatorê°€ Cursor í¬ë§· ì‘ë‹µ ìƒì„±
        return None
    
    def decompose(
        self,
        question: str,
        context: Context,
        budget: Budget,
        **kwargs
    ) -> Optional[Dict[str, Any]]:
        """
        Cursor ëª¨ë“œ: Fermi ë¶„í•´ ë°ì´í„° ì¤€ë¹„
        
        Returns:
            None (Cursor í¬ë§· ë¡œê¹…)
        """
        logger.info(f"[Cursor Fermi] ë¶„í•´ ë°ì´í„° ì¤€ë¹„")
        logger.info(f"  Question: {question}")
        logger.info(f"  Budget: {budget}")
        logger.info(f"  Context: {context.to_dict()}")
        logger.info("  â†’ Cursor Composerì—ì„œ ìœ„ ë°ì´í„°ë¡œ ë¶„í•´ ìˆ˜í–‰")
        
        return None
    
    def evaluate_certainty(
        self,
        question: str,
        value: Any,
        context: Context,
        **kwargs
    ) -> str:
        """
        Cursor ëª¨ë“œ: í™•ì‹ ë„ í‰ê°€ ë¶ˆê°€
        
        Returns:
            "medium" (ê¸°ë³¸ê°’)
        """
        logger.info(f"[Cursor Certainty] ê¸°ë³¸ê°’ ë°˜í™˜ (medium)")
        return "medium"
    
    def validate_boundary(
        self,
        value: Any,
        context: Context,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Cursor ëª¨ë“œ: ê²½ê³„ ê²€ì¦ ìŠ¤í‚µ
        
        Returns:
            ê¸°ë³¸ í†µê³¼ ê²°ê³¼
        """
        logger.info(f"[Cursor Boundary] ê²€ì¦ ìŠ¤í‚µ")
        return {
            "is_valid": True,
            "reason": "Cursor ëª¨ë“œëŠ” ê²€ì¦ ìŠ¤í‚µ",
            "suggested_range": None
        }
    
    def is_native(self) -> bool:
        return True


class CursorLLMProvider(LLMProvider):
    """
    Cursor LLM Provider
    
    Taskì— ê´€ê³„ì—†ì´ í•­ìƒ CursorLLM ë°˜í™˜
    """
    
    def __init__(self):
        logger.info("[CursorLLMProvider] ì´ˆê¸°í™” (Native ëª¨ë“œ)")
    
    def get_llm(self, task: TaskType) -> BaseLLM:
        """
        Taskë³„ CursorLLM ë°˜í™˜
        
        Args:
            task: TaskType
        
        Returns:
            CursorLLM ì¸ìŠ¤í„´ìŠ¤
        """
        logger.debug(f"[CursorLLMProvider] {task.value} â†’ CursorLLM")
        return CursorLLM(task)
    
    def is_native(self) -> bool:
        return True
    
    def get_mode_info(self) -> Dict[str, Any]:
        return {
            "mode": "cursor",
            "provider": "CursorLLMProvider",
            "uses_api": False,
            "cost": "$0 (Cursor êµ¬ë… í¬í•¨)",
            "automation": False,
            "description": "RAG ê²€ìƒ‰ + í¬ë§· â†’ Cursor Composerê°€ ë¶„ì„"
        }
```

**í•µì‹¬ ì„¤ê³„ ê²°ì •**:

1. **None ë°˜í™˜**: CursorëŠ” ì‹¤ì œ ê²°ê³¼ ìƒì„± ë¶ˆê°€ â†’ `None` ë°˜í™˜
2. **ë¡œê¹…**: ëŒ€ì‹  í¬ë§·ëœ ë°ì´í„°ë¥¼ ë¡œê¹… â†’ Cursor Composerê°€ ì½ìŒ
3. **ê¸°ë³¸ê°’**: `certainty="medium"`, `is_valid=True` (ë³´ìˆ˜ì )

---

### Phase 3: External êµ¬í˜„

#### 3.1 ExternalLLM (API í˜¸ì¶œ)

```python
# umis_rag/core/llm_external.py (ì‹ ê·œ)

from typing import Optional, Dict, Any
from umis_rag.core.llm_interface import BaseLLM, TaskType
from umis_rag.core.model_router import ModelRouter, get_model_router
from umis_rag.core.model_configs import ModelConfig, model_config_manager
from umis_rag.agents.estimator.models import EstimationResult, Context
from umis_rag.agents.estimator.common.budget import Budget
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import logging
import json

logger = logging.getLogger(__name__)


class ExternalLLM(BaseLLM):
    """
    External LLM êµ¬í˜„ (OpenAI, Anthropic ë“±)
    
    íŠ¹ì§•:
    - ì‹¤ì œ API í˜¸ì¶œ
    - ì™„ì„±ëœ ê²°ê³¼ ë°˜í™˜
    - í† í°ë‹¹ ê³¼ê¸ˆ
    """
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Task â†’ Stage ë§¤í•‘
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    TASK_TO_STAGE = {
        TaskType.EVIDENCE_COLLECTION: 1,
        TaskType.PRIOR_ESTIMATION: 2,
        TaskType.CERTAINTY_EVALUATION: 2,
        TaskType.FERMI_DECOMPOSITION: 3,
        TaskType.FERMI_VARIABLE_ESTIMATION: 2,  # Stage 2 ì¬ì‚¬ìš©
        TaskType.FUSION_CALCULATION: 4,
        TaskType.BOUNDARY_VALIDATION: 2,
        TaskType.GUARDRAIL_ANALYSIS: 2,
    }
    
    def __init__(
        self,
        task: TaskType,
        router: Optional[ModelRouter] = None
    ):
        self.task = task
        self.stage = self.TASK_TO_STAGE.get(task, 2)
        self.router = router or get_model_router()
        
        # Model ì„ íƒ
        self.model_name, self.model_config = self.router.select_model_with_config(self.stage)
        
        # LLM ê°ì²´ ìƒì„±
        self.llm = self._create_llm()
        
        logger.info(
            f"[ExternalLLM] ì´ˆê¸°í™”: {task.value} "
            f"(Stage {self.stage}, Model: {self.model_name})"
        )
    
    def _create_llm(self) -> ChatOpenAI:
        """LLM ê°ì²´ ìƒì„±"""
        # API íŒŒë¼ë¯¸í„° ë¹Œë“œ
        params = self.model_config.build_api_params(
            prompt="",  # ì‹¤ì œ í˜¸ì¶œ ì‹œ ì„¤ì •
            reasoning_effort="medium" if self.stage == 3 else None
        )
        
        return ChatOpenAI(
            model=self.model_name,
            temperature=params.get("temperature", 0.7),
            max_tokens=params.get("max_tokens", 4000),
            openai_api_key=params.get("api_key")
        )
    
    def estimate(
        self,
        question: str,
        context: Context,
        **kwargs
    ) -> Optional[EstimationResult]:
        """
        External ëª¨ë“œ: ì‹¤ì œ LLM í˜¸ì¶œí•˜ì—¬ ì¶”ì •
        
        Returns:
            EstimationResult (ì™„ì„±ëœ ì¶”ì • ê²°ê³¼)
        """
        logger.info(f"[External Prior] API í˜¸ì¶œ ì‹œì‘")
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_prior_prompt(question, context)
        
        # LLM í˜¸ì¶œ
        response = self._call_llm(prompt)
        
        # íŒŒì‹±
        result = self._parse_prior_response(response, question, context)
        
        logger.info(
            f"[External Prior] ì™„ë£Œ: value={result.value}, "
            f"certainty={result.certainty}, source={result.source}"
        )
        
        return result
    
    def decompose(
        self,
        question: str,
        context: Context,
        budget: Budget,
        **kwargs
    ) -> Optional[Dict[str, Any]]:
        """
        External ëª¨ë“œ: Fermi ë¶„í•´ ì‹¤í–‰
        
        Returns:
            ë¶„í•´ ê²°ê³¼ (variables, formula, reasoning)
        """
        logger.info(f"[External Fermi] API í˜¸ì¶œ ì‹œì‘")
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_fermi_prompt(question, context, budget)
        
        # LLM í˜¸ì¶œ
        response = self._call_llm(prompt)
        
        # íŒŒì‹±
        result = self._parse_fermi_response(response)
        
        logger.info(
            f"[External Fermi] ì™„ë£Œ: {len(result.get('variables', []))}ê°œ ë³€ìˆ˜ ì‹ë³„"
        )
        
        return result
    
    def evaluate_certainty(
        self,
        question: str,
        value: Any,
        context: Context,
        **kwargs
    ) -> str:
        """
        External ëª¨ë“œ: LLMìœ¼ë¡œ í™•ì‹ ë„ í‰ê°€
        
        Returns:
            certainty: "high", "medium", "low"
        """
        logger.info(f"[External Certainty] í‰ê°€ ì‹œì‘")
        
        prompt = self._build_certainty_prompt(question, value, context)
        response = self._call_llm(prompt)
        certainty = self._parse_certainty(response)
        
        logger.info(f"[External Certainty] ì™„ë£Œ: {certainty}")
        return certainty
    
    def validate_boundary(
        self,
        value: Any,
        context: Context,
        **kwargs
    ) -> Dict[str, Any]:
        """
        External ëª¨ë“œ: LLMìœ¼ë¡œ ê²½ê³„ ê²€ì¦
        
        Returns:
            ê²€ì¦ ê²°ê³¼
        """
        logger.info(f"[External Boundary] ê²€ì¦ ì‹œì‘")
        
        prompt = self._build_boundary_prompt(value, context)
        response = self._call_llm(prompt)
        result = self._parse_boundary_response(response)
        
        logger.info(f"[External Boundary] ì™„ë£Œ: valid={result['is_valid']}")
        return result
    
    def is_native(self) -> bool:
        return False
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # í—¬í¼ ë©”ì„œë“œ
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _call_llm(self, prompt: str) -> str:
        """LLM API í˜¸ì¶œ"""
        try:
            chain = ChatPromptTemplate.from_messages([
                ("system", "You are an expert market analyst and estimator."),
                ("user", "{prompt}")
            ]) | self.llm | StrOutputParser()
            
            response = chain.invoke({"prompt": prompt})
            return response
        
        except Exception as e:
            logger.error(f"[ExternalLLM] API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            raise
    
    def _build_prior_prompt(self, question: str, context: Context) -> str:
        """Prior ì¶”ì • í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
Question: {question}

Context:
- Industry: {context.industry}
- Business Model: {context.business_model}
- Region: {context.region}
- Additional: {context.additional_info}

Task: Estimate the value for the question above.

Output format (JSON):
{{
    "value": <estimated_value>,
    "unit": "<unit>",
    "certainty": "high|medium|low",
    "reasoning": "<brief reasoning>"
}}
"""
    
    def _build_fermi_prompt(self, question: str, context: Context, budget: Budget) -> str:
        """Fermi ë¶„í•´ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
Question: {question}

Context:
- Industry: {context.industry}
- Business Model: {context.business_model}

Budget:
- Max variables: {budget.max_variables}
- Max depth: {budget.max_depth}

Task: Decompose the question into Fermi variables.

Output format (JSON):
{{
    "variables": [
        {{"name": "var1", "description": "...", "unit": "..."}}
    ],
    "formula": "<mathematical formula>",
    "reasoning": "<decomposition reasoning>"
}}
"""
    
    def _build_certainty_prompt(self, question: str, value: Any, context: Context) -> str:
        """í™•ì‹ ë„ í‰ê°€ í”„ë¡¬í”„íŠ¸"""
        return f"""
Question: {question}
Estimated Value: {value}
Context: {context.to_dict()}

Task: Evaluate your certainty in this estimate.

Output: high|medium|low
"""
    
    def _build_boundary_prompt(self, value: Any, context: Context) -> str:
        """ê²½ê³„ ê²€ì¦ í”„ë¡¬í”„íŠ¸"""
        return f"""
Value: {value}
Context: {context.to_dict()}

Task: Validate if this value is within reasonable boundaries.

Output format (JSON):
{{
    "is_valid": true|false,
    "reason": "<reasoning>",
    "suggested_range": [<min>, <max>]
}}
"""
    
    def _parse_prior_response(
        self,
        response: str,
        question: str,
        context: Context
    ) -> EstimationResult:
        """Prior ì‘ë‹µ íŒŒì‹±"""
        try:
            data = json.loads(response)
            
            return EstimationResult(
                value=data["value"],
                unit=data.get("unit", "unknown"),
                source="Prior",
                certainty=data.get("certainty", "medium"),
                reasoning=data.get("reasoning", ""),
                cost={"stage": 2, "model": self.model_name}
            )
        
        except Exception as e:
            logger.warning(f"[ExternalLLM] íŒŒì‹± ì‹¤íŒ¨, ê¸°ë³¸ê°’ ë°˜í™˜: {e}")
            return None
    
    def _parse_fermi_response(self, response: str) -> Dict[str, Any]:
        """Fermi ì‘ë‹µ íŒŒì‹±"""
        try:
            return json.loads(response)
        except Exception as e:
            logger.warning(f"[ExternalLLM] Fermi íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {"variables": [], "formula": None, "reasoning": ""}
    
    def _parse_certainty(self, response: str) -> str:
        """í™•ì‹ ë„ íŒŒì‹±"""
        response = response.strip().lower()
        if response in ["high", "medium", "low"]:
            return response
        return "medium"
    
    def _parse_boundary_response(self, response: str) -> Dict[str, Any]:
        """ê²½ê³„ ê²€ì¦ íŒŒì‹±"""
        try:
            return json.loads(response)
        except:
            return {"is_valid": True, "reason": "íŒŒì‹± ì‹¤íŒ¨", "suggested_range": None}


class ExternalLLMProvider(LLMProvider):
    """
    External LLM Provider
    
    Taskë³„ ì ì ˆí•œ External LLM ë°˜í™˜
    """
    
    def __init__(self, router: Optional[ModelRouter] = None):
        self.router = router or get_model_router()
        logger.info("[ExternalLLMProvider] ì´ˆê¸°í™” (External ëª¨ë“œ)")
    
    def get_llm(self, task: TaskType) -> BaseLLM:
        """
        Taskë³„ ExternalLLM ë°˜í™˜
        
        Args:
            task: TaskType
        
        Returns:
            ExternalLLM ì¸ìŠ¤í„´ìŠ¤ (Taskë³„ ëª¨ë¸ ìë™ ì„ íƒ)
        """
        logger.debug(f"[ExternalLLMProvider] {task.value} â†’ ExternalLLM")
        return ExternalLLM(task, router=self.router)
    
    def is_native(self) -> bool:
        return False
    
    def get_mode_info(self) -> Dict[str, Any]:
        return {
            "mode": "external",
            "provider": "ExternalLLMProvider",
            "uses_api": True,
            "cost": "í† í°ë‹¹ ê³¼ê¸ˆ (Taskë³„ ëª¨ë¸ ìë™ ì„ íƒ)",
            "automation": True,
            "description": "RAG ê²€ìƒ‰ + API í˜¸ì¶œ â†’ ì™„ì„±ëœ ê²°ê³¼"
        }
```

---

### Phase 4: Provider íŒ©í† ë¦¬

#### 4.1 Provider ì„ íƒ ë¡œì§

```python
# umis_rag/core/llm_provider_factory.py (ì‹ ê·œ)

from typing import Optional
from umis_rag.core.llm_interface import LLMProvider
from umis_rag.core.llm_cursor import CursorLLMProvider
from umis_rag.core.llm_external import ExternalLLMProvider
from umis_rag.core.config import settings
import logging

logger = logging.getLogger(__name__)


def get_llm_provider(mode: Optional[str] = None) -> LLMProvider:
    """
    LLMProvider íŒ©í† ë¦¬ í•¨ìˆ˜
    
    Args:
        mode: LLM ëª¨ë“œ (Noneì´ë©´ settings.llm_mode ì‚¬ìš©)
            - "cursor": CursorLLMProvider
            - ê·¸ ì™¸: ExternalLLMProvider
    
    Returns:
        LLMProvider êµ¬í˜„ì²´
    
    Example:
        >>> # .env: LLM_MODE=cursor
        >>> provider = get_llm_provider()
        >>> llm = provider.get_llm(TaskType.PRIOR_ESTIMATION)
        >>> result = llm.estimate(question, context)
    """
    mode = mode or settings.llm_mode
    mode = mode.lower().strip()
    
    if mode == "cursor":
        logger.info("[LLMProviderFactory] CursorLLMProvider ì„ íƒ")
        return CursorLLMProvider()
    
    else:
        logger.info(f"[LLMProviderFactory] ExternalLLMProvider ì„ íƒ (ëª¨ë¸: {mode})")
        return ExternalLLMProvider()


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ (ì˜µì…˜)
_provider_instance: Optional[LLMProvider] = None


def get_default_llm_provider() -> LLMProvider:
    """
    ê¸°ë³¸ LLMProvider ë°˜í™˜ (ì‹±ê¸€í†¤)
    
    Returns:
        LLMProvider ì¸ìŠ¤í„´ìŠ¤
    """
    global _provider_instance
    if _provider_instance is None:
        _provider_instance = get_llm_provider()
    return _provider_instance


def reset_llm_provider():
    """Provider ì‹±ê¸€í†¤ ì´ˆê¸°í™” (í…ŒìŠ¤íŠ¸ìš©)"""
    global _provider_instance
    _provider_instance = None
```

---

### Phase 5: Estimator ë¦¬íŒ©í„°ë§

#### 5.1 PriorEstimator (Stage 2)

```python
# umis_rag/agents/estimator/prior_estimator.py (ìˆ˜ì •)

from typing import Optional
from umis_rag.core.llm_interface import LLMProvider, TaskType
from umis_rag.core.llm_provider_factory import get_default_llm_provider
from umis_rag.agents.estimator.models import EstimationResult, Context
import logging

logger = logging.getLogger(__name__)


class PriorEstimator:
    """
    Stage 2: Generative Prior
    
    v7.11.0: LLMProvider ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ (ì™„ì „ ì¶”ìƒí™”)
    """
    
    def __init__(self, llm_provider: Optional[LLMProvider] = None):
        """
        Args:
            llm_provider: LLMProvider êµ¬í˜„ì²´ (Noneì´ë©´ ê¸°ë³¸ Provider)
        """
        self.llm_provider = llm_provider or get_default_llm_provider()
        
        # âŒ ì œê±°: self._llm_mode, self.llm_mode property
        
        logger.info(
            f"[PriorEstimator] ì´ˆê¸°í™” "
            f"(Provider: {self.llm_provider.__class__.__name__})"
        )
    
    def estimate(
        self,
        question: str,
        context: Context,
        **kwargs
    ) -> Optional[EstimationResult]:
        """
        Stage 2: Generative Prior ì¶”ì •
        
        Args:
            question: ì¶”ì • ì§ˆë¬¸
            context: ì»¨í…ìŠ¤íŠ¸
        
        Returns:
            EstimationResult ë˜ëŠ” None
        """
        logger.info(f"[Prior] ì¶”ì • ì‹œì‘: {question}")
        
        # âœ… LLM íšë“ (ë¶„ê¸° ì—†ìŒ!)
        llm = self.llm_provider.get_llm(TaskType.PRIOR_ESTIMATION)
        
        # âœ… ì¶”ì • ì‹¤í–‰ (ë¶„ê¸° ì—†ìŒ!)
        result = llm.estimate(question, context, **kwargs)
        
        # Cursor ëª¨ë“œ: None ë°˜í™˜ (Estimatorê°€ ì²˜ë¦¬)
        if result is None:
            logger.info("[Prior] Cursor ëª¨ë“œ: ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
            return None
        
        # External ëª¨ë“œ: ê²°ê³¼ ë°˜í™˜
        logger.info(
            f"[Prior] ì™„ë£Œ: value={result.value}, "
            f"certainty={result.certainty}"
        )
        
        # Certainty í‰ê°€
        if result.certainty is None:
            certainty_llm = self.llm_provider.get_llm(TaskType.CERTAINTY_EVALUATION)
            result.certainty = certainty_llm.evaluate_certainty(
                question, result.value, context
            )
        
        return result
```

**í•µì‹¬ ë³€ê²½**:
1. âŒ `llm_mode` property ì™„ì „ ì œê±°
2. âœ… `llm_provider` ì˜ì¡´ì„± ì£¼ì…
3. âœ… `llm_provider.get_llm(task)` í˜¸ì¶œë§Œ
4. âœ… ë¶„ê¸° **0ê°œ**

#### 5.2 FermiEstimator (Stage 3)

```python
# umis_rag/agents/estimator/fermi_estimator.py (ìˆ˜ì •)

from typing import Optional, Dict, Any
from umis_rag.core.llm_interface import LLMProvider, TaskType
from umis_rag.core.llm_provider_factory import get_default_llm_provider
from umis_rag.agents.estimator.models import Context
from umis_rag.agents.estimator.common.budget import Budget
from umis_rag.agents.estimator.prior_estimator import PriorEstimator
import logging

logger = logging.getLogger(__name__)


class FermiEstimator:
    """
    Stage 3: Structural Explanation (Fermi Decomposition)
    
    v7.11.0: LLMProvider ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜ (ì™„ì „ ì¶”ìƒí™”)
    """
    
    def __init__(
        self,
        llm_provider: Optional[LLMProvider] = None,
        prior_estimator: Optional[PriorEstimator] = None
    ):
        """
        Args:
            llm_provider: LLMProvider êµ¬í˜„ì²´
            prior_estimator: PriorEstimator (ë³€ìˆ˜ ì¶”ì •ìš©)
        """
        self.llm_provider = llm_provider or get_default_llm_provider()
        self.prior_estimator = prior_estimator or PriorEstimator(self.llm_provider)
        
        # âŒ ì œê±°: self._llm_mode, self.llm_mode property
        
        logger.info(
            f"[FermiEstimator] ì´ˆê¸°í™” "
            f"(Provider: {self.llm_provider.__class__.__name__})"
        )
    
    def decompose(
        self,
        question: str,
        context: Context,
        budget: Budget,
        **kwargs
    ) -> Optional[Dict[str, Any]]:
        """
        Stage 3: Fermi ë¶„í•´
        
        Args:
            question: ë¶„í•´í•  ì§ˆë¬¸
            context: ì»¨í…ìŠ¤íŠ¸
            budget: ì˜ˆì‚° ì œì•½
        
        Returns:
            ë¶„í•´ ê²°ê³¼ ë˜ëŠ” None (Cursor ëª¨ë“œ)
        """
        logger.info(f"[Fermi] ë¶„í•´ ì‹œì‘: {question}")
        
        # âœ… LLM íšë“ (ë¶„ê¸° ì—†ìŒ!)
        llm = self.llm_provider.get_llm(TaskType.FERMI_DECOMPOSITION)
        
        # âœ… ë¶„í•´ ì‹¤í–‰ (ë¶„ê¸° ì—†ìŒ!)
        decomposition = llm.decompose(question, context, budget, **kwargs)
        
        # Cursor ëª¨ë“œ: None ë°˜í™˜
        if decomposition is None:
            logger.info("[Fermi] Cursor ëª¨ë“œ: ë¶„í•´ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
            return None
        
        # External ëª¨ë“œ: ë³€ìˆ˜ ì¶”ì •
        logger.info(f"[Fermi] {len(decomposition['variables'])}ê°œ ë³€ìˆ˜ ì¶”ì • ì‹œì‘")
        
        # ë³€ìˆ˜ ì¶”ì • (Stage 2 ì¬ì‚¬ìš©)
        estimated_variables = self._estimate_variables(
            decomposition['variables'],
            context,
            budget
        )
        
        decomposition['estimated_variables'] = estimated_variables
        
        # ê³µì‹ ê³„ì‚°
        if decomposition.get('formula'):
            final_value = self._calculate_formula(
                decomposition['formula'],
                estimated_variables
            )
            decomposition['final_value'] = final_value
        
        logger.info(
            f"[Fermi] ì™„ë£Œ: {len(estimated_variables)}ê°œ ë³€ìˆ˜ ì¶”ì •, "
            f"ìµœì¢…ê°’: {decomposition.get('final_value')}"
        )
        
        return decomposition
    
    def _estimate_variables(
        self,
        variables: list,
        context: Context,
        budget: Budget
    ) -> Dict[str, Any]:
        """
        ë³€ìˆ˜ ì¶”ì • (Stage 2 Prior ì¬ì‚¬ìš©)
        
        âœ… ë¶„ê¸° ì—†ìŒ (prior_estimatorê°€ ì²˜ë¦¬)
        """
        estimated = {}
        
        for var in variables:
            var_name = var['name']
            question = f"What is the {var['description']}?"
            
            # âœ… Prior ì¶”ì • (ë¶„ê¸° ì—†ìŒ!)
            result = self.prior_estimator.estimate(question, context)
            
            if result:
                estimated[var_name] = result.value
            else:
                # Cursor ëª¨ë“œ or ì‹¤íŒ¨
                estimated[var_name] = None
        
        return estimated
    
    def _calculate_formula(
        self,
        formula: str,
        variables: Dict[str, Any]
    ) -> Optional[float]:
        """ê³µì‹ ê³„ì‚°"""
        try:
            # ê°„ë‹¨í•œ eval (ì‹¤ì œë¡œëŠ” ì•ˆì „í•œ íŒŒì„œ ì‚¬ìš©)
            for var_name, var_value in variables.items():
                if var_value is None:
                    return None
                formula = formula.replace(var_name, str(var_value))
            
            return eval(formula)
        
        except Exception as e:
            logger.error(f"[Fermi] ê³µì‹ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return None
```

**í•µì‹¬ ë³€ê²½**:
1. âŒ `llm_mode` ì™„ì „ ì œê±°
2. âœ… `llm_provider` ì˜ì¡´ì„± ì£¼ì…
3. âœ… ë³€ìˆ˜ ì¶”ì • = `prior_estimator.estimate()` (Stage 2 ì¬ì‚¬ìš©)
4. âœ… ë¶„ê¸° **0ê°œ**

#### 5.3 EstimatorRAG (ë©”ì¸)

```python
# umis_rag/agents/estimator/estimator.py (ìˆ˜ì •)

from typing import Optional
from umis_rag.core.llm_interface import LLMProvider
from umis_rag.core.llm_provider_factory import get_default_llm_provider
from umis_rag.agents.estimator.models import EstimationResult, Context
from umis_rag.agents.estimator.common.budget import Budget, create_standard_budget
from umis_rag.agents.estimator.evidence_collector import EvidenceCollector
from umis_rag.agents.estimator.prior_estimator import PriorEstimator
from umis_rag.agents.estimator.fermi_estimator import FermiEstimator
import logging

logger = logging.getLogger(__name__)


class EstimatorRAG:
    """
    Estimator Agent: 4-Stage Fusion Architecture
    
    v7.11.0: ì™„ì „ ì¶”ìƒí™” (LLMProvider ì¸í„°í˜ì´ìŠ¤ ê¸°ë°˜)
    """
    
    def __init__(
        self,
        llm_provider: Optional[LLMProvider] = None,
        project_id: Optional[str] = None
    ):
        """
        Args:
            llm_provider: LLMProvider êµ¬í˜„ì²´ (Noneì´ë©´ settings ê¸°ë°˜)
            project_id: í”„ë¡œì íŠ¸ ID
        """
        self.llm_provider = llm_provider or get_default_llm_provider()
        self.project_id = project_id
        
        # âŒ ì œê±°: self.llm_mode
        
        # Stageë³„ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (ëª¨ë‘ ê°™ì€ provider)
        self.evidence_collector = EvidenceCollector(
            llm_provider=self.llm_provider,
            project_id=project_id
        )
        self.prior_estimator = PriorEstimator(
            llm_provider=self.llm_provider
        )
        self.fermi_estimator = FermiEstimator(
            llm_provider=self.llm_provider,
            prior_estimator=self.prior_estimator
        )
        
        logger.info(
            f"[EstimatorRAG] ì´ˆê¸°í™” ì™„ë£Œ "
            f"(Provider: {self.llm_provider.__class__.__name__})"
        )
        logger.info(f"  ëª¨ë“œ: {self._get_mode_display()}")
    
    def estimate(
        self,
        question: str,
        context: Optional[Context] = None,
        budget: Optional[Budget] = None,
        **kwargs
    ) -> EstimationResult:
        """
        4-Stage Fusion ì¶”ì •
        
        Args:
            question: ì¶”ì • ì§ˆë¬¸
            context: ì»¨í…ìŠ¤íŠ¸ (Optional)
            budget: ì˜ˆì‚° ì œì•½ (Optional)
        
        Returns:
            EstimationResult (ì™„ì„±ëœ ì¶”ì • ê²°ê³¼)
        """
        logger.info("=" * 60)
        logger.info(f"[Estimator] 4-Stage Fusion ì¶”ì • ì‹œì‘")
        logger.info(f"  ì§ˆë¬¸: {question}")
        logger.info("=" * 60)
        
        # ê¸°ë³¸ê°’
        context = context or Context()
        budget = budget or create_standard_budget()
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 1: Evidence Collection
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info("\n[Stage 1] Evidence Collection")
        evidence = self.evidence_collector.collect(question, context, budget)
        
        # Early Return: Literal ë°œê²¬
        if evidence.get("literal"):
            logger.info("  âœ… Early Return: Literal ì¦ê±° ë°œê²¬")
            return EstimationResult(
                value=evidence["literal"]["value"],
                source="Literal",
                certainty="high",
                reasoning=evidence["literal"]["reasoning"],
                cost={"stage": 1, "method": "literal"}
            )
        
        # Early Return: Direct RAG
        if evidence.get("direct_rag"):
            logger.info("  âœ… Early Return: Direct RAG ì¦ê±° ë°œê²¬")
            return EstimationResult(
                value=evidence["direct_rag"]["value"],
                source="DirectRAG",
                certainty="high",
                reasoning=evidence["direct_rag"]["reasoning"],
                cost={"stage": 1, "method": "direct_rag"}
            )
        
        # Early Return: Validator
        if evidence.get("validator"):
            logger.info("  âœ… Early Return: Validator ë°ì´í„° ë°œê²¬")
            return EstimationResult(
                value=evidence["validator"]["value"],
                source="Validator",
                certainty="high",
                reasoning=evidence["validator"]["reasoning"],
                cost={"stage": 1, "method": "validator"}
            )
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 2: Generative Prior
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info("\n[Stage 2] Generative Prior")
        
        # âœ… Prior ì¶”ì • (ë¶„ê¸° ì—†ìŒ!)
        prior_result = self.prior_estimator.estimate(question, context)
        
        # Cursor ëª¨ë“œ: None ë°˜í™˜ â†’ Cursor í¬ë§· ì‘ë‹µ
        if prior_result is None:
            logger.info("  [Cursor] Stage 2 ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
            return self._prepare_cursor_response(
                stage=2,
                question=question,
                context=context,
                evidence=evidence
            )
        
        # External ëª¨ë“œ: certainty ì²´í¬
        if prior_result.certainty == "high":
            logger.info("  âœ… Early Return: High certainty")
            return prior_result
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 3: Structural Explanation
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info("\n[Stage 3] Structural Explanation (Fermi)")
        
        # âœ… Fermi ë¶„í•´ (ë¶„ê¸° ì—†ìŒ!)
        fermi_result = self.fermi_estimator.decompose(
            question, context, budget
        )
        
        # Cursor ëª¨ë“œ: None ë°˜í™˜
        if fermi_result is None:
            logger.info("  [Cursor] Stage 3 ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
            return self._prepare_cursor_response(
                stage=3,
                question=question,
                context=context,
                evidence=evidence,
                prior_result=prior_result
            )
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Stage 4: Fusion & Validation
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        logger.info("\n[Stage 4] Fusion & Validation")
        
        final_result = self._fuse_results(
            evidence, prior_result, fermi_result
        )
        
        logger.info("=" * 60)
        logger.info(f"[Estimator] ì¶”ì • ì™„ë£Œ")
        logger.info(f"  ìµœì¢…ê°’: {final_result.value}")
        logger.info(f"  Source: {final_result.source}")
        logger.info(f"  Certainty: {final_result.certainty}")
        logger.info("=" * 60)
        
        return final_result
    
    def _prepare_cursor_response(
        self,
        stage: int,
        question: str,
        context: Context,
        evidence: dict,
        prior_result: Optional[EstimationResult] = None,
        **kwargs
    ) -> dict:
        """
        Cursor ëª¨ë“œ: í¬ë§·ëœ ì‘ë‹µ ìƒì„±
        
        Returns:
            dict (Cursor Composerê°€ ì½ì„ ìˆ˜ ìˆëŠ” í¬ë§·)
        """
        return {
            "mode": "cursor",
            "stage_reached": stage,
            "question": question,
            "context": context.to_dict(),
            "evidence": evidence,
            "prior_result": prior_result.to_dict() if prior_result else None,
            "instruction": (
                f"[Stage {stage}] ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì •ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.\n"
                f"Evidence: {len(evidence)}ê°œ ì†ŒìŠ¤\n"
                f"Prior: {prior_result.value if prior_result else 'N/A'}"
            )
        }
    
    def _fuse_results(
        self,
        evidence: dict,
        prior_result: EstimationResult,
        fermi_result: dict
    ) -> EstimationResult:
        """
        Stage 4: ê²°ê³¼ ìœµí•©
        
        ê°€ì¤‘ í‰ê·  ë˜ëŠ” ìš°ì„ ìˆœìœ„ ê¸°ë°˜
        """
        # ê°„ë‹¨í•œ êµ¬í˜„: Fermi ìš°ì„ 
        if fermi_result.get("final_value"):
            return EstimationResult(
                value=fermi_result["final_value"],
                source="Fusion",
                certainty="medium",
                reasoning=f"Fermi ë¶„í•´ ê¸°ë°˜ ({len(fermi_result['variables'])}ê°œ ë³€ìˆ˜)",
                decomposition=fermi_result,
                cost={"stage": 4, "method": "fermi_fusion"}
            )
        
        # Fallback: Prior ê²°ê³¼
        return prior_result
    
    def _get_mode_display(self) -> str:
        """ëª¨ë“œ ë””ìŠ¤í”Œë ˆì´ (ë¡œê¹…ìš©)"""
        info = self.llm_provider.get_mode_info()
        return f"{info['mode']} ({info['description']})"
```

**í•µì‹¬ ë³€ê²½**:
1. âŒ `self.llm_mode` ì™„ì „ ì œê±°
2. âœ… `llm_provider` ì˜ì¡´ì„± ì£¼ì…
3. âœ… ëª¨ë“  Stage ì»´í¬ë„ŒíŠ¸ì— ê°™ì€ `llm_provider` ì „ë‹¬
4. âœ… Cursor ëª¨ë“œ ì²˜ë¦¬: `None` ë°˜í™˜ ì‹œ `_prepare_cursor_response()` í˜¸ì¶œ
5. âœ… ë¶„ê¸° **0ê°œ**

---

### Phase 6: ê¸°íƒ€ ì»´í¬ë„ŒíŠ¸

#### 6.1 EvidenceCollector, SourceCollector, BoundaryValidator ë“±

**ë™ì¼í•œ íŒ¨í„´ ì ìš©**:

```python
class EvidenceCollector:
    def __init__(self, llm_provider: Optional[LLMProvider] = None, ...):
        self.llm_provider = llm_provider or get_default_llm_provider()
        # âŒ llm_mode ì œê±°

class SourceCollector:
    def __init__(self, llm_provider: Optional[LLMProvider] = None):
        self.llm_provider = llm_provider or get_default_llm_provider()
        # âŒ llm_mode ì œê±°

class BoundaryValidator:
    def __init__(self, llm_provider: Optional[LLMProvider] = None):
        self.llm_provider = llm_provider or get_default_llm_provider()
        # âŒ llm_mode ì œê±°
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê³„íš

### Phase 7: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# tests/unit/test_llm_interface_v7_11_0.py (ì‹ ê·œ)

import pytest
from umis_rag.core.llm_interface import TaskType
from umis_rag.core.llm_cursor import CursorLLMProvider
from umis_rag.core.llm_external import ExternalLLMProvider
from umis_rag.core.llm_provider_factory import get_llm_provider
from umis_rag.agents.estimator.models import Context


class TestCursorLLM:
    """CursorLLM í…ŒìŠ¤íŠ¸"""
    
    def test_cursor_provider_initialization(self):
        """CursorLLMProvider ì´ˆê¸°í™”"""
        provider = CursorLLMProvider()
        assert provider.is_native() is True
    
    def test_cursor_llm_estimate_returns_none(self):
        """CursorLLM.estimate()ëŠ” None ë°˜í™˜"""
        provider = CursorLLMProvider()
        llm = provider.get_llm(TaskType.PRIOR_ESTIMATION)
        
        result = llm.estimate("What is LTV?", Context())
        assert result is None  # CursorëŠ” None ë°˜í™˜
    
    def test_cursor_llm_decompose_returns_none(self):
        """CursorLLM.decompose()ëŠ” None ë°˜í™˜"""
        provider = CursorLLMProvider()
        llm = provider.get_llm(TaskType.FERMI_DECOMPOSITION)
        
        from umis_rag.agents.estimator.common.budget import create_fast_budget
        result = llm.decompose("What is TAM?", Context(), create_fast_budget())
        assert result is None


class TestExternalLLM:
    """ExternalLLM í…ŒìŠ¤íŠ¸"""
    
    @pytest.mark.skipif(
        os.getenv("LLM_MODE") == "cursor",
        reason="External LLM í…ŒìŠ¤íŠ¸ëŠ” External ëª¨ë“œ í•„ìš”"
    )
    def test_external_provider_initialization(self):
        """ExternalLLMProvider ì´ˆê¸°í™”"""
        provider = ExternalLLMProvider()
        assert provider.is_native() is False
    
    @pytest.mark.skipif(
        os.getenv("LLM_MODE") == "cursor",
        reason="External LLM í…ŒìŠ¤íŠ¸"
    )
    def test_external_llm_estimate_returns_result(self):
        """ExternalLLM.estimate()ëŠ” EstimationResult ë°˜í™˜"""
        provider = ExternalLLMProvider()
        llm = provider.get_llm(TaskType.PRIOR_ESTIMATION)
        
        result = llm.estimate("What is average SaaS churn rate?", Context(industry="SaaS"))
        
        assert result is not None
        assert result.value is not None
        assert result.source == "Prior"
        assert result.certainty in ["high", "medium", "low"]


class TestLLMProviderFactory:
    """LLMProviderFactory í…ŒìŠ¤íŠ¸"""
    
    def test_factory_returns_cursor_provider_for_cursor_mode(self):
        """LLM_MODE=cursor â†’ CursorLLMProvider"""
        provider = get_llm_provider(mode="cursor")
        assert isinstance(provider, CursorLLMProvider)
        assert provider.is_native() is True
    
    def test_factory_returns_external_provider_for_other_modes(self):
        """LLM_MODE=gpt-4o-mini â†’ ExternalLLMProvider"""
        provider = get_llm_provider(mode="gpt-4o-mini")
        assert isinstance(provider, ExternalLLMProvider)
        assert provider.is_native() is False
```

### Phase 8: í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_estimator_abstraction_v7_11_0.py (ì‹ ê·œ)

import pytest
from umis_rag.agents.estimator.estimator import EstimatorRAG
from umis_rag.agents.estimator.models import Context
from umis_rag.core.llm_provider_factory import get_llm_provider


class TestEstimatorAbstraction:
    """Estimator ì¶”ìƒí™” í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def test_estimator_with_cursor_provider(self):
        """Cursor Providerë¡œ Estimator ì‹¤í–‰"""
        provider = get_llm_provider(mode="cursor")
        estimator = EstimatorRAG(llm_provider=provider)
        
        result = estimator.estimate(
            "What is average SaaS LTV?",
            context=Context(industry="SaaS")
        )
        
        # Cursor ëª¨ë“œ: dict ë°˜í™˜
        assert isinstance(result, dict)
        assert result["mode"] == "cursor"
        assert "question" in result
        assert "instruction" in result
    
    @pytest.mark.skipif(
        os.getenv("LLM_MODE") == "cursor",
        reason="External LLM í…ŒìŠ¤íŠ¸"
    )
    def test_estimator_with_external_provider(self):
        """External Providerë¡œ Estimator ì‹¤í–‰"""
        provider = get_llm_provider(mode="gpt-4o-mini")
        estimator = EstimatorRAG(llm_provider=provider)
        
        result = estimator.estimate(
            "What is average SaaS churn rate?",
            context=Context(industry="SaaS")
        )
        
        # External ëª¨ë“œ: EstimationResult ë°˜í™˜
        from umis_rag.agents.estimator.models import EstimationResult
        assert isinstance(result, EstimationResult)
        assert result.value is not None
        assert result.source in ["Literal", "DirectRAG", "Validator", "Prior", "Fermi", "Fusion"]
    
    def test_estimator_no_llm_mode_in_code(self):
        """Estimator ì½”ë“œì— llm_mode ì°¸ì¡° ì—†ìŒ í™•ì¸"""
        estimator = EstimatorRAG()
        
        # âŒ llm_mode ì†ì„± ì—†ì–´ì•¼ í•¨
        assert not hasattr(estimator, "llm_mode")
        assert not hasattr(estimator, "_llm_mode")
        
        # âœ… llm_provider ì†ì„± ì¡´ì¬
        assert hasattr(estimator, "llm_provider")
```

### Phase 9: E2E í…ŒìŠ¤íŠ¸

```python
# tests/e2e/test_estimator_e2e_abstraction_v7_11_0.py (ì‹ ê·œ)

import pytest
from umis_rag.agents.estimator.estimator import EstimatorRAG
from umis_rag.agents.estimator.models import Context
from umis_rag.agents.estimator.common.budget import create_standard_budget


class TestE2EAbstraction:
    """E2E í…ŒìŠ¤íŠ¸: ì™„ì „ ì¶”ìƒí™”"""
    
    def test_e2e_cursor_mode_full_workflow(self):
        """Cursor ëª¨ë“œ: ì „ì²´ ì›Œí¬í”Œë¡œìš°"""
        estimator = EstimatorRAG()  # ê¸°ë³¸ Provider (settings ê¸°ë°˜)
        
        result = estimator.estimate(
            "What is Spotify's annual revenue?",
            context=Context(
                industry="Music Streaming",
                region="Global"
            ),
            budget=create_standard_budget()
        )
        
        # Cursor: dict ì‘ë‹µ (Composerê°€ ì²˜ë¦¬)
        if isinstance(result, dict) and result.get("mode") == "cursor":
            assert "stage_reached" in result
            assert "evidence" in result
            pytest.skip("Cursor ëª¨ë“œ: Composer ì²˜ë¦¬ í•„ìš”")
    
    @pytest.mark.skipif(
        os.getenv("LLM_MODE") == "cursor",
        reason="External LLM í•„ìš”"
    )
    def test_e2e_external_mode_full_workflow(self):
        """External ëª¨ë“œ: ì „ì²´ ì›Œí¬í”Œë¡œìš°"""
        estimator = EstimatorRAG()
        
        result = estimator.estimate(
            "What is average SaaS CAC?",
            context=Context(
                industry="SaaS",
                business_model="B2B"
            ),
            budget=create_standard_budget()
        )
        
        # External: EstimationResult
        from umis_rag.agents.estimator.models import EstimationResult
        assert isinstance(result, EstimationResult)
        assert result.value is not None
        assert result.source in ["Literal", "DirectRAG", "Validator", "Prior", "Fermi", "Fusion"]
        assert result.certainty in ["high", "medium", "low"]
```

---

## ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 10: ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜

| ë‹¨ê³„ | ì‘ì—… | ì†Œìš” ì‹œê°„ | ìƒíƒœ |
|------|------|----------|------|
| **1. ì¸í„°í˜ì´ìŠ¤ ì •ì˜** | | 4ì‹œê°„ | â¸ï¸ |
| 1.1 | `llm_interface.py` (BaseLLM, LLMProvider, TaskType) | 2ì‹œê°„ | â¸ï¸ |
| 1.2 | ì¸í„°í˜ì´ìŠ¤ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | 1ì‹œê°„ | â¸ï¸ |
| 1.3 | ë¬¸ì„œí™” (Docstring, ì˜ˆì‹œ) | 1ì‹œê°„ | â¸ï¸ |
| **2. Cursor êµ¬í˜„** | | 3ì‹œê°„ | â¸ï¸ |
| 2.1 | `llm_cursor.py` (CursorLLM, CursorLLMProvider) | 2ì‹œê°„ | â¸ï¸ |
| 2.2 | Cursor ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | 1ì‹œê°„ | â¸ï¸ |
| **3. External êµ¬í˜„** | | 5ì‹œê°„ | â¸ï¸ |
| 3.1 | `llm_external.py` (ExternalLLM, ExternalLLMProvider) | 3ì‹œê°„ | â¸ï¸ |
| 3.2 | í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Prior, Fermi, Certainty, Boundary) | 1ì‹œê°„ | â¸ï¸ |
| 3.3 | External ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | 1ì‹œê°„ | â¸ï¸ |
| **4. Provider íŒ©í† ë¦¬** | | 2ì‹œê°„ | â¸ï¸ |
| 4.1 | `llm_provider_factory.py` (get_llm_provider, ì‹±ê¸€í†¤) | 1ì‹œê°„ | â¸ï¸ |
| 4.2 | íŒ©í† ë¦¬ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ | 1ì‹œê°„ | â¸ï¸ |
| **5. PriorEstimator ë¦¬íŒ©í„°ë§** | | 3ì‹œê°„ | â¸ï¸ |
| 5.1 | `llm_mode` ì œê±°, `llm_provider` ì£¼ì… | 1.5ì‹œê°„ | â¸ï¸ |
| 5.2 | í†µí•© í…ŒìŠ¤íŠ¸ (Cursor + External) | 1ì‹œê°„ | â¸ï¸ |
| 5.3 | íšŒê·€ í…ŒìŠ¤íŠ¸ | 0.5ì‹œê°„ | â¸ï¸ |
| **6. FermiEstimator ë¦¬íŒ©í„°ë§** | | 3ì‹œê°„ | â¸ï¸ |
| 6.1 | `llm_mode` ì œê±°, `llm_provider` ì£¼ì… | 1.5ì‹œê°„ | â¸ï¸ |
| 6.2 | ë³€ìˆ˜ ì¶”ì • = Prior ì¬ì‚¬ìš© í™•ì¸ | 1ì‹œê°„ | â¸ï¸ |
| 6.3 | í†µí•© í…ŒìŠ¤íŠ¸ | 0.5ì‹œê°„ | â¸ï¸ |
| **7. EstimatorRAG ë¦¬íŒ©í„°ë§** | | 4ì‹œê°„ | â¸ï¸ |
| 7.1 | `llm_mode` ì œê±°, `llm_provider` ì£¼ì… | 2ì‹œê°„ | â¸ï¸ |
| 7.2 | `_prepare_cursor_response()` êµ¬í˜„ | 1ì‹œê°„ | â¸ï¸ |
| 7.3 | 4-Stage ì›Œí¬í”Œë¡œìš° í†µí•© í…ŒìŠ¤íŠ¸ | 1ì‹œê°„ | â¸ï¸ |
| **8. ê¸°íƒ€ ì»´í¬ë„ŒíŠ¸** | | 4ì‹œê°„ | â¸ï¸ |
| 8.1 | EvidenceCollector | 1ì‹œê°„ | â¸ï¸ |
| 8.2 | SourceCollector | 1ì‹œê°„ | â¸ï¸ |
| 8.3 | BoundaryValidator | 1ì‹œê°„ | â¸ï¸ |
| 8.4 | GuardrailAnalyzer | 1ì‹œê°„ | â¸ï¸ |
| **9. E2E í…ŒìŠ¤íŠ¸** | | 3ì‹œê°„ | â¸ï¸ |
| 9.1 | Cursor ëª¨ë“œ E2E (10ê°œ ì‹œë‚˜ë¦¬ì˜¤) | 1.5ì‹œê°„ | â¸ï¸ |
| 9.2 | External ëª¨ë“œ E2E (10ê°œ ì‹œë‚˜ë¦¬ì˜¤) | 1.5ì‹œê°„ | â¸ï¸ |
| **10. í•˜ìœ„ í˜¸í™˜ì„±** | | 2ì‹œê°„ | â¸ï¸ |
| 10.1 | `compat.py` Adapter (llm_mode property â†’ DeprecationWarning) | 1ì‹œê°„ | â¸ï¸ |
| 10.2 | ë ˆê±°ì‹œ ì½”ë“œ í…ŒìŠ¤íŠ¸ | 1ì‹œê°„ | â¸ï¸ |
| **11. ë¬¸ì„œí™”** | | 2ì‹œê°„ | â¸ï¸ |
| 11.1 | `LLM_INTERFACE_GUIDE_v7_11_0.md` | 1ì‹œê°„ | â¸ï¸ |
| 11.2 | `MIGRATION_FROM_LLM_MODE_v7_11_0.md` | 1ì‹œê°„ | â¸ï¸ |
| **12. ìµœì¢… ê²€ì¦** | | 2ì‹œê°„ | â¸ï¸ |
| 12.1 | ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Native + External) | 1ì‹œê°„ | â¸ï¸ |
| 12.2 | ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ì†ë„, ë¹„ìš© ë³€í™” ì—†ìŒ í™•ì¸) | 1ì‹œê°„ | â¸ï¸ |
| **ì´ ì†Œìš” ì‹œê°„** | | **37ì‹œê°„ (ì•½ 5ì¼)** | â¸ï¸ |

---

## ğŸ¯ í•µì‹¬ ì„±ê³µ ì§€í‘œ

### ì½”ë“œ í’ˆì§ˆ

1. **Estimator ìˆœìˆ˜ì„±**
   - âœ… `llm_mode` ì°¸ì¡°: **61ê³³ â†’ 0ê³³**
   - âœ… ë¶„ê¸°ë¬¸ (`if llm_mode`): **ì™„ì „ ì œê±°**
   - âœ… ì˜ì¡´ì„±: ì¸í„°í˜ì´ìŠ¤ë§Œ ì˜ì¡´

2. **Dependency Inversion**
   - âœ… High-level â†’ Interface â† Low-level
   - âœ… Mock ì£¼ì… ê°€ëŠ¥ (í…ŒìŠ¤íŠ¸)

3. **ë‹¨ì¼ ì±…ì„ ì›ì¹™**
   - âœ… Estimator: ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
   - âœ… LLMProvider: Infrastructure
   - âœ… ModelRouter: Model ì„ íƒ

### í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€

- âœ… ë‹¨ìœ„ í…ŒìŠ¤íŠ¸: 90%+
- âœ… í†µí•© í…ŒìŠ¤íŠ¸: Cursor + External ê° 10ê°œ
- âœ… E2E í…ŒìŠ¤íŠ¸: 20ê°œ ì‹œë‚˜ë¦¬ì˜¤
- âœ… íšŒê·€ í…ŒìŠ¤íŠ¸: ê¸°ì¡´ ê¸°ëŠ¥ 100% ìœ ì§€

### ì„±ëŠ¥

- âœ… ì†ë„: ë³€í™” ì—†ìŒ (Â±5% ì´ë‚´)
- âœ… ë¹„ìš©: ë³€í™” ì—†ìŒ
- âœ… API í˜¸ì¶œ íšŸìˆ˜: ë™ì¼

---

## âš ï¸ ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘

### ìœ„í—˜ 1: Cursor ëª¨ë“œ ë³µì¡ë„ ì¦ê°€

**ë¬¸ì œ**: CursorëŠ” ì‹¤ì œ LLM í˜¸ì¶œ ë¶ˆê°€ â†’ `None` ë°˜í™˜ + ë¡œê¹…

**ëŒ€ì‘**:
1. `CursorLLM`ì€ ë‹¨ìˆœí™” (í¬ë§·ë§Œ)
2. `EstimatorRAG._prepare_cursor_response()` ì¤‘ì•™í™”
3. ë¬¸ì„œ ëª…í™•í™” (Cursor = "ë°ì´í„° ì¤€ë¹„")

### ìœ„í—˜ 2: External LLM í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ

**ë¬¸ì œ**: í”„ë¡¬í”„íŠ¸ê°€ ë¶€ì‹¤í•˜ë©´ ê²°ê³¼ í’ˆì§ˆ ì €í•˜

**ëŒ€ì‘**:
1. ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ì¬ì‚¬ìš© (ê²€ì¦ë¨)
2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿í™” (`_build_*_prompt`)
3. í”„ë¡¬í”„íŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

### ìœ„í—˜ 3: ëŒ€ê·œëª¨ ë¦¬íŒ©í„°ë§ ë¦¬ìŠ¤í¬

**ë¬¸ì œ**: 61ê³³ ë³€ê²½ â†’ ë²„ê·¸ ê°€ëŠ¥ì„±

**ëŒ€ì‘**:
1. **ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜** (Stageë³„)
2. **íšŒê·€ í…ŒìŠ¤íŠ¸ ìë™í™”**
3. **í•˜ìœ„ í˜¸í™˜ì„±** (`compat.py`)

### ìœ„í—˜ 4: ê°œë°œ ì‹œê°„ ì´ˆê³¼

**ë¬¸ì œ**: ì˜ˆìƒ 37ì‹œê°„ (5ì¼)

**ëŒ€ì‘**:
1. ìš°ì„ ìˆœìœ„: Core â†’ í…ŒìŠ¤íŠ¸ â†’ ê¸°íƒ€
2. ë³‘ë ¬í™”: ì¸í„°í˜ì´ìŠ¤ + Cursor ë™ì‹œ ì§„í–‰
3. ìŠ¤í‚µ ê°€ëŠ¥: ì¼ë¶€ ê¸°íƒ€ ì»´í¬ë„ŒíŠ¸ (EvidenceCollector ë“±)

---

## ğŸ“ˆ ì˜ˆìƒ íš¨ê³¼

### 1. Clean Architecture ë‹¬ì„±

```
Before:
  Estimator (61ê³³ ë¶„ê¸°) â”€â”€â”
                          â”œâ”€ llm_mode ì˜ì¡´
  Infrastructure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

After:
  Estimator â”€â”€â†’ Interface â†â”€â”€ Infrastructure
  (ë¶„ê¸° 0ê³³)      â†‘               â†‘
                  â””â”€ Dependency Inversion
```

### 2. ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ

```bash
# Native â†” External ì „í™˜
# Before: ì½”ë“œ ìˆ˜ì • í•„ìš” (61ê³³)
# After: .envë§Œ ë³€ê²½

LLM_MODE=cursor  â†’  LLM_MODE=gpt-4o-mini
```

### 3. í…ŒìŠ¤íŠ¸ ìš©ì´ì„±

```python
# Mock ì£¼ì…
mock_provider = MockLLMProvider()
estimator = EstimatorRAG(llm_provider=mock_provider)

# ì™„ë²½í•œ ê²©ë¦¬ í…ŒìŠ¤íŠ¸
```

### 4. í™•ì¥ì„±

```python
# ìƒˆ LLM íƒ€ì… ì¶”ê°€ (ì˜ˆ: Claude)
class ClaudeLLMProvider(LLMProvider):
    def get_llm(self, task):
        return ClaudeLLM(task)

# Estimator ì½”ë“œ ìˆ˜ì •: 0ì¤„
```

---

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„

1. **âœ… ì‚¬ìš©ì ìŠ¹ì¸**
   - ì´ ê³„íš ê²€í†  ë° í”¼ë“œë°±

2. **â¸ï¸ Phase 1 ì‹œì‘: ì¸í„°í˜ì´ìŠ¤ ì •ì˜**
   - `llm_interface.py` êµ¬í˜„
   - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

3. **â¸ï¸ Phase 2-4: Provider êµ¬í˜„**
   - Cursor + External + Factory

4. **â¸ï¸ Phase 5-7: Estimator ë¦¬íŒ©í„°ë§**
   - Prior â†’ Fermi â†’ Main

5. **â¸ï¸ Phase 8-9: ê¸°íƒ€ ì»´í¬ë„ŒíŠ¸ + E2E**

6. **â¸ï¸ Phase 10-12: í•˜ìœ„ í˜¸í™˜ + ë¬¸ì„œ + ê²€ì¦**

---

## ğŸ’¬ ì§ˆë¬¸ ë° í”¼ë“œë°±

**ì´ ê³„íšì— ëŒ€í•´**:

1. **Phase ìˆœì„œ** ì ì ˆí•œê°€?
2. **Cursor êµ¬í˜„** (None ë°˜í™˜ + ë¡œê¹…) ë™ì˜í•˜ëŠ”ê°€?
3. **External í”„ë¡¬í”„íŠ¸** í…œí”Œë¦¿í™” ë°©ì‹ ê´œì°®ì€ê°€?
4. **ì´ 37ì‹œê°„** (5ì¼) ì¼ì • í•©ë¦¬ì ì¸ê°€?
5. **ìš°ì„ ìˆœìœ„** ì¡°ì • í•„ìš”í•œ ë¶€ë¶„ ìˆëŠ”ê°€?

**í”¼ë“œë°± ì£¼ì‹œë©´ ì¦‰ì‹œ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤!** ğŸš€

---

**ì‘ì„±**: 2025-11-26
**v7.11.0 ì™„ì „ ì¶”ìƒí™” êµ¬í˜„ ê³„íš** ğŸ¯
