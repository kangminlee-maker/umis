# LLM Mode ì¶”ìƒí™” ë¶„ì„ ë° ê°œì„  ë°©ì•ˆ v7.11.0

**ì‘ì„±ì¼**: 2025-11-26
**ë²„ì „**: v7.11.0
**ëª©í‘œ**: Native/External ë¶„ê¸°ë¥¼ ë¹„ì¦ˆë‹ˆìŠ¤ ë ˆì´ì–´ì—ì„œ ì™„ì „íˆ ì œê±°

---

## ğŸ¯ ë¬¸ì œ ì •ì˜

### í˜„ì¬ ìƒí™©

**3ê°œì˜ ë ˆì´ì–´ê°€ ëª¨ë‘ LLM Modeë¥¼ ì•Œê³  ìˆìŒ**:
```
1. ë¹„ì¦ˆë‹ˆìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° (Cursor Composer)
   â””â”€ í”„ë¡œì íŠ¸ ê´€ë¦¬, Agent ì¡°ìœ¨, ìœ ì € ëŒ€í™”

2. Estimator (4-Stage Fusion)
   â””â”€ Stage 1-4 ë¡œì§, ê°’ ì¶”ì • íŒë‹¨
   â””â”€ âŒ native_mode / external_mode ë¶„ê¸° ì¡´ì¬

3. LLM Infrastructure
   â”œâ”€ model_configs.yaml (ëª¨ë¸ ì •ì˜)
   â”œâ”€ model_router.py (Phase â†’ Model ì„ íƒ)
   â””â”€ llm_provider.py (LLM ê°ì²´ ìƒì„±)
```

**ë¬¸ì œ**:
```python
# Estimator ì½”ë“œ ê³³ê³³ì— ë¶„ê¸°
if self.llm_mode == "cursor":
    # RAGë§Œ ìˆ˜í–‰
    return prepare_for_cursor(...)
else:
    # External API í˜¸ì¶œ
    return call_llm_api(...)
```

**ì´ìœ **: "cursor"ë¥¼ ê°€ì§œ External LLM íƒ€ì…ìœ¼ë¡œ ìš°ê²¨ ë„£ì–´ í†µí•©í•œ ë ˆê±°ì‹œ

---

## ğŸ¯ ëª©í‘œ ìƒíƒœ

### "EstimatorëŠ” LLMì´ ë­”ì§€ ëª¨ë¥´ëŠ” ë°”ë³´"

```
Estimator 4-Stage ì½”ë“œ:
  â”œâ”€ Stage 1: Evidence Collection
  â”œâ”€ Stage 2: Generative Prior
  â”‚   â””â”€ llm = router.get_llm("prior_estimation")
  â”‚       â””â”€ llm.estimate(question, context)
  â”œâ”€ Stage 3: Structural Explanation
  â”‚   â””â”€ llm = router.get_llm("fermi_decomposition")
  â”‚       â””â”€ llm.decompose(question, budget)
  â””â”€ Stage 4: Fusion

âŒ ì œê±°í•  ê²ƒ:
  - if self.llm_mode == "cursor"
  - if native_mode: ... elif external_mode: ...
  - "cursor" íƒ€ì… ì²´í¬

âœ… ë‚¨ê¸¸ ê²ƒ:
  - router.get_llm(task_name) í˜¸ì¶œë§Œ
  - LLM í•¸ë“¤ ì‚¬ìš© (ì¶”ìƒí™”ëœ ì¸í„°í˜ì´ìŠ¤)
```

---

## ğŸ“Š í˜„ì¬ ìƒíƒœ ë¶„ì„

### 1. Estimator ì½”ë“œì˜ llm_mode ì‚¬ìš©

```bash
umis_rag/agents/estimator/
â”œâ”€â”€ estimator.py (8ê³³)
â”‚   â””â”€ self.llm_mode ì´ˆê¸°í™” ë° ì „íŒŒ
â”œâ”€â”€ prior_estimator.py (9ê³³)
â”‚   â””â”€ llm_mode property, ì¡°ê±´ ë¶„ê¸°
â”œâ”€â”€ fermi_estimator.py (7ê³³)
â”‚   â””â”€ llm_mode property, ì¡°ê±´ ë¶„ê¸°
â”œâ”€â”€ evidence_collector.py (7ê³³)
â”‚   â””â”€ llm_mode property
â”œâ”€â”€ source_collector.py (8ê³³)
â”‚   â””â”€ llm_mode property
â”œâ”€â”€ boundary_validator.py (6ê³³)
â”‚   â””â”€ llm_mode == "cursor" ë¶„ê¸°
â”œâ”€â”€ guardrail_analyzer.py (4ê³³)
â”‚   â””â”€ llm_mode property
â””â”€â”€ sources/value.py (12ê³³)
    â””â”€ if llm_mode == "cursor" ë¶„ê¸° âŒ ê°€ì¥ ì‹¬ê°
```

**ì´ 61ê³³ì—ì„œ llm_mode ì‚¬ìš©!**

### 2. model_router.py ë¶„ì„

**í˜„ì¬**:
```python
class ModelRouter:
    def select_model(self, phase: PhaseType) -> str:
        # Phase â†’ ëª¨ë¸ëª…ë§Œ ë°˜í™˜
        if phase in [0, 1, 2]:
            return settings.llm_model_phase0_2
        elif phase == 3:
            return settings.llm_model_phase3
        elif phase == 4:
            return settings.llm_model_phase4
    
    def select_model_with_config(self, phase: PhaseType) -> Tuple[str, ModelConfig]:
        # Phase â†’ (ëª¨ë¸ëª…, ModelConfig)
        model_name = self.select_model(phase)
        config = model_config_manager.get_config(model_name)
        return model_name, config
```

**ë¬¸ì œ**: ëª¨ë¸ëª…ê³¼ Configë§Œ ë°˜í™˜, **ì‹¤ì œ LLM ê°ì²´ëŠ” Estimatorê°€ ì§ì ‘ ìƒì„±**

### 3. llm_provider.py ë¶„ì„

```python
class LLMProvider:
    @staticmethod
    def create_llm() -> Optional[BaseChatModel]:
        mode = settings.llm_mode.lower()
        
        if mode == "cursor":
            return None  # â† Cursor ëª¨ë“œëŠ” None ë°˜í™˜
        else:
            return ChatOpenAI(...)  # â† Externalì€ ê°ì²´ ìƒì„±
```

**ë¬¸ì œ**: `None` ë°˜í™˜ â†’ Estimatorê°€ `if llm is None` ë¶„ê¸° í•„ìš”

---

## ğŸ’¡ ì œì•ˆëœ ëŒ€ì•ˆ (ì‚¬ìš©ì)

### ê°œë…

**"í•˜ë‚˜ì˜ ëŠ¥ë ¥ ìˆëŠ” LLM Router"ë§Œ Estimatorê°€ ì•Œë„ë¡**:

```python
# Estimator ì½”ë“œ
class EstimatorRAG:
    def __init__(self):
        self.llm_router = UnifiedLLMRouter()  # â† í†µí•© ë¼ìš°í„°
        # âŒ self.llm_mode ì œê±°
    
    def estimate(self, question):
        # Stage 2: Prior
        llm = self.llm_router.get_llm("prior_estimation")
        prior_result = llm.estimate(question, context)
        
        # Stage 3: Fermi
        llm = self.llm_router.get_llm("fermi_decomposition")
        fermi_result = llm.decompose(question, budget)
```

**Router ë’¤ì—ì„œ**:
```python
class UnifiedLLMRouter:
    def get_llm(self, task: str) -> LLMInterface:
        # .env LLM_MODE í™•ì¸
        if settings.llm_mode == "cursor":
            return CursorLLMAdapter()  # â† ì¶”ìƒí™”ëœ ì¸í„°í˜ì´ìŠ¤
        else:
            # model_configs.yamlì—ì„œ taskë³„ ëª¨ë¸ ì„ íƒ
            model = self._select_model_for_task(task)
            return ExternalLLMAdapter(model)
```

**ì¥ì **:
- âœ… Estimator ì½”ë“œì—ì„œ `if llm_mode` ì™„ì „ ì œê±°
- âœ… Native/External ì „í™˜ ì‹œ ì½”ë“œ ìˆ˜ì • 0ì¤„
- âœ… .env / YAMLë§Œ ë³€ê²½
- âœ… Clean Architecture (Dependency Inversion)

**ë‹¨ì **:
- âš ï¸ LLMInterface ì¶”ìƒí™” í•„ìš” (ìƒˆ ì½”ë“œ)
- âš ï¸ ê¸°ì¡´ ì½”ë“œ ëŒ€ëŒ€ì  ë¦¬íŒ©í„°ë§ (61ê³³)

---

## ğŸ” ëŒ€ì•ˆ ë¶„ì„

### ëŒ€ì•ˆ 1: ì‚¬ìš©ì ì œì•ˆ (ì™„ì „ ì¶”ìƒí™”)

**êµ¬ì¡°**:
```
Estimator (ë¹„ì¦ˆë‹ˆìŠ¤ ë ˆì´ì–´)
  â””â”€ UnifiedLLMRouter.get_llm(task) í˜¸ì¶œ
      â””â”€ LLMInterface ë°˜í™˜
          â”œâ”€ CursorLLMAdapter (Native)
          â””â”€ ExternalLLMAdapter (OpenAI/Anthropic)
```

**êµ¬í˜„ í•„ìš”**:
1. `LLMInterface` ì¶”ìƒ í´ë˜ìŠ¤
2. `CursorLLMAdapter` (Native êµ¬í˜„)
3. `ExternalLLMAdapter` (External êµ¬í˜„)
4. `UnifiedLLMRouter` (Task â†’ LLM ë§¤í•‘)
5. Estimator ì „ì²´ ë¦¬íŒ©í„°ë§ (61ê³³)

**ì¥ì **:
- âœ… ì™„ë²½í•œ ì¶”ìƒí™” (Clean Architecture)
- âœ… ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ìˆœìˆ˜ì„±
- âœ… í…ŒìŠ¤íŠ¸ ìš©ì´ (Mock ì£¼ì…)
- âœ… í™•ì¥ ê°€ëŠ¥ (ìƒˆ LLM íƒ€ì… ì¶”ê°€ ì‰¬ì›€)

**ë‹¨ì **:
- âš ï¸ ëŒ€ê·œëª¨ ë¦¬íŒ©í„°ë§ (61ê³³)
- âš ï¸ CursorLLMAdapter êµ¬í˜„ ë³µì¡ (CursorëŠ” ì‹¤ì œ í˜¸ì¶œ ë¶ˆê°€)
- âš ï¸ ê°œë°œ ì‹œê°„ (2-3ì¼)

**ìœ„í—˜ë„**: ì¤‘ê°„ (ëŒ€ê·œëª¨ ë³€ê²½)

---

### ëŒ€ì•ˆ 2: Router í™•ì¥ (ì ì§„ì  ê°œì„ )

**êµ¬ì¡°**:
```
Estimator
  â””â”€ router.execute_llm_task(task, prompt, context)
      â””â”€ Router ë‚´ë¶€ì—ì„œ native/external ë¶„ê¸°
          â”œâ”€ if cursor: return MockResult (Cursorìš© í¬ë§·)
          â””â”€ else: call External API
```

**êµ¬í˜„**:
```python
class ModelRouter:
    def execute_llm_task(
        self, 
        task: str,  # "prior_estimation", "fermi_decomposition"
        prompt: str,
        context: dict
    ) -> Union[EstimationResult, dict]:
        """
        LLM ì‘ì—… ì‹¤í–‰ (Native/External ìë™ ë¶„ê¸°)
        """
        if settings.llm_mode == "cursor":
            # Cursor ëª¨ë“œ: í¬ë§·ëœ ê²°ê³¼ë§Œ ë°˜í™˜
            return {
                "mode": "cursor",
                "task": task,
                "prompt": prompt,
                "context": context,
                "instruction": f"ìœ„ contextë¡œ {task} ìˆ˜í–‰"
            }
        else:
            # External ëª¨ë“œ: ì‹¤ì œ API í˜¸ì¶œ
            model_name, config = self.select_model_with_config_for_task(task)
            llm = self._create_llm(model_name, config)
            return llm.invoke(prompt, context)
```

**Estimator ì½”ë“œ**:
```python
# Before
if self.llm_mode == "cursor":
    return prepare_cursor(...)
else:
    llm = ChatOpenAI(...)
    return llm.invoke(...)

# After
result = router.execute_llm_task("prior_estimation", prompt, context)
return result
```

**ì¥ì **:
- âœ… Estimatorì—ì„œ ë¶„ê¸° ì œê±°
- âœ… Routerì— ë¶„ê¸° ì§‘ì¤‘ (1ê³³)
- âœ… ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ëŠ¥
- âœ… ê°œë°œ ì‹œê°„ ì§§ìŒ (1ì¼)

**ë‹¨ì **:
- âš ï¸ Routerê°€ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¼ë¶€ í¬í•¨ (ì™„ì „í•œ ì¶”ìƒí™” ì•„ë‹˜)
- âš ï¸ Task íƒ€ì… ì •ì˜ í•„ìš”

**ìœ„í—˜ë„**: ë‚®ìŒ

---

### ëŒ€ì•ˆ 3: Facade íŒ¨í„´ (ì¤‘ê°„ ì§€ì )

**êµ¬ì¡°**:
```
Estimator
  â””â”€ LLMFacade
      â”œâ”€ estimate_prior(question, context) â†’ EstimationResult
      â”œâ”€ decompose_fermi(question, budget) â†’ DecompositionResult
      â””â”€ validate_reasoning(reasoning) â†’ bool
      
LLMFacade ë‚´ë¶€:
  â””â”€ if cursor: CursorStrategy
  â””â”€ else: ExternalStrategy
```

**êµ¬í˜„**:
```python
class LLMFacade:
    """í†µí•© LLM ì¸í„°í˜ì´ìŠ¤ (Facade Pattern)"""
    
    def __init__(self):
        if settings.llm_mode == "cursor":
            self.strategy = CursorStrategy()
        else:
            self.strategy = ExternalStrategy()
    
    def estimate_prior(self, question: str, context: dict) -> EstimationResult:
        """Prior ì¶”ì • (Stage 2)"""
        return self.strategy.estimate_prior(question, context)
    
    def decompose_fermi(self, question: str, budget: Budget) -> DecompositionResult:
        """Fermi ë¶„í•´ (Stage 3)"""
        return self.strategy.decompose_fermi(question, budget)
```

**Estimator ì½”ë“œ**:
```python
class EstimatorRAG:
    def __init__(self):
        self.llm = LLMFacade()  # â† í†µí•© ì¸í„°í˜ì´ìŠ¤
        # âŒ self.llm_mode ì œê±°
    
    def _run_stage2_prior(self, ...):
        result = self.llm.estimate_prior(question, context)
        # âœ… ë¶„ê¸° ì—†ìŒ
```

**ì¥ì **:
- âœ… Estimator ë¶„ê¸° ì œê±°
- âœ… Strategy Pattern (í™•ì¥ ìš©ì´)
- âœ… Facade Pattern (ë‹¨ìˆœ ì¸í„°í˜ì´ìŠ¤)
- âœ… Taskë³„ ë©”ì„œë“œ (íƒ€ì… ì•ˆì •ì„±)

**ë‹¨ì **:
- âš ï¸ ì¤‘ê°„ ë ˆì´ì–´ ì¶”ê°€ (ë³µì¡ë„ ì¦ê°€)
- âš ï¸ CursorStrategy êµ¬í˜„ í•„ìš”

**ìœ„í—˜ë„**: ë‚®ìŒ

---

## ğŸ† ìµœì„ ì˜ ëŒ€ì•ˆ: **ëŒ€ì•ˆ 2 (Router í™•ì¥) + Cursor ê°„ì†Œí™”**

### ì´ìœ 

1. **í˜„ì‹¤ì„±**
   - CursorëŠ” ì‹¤ì œ API í˜¸ì¶œì´ **ë¶ˆê°€ëŠ¥**
   - Cursor ëª¨ë“œ = "RAG ê²°ê³¼ë§Œ ì¤€ë¹„"ê°€ ë³¸ì§ˆ
   - ì™„ì „í•œ ì¶”ìƒí™”ëŠ” Cursorì˜ í•œê³„ë¡œ ì˜ë¯¸ ì—†ìŒ

2. **íš¨ìœ¨ì„±**
   - 61ê³³ ë¦¬íŒ©í„°ë§ vs 1ê³³ ì§‘ì¤‘
   - ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ëŠ¥
   - v7.11.0 ë°°í¬ ì§€ì—° ìµœì†Œí™”

3. **ëª…í™•ì„±**
   - Router = "LLM ì„ íƒ + ì‹¤í–‰"ì˜ ë‹¨ì¼ ì±…ì„
   - Estimator = "Stage ë¡œì§"ì˜ ë‹¨ì¼ ì±…ì„

---

## ğŸš€ ì œì•ˆ êµ¬ì¡°

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Estimator (ë¹„ì¦ˆë‹ˆìŠ¤ ë ˆì´ì–´)        â”‚
â”‚  âŒ llm_mode ëª°ë¼ë„ ë¨             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ router.execute(task, prompt, context)
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UnifiedLLMRouter                  â”‚
â”‚  âœ… llm_mode ì•Œê³  ë¶„ê¸°             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  execute_llm_task(task, ...)       â”‚
â”‚    â”œâ”€ if cursor: return Mock       â”‚
â”‚    â””â”€ else: call External API      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â”‚ Task â†’ Stage/Model ë§¤í•‘
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Infrastructure                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - model_configs.yaml              â”‚
â”‚  - .env (LLM_MODE, LLM_MODEL_*)    â”‚
â”‚  - ModelConfig, LLMProvider        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Task ì •ì˜

```python
# Task Types (Stage ê¸°ë°˜)
TASK_STAGE1_EVIDENCE = "evidence_collection"      # Stage 1 (ê²€ìƒ‰ë§Œ, LLM ë¶ˆí•„ìš”)
TASK_STAGE2_PRIOR = "prior_estimation"            # Stage 2 (ì§ì ‘ ì¶”ì •)
TASK_STAGE2_CERTAINTY = "certainty_evaluation"    # Stage 2 (í™•ì‹ ë„ í‰ê°€)
TASK_STAGE3_DECOMPOSE = "fermi_decomposition"     # Stage 3 (ë³€ìˆ˜ ì‹ë³„)
TASK_STAGE3_VARIABLE = "fermi_variable_estimate"  # Stage 3 (ë³€ìˆ˜ ì¶”ì • = Stage 2 ì¬ì‚¬ìš©)
TASK_STAGE4_FUSION = "fusion_calculation"         # Stage 4 (ê³„ì‚°ë§Œ, LLM ë¶ˆí•„ìš”)
```

### Router í™•ì¥

```python
class UnifiedLLMRouter:
    """í†µí•© LLM Router (v7.11.0: Stage ê¸°ë°˜)"""
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Task â†’ Stage ë§¤í•‘
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    TASK_TO_STAGE = {
        "evidence_collection": 1,     # Stage 1 (LLM ë¶ˆí•„ìš”)
        "prior_estimation": 2,        # Stage 2
        "certainty_evaluation": 2,    # Stage 2
        "fermi_decomposition": 3,     # Stage 3
        "fermi_variable_estimate": 2, # Stage 3 ë³€ìˆ˜ ì¶”ì • = Stage 2 ì¬ì‚¬ìš©
        "fusion_calculation": 4,      # Stage 4 (LLM ë¶ˆí•„ìš”)
    }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # í•µì‹¬ ë©”ì„œë“œ
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def execute_llm_task(
        self,
        task: str,
        prompt: str,
        context: dict = None,
        **kwargs
    ) -> Union[str, dict]:
        """
        LLM ì‘ì—… ì‹¤í–‰ (Native/External ìë™ ë¶„ê¸°)
        
        Args:
            task: Task íƒ€ì… ("prior_estimation", "fermi_decomposition" ë“±)
            prompt: LLM í”„ë¡¬í”„íŠ¸
            context: ì»¨í…ìŠ¤íŠ¸ ë°ì´í„°
            **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„° (temperature, max_tokens ë“±)
        
        Returns:
            - Cursor ëª¨ë“œ: dict (í¬ë§·ëœ ë°ì´í„°)
            - External ëª¨ë“œ: str (LLM ì‘ë‹µ)
        """
        # Stage ë§¤í•‘
        stage = self.TASK_TO_STAGE.get(task, 2)  # ê¸°ë³¸ Stage 2
        
        # LLM Mode ì²´í¬
        if settings.llm_mode == "cursor":
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            # Cursor ëª¨ë“œ: í¬ë§·ë§Œ ë°˜í™˜
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            return {
                "mode": "cursor",
                "task": task,
                "stage": stage,
                "prompt": prompt,
                "context": context,
                "instruction": f"[{task}] ìœ„ contextë¡œ ì¶”ì • ìˆ˜í–‰"
            }
        
        else:
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            # External ëª¨ë“œ: ì‹¤ì œ API í˜¸ì¶œ
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            
            # 1. Task â†’ Stage â†’ Model ì„ íƒ
            model_name, config = self.select_model_with_config(stage)
            
            # 2. LLM ê°ì²´ ìƒì„±
            llm = self._create_llm(model_name, config)
            
            # 3. API í˜¸ì¶œ
            params = config.build_api_params(
                prompt=prompt,
                **kwargs
            )
            
            response = llm.invoke(params)
            return self._parse_response(response, config.api_type)
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # í—¬í¼ ë©”ì„œë“œ
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _create_llm(self, model_name: str, config: ModelConfig):
        """LLM ê°ì²´ ìƒì„± (Externalë§Œ)"""
        if config.api_type == "responses":
            # Responses API
            from openai import OpenAI
            return OpenAI().responses
        elif config.api_type == "chat":
            # Chat API
            from langchain_openai import ChatOpenAI
            return ChatOpenAI(model=model_name, ...)
        else:
            raise ValueError(f"Unknown api_type: {config.api_type}")
    
    def _parse_response(self, response, api_type: str) -> str:
        """API ì‘ë‹µ íŒŒì‹±"""
        if api_type == "responses":
            return response.choices[0].message.content
        else:  # chat
            return response.content
```

### Estimator ì½”ë“œ ë³€ê²½

```python
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Before (v7.10.2)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class PriorEstimator:
    def __init__(self, llm_mode: Optional[str] = None):
        self._llm_mode = llm_mode
    
    @property
    def llm_mode(self) -> str:
        if self._llm_mode is None:
            return settings.llm_mode
        return self._llm_mode
    
    def estimate(self, question, context):
        if self.llm_mode == "cursor":
            # Cursor ëª¨ë“œ ì²˜ë¦¬
            return self._prepare_cursor_output(...)
        else:
            # External ëª¨ë“œ ì²˜ë¦¬
            llm = ChatOpenAI(...)
            return llm.invoke(...)

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# After (v7.11.0 ì œì•ˆ)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class PriorEstimator:
    def __init__(self, router: Optional[UnifiedLLMRouter] = None):
        self.router = router or get_unified_router()
        # âŒ llm_mode ì œê±°
    
    def estimate(self, question, context):
        # âœ… ë¶„ê¸° ì—†ìŒ
        prompt = self._build_prompt(question, context)
        result = self.router.execute_llm_task(
            task="prior_estimation",
            prompt=prompt,
            context=context
        )
        
        # Result ì²˜ë¦¬ (Cursor/External ë™ì¼)
        return self._parse_result(result)
```

**ì¥ì **:
- âœ… Estimator ë¶„ê¸° ì™„ì „ ì œê±°
- âœ… Router 1ê³³ì—ë§Œ ë¶„ê¸° ì§‘ì¤‘
- âœ… ê¸°ì¡´ infrastructure ì¬ì‚¬ìš©
- âœ… ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜

**ë‹¨ì **:
- âš ï¸ Cursor ê²°ê³¼ í¬ë§· ë‹¤ë¦„ (dict vs str)
- âš ï¸ `_parse_result()` í•„ìš”

**ìœ„í—˜ë„**: ë‚®ìŒ

---

### ëŒ€ì•ˆ 4: í˜„ìƒ ìœ ì§€ + Documentation

**í˜„ì¬ ìƒíƒœ**:
- Estimatorê°€ `llm_mode` property ë³´ìœ 
- ê° ì»´í¬ë„ŒíŠ¸ì—ì„œ ë¶„ê¸° ì²˜ë¦¬
- 61ê³³ì—ì„œ `llm_mode` ì‚¬ìš©

**ê°œì„ **:
- ë¬¸ì„œí™” ê°•í™”
- ì¼ê´€ëœ íŒ¨í„´ ì ìš©
- í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ëŒ€

**ì¥ì **:
- âœ… ë¦¬íŒ©í„°ë§ ë¶ˆí•„ìš”
- âœ… ì•ˆì •ì„± (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)

**ë‹¨ì **:
- âŒ ê·¼ë³¸ì  í•´ê²° ì•„ë‹˜
- âŒ ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€ ì§€ì†

**ìœ„í—˜ë„**: ì—†ìŒ (ë³€ê²½ ì—†ìŒ)

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ì•ˆ

### **ëŒ€ì•ˆ 2 + Cursor íŠ¹ìˆ˜ ì²˜ë¦¬**

**í•µì‹¬ ì¸ì‚¬ì´íŠ¸**:

Cursor ëª¨ë“œëŠ” ì‹¤ì œ "LLM"ì´ ì•„ë‹ˆë¼ **"LLMì—ê²Œ ì „ë‹¬í•  ë°ì´í„° ì¤€ë¹„"**ì…ë‹ˆë‹¤.

ë”°ë¼ì„œ:
1. **External LLM**: Routerê°€ API í˜¸ì¶œ â†’ ê²°ê³¼ ë°˜í™˜
2. **Cursor "LLM"**: Routerê°€ í¬ë§·ë§Œ ë°˜í™˜ â†’ Estimatorê°€ ì¦‰ì‹œ ë°˜í™˜

### êµ¬í˜„ ê³„íš

#### Phase 1: Router í™•ì¥ (1ì¼)

```python
# umis_rag/core/unified_llm_router.py (ì‹ ê·œ)

class UnifiedLLMRouter:
    """
    í†µí•© LLM Router (v7.11.0)
    
    ì±…ì„:
    - Task â†’ Stage â†’ Model ì„ íƒ
    - Native/External ë¶„ê¸° (ì—¬ê¸°ì„œë§Œ!)
    - LLM ì‹¤í–‰ (Externalë§Œ)
    """
    
    def execute_llm_task(
        self,
        task: str,
        prompt: str,
        context: dict = None,
        budget: Optional[Budget] = None,
        **kwargs
    ) -> Union[str, dict]:
        """
        í†µí•© LLM ì‘ì—… ì‹¤í–‰
        
        Returns:
            - Cursor: dict (í¬ë§·ëœ ë°ì´í„°)
            - External: str (LLM ì‘ë‹µ)
        """
        stage = self._task_to_stage(task)
        
        if settings.llm_mode == "cursor":
            # Cursor ëª¨ë“œ: ì¤€ë¹„ë§Œ
            return self._prepare_cursor_format(task, stage, prompt, context)
        else:
            # External ëª¨ë“œ: ì‹¤í–‰
            return self._execute_external_llm(stage, prompt, context, **kwargs)
    
    def _execute_external_llm(self, stage, prompt, context, **kwargs) -> str:
        """External LLM ì‹¤í–‰ (Router ë‚´ë¶€)"""
        # 1. Model ì„ íƒ
        model_name, config = self.select_model_with_config(stage)
        
        # 2. API íŒŒë¼ë¯¸í„° ë¹Œë“œ
        params = config.build_api_params(prompt=prompt, **kwargs)
        
        # 3. LLM í˜¸ì¶œ
        if config.api_type == "responses":
            response = self._call_responses_api(model_name, params)
        else:  # chat
            response = self._call_chat_api(model_name, params)
        
        return response
    
    def _prepare_cursor_format(self, task, stage, prompt, context) -> dict:
        """Cursor ëª¨ë“œ: í¬ë§·ë§Œ ë°˜í™˜"""
        return {
            "mode": "cursor",
            "task": task,
            "stage": stage,
            "prompt": prompt,
            "context": context or {},
            "instruction": f"ìœ„ contextë¡œ {task} ìˆ˜í–‰í•´ì£¼ì„¸ìš”."
        }
```

#### Phase 2: Estimator ë¦¬íŒ©í„°ë§ (1ì¼)

```python
# umis_rag/agents/estimator/prior_estimator.py

class PriorEstimator:
    def __init__(self, router: Optional[UnifiedLLMRouter] = None):
        self.router = router or get_unified_router()
        # âŒ llm_mode ì™„ì „ ì œê±°
    
    def estimate(self, question: str, context: Context) -> Optional[EstimationResult]:
        """Stage 2: Generative Prior"""
        
        # 1. í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._build_prompt(question, context)
        
        # 2. Router ì‹¤í–‰ (ë¶„ê¸° ì—†ìŒ!)
        response = self.router.execute_llm_task(
            task="prior_estimation",
            prompt=prompt,
            context=context.to_dict()
        )
        
        # 3. ê²°ê³¼ íŒŒì‹±
        if isinstance(response, dict) and response.get("mode") == "cursor":
            # Cursor ëª¨ë“œ: í¬ë§·ëœ ë°ì´í„° ë°˜í™˜ (Estimatorê°€ ì¦‰ì‹œ ë°˜í™˜)
            logger.info("  [Cursor] Prior ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
            return None  # Estimator.estimate()ê°€ Cursor í¬ë§· ë°˜í™˜
        else:
            # External ëª¨ë“œ: LLM ì‘ë‹µ íŒŒì‹±
            return self._parse_llm_response(response)
```

#### Phase 3: Estimator ë©”ì¸ ë¡œì§ ìˆ˜ì • (0.5ì¼)

```python
# umis_rag/agents/estimator/estimator.py

class EstimatorRAG:
    def __init__(self):
        self.router = get_unified_router()  # â† í†µí•© ë¼ìš°í„°
        # âŒ self.llm_mode ì œê±°
        
        # ê° ì»´í¬ë„ŒíŠ¸ì— router ì „ë‹¬
        self.evidence_collector = EvidenceCollector(router=self.router)
        self.prior_estimator = PriorEstimator(router=self.router)
        self.fermi_estimator = FermiEstimator(
            router=self.router,
            prior_estimator=self.prior_estimator
        )
    
    def estimate(self, question: str, ...) -> EstimationResult:
        """4-Stage ì¶”ì • (ë¶„ê¸° ì—†ìŒ!)"""
        
        # Stage 1: Evidence
        evidence = self.evidence_collector.collect(...)
        
        # Stage 2: Prior
        prior_result = self.prior_estimator.estimate(...)
        
        # Cursor ëª¨ë“œ ì²´í¬ (Routerê°€ ë°˜í™˜í•œ dict)
        if isinstance(prior_result, dict) and prior_result.get("mode") == "cursor":
            # Cursor ëª¨ë“œ: ì¦‰ì‹œ ë°˜í™˜ (Composerê°€ ì²˜ë¦¬)
            return prior_result
        
        # Stage 3: Fermi (Externalë§Œ)
        fermi_result = self.fermi_estimator.decompose(...)
        
        # Stage 4: Fusion
        final_result = self._fuse_results(...)
        
        return final_result
```

---

## ğŸ“Š ëŒ€ì•ˆ ë¹„êµ

| í•­ëª© | ëŒ€ì•ˆ 1 (ì™„ì „ ì¶”ìƒí™”) | ëŒ€ì•ˆ 2 (Router í™•ì¥) | ëŒ€ì•ˆ 3 (Facade) | ëŒ€ì•ˆ 4 (í˜„ìƒ ìœ ì§€) |
|------|---------------------|---------------------|-----------------|-------------------|
| **Estimator ë¶„ê¸°** | âœ… ì™„ì „ ì œê±° | âœ… ì™„ì „ ì œê±° | âœ… ì™„ì „ ì œê±° | âŒ ìœ ì§€ (61ê³³) |
| **Clean Architecture** | âœ… ì™„ë²½ | âš ï¸ 90% | âš ï¸ 85% | âŒ 50% |
| **ê°œë°œ ì‹œê°„** | âš ï¸ 2-3ì¼ | âœ… 1-1.5ì¼ | âš ï¸ 1.5-2ì¼ | âœ… 0ì¼ |
| **ìœ„í—˜ë„** | âš ï¸ ì¤‘ê°„ | âœ… ë‚®ìŒ | âœ… ë‚®ìŒ | âœ… ì—†ìŒ |
| **Cursor í•œê³„** | âš ï¸ ë³µì¡í•œ Adapter | âœ… ê°„ë‹¨í•œ í¬ë§· | âš ï¸ Strategy í•„ìš” | - |
| **í™•ì¥ì„±** | âœ… ìµœê³  | âš ï¸ ì¤‘ê°„ | âœ… ë†’ìŒ | âŒ ë‚®ìŒ |
| **ìœ ì§€ë³´ìˆ˜** | âœ… ì‰¬ì›€ | âš ï¸ ì¤‘ê°„ | âš ï¸ ì¤‘ê°„ | âŒ ì–´ë ¤ì›€ |

### ì ìˆ˜
- **ëŒ€ì•ˆ 1**: 85ì  (ì´ìƒì ì´ì§€ë§Œ í˜„ì‹¤ì  í•œê³„)
- **ëŒ€ì•ˆ 2**: **95ì ** â­ (í˜„ì‹¤ì  ìµœì„ )
- **ëŒ€ì•ˆ 3**: 80ì  (ì¤‘ê°„ ë ˆì´ì–´ ì˜¤ë²„í—¤ë“œ)
- **ëŒ€ì•ˆ 4**: 40ì  (ê·¼ë³¸ í•´ê²° ì•„ë‹˜)

---

## ğŸ¯ ìµœì¢… ê²°ë¡ 

### **ëŒ€ì•ˆ 2 (Router í™•ì¥) ê¶Œì¥**

**ì´ìœ **:

1. **Cursorì˜ ë³¸ì§ˆ ì´í•´**
   - Cursor = ì‹¤ì œ LLM ì•„ë‹˜
   - Cursor = "ë°ì´í„° ì¤€ë¹„" + Composerê°€ ì½ìŒ
   - ì™„ì „ ì¶”ìƒí™”ëŠ” Cursor í•œê³„ë¡œ ì˜¤íˆë ¤ ë³µì¡

2. **í˜„ì‹¤ì  Trade-off**
   - Clean Architecture 90% ë‹¬ì„±
   - ê°œë°œ ì‹œê°„ ìµœì†Œ (1-1.5ì¼)
   - ìœ„í—˜ë„ ë‚®ìŒ

3. **ëª…í™•í•œ ì±…ì„ ë¶„ë¦¬**
   ```
   Estimator: "ë­˜ ì¶”ì •í• ì§€" (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
   Router: "ì–´ë–»ê²Œ ì¶”ì •í• ì§€" (Infrastructure)
   ```

4. **ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜**
   - Stage 2 (Prior) ë¨¼ì € ì ìš©
   - í…ŒìŠ¤íŠ¸ í›„ Stage 3 (Fermi) í™•ì¥
   - ë¬¸ì œ ë°œìƒ ì‹œ ë¡¤ë°± ì‰¬ì›€

---

## ğŸš€ ì‹¤í–‰ ê³„íš

### Phase 1: Router í™•ì¥ (4ì‹œê°„)
1. `unified_llm_router.py` ìƒì„±
2. `execute_llm_task()` êµ¬í˜„
3. Task íƒ€ì… ì •ì˜
4. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

### Phase 2: PriorEstimator ë¦¬íŒ©í„°ë§ (3ì‹œê°„)
1. `llm_mode` property ì œê±°
2. `router.execute_llm_task()` ì‚¬ìš©
3. Cursor ëª¨ë“œ í¬ë§· ì²˜ë¦¬
4. í†µí•© í…ŒìŠ¤íŠ¸

### Phase 3: FermiEstimator ë¦¬íŒ©í„°ë§ (3ì‹œê°„)
1. `llm_mode` property ì œê±°
2. `router.execute_llm_task()` ì‚¬ìš©
3. ë³€ìˆ˜ ì¶”ì • = Stage 2 ì¬ì‚¬ìš©
4. E2E í…ŒìŠ¤íŠ¸

### Phase 4: ê¸°íƒ€ ì»´í¬ë„ŒíŠ¸ (2ì‹œê°„)
1. EvidenceCollector
2. SourceCollector
3. BoundaryValidator
4. GuardrailAnalyzer

### Phase 5: ê²€ì¦ (2ì‹œê°„)
1. ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
2. Native/External ëª¨ë“œ ê²€ì¦
3. ë¬¸ì„œ ì—…ë°ì´íŠ¸

**ì´ ì†Œìš” ì‹œê°„**: 14ì‹œê°„ (2ì¼)

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### Cursor ëª¨ë“œì˜ í•œê³„

CursorëŠ” **ì‹¤ì œ LLMì´ ì•„ë‹™ë‹ˆë‹¤**:
- API í˜¸ì¶œ ë¶ˆê°€
- ë™ê¸° ì‹¤í–‰ ë¶ˆê°€
- Composer/Chatì´ ì½ì–´ì•¼ í•¨

ë”°ë¼ì„œ:
- âœ… "ì™„ì „í•œ ì¶”ìƒí™”"ë³´ë‹¤ "ëª…í™•í•œ êµ¬ë¶„"ì´ ë‚«ìŠµë‹ˆë‹¤
- âœ… Cursor = "ë°ì´í„° ì¤€ë¹„", External = "ì‹¤í–‰ ì™„ë£Œ"
- âœ… Routerê°€ ì´ ì°¨ì´ë¥¼ ê´€ë¦¬

### í•˜ìœ„ í˜¸í™˜ì„±

`compat.py`ì— Adapter ì¶”ê°€:
```python
class LegacyLLMModeMixin:
    """í•˜ìœ„ í˜¸í™˜ì„±: llm_mode property ì œê³µ"""
    
    @property
    def llm_mode(self) -> str:
        warnings.warn(
            "llm_mode propertyëŠ” deprecated. "
            "router.execute_llm_task() ì‚¬ìš© ê¶Œì¥",
            DeprecationWarning
        )
        return settings.llm_mode
```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- **í˜„ì¬ êµ¬ì¡°**: `umis_rag/core/model_router.py`
- **Model Config**: `config/model_configs.yaml`
- **LLM Provider**: `umis_rag/core/llm_provider.py`
- **v7.11.0 Migration**: `dev_docs/improvements/V7_11_0_MIGRATION_COMPLETE.md`

---

## ğŸŠ ì˜ˆìƒ íš¨ê³¼

### 1. ì½”ë“œ í’ˆì§ˆ
- âœ… Estimator ìˆœìˆ˜ì„± (61ê³³ â†’ 0ê³³)
- âœ… Single Responsibility (Routerë§Œ ë¶„ê¸°)
- âœ… Dependency Inversion (ì¶”ìƒí™” ì˜ì¡´)

### 2. ìœ ì§€ë³´ìˆ˜
- âœ… Native/External ì „í™˜ ì‹œ ì½”ë“œ ìˆ˜ì • 0ì¤„
- âœ… .env / YAMLë§Œ ë³€ê²½
- âœ… ìƒˆ LLM íƒ€ì… ì¶”ê°€ ì‰¬ì›€

### 3. í…ŒìŠ¤íŠ¸
- âœ… Mock Router ì£¼ì… (ë‹¨ìœ„ í…ŒìŠ¤íŠ¸)
- âœ… Native/External ë…ë¦½ í…ŒìŠ¤íŠ¸
- âœ… Integration í…ŒìŠ¤íŠ¸ ê°„ì†Œí™”

---

## ğŸ’¬ ê²°ë¡ 

**ëŒ€ì•ˆ 2 (Router í™•ì¥ + Cursor íŠ¹ìˆ˜ ì²˜ë¦¬)** ë¥¼ ê°•ë ¥ ê¶Œì¥í•©ë‹ˆë‹¤.

**í•µì‹¬**:
```python
# EstimatorëŠ” ì´ì œ ì´ê²ƒë§Œ ì•Œë©´ ë©ë‹ˆë‹¤:
result = router.execute_llm_task(task, prompt, context)

# Router ë’¤ì—ì„œ ëª¨ë“  ê²ƒì´ ê²°ì •ë©ë‹ˆë‹¤:
# - Cursorì¸ì§€ Externalì¸ì§€
# - ì–´ë–¤ ëª¨ë¸ì¸ì§€
# - ì–´ë–»ê²Œ í˜¸ì¶œí• ì§€
```

**ì‹¤í–‰ ì—¬ë¶€**: ì‚¬ìš©ì ìŠ¹ì¸ í›„ ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥ (2ì¼ ì™„ë£Œ)

---

**ì‘ì„±**: 2025-11-26
**v7.11.0 LLM Mode ì¶”ìƒí™” ì œì•ˆ** ğŸ¯
