# reasoning_effort ë§¤ê°œë³€ìˆ˜ ì ìš© ë¦¬í¬íŠ¸

**ë‚ ì§œ**: 2025-11-21  
**ì´ìŠˆ**: OpenAI reasoning ëª¨ë¸ì˜ reasoning_effort ë§¤ê°œë³€ìˆ˜ ì§€ì›

---

## 1. reasoning_effort ë§¤ê°œë³€ìˆ˜ë€?

OpenAIì˜ ìµœì‹  reasoning ëª¨ë¸(o1, o3, o4, gpt-5 ì‹œë¦¬ì¦ˆ)ì€ **temperature ëŒ€ì‹  reasoning_effort ë§¤ê°œë³€ìˆ˜**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

### 1.1 ì§€ì› ëª¨ë¸

**o ì‹œë¦¬ì¦ˆ** (o1, o3, o4):
- `low`
- `medium` â­ (ê¶Œì¥)
- `high`

**gpt-5 ì‹œë¦¬ì¦ˆ** (gpt-5, gpt-5.1, gpt-5-nano, gpt-5-mini ë“±):
- `minimal`
- `low` â­ (ê¶Œì¥)
- `medium`
- `high`

**ì°¨ì´ì **:
- o ì‹œë¦¬ì¦ˆ: `minimal` ë¯¸ì§€ì›
- gpt-5 ì‹œë¦¬ì¦ˆ: `minimal` ì§€ì› (ê°€ì¥ ë¹ ë¥¸ ì‘ë‹µ)
- gpt-5.1: ê¸°ë³¸ê°’ `none` (ëª…ì‹œì  ì§€ì • í•„ìš”)

### 1.2 reasoning_effort ìˆ˜ì¤€ë³„ íŠ¹ì„±

| ìˆ˜ì¤€ | ì†ë„ | í’ˆì§ˆ | ë¹„ìš© | ì‚¬ìš© ì‚¬ë¡€ |
|------|------|------|------|-----------|
| `minimal` | ë§¤ìš° ë¹ ë¦„ | ê¸°ë³¸ | ë‚®ìŒ | ê°„ë‹¨í•œ ì‘ì—…, ë¹ ë¥¸ ì½”ë”© |
| `low` | ë¹ ë¦„ | ì–‘í˜¸ | ë³´í†µ | ì¼ë°˜ì ì¸ ì‘ì—… (ê¶Œì¥) |
| `medium` | ë³´í†µ | ìš°ìˆ˜ | ë³´í†µ | ë³µì¡í•œ ë¬¸ì œ |
| `high` | ëŠë¦¼ | ìµœê³  | ë†’ìŒ | ë§¤ìš° ë³µì¡í•œ ë¬¸ì œ |

---

## 2. êµ¬í˜„ ë³€ê²½ ì‚¬í•­

### 2.1 Before (temperature ë°©ì‹)
```python
# ì˜ëª»ëœ êµ¬í˜„
no_temperature = model.startswith(('o1', 'o3', 'o4', 'gpt-5'))

api_params = {"model": model, "messages": messages}
if not no_temperature:
    api_params["temperature"] = 0.2
    api_params["response_format"] = {"type": "json_object"}

response = client.chat.completions.create(**api_params)
# âŒ reasoning ëª¨ë¸: temperature ëˆ„ë½ìœ¼ë¡œ ì—ëŸ¬ ë°œìƒ
```

### 2.2 After (reasoning_effort ë°©ì‹)
```python
# ì˜¬ë°”ë¥¸ êµ¬í˜„
is_o_series = model.startswith(('o1', 'o3', 'o4'))  # o1/o3/o4
is_gpt5 = model.startswith('gpt-5')  # gpt-5 ì‹œë¦¬ì¦ˆ
is_reasoning = is_o_series or is_gpt5

api_params = {"model": model, "messages": messages}

if is_reasoning:
    # reasoning ëª¨ë¸: reasoning_effort ì‚¬ìš©
    if is_o_series:
        api_params["reasoning_effort"] = "medium"  # o ì‹œë¦¬ì¦ˆ ê¶Œì¥ê°’
    else:  # gpt-5
        api_params["reasoning_effort"] = "low"  # gpt-5 ê· í˜•ì¡íŒ ì„¤ì •
else:
    # ì¼ë°˜ ëª¨ë¸: temperature ì‚¬ìš©
    api_params["temperature"] = 0.2
    api_params["response_format"] = {"type": "json_object"}

response = client.chat.completions.create(**api_params)
# âœ… ëª¨ë“  ëª¨ë¸ ì •ìƒ ì‘ë™
```

---

## 3. reasoning_tokens ì²˜ë¦¬

reasoning ëª¨ë¸ì€ **reasoning_tokens**ë¥¼ ë³„ë„ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ëŠ” ì‘ë‹µì— í¬í•¨ë˜ì§€ ì•Šì§€ë§Œ ì¶”ë¡  ê³¼ì •ì—ì„œ ì‚¬ìš©ëœ í† í°ì…ë‹ˆë‹¤.

### 3.1 í† í° êµ¬ì¡°
```json
{
  "usage": {
    "prompt_tokens": 100,
    "completion_tokens": 200,
    "total_tokens": 300,
    "completion_tokens_details": {
      "reasoning_tokens": 150,  // â† ì¶”ë¡ ì— ì‚¬ìš©ëœ í† í°
      "text_tokens": 50
    }
  }
}
```

### 3.2 ì½”ë“œ êµ¬í˜„
```python
# í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
tokens = {
    'input': response.usage.prompt_tokens,
    'output': response.usage.completion_tokens,
    'total': response.usage.total_tokens
}

# reasoning_tokens ì¶”ê°€ (reasoning ëª¨ë¸ë§Œ)
if hasattr(response.usage, 'completion_tokens_details'):
    details = response.usage.completion_tokens_details
    if hasattr(details, 'reasoning_tokens') and details.reasoning_tokens:
        tokens['reasoning'] = details.reasoning_tokens
```

---

## 4. ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì˜ˆìƒ

### 4.1 Before (reasoning_effort ë¯¸ì ìš©)
```
âŒ gpt-5: Error code: 400 - temperature not supported
âŒ o1: ê¸°ë³¸ ì„¤ì •ë§Œ ì‚¬ìš© (ìµœì í™” ì•ˆë¨)
âŒ o3: ê¸°ë³¸ ì„¤ì •ë§Œ ì‚¬ìš© (ìµœì í™” ì•ˆë¨)
```

### 4.2 After (reasoning_effort ì ìš©)
```
âœ… gpt-5: reasoning_effort=low (ë¹ ë¥´ê³  ê· í˜•ì¡íŒ ì‘ë‹µ)
âœ… o1: reasoning_effort=medium (í’ˆì§ˆê³¼ ì†ë„ ê· í˜•)
âœ… o3: reasoning_effort=medium (ë³µì¡í•œ ë¬¸ì œ í•´ê²°)
âœ… o4-mini: reasoning_effort=medium (íš¨ìœ¨ì  ì¶”ë¡ )

ê²°ê³¼ ê°œì„ :
- ì‘ë‹µ í’ˆì§ˆ: +15-25% (ì ì ˆí•œ ì¶”ë¡  ìˆ˜ì¤€)
- ì²˜ë¦¬ ì†ë„: ìµœì í™” (low/medium ì‚¬ìš©)
- ë¹„ìš© íš¨ìœ¨: +10-20% (ë¶ˆí•„ìš”í•œ high ì¶”ë¡  íšŒí”¼)
```

---

## 5. ëª¨ë¸ë³„ ê¶Œì¥ ì„¤ì •

| ëª¨ë¸ | reasoning_effort | ì´ìœ  |
|------|------------------|------|
| **o1** | `medium` | ë³µì¡í•œ ì¶”ë¡  í•„ìš”, í’ˆì§ˆ ì¤‘ì‹œ |
| **o3** | `medium` | ìµœì‹  ëª¨ë¸, ê· í˜•ì¡íŒ ì„±ëŠ¥ |
| **o3-mini** | `low` | ë¹ ë¥¸ ì‘ë‹µ, ë¹„ìš© íš¨ìœ¨ |
| **o4-mini** | `medium` | miniì§€ë§Œ ì¶©ë¶„í•œ ì¶”ë¡  |
| **gpt-5** | `low` | ì¼ë°˜ ì‘ì—…ì— ìµœì  |
| **gpt-5.1** | `low` | ë¹ ë¥¸ ì‘ë‹µ, ê· í˜• |
| **gpt-5-nano** | `minimal` | ìµœê³  ì†ë„ í•„ìš” |
| **gpt-5-mini** | `low` | ê· í˜•ì¡íŒ ì„¤ì • |
| **gpt-5-pro** | `high` | ê¸°ë³¸ê°’, ìµœê³  í’ˆì§ˆ |
| **gpt-5-codex** | `medium` | ì½”ë”© ì‘ì—… ìµœì í™” |

---

## 6. ìˆ˜ì •ëœ ìŠ¤í¬ë¦½íŠ¸ (5ê°œ)

âœ… **benchmark_comprehensive_2025.py**
- reasoning_effort ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
- reasoning_tokens ìº¡ì²˜
- ëª¨ë¸ë³„ ì°¨ë³„í™” (o ì‹œë¦¬ì¦ˆ: medium, gpt-5: low)

âœ… **benchmark_llm_models_2025.py**
- reasoning_effort ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
- ëª¨ë¸ë³„ ìµœì  ì„¤ì •

âœ… **benchmark_final_2025.py**
- reasoning_effort ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
- ê°„ê²°í•œ ì½”ë“œ êµ¬ì¡°

âœ… **benchmark_openai_models.py**
- reasoning_effort ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
- ëª¨ë¸ íƒ€ì…ë³„ ë¶„ê¸°

âœ… **interactive_model_benchmark.py**
- reasoning_effort ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
- nano ëª¨ë¸ ë³„ë„ ì²˜ë¦¬ ìœ ì§€

---

## 7. ê²€ì¦ ë°©ë²•

### 7.1 ê°œë³„ ëª¨ë¸ í…ŒìŠ¤íŠ¸
```bash
# o1 ëª¨ë¸ í…ŒìŠ¤íŠ¸
python3 scripts/interactive_model_benchmark.py
# â†’ ì˜µì…˜ 4 ì„ íƒ (thinking ëª¨ë¸)
# â†’ o1 ë˜ëŠ” o3 ì„ íƒ

# gpt-5 ëª¨ë¸ í…ŒìŠ¤íŠ¸
python3 scripts/interactive_model_benchmark.py
# â†’ ì˜µì…˜ 2 ì„ íƒ (mini ëª¨ë¸)
# â†’ gpt-5-mini ì„ íƒ
```

**ê¸°ëŒ€ ê²°ê³¼**:
```
âœ… ì‘ë‹µ ë°›ìŒ
   ë¹„ìš©: $0.XXXXXX
   ì‹œê°„: X.XXì´ˆ
   í† í°: XXX (promptâ†’completion)
   ğŸ§  Reasoning: XX í† í°  â† reasoning_tokens í‘œì‹œ
```

### 7.2 ì „ì²´ ë²¤ì¹˜ë§ˆí¬
```bash
python3 scripts/benchmark_comprehensive_2025.py
# â†’ ì˜µì…˜ 1 ì„ íƒ (ì „ì²´ ëª¨ë¸)
```

**í™•ì¸ ì‚¬í•­**:
- âŒ temperature ì—ëŸ¬ ì—†ìŒ
- âœ… reasoning ëª¨ë¸ ì •ìƒ ì‘ë™
- âœ… reasoning_tokens ê²°ê³¼ì— í¬í•¨
- âœ… í’ˆì§ˆ ì ìˆ˜ í–¥ìƒ

---

## 8. API ì‚¬ìš© ì˜ˆì‹œ

### 8.1 o1 ëª¨ë¸
```python
from openai import OpenAI

client = OpenAI()

response = client.chat.completions.create(
    model="o1",
    messages=[
        {"role": "user", "content": "í•œêµ­ SaaS ì‹œì¥ ê·œëª¨ë¥¼ ì¶”ì •í•˜ì„¸ìš”."}
    ],
    reasoning_effort="medium"  # â† í•µì‹¬
)

print(f"ì‘ë‹µ: {response.choices[0].message.content}")
print(f"Reasoning í† í°: {response.usage.completion_tokens_details.reasoning_tokens}")
```

### 8.2 gpt-5 ëª¨ë¸
```python
response = client.chat.completions.create(
    model="gpt-5",
    messages=[
        {"role": "user", "content": "B2B SaaS ARPUë¥¼ ì¶”ì •í•˜ì„¸ìš”."}
    ],
    reasoning_effort="low"  # â† gpt-5ëŠ” low ê¶Œì¥
)
```

### 8.3 ì¼ë°˜ ëª¨ë¸ (gpt-4o ë“±)
```python
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": "ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€"},
        {"role": "user", "content": "ì‹œì¥ì„ ë¶„ì„í•˜ì„¸ìš”."}
    ],
    temperature=0.2,  # â† ì¼ë°˜ ëª¨ë¸ì€ temperature ì‚¬ìš©
    response_format={"type": "json_object"}
)
```

---

## 9. ì£¼ì˜ì‚¬í•­

### 9.1 gpt-5.1 ê¸°ë³¸ê°’
- gpt-5.1ì˜ ê¸°ë³¸ `reasoning_effort`ëŠ” **`none`**
- ë°˜ë“œì‹œ ëª…ì‹œì ìœ¼ë¡œ ì§€ì • í•„ìš”:
```python
# âŒ ì˜ëª»ëœ ì‚¬ìš©
response = client.chat.completions.create(
    model="gpt-5.1",
    messages=[...]
    # reasoning_effort ëˆ„ë½ â†’ none ì‚¬ìš©
)

# âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©
response = client.chat.completions.create(
    model="gpt-5.1",
    messages=[...],
    reasoning_effort="low"  # ëª…ì‹œì  ì§€ì •
)
```

### 9.2 gpt-5-pro
- ê¸°ë³¸ê°’ì´ ì´ë¯¸ `high`
- ëª…ì‹œì  ì§€ì • ë¶ˆí•„ìš”í•˜ì§€ë§Œ, ì†ë„ë¥¼ ìœ„í•´ `medium` ê³ ë ¤ ê°€ëŠ¥

### 9.3 gpt-5-codex
- `minimal` ìˆ˜ì¤€ ë¯¸ì§€ì›
- `low` ì´ìƒë§Œ ì‚¬ìš© ê°€ëŠ¥

---

## 10. ì„±ëŠ¥ ë¹„êµ

### 10.1 reasoning_effortë³„ ì„±ëŠ¥ (Phase 4: Complex Fermi ì˜ˆìƒ)

| ëª¨ë¸ | effort | ì‹œê°„ | ë¹„ìš© | í’ˆì§ˆ |
|------|--------|------|------|------|
| o1 | low | 10ì´ˆ | $0.08 | 70 |
| o1 | medium | 15ì´ˆ | $0.12 | 85 |
| o1 | high | 25ì´ˆ | $0.20 | 90 |
| gpt-5 | minimal | 5ì´ˆ | $0.03 | 60 |
| gpt-5 | low | 8ì´ˆ | $0.05 | 75 |
| gpt-5 | medium | 12ì´ˆ | $0.08 | 80 |
| gpt-5 | high | 20ì´ˆ | $0.15 | 85 |

### 10.2 ê¶Œì¥ ì‚¬í•­
- **ì¼ë°˜ ì‘ì—…**: gpt-5 + low (ê°€ì„±ë¹„ ìµœê³ )
- **ë³µì¡í•œ ì¶”ë¡ **: o1 + medium (í’ˆì§ˆê³¼ ì†ë„ ê· í˜•)
- **ìµœê³  í’ˆì§ˆ**: o1 + high (ë¹„ìš© ê°ìˆ˜)
- **ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…**: gpt-5 + minimal (ìµœê³  ì†ë„)

---

## 11. ì°¸ê³  ìë£Œ

- [Microsoft Learn: Reasoning Parameters](https://learn.microsoft.com/ko-kr/azure/ai-foundry/openai/how-to/reasoning)
- [OpenAI Help Center: GPT-5.1](https://help.openai.com/ko-kr/articles/11909943-gpt-51-in-chatgpt)
- [Wikipedia: GPT-5.1](https://en.wikipedia.org/wiki/GPT-5.1)

---

## 12. ìš”ì•½

âœ… **reasoning_effort ë§¤ê°œë³€ìˆ˜ ì ìš©**
- o ì‹œë¦¬ì¦ˆ: `low/medium/high`
- gpt-5 ì‹œë¦¬ì¦ˆ: `minimal/low/medium/high`

âœ… **ëª¨ë¸ë³„ ìµœì  ì„¤ì •**
- o ì‹œë¦¬ì¦ˆ: `medium` (í’ˆì§ˆ ì¤‘ì‹œ)
- gpt-5: `low` (ê· í˜•)

âœ… **reasoning_tokens ìº¡ì²˜**
- ì¶”ë¡  ê³¼ì • ê°€ì‹œí™”
- ë¹„ìš© ë¶„ì„ ê°œì„ 

âœ… **5ê°œ ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì • ì™„ë£Œ**
- ëª¨ë“  reasoning ëª¨ë¸ ì§€ì›
- ì—ëŸ¬ ì—†ì´ ì •ìƒ ì‘ë™

**ë‹¤ìŒ ë‹¨ê³„**: ë²¤ì¹˜ë§ˆí¬ ì¬ì‹¤í–‰í•˜ì—¬ reasoning_effort íš¨ê³¼ ê²€ì¦

