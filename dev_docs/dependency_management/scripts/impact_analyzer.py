#!/usr/bin/env python3
"""
ë³€ê²½ ì˜í–¥ ë¶„ì„ ë„êµ¬

ê¸°ëŠ¥:
- ì½”ë“œ ë³€ê²½ ì „ ì˜í–¥ ë²”ìœ„ íŒŒì•…
- ì§ì ‘ ì˜ì¡´ì„± + ê°„ì ‘ ì˜ì¡´ì„± ì¶”ì 
- ì˜ˆìƒ ì†Œìš” ì‹œê°„ ì¶”ì •

ì‚¬ìš© ì˜ˆì‹œ:
$ python scripts/impact_analyzer.py --change "explorer" --type "agent_rename" --new-name "opportunity_hunter"
$ python scripts/impact_analyzer.py --change "llm_mode" --type "config_change"
$ python scripts/impact_analyzer.py --change "ExplorerRAG" --type "class_rename"

ì§€ì› ë³€ê²½ ìœ í˜•:
- agent_rename: Agent ID ë³€ê²½
- class_rename: í´ë˜ìŠ¤ ì´ë¦„ ë³€ê²½
- module_move: ëª¨ë“ˆ ì´ë™
- config_change: ì„¤ì • í‚¤ ë³€ê²½
- collection_rename: Collection ì´ë¦„ ë³€ê²½
"""

import argparse
import re
import json
from pathlib import Path
from typing import Dict, List, Set, Tuple
from collections import defaultdict


class ImpactAnalyzer:
    """ë³€ê²½ ì˜í–¥ ë¶„ì„ê¸°"""
    
    def __init__(self, root_dir: Path):
        self.root = root_dir
        self.affected_files: Dict[str, List[str]] = {
            "code": [],
            "config": [],
            "data": [],
            "docs": [],
            "scripts": []
        }
        self.indirect_dependencies: List[Tuple[str, str]] = []
        
    def analyze(self, target: str, change_type: str, new_name: str = None) -> Dict:
        """ë³€ê²½ ì˜í–¥ ë¶„ì„"""
        print(f"ğŸ” ë³€ê²½ ì˜í–¥ ë¶„ì„")
        print(f"   ëŒ€ìƒ: {target}")
        print(f"   ìœ í˜•: {change_type}")
        if new_name:
            print(f"   ë³€ê²½ í›„: {new_name}")
        print()
        
        if change_type == "agent_rename":
            return self._analyze_agent_rename(target, new_name)
        elif change_type == "class_rename":
            return self._analyze_class_rename(target, new_name)
        elif change_type == "config_change":
            return self._analyze_config_change(target, new_name)
        elif change_type == "collection_rename":
            return self._analyze_collection_rename(target, new_name)
        elif change_type == "module_move":
            return self._analyze_module_move(target, new_name)
        else:
            return {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ë³€ê²½ ìœ í˜•: {change_type}"}
    
    def _analyze_agent_rename(self, agent_id: str, new_id: str) -> Dict:
        """Agent ID ë³€ê²½ ì˜í–¥ ë¶„ì„"""
        print("ğŸ“‹ Agent ì´ë¦„ ë³€ê²½ ì˜í–¥ ë¶„ì„ ì¤‘...")
        print()
        
        # 1. Python ì½”ë“œ
        print("1ï¸âƒ£  Python ì½”ë“œ ê²€ìƒ‰...")
        self._search_in_python(agent_id)
        
        # 2. YAML ì„¤ì •
        print("2ï¸âƒ£  YAML ì„¤ì • ê²€ìƒ‰...")
        self._search_in_yaml(agent_id)
        
        # 3. ë¬¸ì„œ
        print("3ï¸âƒ£  ë¬¸ì„œ ê²€ìƒ‰...")
        self._search_in_docs(agent_id)
        
        # 4. ë°ì´í„° (RAG ì¸ë±ìŠ¤, chunks)
        print("4ï¸âƒ£  ë°ì´í„° íŒŒì¼ ê²€ìƒ‰...")
        self._search_in_data(agent_id)
        
        # 5. ê°„ì ‘ ì˜ì¡´ì„±
        print("5ï¸âƒ£  ê°„ì ‘ ì˜ì¡´ì„± ë¶„ì„...")
        self._find_indirect_dependencies(agent_id)
        
        return self._generate_report(agent_id, new_id, "agent_rename")
    
    def _analyze_class_rename(self, class_name: str, new_name: str) -> Dict:
        """í´ë˜ìŠ¤ ì´ë¦„ ë³€ê²½ ì˜í–¥ ë¶„ì„"""
        print("ğŸ“‹ í´ë˜ìŠ¤ ì´ë¦„ ë³€ê²½ ì˜í–¥ ë¶„ì„ ì¤‘...")
        print()
        
        # Python ì½”ë“œë§Œ ê²€ìƒ‰
        self._search_in_python(class_name)
        self._search_in_docs(class_name)
        
        return self._generate_report(class_name, new_name, "class_rename")
    
    def _analyze_config_change(self, config_key: str, new_key: str) -> Dict:
        """ì„¤ì • í‚¤ ë³€ê²½ ì˜í–¥ ë¶„ì„"""
        print("ğŸ“‹ ì„¤ì • í‚¤ ë³€ê²½ ì˜í–¥ ë¶„ì„ ì¤‘...")
        print()
        
        # YAML ë° Python ì½”ë“œì—ì„œ ê²€ìƒ‰
        self._search_in_yaml(config_key)
        self._search_in_python(config_key)
        self._search_in_docs(config_key)
        
        return self._generate_report(config_key, new_key, "config_change")
    
    def _analyze_collection_rename(self, collection_name: str, new_name: str) -> Dict:
        """Collection ì´ë¦„ ë³€ê²½ ì˜í–¥ ë¶„ì„"""
        print("ğŸ“‹ Collection ì´ë¦„ ë³€ê²½ ì˜í–¥ ë¶„ì„ ì¤‘...")
        print()
        
        # Python (collection_name=), YAML, ë°ì´í„° ë””ë ‰í† ë¦¬
        self._search_in_python(collection_name)
        self._search_in_yaml(collection_name)
        self._search_in_data(collection_name)
        
        # ChromaDB ë””ë ‰í† ë¦¬
        chroma_dir = self.root / "data" / "chroma"
        if chroma_dir.exists():
            for item in chroma_dir.iterdir():
                if collection_name in item.name:
                    self.affected_files["data"].append(str(item.relative_to(self.root)))
        
        return self._generate_report(collection_name, new_name, "collection_rename")
    
    def _analyze_module_move(self, old_path: str, new_path: str) -> Dict:
        """ëª¨ë“ˆ ì´ë™ ì˜í–¥ ë¶„ì„"""
        print("ğŸ“‹ ëª¨ë“ˆ ì´ë™ ì˜í–¥ ë¶„ì„ ì¤‘...")
        print()
        
        # import ë¬¸ì—ì„œ í•´ë‹¹ ëª¨ë“ˆ ê²€ìƒ‰
        module_name = old_path.replace("/", ".").replace(".py", "")
        self._search_in_python(module_name)
        
        return self._generate_report(old_path, new_path, "module_move")
    
    def _search_in_python(self, pattern: str):
        """Python íŒŒì¼ì—ì„œ íŒ¨í„´ ê²€ìƒ‰"""
        dirs_to_search = [
            self.root / "umis_rag",
            self.root / "scripts"
        ]
        
        for directory in dirs_to_search:
            if not directory.exists():
                continue
            
            for py_file in directory.rglob("*.py"):
                if any(exclude in str(py_file) for exclude in ["__pycache__", "venv", ".venv", "archive"]):
                    continue
                
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    if pattern in content:
                        rel_path = str(py_file.relative_to(self.root))
                        
                        # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
                        if rel_path.startswith("scripts/"):
                            self.affected_files["scripts"].append(rel_path)
                        else:
                            self.affected_files["code"].append(rel_path)
                        
                        # ë§¤ì¹­ëœ ë¼ì¸ ì°¾ê¸° (ë‚˜ì¤‘ì— ë³´ê³ ì„œì— í‘œì‹œ)
                        
                except Exception:
                    pass
    
    def _search_in_yaml(self, pattern: str):
        """YAML íŒŒì¼ì—ì„œ íŒ¨í„´ ê²€ìƒ‰"""
        yaml_dirs = [
            self.root / "config",
            self.root / "data" / "raw"
        ]
        
        for yaml_dir in yaml_dirs:
            if not yaml_dir.exists():
                continue
            
            for yaml_file in yaml_dir.rglob("*.yaml"):
                try:
                    with open(yaml_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    if pattern in content:
                        rel_path = str(yaml_file.relative_to(self.root))
                        self.affected_files["config"].append(rel_path)
                        
                except Exception:
                    pass
    
    def _search_in_docs(self, pattern: str):
        """ë¬¸ì„œ íŒŒì¼ì—ì„œ íŒ¨í„´ ê²€ìƒ‰"""
        doc_files = [
            "umis.yaml",
            "umis_core.yaml",
            ".cursorrules",
            "README.md",
            "umis_examples.yaml",
            "umis_deliverable_standards.yaml"
        ]
        
        for doc_file in doc_files:
            doc_path = self.root / doc_file
            if doc_path.exists():
                try:
                    with open(doc_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    if pattern in content:
                        self.affected_files["docs"].append(doc_file)
                        
                except Exception:
                    pass
        
        # docs/ ë””ë ‰í† ë¦¬
        docs_dir = self.root / "docs"
        if docs_dir.exists():
            for doc_file in docs_dir.rglob("*.md"):
                try:
                    with open(doc_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    if pattern in content:
                        rel_path = str(doc_file.relative_to(self.root))
                        self.affected_files["docs"].append(rel_path)
                        
                except Exception:
                    pass
    
    def _search_in_data(self, pattern: str):
        """ë°ì´í„° íŒŒì¼ì—ì„œ íŒ¨í„´ ê²€ìƒ‰"""
        data_dir = self.root / "data"
        
        if not data_dir.exists():
            return
        
        # chunks/ ë””ë ‰í† ë¦¬ (JSONL íŒŒì¼ëª…)
        chunks_dir = data_dir / "chunks"
        if chunks_dir.exists():
            for jsonl_file in chunks_dir.glob("*.jsonl"):
                if pattern in jsonl_file.name:
                    rel_path = str(jsonl_file.relative_to(self.root))
                    self.affected_files["data"].append(rel_path)
    
    def _find_indirect_dependencies(self, target: str):
        """ê°„ì ‘ ì˜ì¡´ì„± ì°¾ê¸°"""
        # ì§ì ‘ ì˜ì¡´í•˜ëŠ” íŒŒì¼ë“¤ì„ ì°¾ê³ ,
        # ê·¸ íŒŒì¼ë“¤ì„ importí•˜ëŠ” ë‹¤ë¥¸ íŒŒì¼ë“¤ì„ ì°¾ê¸°
        
        direct_files = (
            self.affected_files["code"] + 
            self.affected_files["scripts"]
        )
        
        for direct_file in direct_files:
            # ì´ íŒŒì¼ì„ importí•˜ëŠ” ë‹¤ë¥¸ íŒŒì¼ ì°¾ê¸°
            module_name = direct_file.replace("/", ".").replace(".py", "")
            
            for py_file in self.root.rglob("*.py"):
                if any(exclude in str(py_file) for exclude in ["__pycache__", "venv", ".venv", "archive"]):
                    continue
                
                try:
                    with open(py_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # import ë¬¸ ê²€ìƒ‰
                    if re.search(rf'from\s+{re.escape(module_name)}|import\s+{re.escape(module_name)}', content):
                        rel_path = str(py_file.relative_to(self.root))
                        
                        # ì§ì ‘ ì˜ì¡´ì„±ì´ ì•„ë‹Œ ê²½ìš°ë§Œ
                        if rel_path not in direct_files:
                            self.indirect_dependencies.append((direct_file, rel_path))
                            
                except Exception:
                    pass
    
    def _generate_report(self, target: str, new_name: str, change_type: str) -> Dict:
        """ë¶„ì„ ë³´ê³ ì„œ ìƒì„±"""
        total_files = sum(len(files) for files in self.affected_files.values())
        
        report = {
            "target": target,
            "new_name": new_name,
            "change_type": change_type,
            "total_affected_files": total_files,
            "direct_dependencies": self.affected_files,
            "indirect_dependencies_count": len(self.indirect_dependencies),
            "indirect_dependencies": self.indirect_dependencies,
            "estimated_time_minutes": self._estimate_time(total_files, change_type),
            "recommended_steps": self._get_recommended_steps(change_type)
        }
        
        return report
    
    def _estimate_time(self, file_count: int, change_type: str) -> int:
        """ì˜ˆìƒ ì†Œìš” ì‹œê°„ ì¶”ì • (ë¶„)"""
        base_time = {
            "agent_rename": 30,
            "class_rename": 15,
            "config_change": 20,
            "collection_rename": 25,
            "module_move": 20
        }
        
        base = base_time.get(change_type, 20)
        
        # íŒŒì¼ ìˆ˜ì— ë¹„ë¡€ (íŒŒì¼ë‹¹ 2ë¶„)
        estimated = base + (file_count * 2)
        
        # ê°„ì ‘ ì˜ì¡´ì„± (ì¶”ê°€ ì‹œê°„)
        estimated += len(self.indirect_dependencies) * 3
        
        return estimated
    
    def _get_recommended_steps(self, change_type: str) -> List[str]:
        """ê¶Œì¥ ë‹¨ê³„"""
        common_steps = [
            "ë³€ê²½ ì „ í˜„ì¬ ë¸Œëœì¹˜ ì»¤ë°‹ ë˜ëŠ” stash",
            "ìƒˆ ë¸Œëœì¹˜ ìƒì„±: git checkout -b refactor/ë³€ê²½ëª…",
        ]
        
        type_specific = {
            "agent_rename": [
                "scripts/safe_refactor.py ì‚¬ìš© (ìë™ ë¦¬íŒ©í† ë§)",
                "YAML ì„¤ì • íŒŒì¼ ìˆ˜ë™ ì—…ë°ì´íŠ¸",
                "RAG ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (scripts/02_build_index.py)",
                "ë¬¸ì„œ ì—…ë°ì´íŠ¸ (umis.yaml, umis_core.yaml)",
            ],
            "class_rename": [
                "Rope ë˜ëŠ” IDE ë¦¬íŒ©í† ë§ ê¸°ëŠ¥ ì‚¬ìš©",
                "ëª¨ë“  import ë¬¸ ìë™ ì—…ë°ì´íŠ¸",
            ],
            "config_change": [
                "config/ íŒŒì¼ ì—…ë°ì´íŠ¸",
                "umis_rag/core/config.py ìŠ¤í‚¤ë§ˆ ì—…ë°ì´íŠ¸",
                "ê´€ë ¨ ì½”ë“œì—ì„œ ì°¸ì¡° ë³€ê²½",
            ],
            "collection_rename": [
                "Agent ì½”ë“œì˜ collection_name ì—…ë°ì´íŠ¸",
                "RAG ì¸ë±ìŠ¤ ì¬êµ¬ì¶•",
                "ChromaDB ë””ë ‰í† ë¦¬ ì •ë¦¬",
            ],
            "module_move": [
                "Rope ì‚¬ìš© ê¶Œì¥",
                "ëª¨ë“  import ë¬¸ ìë™ ì—…ë°ì´íŠ¸",
            ]
        }
        
        steps = common_steps + type_specific.get(change_type, [])
        steps.extend([
            "pytest ì‹¤í–‰ (í…ŒìŠ¤íŠ¸ ì¡´ì¬ ì‹œ)",
            "scripts/validate_consistency.py ì‹¤í–‰",
            "ì˜ì¡´ì„± ë§¤íŠ¸ë¦­ìŠ¤ ì¬ìƒì„±",
            "git commit -m 'refactor: ë³€ê²½ ì„¤ëª…'"
        ])
        
        return steps
    
    def print_report(self, report: Dict):
        """ë³´ê³ ì„œ ì¶œë ¥"""
        print()
        print("=" * 60)
        print(f"âœ… ì˜í–¥ ë¶„ì„ ì™„ë£Œ")
        print("=" * 60)
        print()
        
        print(f"ğŸ¯ ë³€ê²½ ëŒ€ìƒ: {report['target']}")
        if report['new_name']:
            print(f"   ë³€ê²½ í›„: {report['new_name']}")
        print(f"   ìœ í˜•: {report['change_type']}")
        print()
        
        print(f"ğŸ“Š ì˜í–¥ ë°›ëŠ” íŒŒì¼: {report['total_affected_files']}ê°œ")
        print()
        
        for category, files in report['direct_dependencies'].items():
            if files:
                print(f"  {category.upper()}: {len(files)}ê°œ")
                for file in sorted(files)[:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
                    print(f"    - {file}")
                if len(files) > 5:
                    print(f"    ... ì™¸ {len(files) - 5}ê°œ")
                print()
        
        if report['indirect_dependencies']:
            print(f"âš ï¸  ê°„ì ‘ ì˜ì¡´ì„±: {report['indirect_dependencies_count']}ê°œ")
            print()
            for direct, indirect in report['indirect_dependencies'][:3]:
                print(f"  - {direct}")
                print(f"    â†’ {indirect}")
                print()
            if len(report['indirect_dependencies']) > 3:
                print(f"  ... ì™¸ {len(report['indirect_dependencies']) - 3}ê°œ")
                print()
        
        print(f"â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: {report['estimated_time_minutes']}ë¶„")
        print()
        
        print("ğŸ’¡ ê¶Œì¥ ë‹¨ê³„:")
        for idx, step in enumerate(report['recommended_steps'], 1):
            print(f"  {idx}. {step}")
        print()
        
        print("=" * 60)
        print()
        
        # JSON ì €ì¥
        json_path = self.root / "impact_analysis_result.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ ìƒì„¸ ê²°ê³¼ ì €ì¥: {json_path}")
        print()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="UMIS ë³€ê²½ ì˜í–¥ ë¶„ì„ ë„êµ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # Agent ì´ë¦„ ë³€ê²½
  python scripts/impact_analyzer.py --change explorer --type agent_rename --new-name opportunity_hunter
  
  # í´ë˜ìŠ¤ ì´ë¦„ ë³€ê²½
  python scripts/impact_analyzer.py --change ExplorerRAG --type class_rename --new-name OpportunityHunterRAG
  
  # ì„¤ì • í‚¤ ë³€ê²½
  python scripts/impact_analyzer.py --change llm_mode --type config_change --new-name ai_mode
  
  # Collection ì´ë¦„ ë³€ê²½
  python scripts/impact_analyzer.py --change explorer_knowledge_base --type collection_rename --new-name explorer_kb
        """
    )
    
    parser.add_argument("--change", required=True, help="ë³€ê²½ ëŒ€ìƒ (Agent ID, í´ë˜ìŠ¤ëª…, ì„¤ì • í‚¤ ë“±)")
    parser.add_argument("--type", required=True, 
                       choices=["agent_rename", "class_rename", "config_change", "collection_rename", "module_move"],
                       help="ë³€ê²½ ìœ í˜•")
    parser.add_argument("--new-name", help="ë³€ê²½ í›„ ì´ë¦„ (ì„ íƒ)")
    
    args = parser.parse_args()
    
    root_dir = Path(__file__).parent.parent
    
    analyzer = ImpactAnalyzer(root_dir)
    report = analyzer.analyze(args.change, args.type, args.new_name)
    
    if "error" in report:
        print(f"âŒ ì—ëŸ¬: {report['error']}")
        return
    
    analyzer.print_report(report)


if __name__ == "__main__":
    main()

