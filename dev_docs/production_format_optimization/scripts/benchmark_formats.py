#!/usr/bin/env python3
"""
UMIS í”„ë¡œë•ì…˜ í¬ë§· ë²¤ì¹˜ë§ˆí¬

ë‹¤ì–‘í•œ ì§ë ¬í™” í¬ë§·ì˜ ì„±ëŠ¥ ë¹„êµ:
- YAML (baseline)
- JSON
- MessagePack
- Protobuf (TODO)
- Parquet
"""

import sys
import time
import json
import yaml
from pathlib import Path
from typing import Dict, Any, List
import tempfile

# ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì €ì¥
results = {}

def measure_time(func):
    """ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°"""
    def wrapper(*args, **kwargs):
        start = time.perf_counter()
        result = func(*args, **kwargs)
        elapsed = (time.perf_counter() - start) * 1000  # ms
        return result, elapsed
    return wrapper


class FormatBenchmark:
    """í¬ë§·ë³„ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    def __init__(self, test_data: Dict[str, Any]):
        self.test_data = test_data
        self.results = {}
        
    def run_all(self) -> Dict[str, Dict[str, float]]:
        """ëª¨ë“  í¬ë§· í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("=" * 60)
        print("UMIS í¬ë§· ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
        print("=" * 60)
        
        # 1. YAML (baseline)
        print("\n[1/5] YAML í…ŒìŠ¤íŠ¸...")
        self.test_yaml()
        
        # 2. JSON
        print("[2/5] JSON í…ŒìŠ¤íŠ¸...")
        self.test_json()
        
        # 3. MessagePack
        print("[3/5] MessagePack í…ŒìŠ¤íŠ¸...")
        try:
            import msgpack
            self.test_msgpack()
        except ImportError:
            print("  âš ï¸  msgpack ë¯¸ì„¤ì¹˜ (pip install msgpack)")
            self.results['msgpack'] = None
        
        # 4. Parquet
        print("[4/5] Parquet í…ŒìŠ¤íŠ¸...")
        try:
            import pandas as pd
            self.test_parquet()
        except ImportError:
            print("  âš ï¸  pandas ë¯¸ì„¤ì¹˜ (pip install pandas pyarrow)")
            self.results['parquet'] = None
        
        # 5. CBOR
        print("[5/5] CBOR í…ŒìŠ¤íŠ¸...")
        try:
            import cbor2
            self.test_cbor()
        except ImportError:
            print("  âš ï¸  cbor2 ë¯¸ì„¤ì¹˜ (pip install cbor2)")
            self.results['cbor'] = None
        
        return self.results
    
    @measure_time
    def _write_yaml(self, filepath):
        """YAML ì“°ê¸°"""
        with open(filepath, 'w', encoding='utf-8') as f:
            yaml.dump(self.test_data, f, default_flow_style=False)
    
    @measure_time
    def _read_yaml(self, filepath):
        """YAML ì½ê¸°"""
        with open(filepath, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    
    def test_yaml(self):
        """YAML ì„±ëŠ¥ ì¸¡ì •"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.yaml', delete=False) as tmp:
            tmp_path = tmp.name
        
        try:
            # Write
            _, write_time = self._write_yaml(tmp_path)
            file_size = Path(tmp_path).stat().st_size
            
            # Read
            _, read_time = self._read_yaml(tmp_path)
            
            self.results['yaml'] = {
                'write_ms': write_time,
                'read_ms': read_time,
                'size_bytes': file_size,
                'size_kb': file_size / 1024
            }
            
            print(f"  âœ… Write: {write_time:.2f}ms | Read: {read_time:.2f}ms | Size: {file_size/1024:.2f}KB")
        finally:
            Path(tmp_path).unlink(missing_ok=True)
    
    @measure_time
    def _write_json(self, filepath):
        """JSON ì“°ê¸°"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.test_data, f, separators=(',', ':'))
    
    @measure_time
    def _read_json(self, filepath):
        """JSON ì½ê¸°"""
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def test_json(self):
        """JSON ì„±ëŠ¥ ì¸¡ì •"""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp:
            tmp_path = tmp.name
        
        try:
            # Write
            _, write_time = self._write_json(tmp_path)
            file_size = Path(tmp_path).stat().st_size
            
            # Read
            _, read_time = self._read_json(tmp_path)
            
            self.results['json'] = {
                'write_ms': write_time,
                'read_ms': read_time,
                'size_bytes': file_size,
                'size_kb': file_size / 1024
            }
            
            print(f"  âœ… Write: {write_time:.2f}ms | Read: {read_time:.2f}ms | Size: {file_size/1024:.2f}KB")
        finally:
            Path(tmp_path).unlink(missing_ok=True)
    
    @measure_time
    def _write_msgpack(self, filepath):
        """MessagePack ì“°ê¸°"""
        import msgpack
        with open(filepath, 'wb') as f:
            msgpack.pack(self.test_data, f)
    
    @measure_time
    def _read_msgpack(self, filepath):
        """MessagePack ì½ê¸°"""
        import msgpack
        with open(filepath, 'rb') as f:
            return msgpack.unpack(f, raw=False)
    
    def test_msgpack(self):
        """MessagePack ì„±ëŠ¥ ì¸¡ì •"""
        with tempfile.NamedTemporaryFile(mode='wb', suffix='.msgpack', delete=False) as tmp:
            tmp_path = tmp.name
        
        try:
            # Write
            _, write_time = self._write_msgpack(tmp_path)
            file_size = Path(tmp_path).stat().st_size
            
            # Read
            _, read_time = self._read_msgpack(tmp_path)
            
            self.results['msgpack'] = {
                'write_ms': write_time,
                'read_ms': read_time,
                'size_bytes': file_size,
                'size_kb': file_size / 1024
            }
            
            print(f"  âœ… Write: {write_time:.2f}ms | Read: {read_time:.2f}ms | Size: {file_size/1024:.2f}KB")
        finally:
            Path(tmp_path).unlink(missing_ok=True)
    
    @measure_time
    def _write_parquet(self, filepath, df):
        """Parquet ì“°ê¸°"""
        df.to_parquet(filepath, compression='zstd', index=False)
    
    @measure_time
    def _read_parquet(self, filepath):
        """Parquet ì½ê¸°"""
        import pandas as pd
        return pd.read_parquet(filepath)
    
    def test_parquet(self):
        """Parquet ì„±ëŠ¥ ì¸¡ì • (í…Œì´ë¸” ë°ì´í„°ë§Œ)"""
        import pandas as pd
        
        # test_dataê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•¨
        if not isinstance(self.test_data, list):
            # Dictë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì‹œë„
            if 'patterns' in self.test_data and isinstance(self.test_data['patterns'], list):
                table_data = self.test_data['patterns']
            else:
                print("  âš ï¸  ParquetëŠ” í…Œì´ë¸” ë°ì´í„°ë§Œ ì§€ì› (ìŠ¤í‚µ)")
                self.results['parquet'] = None
                return
        else:
            table_data = self.test_data
        
        df = pd.DataFrame(table_data)
        
        with tempfile.NamedTemporaryFile(suffix='.parquet', delete=False) as tmp:
            tmp_path = tmp.name
        
        try:
            # Write
            _, write_time = self._write_parquet(tmp_path, df)
            file_size = Path(tmp_path).stat().st_size
            
            # Read
            _, read_time = self._read_parquet(tmp_path)
            
            self.results['parquet'] = {
                'write_ms': write_time,
                'read_ms': read_time,
                'size_bytes': file_size,
                'size_kb': file_size / 1024
            }
            
            print(f"  âœ… Write: {write_time:.2f}ms | Read: {read_time:.2f}ms | Size: {file_size/1024:.2f}KB")
        finally:
            Path(tmp_path).unlink(missing_ok=True)
    
    @measure_time
    def _write_cbor(self, filepath):
        """CBOR ì“°ê¸°"""
        import cbor2
        with open(filepath, 'wb') as f:
            cbor2.dump(self.test_data, f)
    
    @measure_time
    def _read_cbor(self, filepath):
        """CBOR ì½ê¸°"""
        import cbor2
        with open(filepath, 'rb') as f:
            return cbor2.load(f)
    
    def test_cbor(self):
        """CBOR ì„±ëŠ¥ ì¸¡ì •"""
        with tempfile.NamedTemporaryFile(mode='wb', suffix='.cbor', delete=False) as tmp:
            tmp_path = tmp.name
        
        try:
            # Write
            _, write_time = self._write_cbor(tmp_path)
            file_size = Path(tmp_path).stat().st_size
            
            # Read
            _, read_time = self._read_cbor(tmp_path)
            
            self.results['cbor'] = {
                'write_ms': write_time,
                'read_ms': read_time,
                'size_bytes': file_size,
                'size_kb': file_size / 1024
            }
            
            print(f"  âœ… Write: {write_time:.2f}ms | Read: {read_time:.2f}ms | Size: {file_size/1024:.2f}KB")
        finally:
            Path(tmp_path).unlink(missing_ok=True)


def generate_test_data(size='small') -> Dict[str, Any]:
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    
    Args:
        size: 'small', 'medium', 'large'
    """
    if size == 'small':
        # 1ê°œ íŒ¨í„´ (ì‹¤ì œ UMIS íŒ¨í„´ êµ¬ì¡°)
        return {
            'patterns': [{
                'id': 'BM001',
                'name': 'Subscription Model',
                'category': 'Revenue Model',
                'description': 'ì •ê¸° êµ¬ë…ì„ í†µí•œ ë°˜ë³µ ìˆ˜ìµ ëª¨ë¸',
                'triggers': [
                    'High churn in traditional sales',
                    'Customer wants predictable costs',
                    'Product has ongoing value'
                ],
                'examples': [
                    {'company': 'Netflix', 'industry': 'Entertainment'},
                    {'company': 'Spotify', 'industry': 'Music'},
                    {'company': 'Adobe', 'industry': 'Software'}
                ],
                'metrics': {
                    'MRR': 'Monthly Recurring Revenue',
                    'Churn_Rate': 'Customer attrition rate',
                    'LTV': 'Lifetime Value'
                }
            }]
        }
    
    elif size == 'medium':
        # 10ê°œ íŒ¨í„´
        pattern = generate_test_data('small')['patterns'][0]
        return {
            'patterns': [
                {**pattern, 'id': f'BM{i:03d}', 'name': f'Pattern {i}'}
                for i in range(1, 11)
            ]
        }
    
    else:  # large
        # 54ê°œ íŒ¨í„´ (ì‹¤ì œ UMIS Explorer ê·œëª¨)
        pattern = generate_test_data('small')['patterns'][0]
        return {
            'patterns': [
                {**pattern, 'id': f'BM{i:03d}', 'name': f'Pattern {i}'}
                for i in range(1, 55)
            ]
        }


def print_comparison_table(results: Dict[str, Dict[str, float]]):
    """ê²°ê³¼ ë¹„êµ í…Œì´ë¸” ì¶œë ¥"""
    print("\n" + "=" * 60)
    print("ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¹„êµ")
    print("=" * 60)
    
    # YAMLì„ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ì„±ëŠ¥ ê³„ì‚°
    yaml_results = results.get('yaml')
    if not yaml_results:
        print("âš ï¸  YAML ê²°ê³¼ ì—†ìŒ")
        return
    
    print(f"\n{'Format':<12} {'Size (KB)':<12} {'Write (ms)':<12} {'Read (ms)':<12} {'Total (ms)':<12}")
    print("-" * 60)
    
    for format_name in ['yaml', 'json', 'msgpack', 'cbor', 'parquet']:
        if format_name not in results or results[format_name] is None:
            continue
        
        r = results[format_name]
        size_kb = r['size_kb']
        write_ms = r['write_ms']
        read_ms = r['read_ms']
        total_ms = write_ms + read_ms
        
        print(f"{format_name.upper():<12} {size_kb:<12.2f} {write_ms:<12.2f} {read_ms:<12.2f} {total_ms:<12.2f}")
    
    # ìƒëŒ€ ë¹„êµ
    print("\n" + "=" * 60)
    print("YAML ëŒ€ë¹„ ì„±ëŠ¥ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)")
    print("=" * 60)
    print(f"\n{'Format':<12} {'Size':<12} {'Write':<12} {'Read':<12} {'Total':<12}")
    print("-" * 60)
    
    yaml_size = yaml_results['size_kb']
    yaml_write = yaml_results['write_ms']
    yaml_read = yaml_results['read_ms']
    yaml_total = yaml_write + yaml_read
    
    for format_name in ['yaml', 'json', 'msgpack', 'cbor', 'parquet']:
        if format_name not in results or results[format_name] is None:
            continue
        
        r = results[format_name]
        
        size_ratio = r['size_kb'] / yaml_size
        write_ratio = r['write_ms'] / yaml_write if yaml_write > 0 else 0
        read_ratio = r['read_ms'] / yaml_read if yaml_read > 0 else 0
        total_ratio = (r['write_ms'] + r['read_ms']) / yaml_total if yaml_total > 0 else 0
        
        print(f"{format_name.upper():<12} {size_ratio:<12.2f} {write_ratio:<12.2f} {read_ratio:<12.2f} {total_ratio:<12.2f}")
    
    # ê¶Œì¥ì‚¬í•­
    print("\n" + "=" * 60)
    print("ê¶Œì¥ì‚¬í•­")
    print("=" * 60)
    
    # ê°€ì¥ ì‘ì€ í¬ê¸°
    smallest = min(
        [(k, v['size_kb']) for k, v in results.items() if v is not None],
        key=lambda x: x[1]
    )
    print(f"ğŸ“¦ ìµœì†Œ í¬ê¸°: {smallest[0].upper()} ({smallest[1]:.2f}KB)")
    
    # ê°€ì¥ ë¹ ë¥¸ ì½ê¸°
    fastest_read = min(
        [(k, v['read_ms']) for k, v in results.items() if v is not None],
        key=lambda x: x[1]
    )
    print(f"âš¡ ìµœê³  ì½ê¸° ì†ë„: {fastest_read[0].upper()} ({fastest_read[1]:.2f}ms)")
    
    # ê°€ì¥ ë¹ ë¥¸ ì „ì²´
    fastest_total = min(
        [(k, v['write_ms'] + v['read_ms']) for k, v in results.items() if v is not None],
        key=lambda x: x[1]
    )
    print(f"ğŸš€ ìµœê³  ì „ì²´ ì†ë„: {fastest_total[0].upper()} ({fastest_total[1]:.2f}ms)")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description='UMIS í¬ë§· ë²¤ì¹˜ë§ˆí¬')
    parser.add_argument(
        '--size',
        choices=['small', 'medium', 'large'],
        default='medium',
        help='í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸° (default: medium)'
    )
    parser.add_argument(
        '--iterations',
        type=int,
        default=1,
        help='ë°˜ë³µ íšŸìˆ˜ (í‰ê·  ê³„ì‚°ìš©, default: 1)'
    )
    
    args = parser.parse_args()
    
    print(f"\ní…ŒìŠ¤íŠ¸ ì„¤ì •:")
    print(f"  - ë°ì´í„° í¬ê¸°: {args.size}")
    print(f"  - ë°˜ë³µ íšŸìˆ˜: {args.iterations}")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_data = generate_test_data(args.size)
    
    if args.iterations == 1:
        # ë‹¨ì¼ ì‹¤í–‰
        benchmark = FormatBenchmark(test_data)
        results = benchmark.run_all()
        print_comparison_table(results)
    else:
        # ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰ í›„ í‰ê· 
        print(f"\n{args.iterations}íšŒ ë°˜ë³µ ì‹¤í–‰ ì¤‘...\n")
        
        all_results = []
        for i in range(args.iterations):
            print(f"[ë°˜ë³µ {i+1}/{args.iterations}]")
            benchmark = FormatBenchmark(test_data)
            results = benchmark.run_all()
            all_results.append(results)
        
        # í‰ê·  ê³„ì‚°
        avg_results = {}
        for format_name in all_results[0].keys():
            if all_results[0][format_name] is None:
                avg_results[format_name] = None
                continue
            
            avg_results[format_name] = {
                'write_ms': sum(r[format_name]['write_ms'] for r in all_results) / args.iterations,
                'read_ms': sum(r[format_name]['read_ms'] for r in all_results) / args.iterations,
                'size_bytes': all_results[0][format_name]['size_bytes'],  # í¬ê¸°ëŠ” ë™ì¼
                'size_kb': all_results[0][format_name]['size_kb']
            }
        
        print(f"\ní‰ê·  ê²°ê³¼ ({args.iterations}íšŒ):")
        print_comparison_table(avg_results)


if __name__ == '__main__':
    main()

