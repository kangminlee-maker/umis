# Phase 3 ë¶„ì„ - ì‚¬ìš©ì ì§€ì  í™•ì¸

## ë‚ ì§œ
2025-11-25

## âœ… ì‚¬ìš©ì ì§€ì  í™•ì¸ ê²°ê³¼

**ì‚¬ìš©ì ë§ì”€**: 100% ì •í™•í•©ë‹ˆë‹¤!

---

## ë°œê²¬ ì‚¬í•­

### 1. Native Modeìš© ì™„ì „í•œ êµ¬í˜„ì´ ì¡´ì¬í•¨! âœ…

**íŒŒì¼**: `umis_rag/agents/estimator/sources/value.py`

**`_build_native_instruction` ë©”ì„œë“œ** (Line 128-303):
- âœ… **ì™„ì „í•œ êµ¬í˜„** (175ì¤„)
- âœ… Step 1-5 ìƒì„¸ í”„ë¡œì„¸ìŠ¤
- âœ… LLM ì§€ì‹ ê¸°ë°˜ ì¶”ì • (Step 1)
- âœ… ì›¹ ê²€ìƒ‰ ë¡œì§ (Step 2)
- âœ… ìˆ«ì ì¶”ì¶œ ë° ë³€í™˜ (Step 3)
- âœ… Consensus ê³„ì‚° (Step 4)
- âœ… JSON í˜•ì‹ ë°˜í™˜ (Step 5)

**ë‚´ìš© ì˜ˆì‹œ**:
```python
def _build_native_instruction(...) -> str:
    instruction = """# AI Augmented Estimation

**ì§ˆë¬¸**: {question}

## Step 1: ì§€ì‹ ê¸°ë°˜ ì¶”ì • (ìš°ì„ )
- í™•ì‹ ë„ â‰¥ 80%: ì¦‰ì‹œ ê°’ ë°˜í™˜
- í™•ì‹ ë„ < 80%: Step 2ë¡œ ì§„í–‰

## Step 2: ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
- Google/ë„¤ì´ë²„ ê²€ìƒ‰
- ìƒìœ„ 5-10ê°œ ê²°ê³¼

## Step 3: ìˆ«ì ì¶”ì¶œ ë° ë³€í™˜
- 51.7M â†’ 51,700,000
- 2ì¡° 3000ì–µ â†’ 2,300,000,000,000

## Step 4: Consensus ê³„ì‚°
- ì¤‘ì•™ê°’ Â±50% ë²”ìœ„
- ì´ìƒì¹˜ ì œê±°
- í‰ê·  ê³„ì‚°

## Step 5: ê²°ê³¼ ë°˜í™˜ (JSON)
```

---

### 2. í˜„ì¬ ì½”ë“œ êµ¬ì¡° í™•ì¸

**AIAugmentedEstimationSource.collect()** (Line 100-126):

```python
def collect(self, question: str, context: Optional[Context] = None):
    if self.llm_mode == "skip":
        return []
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Cursor AI ë¶„ê¸°
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    if self.llm_mode == "cursor":
        instruction = self._build_native_instruction(question, context)
        # instruction ìƒì„±ë§Œ í•˜ê³  ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return []
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # External API ë¶„ê¸°
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    else:  # External API
        logger.info(f"  [AI+Web] External API ëª¨ë“œ (TODO: API í˜¸ì¶œ)")
        # TODO: LangChain + Tavily/SerpAPI
        return []  # âŒ ì•„ë¬´ê²ƒë„ ì•ˆí•¨
```

---

### 3. ì‚¬ìš©ì ì œì•ˆ ê²€ì¦ âœ…

**ì‚¬ìš©ì ì œì•ˆ**:
> native modeìš©ìœ¼ë¡œ êµ¬í˜„ëœ ì½”ë“œë¥¼ ì˜®ê²¨ì™€ì„œ ì¬êµ¬ì„±í•´ì•¼ í•´. 
> ì˜¤íˆë ¤ native mode ë¶„ê¸°ëŠ” í•„ìš”ê°€ ì—†ì–´ì¡Œì§€.

**ê²€ì¦ ê²°ê³¼**: âœ… **ì™„ì „íˆ ë§ìŠµë‹ˆë‹¤!**

**ì´ìœ **:
1. `_build_native_instruction`ì— **ì™„ì „í•œ ë¡œì§**ì´ ìˆìŒ
2. ì´ ë¡œì§ì€ **Cursor AIë“  External LLMì´ë“  ë™ì¼í•˜ê²Œ ì ìš© ê°€ëŠ¥**
3. ì°¨ì´ëŠ” **"ëˆ„ê°€ ì´ instructionì„ ì‹¤í–‰í•˜ëŠëƒ"**ë§Œ:
   - Cursor: ì‚¬ëŒ(AI Assistant)ì´ ëŒ€í™”ì—ì„œ ì‹¤í–‰
   - External LLM: APIë¡œ ìë™ ì‹¤í–‰

---

## ğŸ¯ ì˜¬ë°”ë¥¸ ìˆ˜ì • ë°©í–¥

### Before (í˜„ì¬)

```python
if self.llm_mode == "cursor":
    instruction = self._build_native_instruction(...)
    return []  # instructionë§Œ ìƒì„±
else:  # External API
    return []  # TODO: ë¯¸êµ¬í˜„
```

### After (í†µí•©)

```python
# cursorë“  externalì´ë“  ë™ì¼í•œ í”„ë¡œì„¸ìŠ¤
instruction = self._build_native_instruction(question, context)

if self.llm_mode == "cursor":
    # Cursor AI: instructionì„ ë¡œê·¸ì— ì¶œë ¥ (ëŒ€í™”í˜•)
    logger.info("Cursor AIì—ê²Œ instruction ì „ë‹¬ (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸)")
    return []  # Phase 3ì—ì„œëŠ” ëŒ€í™”í˜• ë¶ˆê°€
else:
    # External LLM: instructionì„ LLMì—ê²Œ ì „ë‹¬í•˜ê³  ê²°ê³¼ ë°›ê¸°
    llm_output = self._call_external_llm(instruction)
    result = self._parse_llm_response(llm_output)
    return [result]  # âœ… ValueEstimate ë°˜í™˜
```

**í•µì‹¬**: 
- âœ… `_build_native_instruction`ì˜ ë¡œì§ì„ **ëª¨ë“  ëª¨ë“œì—ì„œ ì¬ì‚¬ìš©**
- âœ… Cursor ë¶„ê¸°ëŠ” ë‹¨ì§€ "ì‹¤í–‰ ë°©ì‹"ë§Œ ë‹¤ë¦„ (ëŒ€í™” vs API)
- âœ… External APIì— ì‹¤ì œ êµ¬í˜„ ì¶”ê°€

---

## ğŸ” ì¶”ê°€ ë°œê²¬: LLMEstimationSourceë„ DEPRECATED

**íŒŒì¼**: `umis_rag/agents/estimator/sources/value.py:306-340`

```python
class LLMEstimationSource(ValueSourceBase):
    """âš ï¸ DEPRECATED (v7.8.0)
    â†’ AIAugmentedEstimationSourceë¡œ í†µí•©ë¨"""
    
    def collect(...):
        # TODO: ì‹¤ì œ LLM í˜¸ì¶œ
        # í˜„ì¬ëŠ” ìŠ¤í‚µ
        return []
```

**ì˜ë¯¸**:
- ì´ì „ì—ëŠ” `LLMEstimationSource`ê°€ ë³„ë„ë¡œ ìˆì—ˆìŒ
- v7.8.0ì—ì„œ `AIAugmentedEstimationSource`ë¡œ í†µí•©
- **í•˜ì§€ë§Œ External API ë¶€ë¶„ì€ í†µí•© ì•ˆë¨** (TODO ìƒíƒœ)

---

## ğŸ¯ ê²°ë¡ 

**ì‚¬ìš©ì ë§ì”€ì´ ì •í™•í–ˆìŠµë‹ˆë‹¤**:

1. âœ… Phase 3ëŠ” **Native Modeìš©ìœ¼ë¡œ êµ¬í˜„ë˜ì–´ ìˆìŒ**
   - `_build_native_instruction`: ì™„ì „í•œ 175ì¤„ ë¡œì§

2. âœ… **ì„œë¡œ ë‹¤ë¥¸ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ë ¤ í–ˆìŒ**
   - Cursor: instruction ìƒì„±ë§Œ
   - External: TODO ìƒíƒœ (ë³„ë„ êµ¬í˜„ ê³„íš)

3. âœ… **Nativeë¥¼ Externalì²˜ëŸ¼ ì·¨ê¸‰í•˜ê¸°ë¡œ í•¨**
   - í†µì¼ëœ `llm_mode` (cursor/gpt-4o-mini/o1-mini)
   - ë™ì¼í•œ ì½”ë“œ, ë‹¤ë¥¸ ì‹¤í–‰ ë°©ì‹

4. âœ… **Native Mode ë¶„ê¸° ë¶ˆí•„ìš”**
   - instructionì€ ê³µí†µ
   - ì‹¤í–‰ë§Œ ë‹¤ë¦„ (ëŒ€í™” vs API)

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

**Phase 3 External API êµ¬í˜„**:

```python
def collect(self, question, context):
    # í†µí•© instruction ìƒì„±
    instruction = self._build_native_instruction(question, context)
    
    if self.llm_mode == "cursor":
        # ëŒ€í™”í˜• (Phase 3ì—ì„œëŠ” ìŠ¤í‚µ)
        return []
    else:
        # External LLMìœ¼ë¡œ instruction ì‹¤í–‰
        from umis_rag.core.llm_provider import get_llm
        llm = get_llm()
        
        response = llm.invoke(instruction)
        result = self._parse_json_response(response.content)
        
        return [ValueEstimate(
            source_type=SourceType.AI_AUGMENTED,
            value=result['value'],
            confidence=result['confidence'],
            reasoning=result['reasoning'],
            ...
        )]
```

---

**ì‘ì„±**: AI Assistant  
**ë‚ ì§œ**: 2025-11-25  
**ê°ì‚¬**: ì •í™•í•œ ì§€ì  ê°ì‚¬ë“œë¦½ë‹ˆë‹¤!




