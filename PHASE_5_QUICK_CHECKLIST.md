# Phase 5 êµ¬í˜„ ë¹ ë¥¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

**ëª©í‘œ**: í•™ìŠµ ì‹œìŠ¤í…œ êµ¬í˜„ (1-2ì¼)  
**í•µì‹¬**: Tier 2 ê²°ê³¼ â†’ Tier 1ë¡œ ìë™ í¸ì…

---

## ğŸ¯ 3ì¤„ ìš”ì•½

```yaml
1. Tier 2ê°€ ë‹µì„ ì°¾ìœ¼ë©´ â†’ Canonicalì— ì €ì¥
2. Canonical â†’ Projected (guestimation view) ìë™ ìƒì„±
3. ë‹¤ìŒì—” Tier 1 RAGê°€ 0.5ì´ˆ ì•ˆì— ë¦¬í„´! âœ¨
```

---

## âœ… êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Step 1: Learning Writer (3-4ì‹œê°„)

```bash
[ ] íŒŒì¼ ìƒì„±: umis_rag/guestimation_v3/learning_writer.py
[ ] LearningWriter í´ë˜ìŠ¤ êµ¬í˜„
[ ] save_learned_rule() ë©”ì„œë“œ
[ ] LearnedRule â†’ Canonical ë³€í™˜
[ ] í…ŒìŠ¤íŠ¸ ì‘ì„± ë° ì‹¤í–‰
```

**í•µì‹¬ ì½”ë“œ**:
```python
class LearningWriter:
    def save_learned_rule(self, question, result, context):
        # EstimationResult â†’ Canonical ì €ì¥
        # chunk_type: "learned_rule"
        # sections: [agent_view: "guestimation"]
```

### Step 2: Projection Generator (2-3ì‹œê°„)

```bash
[ ] ìˆ˜ì •: umis_rag/projection/rule_based_projector.py
[ ] learned_rule íƒ€ì… ì²˜ë¦¬ ì¶”ê°€
[ ] ìˆ˜ì •: config/projection_rules.yaml
[ ] chunk_type_rules.learned_rule ì¶”ê°€
[ ] í…ŒìŠ¤íŠ¸: Projected Index ìƒì„± í™•ì¸
```

**í•µì‹¬ Rule**:
```yaml
chunk_type_rules:
  learned_rule:
    target_agents: ["guestimation"]
    strategy: "direct_projection"
    ttl: "persistent"
```

### Step 3: Tier 1 í†µí•© (1-2ì‹œê°„)

```bash
[ ] ìˆ˜ì •: umis_rag/guestimation_v3/tier1.py
[ ] search_learned_rule() í˜¸ì¶œ ì¶”ê°€
[ ] similarity_threshold: 0.85 ì„¤ì •
[ ] ë§¥ë½ í•„í„°ë§ (domain, region)
[ ] í…ŒìŠ¤íŠ¸: RAG ê²€ìƒ‰ ì‘ë™ í™•ì¸
```

**í•µì‹¬ ë¡œì§**:
```python
# Built-in ì‹¤íŒ¨ ì‹œ
learned_result = self.rag_searcher.search_learned_rule(
    question, context, min_similarity=0.85
)
if learned_result:
    return result  # âœ¨ 0.5ì´ˆ ì•ˆì— ë¦¬í„´!
```

### Step 4: Tier 2 ì—°ê²° (1ì‹œê°„)

```bash
[ ] ìˆ˜ì •: umis_rag/guestimation_v3/tier2.py
[ ] LearningWriter ì¸ìŠ¤í„´ìŠ¤ ì—°ê²°
[ ] íŒë‹¨ í›„ í•™ìŠµ íŠ¸ë¦¬ê±° ì¶”ê°€
[ ] í…ŒìŠ¤íŠ¸: í•™ìŠµ ì™„ë£Œ ë©”ì‹œì§€ í™•ì¸
```

**í•µì‹¬ ë¡œì§**:
```python
if self._should_learn(result):
    rule_id = self.learning_writer.save_learned_rule(...)
    print(f"âœ… í•™ìŠµ ì™„ë£Œ: {rule_id}")
```

### Step 5: E2E í…ŒìŠ¤íŠ¸ (1ì‹œê°„)

```bash
[ ] í…ŒìŠ¤íŠ¸ ì‘ì„±: scripts/test_learning_e2e.py
[ ] ì‹œë‚˜ë¦¬ì˜¤ 1: ì²« ì‹¤í–‰(ëŠë¦¼) â†’ ì¬ì‹¤í–‰(ë¹ ë¦„)
[ ] ì‹œë‚˜ë¦¬ì˜¤ 2: ë§¥ë½ í•„í„°ë§ ê²€ì¦
[ ] ì„±ëŠ¥ í™•ì¸: 6-16ë°° ê°œì„ 
```

---

## ğŸ“Š ì„±ê³µ ì§€í‘œ

```yaml
âœ… ì²« ì‹¤í–‰: Tier 2 (3-8ì´ˆ)
âœ… ì¬ì‹¤í–‰: Tier 1 (<0.5ì´ˆ)
âœ… ê°œì„ : 6-16ë°° ë¹ ë¦„
âœ… False Positive: <1%
âœ… ë§¥ë½ ì¼ì¹˜: >95%
```

---

## ğŸš€ ë°”ë¡œ ì‹œì‘í•˜ê¸°

```bash
# 1. ì‘ì—… ë””ë ‰í† ë¦¬
cd /Users/kangmin/umis_main_1103/umis

# 2. Learning Writer ìƒì„±
touch umis_rag/guestimation_v3/learning_writer.py

# 3. ìƒì„¸ ê°€ì´ë“œ ì—´ê¸°
open PHASE_5_IMPLEMENTATION_GUIDE.md

# 4. êµ¬í˜„ ì‹œì‘! ğŸ¯
```

---

## ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸

```yaml
1. False Positive ë°©ì§€:
   - similarity_threshold: 0.85 (ë†’ê²Œ!)
   - domain ì¼ì¹˜ í•„ìˆ˜

2. ë©”íƒ€ë°ì´í„° ì™„ì „ì„±:
   - domain, value, unit, confidence í•„ìˆ˜
   - time_period ê¶Œì¥

3. í•™ìŠµ ì¡°ê±´:
   - confidence >= 0.80
   - evidence_count >= 2

4. ë°ì´í„° í˜•ì‹:
   - chunk_type: "learned_rule"
   - agent_view: "guestimation"
   - 1ì§ˆë¬¸ = 1ì²­í¬
```

---

**ì˜ˆìƒ ì‹œê°„**: 1-2ì¼  
**ìš°ì„ ìˆœìœ„**: P1 (í•µì‹¬!)  
**ìƒì„¸ ê°€ì´ë“œ**: `PHASE_5_IMPLEMENTATION_GUIDE.md`

**ì‹œì‘!** ğŸš€

