"""
Multi-Layer Guestimation Engine
v2.1 - 2025-11-05

8ê°œ ë°ì´í„° ì¶œì²˜ë¥¼ ê³„ì¸µí™”í•˜ì—¬ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•˜ëŠ” Fallback êµ¬ì¡°
ê¸€ë¡œë²Œ ì„¤ì • íŒŒì¼ (config/multilayer_config.yaml) í†µí•©
"""

from dataclasses import dataclass, field
from typing import Optional, List, Dict, Any, Tuple
from enum import Enum
import re
import os
from pathlib import Path

# ê¸°ì¡´ GuestimationEngine ì¬ì‚¬ìš©
from umis_rag.utils.guestimation import (
    GuestimationEngine,
    BenchmarkCandidate,
    ComparabilityResult
)

# ê¸€ë¡œë²Œ ì„¤ì • ë¡œë”
from umis_rag.core.multilayer_config import get_multilayer_config


class DataSource(Enum):
    """ë°ì´í„° ì¶œì²˜ (Layer)"""
    PROJECT_DATA = 1      # í”„ë¡œì íŠ¸ ë°ì´í„° (100% ì‹ ë¢°)
    LLM_DIRECT = 2        # LLM ì§ì ‘ ë‹µë³€ (70% ì‹ ë¢°)
    WEB_CONSENSUS = 3     # ì›¹ ê²€ìƒ‰ ê³µí†µ ë§¥ë½ (80% ì‹ ë¢°)
    LAW = 4               # ë²•ì¹™ (ë¬¼ë¦¬/ë²•ë¥ ) (100% ì‹ ë¢°)
    BEHAVIORAL = 5        # í–‰ë™ê²½ì œí•™ (70% ì‹ ë¢°)
    STATISTICAL = 6       # í†µê³„ íŒ¨í„´ (60% ì‹ ë¢°)
    RULE_OF_THUMB = 7     # RAG + ë¹„êµ ê²€ì¦ (30-80% ì‹ ë¢°)
    CONSTRAINT = 8        # ì‹œê³µê°„ ì œì•½ (50% ì‹ ë¢°)


@dataclass
class EstimationResult:
    """ì¶”ì • ê²°ê³¼"""
    question: str
    value: Optional[float] = None
    value_range: Optional[Tuple[float, float]] = None  # (min, max)
    source_layer: Optional[DataSource] = None
    confidence: float = 0.0  # 0.0 ~ 1.0
    logic_steps: List[str] = field(default_factory=list)
    used_data: List[Dict] = field(default_factory=list)
    rejected_data: List[Dict] = field(default_factory=list)
    error_range: str = "Â±30%"
    
    def is_successful(self) -> bool:
        """ì¶”ì • ì„±ê³µ ì—¬ë¶€"""
        return self.value is not None or self.value_range is not None
    
    def get_display_value(self) -> str:
        """í‘œì‹œìš© ê°’"""
        if self.value is not None:
            return f"{self.value:,.0f}"
        elif self.value_range:
            return f"{self.value_range[0]:,.0f} ~ {self.value_range[1]:,.0f}"
        return "ì¶”ì • ë¶ˆê°€"


class MultiLayerGuestimation:
    """
    ë©€í‹°ë ˆì´ì–´ Guestimation ì—”ì§„
    
    8ê°œ ë°ì´í„° ì¶œì²˜ë¥¼ ê³„ì¸µì ìœ¼ë¡œ ì‹œë„í•˜ì—¬
    ìµœì ì˜ ì¶”ì • ë°©ë²• ìë™ ì„ íƒ
    
    Usage:
        estimator = MultiLayerGuestimation(project_context={...})
        result = estimator.estimate("í•œêµ­ ìŒì‹ì  ì¬ë°©ë¬¸ ì£¼ê¸°ëŠ”?")
        print(f"ê²°ê³¼: {result.value} (ì¶œì²˜: {result.source_layer.name})")
    """
    
    def __init__(
        self,
        project_context: Optional[Dict] = None,
        config_override: Optional[Dict] = None,  # ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            project_context: í”„ë¡œì íŠ¸ ë°ì´í„° (í™•ì •ëœ ê°’ë“¤)
            config_override: ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ (ì˜µì…˜, ê¸°ë³¸ì€ ê¸€ë¡œë²Œ ì„¤ì • ì‚¬ìš©)
        """
        self.project_context = project_context or {}
        
        # ê¸€ë¡œë²Œ ì„¤ì • ë¡œë“œ
        self.config_loader = get_multilayer_config()
        self.global_modes = self.config_loader.get_global_modes()
        
        # ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ ì ìš©
        if config_override:
            if 'llm_mode' in config_override:
                self.global_modes.llm_mode = config_override['llm_mode']
            if 'web_search_mode' in config_override:
                self.global_modes.web_search_mode = config_override['web_search_mode']
            if 'interactive_mode' in config_override:
                self.global_modes.interactive_mode = config_override['interactive_mode']
        
        # ê¸°ì¡´ GuestimationEngine í™œìš© (Layer 7ìš©)
        self.benchmark_engine = GuestimationEngine()
        
        # ë ˆì´ì–´ë³„ í™œì„±í™” ìƒíƒœ (ê¸€ë¡œë²Œ ì„¤ì • ê¸°ë°˜)
        self.layer_enabled = {
            DataSource.PROJECT_DATA: True,  # í•­ìƒ í™œì„±
            DataSource.LLM_DIRECT: self.global_modes.llm_mode != 'skip',
            DataSource.WEB_CONSENSUS: self.global_modes.web_search_mode != 'skip',
            DataSource.LAW: True,
            DataSource.BEHAVIORAL: True,
            DataSource.STATISTICAL: True,
            DataSource.RULE_OF_THUMB: True,  # RAG í•­ìƒ í™œì„±
            DataSource.CONSTRAINT: True,
        }
    
    def estimate(
        self,
        question: str,
        target_profile: Optional[BenchmarkCandidate] = None,
        rag_candidates: Optional[List[BenchmarkCandidate]] = None
    ) -> EstimationResult:
        """
        ë©€í‹°ë ˆì´ì–´ ì¶”ì •
        
        Args:
            question: ì¶”ì • ì§ˆë¬¸ (ì˜ˆ: "í•œêµ­ ìŒì‹ì  ì¬ë°©ë¬¸ ì£¼ê¸°ëŠ”?")
            target_profile: íƒ€ê²Ÿ í”„ë¡œí•„ (ë¹„êµ ê¸°ì¤€)
            rag_candidates: RAGì—ì„œ ê²€ìƒ‰í•œ ë²¤ì¹˜ë§ˆí¬ í›„ë³´ë“¤
        
        Returns:
            EstimationResult
        """
        
        # ì´ˆê¸°í™”
        result = EstimationResult(question=question)
        
        # Layer 1: í”„ë¡œì íŠ¸ ë°ì´í„°
        if self.layer_enabled[DataSource.PROJECT_DATA]:
            layer_result = self._try_project_data(question)
            if layer_result.is_successful():
                return layer_result
        
        # Layer 2: LLM ì§ì ‘ ë‹µë³€
        if self.layer_enabled[DataSource.LLM_DIRECT]:
            layer_result = self._try_llm_direct(question)
            if layer_result.is_successful() and layer_result.confidence >= 0.7:
                return layer_result
        
        # Layer 3: ì›¹ ê²€ìƒ‰ (ì˜µì…˜)
        if self.layer_enabled[DataSource.WEB_CONSENSUS]:
            layer_result = self._try_web_consensus(question)
            if layer_result.is_successful() and layer_result.confidence >= 0.8:
                return layer_result
        
        # Layer 4: ë²•ì¹™ ê¸°ë°˜
        if self.layer_enabled[DataSource.LAW]:
            layer_result = self._try_law_based(question)
            if layer_result.is_successful():
                return layer_result
        
        # Layer 5: í–‰ë™ê²½ì œí•™
        if self.layer_enabled[DataSource.BEHAVIORAL]:
            layer_result = self._try_behavioral(question, target_profile)
            if layer_result.is_successful() and layer_result.confidence >= 0.6:
                return layer_result
        
        # Layer 6: í†µê³„ íŒ¨í„´
        if self.layer_enabled[DataSource.STATISTICAL]:
            layer_result = self._try_statistical(question)
            if layer_result.is_successful() and layer_result.confidence >= 0.5:
                return layer_result
        
        # Layer 7: RAG ë²¤ì¹˜ë§ˆí¬ (í•µì‹¬!)
        if self.layer_enabled[DataSource.RULE_OF_THUMB] and rag_candidates:
            layer_result = self._try_rag_benchmark(question, target_profile, rag_candidates)
            if layer_result.is_successful() and layer_result.confidence >= 0.5:
                return layer_result
        
        # Layer 8: ì œì•½ì¡°ê±´ (ìµœí›„ ìˆ˜ë‹¨)
        if self.layer_enabled[DataSource.CONSTRAINT]:
            layer_result = self._try_constraint_boundary(question)
            if layer_result.is_successful():
                return layer_result
        
        # ëª¨ë“  ë ˆì´ì–´ ì‹¤íŒ¨
        result.logic_steps.append("âŒ ëª¨ë“  ë ˆì´ì–´ì—ì„œ ì¶”ì • ì‹¤íŒ¨")
        result.confidence = 0.0
        return result
    
    # ===========================================
    # Layer êµ¬í˜„
    # ===========================================
    
    def _try_project_data(self, question: str) -> EstimationResult:
        """
        Layer 1: í”„ë¡œì íŠ¸ ë°ì´í„°
        
        í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ì—ì„œ í™•ì •ëœ ê°’ ê²€ìƒ‰
        """
        result = EstimationResult(
            question=question,
            source_layer=DataSource.PROJECT_DATA
        )
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë§¤ì¹­)
        keywords = self._extract_keywords(question)
        
        # í”„ë¡œì íŠ¸ ë°ì´í„° ê²€ìƒ‰
        for key, value in self.project_context.items():
            if any(kw in key.lower() for kw in keywords):
                result.value = value
                result.confidence = 1.0
                result.logic_steps.append(f"âœ… Layer 1: í”„ë¡œì íŠ¸ ë°ì´í„° '{key}' ì‚¬ìš©")
                result.used_data.append({
                    'source': 'í”„ë¡œì íŠ¸ ë°ì´í„°',
                    'key': key,
                    'value': value
                })
                return result
        
        result.logic_steps.append("âŒ Layer 1: í”„ë¡œì íŠ¸ ë°ì´í„° ì—†ìŒ â†’ Layer 2ë¡œ")
        return result
    
    def _try_llm_direct(self, question: str) -> EstimationResult:
        """
        Layer 2: LLM ì§ì ‘ ë‹µë³€
        
        ê°„ë‹¨í•œ ì‚¬ì‹¤ ì§ˆë¬¸ (ì¸êµ¬, ìƒì‹ ë“±)
        ê¸€ë¡œë²Œ ì„¤ì •(llm_mode)ì— ë”°ë¼ Native/External ìë™ ì„ íƒ
        """
        result = EstimationResult(
            question=question,
            source_layer=DataSource.LLM_DIRECT
        )
        
        # ê°„ë‹¨í•œ ì‚¬ì‹¤ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
        if not self._is_simple_fact(question):
            result.logic_steps.append("âŒ Layer 2: ë³µì¡í•œ ì§ˆë¬¸ â†’ LLM ì§ì ‘ ë‹µë³€ ë¶€ì í•© â†’ Layer 3ìœ¼ë¡œ")
            return result
        
        # ê¸€ë¡œë²Œ ì„¤ì •ì— ë”°ë¼ ë¶„ê¸°
        llm_mode = self.global_modes.llm_mode
        
        if llm_mode == 'native':
            return self._llm_native_mode(question, result)
        elif llm_mode == 'external':
            return self._llm_external_mode(question, result)
        else:  # skip
            result.logic_steps.append("âš ï¸ Layer 2: LLM ëª¨ë“œ 'skip' â†’ Layer 3ìœ¼ë¡œ")
            return result
    
    def _llm_native_mode(self, question: str, result: EstimationResult) -> EstimationResult:
        """Layer 2 - Native Mode (Cursor LLM í™œìš©)"""
        
        # Interactive ëª¨ë“œ: ì‚¬ìš©ì ì…ë ¥
        if self.global_modes.interactive_mode:
            result.logic_steps.append("ğŸ’¡ Layer 2: LLM ì§ì ‘ ë‹µë³€ (Native Interactive)")
            print(f"\nâ“ LLMì—ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”: {question}")
            print("   (Cursor Composer/Chatì—ì„œ ì§ˆë¬¸ í›„ ë‹µë³€ë§Œ ì…ë ¥)")
            user_input = input("   ë‹µë³€ (ìˆ«ìë§Œ ì…ë ¥, ê±´ë„ˆë›°ë ¤ë©´ Enter): ")
            
            if user_input.strip():
                value = self._extract_number(user_input)
                if value:
                    result.value = value
                    result.confidence = self.config_loader.get_llm_config('native').get('confidence', 0.7)
                    result.logic_steps.append(f"âœ… Layer 2: ì‚¬ìš©ì ì…ë ¥ = {value}")
                    result.used_data.append({
                        'source': 'Native LLM (ì‚¬ìš©ì ì…ë ¥)',
                        'value': value
                    })
                    return result
        
        # ë¹„-Interactive: ì•ˆë‚´ë§Œ
        result.logic_steps.append("ğŸ’¡ Layer 2: Native LLM ê¶Œì¥")
        result.logic_steps.append(f"   ì§ˆë¬¸: \"{question}\"")
        result.logic_steps.append("   â†’ Cursor Composerì—ì„œ ì§ì ‘ ì§ˆë¬¸í•˜ì„¸ìš”")
        result.logic_steps.append("âš ï¸ Layer 2: Interactive ëª¨ë“œ ë¹„í™œì„± â†’ Layer 3ìœ¼ë¡œ")
        return result
    
    def _llm_external_mode(self, question: str, result: EstimationResult) -> EstimationResult:
        """Layer 2 - External Mode (OpenAI API)"""
        
        llm_config = self.config_loader.get_llm_config('external')
        
        if not llm_config.get('enabled', False):
            result.logic_steps.append("âš ï¸ Layer 2: External API ë¹„í™œì„± â†’ Layer 3ìœ¼ë¡œ")
            return result
        
        try:
            from openai import OpenAI
            
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                result.logic_steps.append("âŒ Layer 2: OPENAI_API_KEY ì—†ìŒ â†’ Layer 3ìœ¼ë¡œ")
                return result
            
            client = OpenAI(api_key=api_key)
            
            # Prompt ìƒì„±
            prompt = llm_config.get('prompt_template', '').format(question=question)
            
            # API í˜¸ì¶œ
            response = client.chat.completions.create(
                model=llm_config.get('model', 'gpt-4o-mini'),
                messages=[{"role": "user", "content": prompt}],
                temperature=llm_config.get('temperature', 0.1),
                max_tokens=llm_config.get('max_tokens', 50)
            )
            
            answer = response.choices[0].message.content
            
            # ìˆ«ì ì¶”ì¶œ
            value = self._extract_number(answer)
            
            if value:
                result.value = value
                result.confidence = llm_config.get('confidence', 0.7)
                result.logic_steps.append(f"âœ… Layer 2: LLM API ë‹µë³€ = {answer}")
                result.logic_steps.append(f"   ì¶”ì¶œê°’: {value}")
                result.used_data.append({
                    'source': f"LLM API ({llm_config.get('model')})",
                    'raw_answer': answer,
                    'extracted': value
                })
                return result
            else:
                result.logic_steps.append(f"âš ï¸ Layer 2: ìˆ«ì ì¶”ì¶œ ì‹¤íŒ¨ '{answer}' â†’ Layer 3ìœ¼ë¡œ")
        
        except Exception as e:
            result.logic_steps.append(f"âŒ Layer 2: API ì—ëŸ¬ ({str(e)[:50]}) â†’ Layer 3ìœ¼ë¡œ")
        
        return result
    
    def _try_web_consensus(self, question: str) -> EstimationResult:
        """
        Layer 3: ì›¹ ê²€ìƒ‰ ê³µí†µ ë§¥ë½
        
        ìƒìœ„ 20ê°œ ê²°ê³¼ì˜ ê³µí†µê°’ ì¶”ì¶œ (ì´ìƒì¹˜ ì œì™¸, ìœ ì‚¬ë„ 0.7 ì´ìƒ)
        ê¸€ë¡œë²Œ ì„¤ì •(web_search_mode)ì— ë”°ë¼ Native/API/Scraping ìë™ ì„ íƒ
        """
        result = EstimationResult(
            question=question,
            source_layer=DataSource.WEB_CONSENSUS
        )
        
        # ê¸€ë¡œë²Œ ì„¤ì •ì— ë”°ë¼ ë¶„ê¸°
        web_mode = self.global_modes.web_search_mode
        
        if web_mode == 'native':
            return self._web_native_mode(question, result)
        elif web_mode == 'api':
            return self._web_api_mode(question, result)
        elif web_mode == 'scraping':
            return self._web_scraping_mode(question, result)
        else:  # skip
            result.logic_steps.append("âš ï¸ Layer 3: ì›¹ ê²€ìƒ‰ ëª¨ë“œ 'skip' â†’ Layer 4ë¡œ")
            return result
    
    def _web_native_mode(self, question: str, result: EstimationResult) -> EstimationResult:
        """Layer 3 - Native Mode (ì‚¬ìš©ìê°€ ì§ì ‘ ê²€ìƒ‰)"""
        
        # Interactive ëª¨ë“œ: ì‚¬ìš©ì ì…ë ¥
        if self.global_modes.interactive_mode:
            result.logic_steps.append("ğŸ’¡ Layer 3: ì›¹ ê²€ìƒ‰ (Native Interactive)")
            print(f"\nğŸ” ì›¹ ê²€ìƒ‰í•˜ì„¸ìš”: {question}")
            print("   ê¶Œì¥: Google, Naverì—ì„œ ê²€ìƒ‰ í›„ ìƒìœ„ 5-10ê°œ ê³µí†µê°’ í™•ì¸")
            user_input = input("   ê³µí†µê°’ (ìˆ«ì ì…ë ¥, ê±´ë„ˆë›°ë ¤ë©´ Enter): ")
            
            if user_input.strip():
                value = self._extract_number(user_input)
                if value:
                    result.value = value
                    web_config = self.config_loader.get_web_search_config('native')
                    result.confidence = 0.75
                    result.logic_steps.append(f"âœ… Layer 3: ì‚¬ìš©ì ì…ë ¥ (ì›¹ ê²€ìƒ‰ ê²°ê³¼) = {value}")
                    result.used_data.append({
                        'source': 'ì›¹ ê²€ìƒ‰ (ì‚¬ìš©ì í™•ì¸)',
                        'value': value
                    })
                    return result
        
        # ë¹„-Interactive: ì•ˆë‚´ë§Œ
        result.logic_steps.append("ğŸ’¡ Layer 3: ì›¹ ê²€ìƒ‰ ê¶Œì¥")
        result.logic_steps.append(f"   ì§ˆë¬¸: \"{question}\"")
        result.logic_steps.append("   â†’ Google/Naverì—ì„œ ê²€ìƒ‰ í›„ ìƒìœ„ 20ê°œ ê³µí†µê°’ í™•ì¸")
        result.logic_steps.append("âš ï¸ Layer 3: Interactive ëª¨ë“œ ë¹„í™œì„± â†’ Layer 4ë¡œ")
        return result
    
    def _web_api_mode(self, question: str, result: EstimationResult) -> EstimationResult:
        """Layer 3 - API Mode (SerpAPI ë˜ëŠ” Google Custom Search)"""
        
        web_config = self.config_loader.get_web_search_config('api')
        
        if not web_config.get('enabled', False):
            result.logic_steps.append("âš ï¸ Layer 3: API ëª¨ë“œ ë¹„í™œì„± â†’ Layer 4ë¡œ")
            return result
        
        # SerpAPI ì‚¬ìš©
        serpapi_config = web_config.get('serpapi', {})
        api_key = os.getenv(serpapi_config.get('api_key_env', 'SERPAPI_KEY'))
        
        if not api_key:
            result.logic_steps.append("âŒ Layer 3: SERPAPI_KEY ì—†ìŒ â†’ Layer 4ë¡œ")
            return result
        
        try:
            import requests
            
            # ê²€ìƒ‰ ì‹¤í–‰
            params = {
                'q': question,
                'api_key': api_key,
                'num': serpapi_config.get('results_count', 20),  # ìƒìœ„ 20ê°œ
                'gl': 'kr',  # í•œêµ­
                'hl': 'ko',  # í•œêµ­ì–´
            }
            
            response = requests.get(
                serpapi_config.get('endpoint', 'https://serpapi.com/search'),
                params=params,
                timeout=10
            )
            
            data = response.json()
            results = data.get('organic_results', [])
            
            # ê° ê²°ê³¼ì—ì„œ ìˆ«ì ì¶”ì¶œ
            numbers = []
            for r in results[:20]:  # ìƒìœ„ 20ê°œ
                snippet = r.get('snippet', '') + ' ' + r.get('title', '')
                num = self._extract_number(snippet)
                if num:
                    numbers.append(num)
            
            # ê³µí†µê°’ ì¶”ì¶œ (ì´ìƒì¹˜ ì œì™¸, ìœ ì‚¬ë„ 0.7 ê¸°ë°˜)
            if len(numbers) >= 3:
                consensus_value = self._find_web_consensus(numbers)
                
                if consensus_value:
                    result.value = consensus_value
                    result.confidence = self._calculate_web_confidence(len(numbers))
                    result.logic_steps.append(f"âœ… Layer 3: ì›¹ ê²€ìƒ‰ {len(results)}ê°œ ê²°ê³¼")
                    result.logic_steps.append(f"   ì¶”ì¶œëœ ìˆ«ì: {len(numbers)}ê°œ")
                    result.logic_steps.append(f"   ê³µí†µê°’ (ì´ìƒì¹˜ ì œì™¸): {consensus_value}")
                    result.used_data.append({
                        'source': 'SerpAPI ì›¹ ê²€ìƒ‰',
                        'results_count': len(results),
                        'numbers_found': len(numbers),
                        'consensus': consensus_value,
                        'all_numbers': numbers[:10]  # ìƒìœ„ 10ê°œë§Œ ì €ì¥
                    })
                    return result
                else:
                    result.logic_steps.append(f"âš ï¸ Layer 3: ê³µí†µê°’ ì°¾ê¸° ì‹¤íŒ¨ ({len(numbers)}ê°œ ê°’) â†’ Layer 4ë¡œ")
            else:
                result.logic_steps.append(f"âš ï¸ Layer 3: ì¶©ë¶„í•œ ê²°ê³¼ ì—†ìŒ ({len(numbers)}ê°œ) â†’ Layer 4ë¡œ")
        
        except Exception as e:
            result.logic_steps.append(f"âŒ Layer 3: API ì—ëŸ¬ ({str(e)[:50]}) â†’ Layer 4ë¡œ")
        
        return result
    
    def _web_scraping_mode(self, question: str, result: EstimationResult) -> EstimationResult:
        """Layer 3 - Scraping Mode (ì§ì ‘ ìŠ¤í¬ë˜í•‘, ì‚¬ìš© ë¹„ê¶Œì¥)"""
        
        result.logic_steps.append("âš ï¸ Layer 3: Scraping ëª¨ë“œëŠ” ë¶ˆì•ˆì • â†’ ê±´ë„ˆëœ€ â†’ Layer 4ë¡œ")
        # ì‹¤ì œ êµ¬í˜„ì€ ë³µì¡í•˜ê³  ë¶ˆì•ˆì •í•˜ë¯€ë¡œ ìƒëµ
        return result
    
    def _try_law_based(self, question: str) -> EstimationResult:
        """
        Layer 4: ë²•ì¹™ ê¸°ë°˜ (ë¬¼ë¦¬/ë²•ë¥ )
        
        ì ˆëŒ€ì  ì œì•½ì¡°ê±´ í™•ì¸
        """
        result = EstimationResult(
            question=question,
            source_layer=DataSource.LAW
        )
        
        # ì‹œê°„ ì œì•½ (ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­)
        time_laws = {
            r'\bí•˜ë£¨\b': (24, 'ì‹œê°„'),
            r'\bì¼ì£¼ì¼\b|\b1ì£¼\b': (7, 'ì¼'),
            r'\bí•œ ë‹¬\b|\b1ê°œì›”\b': (30, 'ì¼'),
            r'\b1ë…„\b|\bë…„ê°„\b': (365, 'ì¼'),
        }
        
        for pattern, (value, unit) in time_laws.items():
            if re.search(pattern, question):
                result.value = value
                result.confidence = 1.0
                result.logic_steps.append(f"âœ… Layer 4: ë²•ì¹™ '{pattern}' = {value} {unit}")
                result.used_data.append({
                    'source': 'ë¬¼ë¦¬ ë²•ì¹™',
                    'law': f'{pattern} = {value} {unit}',
                    'reliability': 'ì ˆëŒ€ì '
                })
                return result
        
        result.logic_steps.append("âŒ Layer 4: ì ìš© ê°€ëŠ¥í•œ ë²•ì¹™ ì—†ìŒ â†’ Layer 5ë¡œ")
        return result
    
    def _try_behavioral(
        self,
        question: str,
        target_profile: Optional[BenchmarkCandidate]
    ) -> EstimationResult:
        """
        Layer 5: í–‰ë™ê²½ì œí•™
        
        ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë¹„í•©ë¦¬ì„± í™œìš©
        """
        result = EstimationResult(
            question=question,
            source_layer=DataSource.BEHAVIORAL
        )
        
        # Loss Aversion íŒ¨í„´
        if 'ì†ì‹¤' in question or 'í•´ì§€' in question or 'ì´íƒˆ' in question:
            if 'ê°€ì…' in question or 'êµ¬ë…' in question:
                # Loss Aversion: ì†ì‹¤ íšŒí”¼ê°€ ì´ë“ ì¶”êµ¬ë³´ë‹¤ 2ë°° ê°•í•¨
                result.logic_steps.append("ğŸ’¡ Layer 5: Loss Aversion ì ìš© ê°€ëŠ¥")
                result.logic_steps.append("   â†’ ì†ì‹¤ íšŒí”¼ > ì´ë“ ì¶”êµ¬ (2ë°°)")
                result.confidence = 0.7
                result.used_data.append({
                    'source': 'í–‰ë™ê²½ì œí•™',
                    'principle': 'Loss Aversion',
                    'multiplier': 2.0
                })
                # í•˜ì§€ë§Œ êµ¬ì²´ì ì¸ ê°’ì€ ë‹¤ë¥¸ ë ˆì´ì–´ í•„ìš”
                result.logic_steps.append("âš ï¸ Layer 5: êµ¬ì²´ì  ê°’ í•„ìš” â†’ Layer 6ìœ¼ë¡œ")
                result.confidence = 0.0
        else:
            result.logic_steps.append("âŒ Layer 5: í–‰ë™ê²½ì œí•™ íŒ¨í„´ ë¯¸ë°œê²¬ â†’ Layer 6ìœ¼ë¡œ")
        
        return result
    
    def _try_statistical(self, question: str) -> EstimationResult:
        """
        Layer 6: í†µê³„ íŒ¨í„´
        
        íŒŒë ˆí†  80-20, ì •ê·œë¶„í¬ ë“±
        """
        result = EstimationResult(
            question=question,
            source_layer=DataSource.STATISTICAL
        )
        
        # íŒŒë ˆí†  íŒ¨í„´ (80-20 ë²•ì¹™)
        if 'ìƒìœ„' in question or 'ì£¼ìš”' in question or 'í•µì‹¬' in question:
            if 'ë¹„ìœ¨' in question or '%' in question or 'ì ìœ ' in question:
                result.value = 0.20  # íŒŒë ˆí† : ìƒìœ„ 20%
                result.confidence = 0.6
                result.logic_steps.append("âœ… Layer 6: íŒŒë ˆí†  ë²•ì¹™ (80-20)")
                result.logic_steps.append("   â†’ ìƒìœ„ 20%ê°€ 80% ì°¨ì§€")
                result.used_data.append({
                    'source': 'í†µê³„ íŒ¨í„´',
                    'pattern': 'Pareto Principle',
                    'value': '20%'
                })
                return result
        
        # ì •ê·œë¶„í¬ (í‰ê·  Â±1SD = 68%)
        if 'ëŒ€ë¶€ë¶„' in question or 'ë³´í†µ' in question:
            result.logic_steps.append("ğŸ’¡ Layer 6: ì •ê·œë¶„í¬ ì ìš© ê°€ëŠ¥")
            result.logic_steps.append("   â†’ í‰ê·  Â±1SD (68% ë²”ìœ„)")
            result.confidence = 0.5
            # í•˜ì§€ë§Œ í‰ê· ê°’ì´ í•„ìš”í•¨
            result.logic_steps.append("âš ï¸ Layer 6: í‰ê· ê°’ í•„ìš” â†’ Layer 7ë¡œ")
            result.confidence = 0.0
        else:
            result.logic_steps.append("âŒ Layer 6: í†µê³„ íŒ¨í„´ ë¯¸ë°œê²¬ â†’ Layer 7ë¡œ")
        
        return result
    
    def _try_rag_benchmark(
        self,
        question: str,
        target_profile: Optional[BenchmarkCandidate],
        rag_candidates: Optional[List[BenchmarkCandidate]]
    ) -> EstimationResult:
        """
        Layer 7: RAG ë²¤ì¹˜ë§ˆí¬ + ë¹„êµ ê°€ëŠ¥ì„± ê²€ì¦
        
        ê¸°ì¡´ GuestimationEngine í™œìš©
        """
        result = EstimationResult(
            question=question,
            source_layer=DataSource.RULE_OF_THUMB
        )
        
        if not rag_candidates:
            result.logic_steps.append("âŒ Layer 7: RAG í›„ë³´ ì—†ìŒ â†’ Layer 8ë¡œ")
            return result
        
        if not target_profile:
            result.logic_steps.append("âš ï¸ Layer 7: íƒ€ê²Ÿ í”„ë¡œí•„ ì—†ìŒ (ë¹„êµ ë¶ˆê°€) â†’ Layer 8ë¡œ")
            return result
        
        # ë¹„êµ ê°€ëŠ¥ì„± ê²€ì¦ (ê¸°ì¡´ ì—”ì§„ í™œìš©)
        filtered = self.benchmark_engine.filter_candidates(target_profile, rag_candidates)
        
        # ì±„íƒ ê°€ëŠ¥í•œ ë²¤ì¹˜ë§ˆí¬
        if filtered['adopt']:
            adopted = filtered['adopt'][0]  # ìµœê³  ì ìˆ˜
            result.value = adopted.candidate.value
            result.confidence = adopted.score / 4.0  # 4ì  ë§Œì  â†’ 0-1.0
            result.logic_steps.append(f"âœ… Layer 7: RAG ë²¤ì¹˜ë§ˆí¬ '{adopted.candidate.name}' ì±„íƒ")
            result.logic_steps.append(f"   â†’ ë¹„êµ ê°€ëŠ¥ì„±: {adopted.score}/4")
            result.logic_steps.append(f"   â†’ ê·¼ê±°: {', '.join(adopted.reasons)}")
            result.used_data.append({
                'source': 'RAG ë²¤ì¹˜ë§ˆí¬',
                'name': adopted.candidate.name,
                'value': adopted.candidate.value,
                'comparability': adopted.score
            })
            
            # ê¸°ê°ëœ í›„ë³´ ê¸°ë¡
            for rejected in filtered['reject']:
                result.rejected_data.append({
                    'name': rejected.candidate.name,
                    'reason': ', '.join(rejected.details.values())
                })
            
            return result
        
        # ì°¸ê³ ë§Œ ê°€ëŠ¥
        elif filtered['reference']:
            ref = filtered['reference'][0]
            result.value = ref.candidate.value
            result.confidence = ref.score / 4.0
            result.logic_steps.append(f"âš ï¸ Layer 7: RAG ë²¤ì¹˜ë§ˆí¬ '{ref.candidate.name}' ì°¸ê³ ë§Œ")
            result.logic_steps.append(f"   â†’ ë¹„êµ ê°€ëŠ¥ì„± ë‚®ìŒ: {ref.score}/4")
            result.logic_steps.append(f"   â†’ ì£¼ì˜: ì˜¤ì°¨ í´ ìˆ˜ ìˆìŒ (Â±50%)")
            result.error_range = "Â±50%"
            result.used_data.append({
                'source': 'RAG ë²¤ì¹˜ë§ˆí¬ (ì°¸ê³ )',
                'name': ref.candidate.name,
                'value': ref.candidate.value,
                'comparability': ref.score
            })
            return result
        
        # ëª¨ë‘ ê¸°ê°
        else:
            result.logic_steps.append("âŒ Layer 7: ëª¨ë“  RAG ë²¤ì¹˜ë§ˆí¬ ê¸°ê° (ë¹„êµ ë¶ˆê°€) â†’ Layer 8ë¡œ")
            for rejected in filtered['reject'][:3]:
                result.rejected_data.append({
                    'name': rejected.candidate.name,
                    'reason': ', '.join(rejected.details.values())
                })
            return result
    
    def _try_constraint_boundary(self, question: str) -> EstimationResult:
        """
        Layer 8: ì œì•½ì¡°ê±´ ê¸°ë°˜ ê²½ê³„ ì¶”ì •
        
        ìµœì†Œ/ìµœëŒ€ ê²½ê³„ë§Œ ì œì‹œ
        """
        result = EstimationResult(
            question=question,
            source_layer=DataSource.CONSTRAINT
        )
        
        # ë¹„ìœ¨ ì§ˆë¬¸ (0-100%)
        if 'ë¹„ìœ¨' in question or '%' in question or 'ì ìœ ìœ¨' in question:
            result.value_range = (0.0, 1.0)
            result.confidence = 0.5
            result.logic_steps.append("âœ… Layer 8: ë¹„ìœ¨ ì œì•½ (0-100%)")
            result.logic_steps.append("   â†’ ìµœì†Œ: 0%, ìµœëŒ€: 100%")
            result.used_data.append({
                'source': 'ë…¼ë¦¬ì  ì œì•½',
                'constraint': 'ë¹„ìœ¨ì€ 0-100%'
            })
            return result
        
        # ì‹œê°„ ì œì•½
        if 'ì‹œê°„' in question or 'ë¶„' in question or 'ì£¼ê¸°' in question:
            if 'í•˜ë£¨' in question:
                result.value_range = (0, 24)
                result.logic_steps.append("âœ… Layer 8: ì‹œê°„ ì œì•½ (í•˜ë£¨ 0-24ì‹œê°„)")
            elif 'ì£¼' in question:
                result.value_range = (0, 7)
                result.logic_steps.append("âœ… Layer 8: ì‹œê°„ ì œì•½ (ì£¼ 0-7ì¼)")
            elif 'ì›”' in question or 'ì¬ë°©ë¬¸' in question:
                result.value_range = (0, 90)
                result.logic_steps.append("âœ… Layer 8: ì‹œê°„ ì œì•½ (ì¬ë°©ë¬¸ 0-90ì¼)")
                result.confidence = 0.4
            
            if result.value_range:
                result.confidence = 0.5
                result.used_data.append({
                    'source': 'ì‹œê°„ì  ì œì•½',
                    'range': result.value_range
                })
                return result
        
        # ì¶”ì • ë¶ˆê°€ëŠ¥
        result.logic_steps.append("âŒ Layer 8: ì œì•½ì¡°ê±´ ë¯¸ë°œê²¬ â†’ ì¶”ì • ì‹¤íŒ¨")
        return result
    
    # ===========================================
    # ìœ í‹¸ë¦¬í‹°
    # ===========================================
    
    def _extract_keywords(self, question: str) -> List[str]:
        """ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (stopwords ì œê±°)
        stopwords = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì—', '?', 'ì–¼ë§ˆ', 'ëª‡'}
        keywords = []
        for word in question.split():
            cleaned = word.strip('?.,!')
            if cleaned and cleaned not in stopwords and len(cleaned) > 1:
                keywords.append(cleaned.lower())
        return keywords
    
    def _is_simple_fact(self, question: str) -> bool:
        """
        ê°„ë‹¨í•œ ì‚¬ì‹¤ ì§ˆë¬¸ì¸ì§€ íŒë‹¨
        
        ê°„ë‹¨í•œ ì‚¬ì‹¤: "í•œêµ­ ì¸êµ¬ëŠ”?", "í‰ê·  ì‹ì‚¬ ì‹œê°„ì€?"
        ë³µì¡í•œ ì§ˆë¬¸: "ì™œ ~í•œê°€?", "ì–´ë–»ê²Œ ë¹„êµí•˜ë©´?"
        """
        # ì„¤ì •ì—ì„œ íŒ¨í„´ ë¡œë“œ
        llm_config = self.config_loader.get_layer_config('layer_2')
        native_config = llm_config.get('native', {})
        
        simple_patterns = native_config.get('simple_fact_patterns', [
            r'ì¸êµ¬',
            r'í‰ê· .*ì‹œê°„',
            r'ì¼ë°˜ì ',
            r'ë³´í†µ',
            r'í†µìƒ',
            r'ëª‡\s*(ëª…|ê°œ|ì‹œê°„|ì¼)',
        ])
        
        complex_patterns = native_config.get('complex_patterns', [
            r'ì™œ',
            r'ì–´ë–»ê²Œ',
            r'~í•œë‹¤ë©´',
            r'ë¹„êµ',
            r'ë¶„ì„',
        ])
        
        has_simple = any(re.search(p, question) for p in simple_patterns)
        has_complex = any(re.search(p, question) for p in complex_patterns)
        
        return has_simple and not has_complex
    
    def _extract_number(self, text: str) -> Optional[float]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì„¤ì • ê¸°ë°˜ íŒ¨í„´)
        
        ì§€ì›: "5200ë§Œ", "27ì–µ", "15%", "52,000,000" ë“±
        """
        if not text:
            return None
        
        # ì„¤ì •ì—ì„œ íŒ¨í„´ ë¡œë“œ
        patterns = self.config_loader.get_number_extraction_patterns()
        
        # ê¸°ë³¸ íŒ¨í„´ (ì„¤ì • ì—†ì„ ê²½ìš°)
        if not patterns:
            patterns = [
                {'pattern': r'([\d,]+\.?\d*)\s*ì–µ', 'multiplier': 100000000},
                {'pattern': r'([\d,]+\.?\d*)\s*ì²œë§Œ', 'multiplier': 10000000},
                {'pattern': r'([\d,]+\.?\d*)\s*ë§Œ', 'multiplier': 10000},
                {'pattern': r'([\d,]+\.?\d*)\s*ì²œ', 'multiplier': 1000},
                {'pattern': r'([\d,]+\.?\d*)\s*%', 'multiplier': 0.01},
                {'pattern': r'([\d,]+\.?\d*)', 'multiplier': 1},
            ]
        
        for p in patterns:
            pattern = p.get('pattern', p) if isinstance(p, dict) else p
            multiplier = p.get('multiplier', 1) if isinstance(p, dict) else 1
            
            match = re.search(pattern, text)
            if match:
                num_str = match.group(1).replace(',', '')
                try:
                    value = float(num_str) * multiplier
                    return value
                except:
                    continue
        
        return None
    
    def _find_web_consensus(self, numbers: List[float]) -> Optional[float]:
        """
        ì›¹ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê³µí†µê°’ ì¶”ì¶œ
        
        ë°©ë²•:
        1. ì´ìƒì¹˜ ì œê±° (IQR ë°©ë²•)
        2. í´ëŸ¬ìŠ¤í„°ë§ (Â±20% ë²”ìœ„, ìœ ì‚¬ë„ 0.7 ì ìš©)
        3. ê°€ì¥ í° í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì•™ê°’
        """
        if len(numbers) < 3:
            return None
        
        # ì„¤ì • ë¡œë“œ
        consensus_config = self.config_loader.get_consensus_config()
        outlier_config = consensus_config.get('outlier_removal', {})
        clustering_config = consensus_config.get('clustering', {})
        
        # 1. ì´ìƒì¹˜ ì œê±° (IQR ë°©ë²•)
        if outlier_config.get('enabled', True):
            numbers = self._remove_outliers_iqr(
                numbers,
                threshold=outlier_config.get('threshold', 1.5)
            )
            
            if len(numbers) < 3:
                return None
        
        # 2. í´ëŸ¬ìŠ¤í„°ë§ (ìœ ì‚¬ë„ 0.7 ë°˜ì˜)
        if clustering_config.get('enabled', True):
            tolerance = clustering_config.get('tolerance', 0.2)  # Â±20%
            clusters = self._cluster_numbers(numbers, tolerance)
            
            # ê°€ì¥ í° í´ëŸ¬ìŠ¤í„° ì„ íƒ
            if clusters:
                largest_cluster = max(clusters, key=len)
                
                # ìµœì†Œ í¬ê¸° ì²´í¬
                min_size = clustering_config.get('min_cluster_size', 3)
                if len(largest_cluster) >= min_size:
                    # ì¤‘ì•™ê°’ ë°˜í™˜
                    largest_cluster.sort()
                    return largest_cluster[len(largest_cluster) // 2]
        
        # 3. Fallback: ì „ì²´ ì¤‘ì•™ê°’
        numbers.sort()
        return numbers[len(numbers) // 2]
    
    def _remove_outliers_iqr(self, numbers: List[float], threshold: float = 1.5) -> List[float]:
        """
        IQR ë°©ë²•ìœ¼ë¡œ ì´ìƒì¹˜ ì œê±°
        
        Args:
            numbers: ìˆ«ì ë¦¬ìŠ¤íŠ¸
            threshold: IQR ë°°ìˆ˜ (ê¸°ë³¸ 1.5)
        """
        if len(numbers) < 4:
            return numbers
        
        sorted_nums = sorted(numbers)
        n = len(sorted_nums)
        
        q1 = sorted_nums[n // 4]
        q3 = sorted_nums[3 * n // 4]
        iqr = q3 - q1
        
        lower_bound = q1 - threshold * iqr
        upper_bound = q3 + threshold * iqr
        
        # ë²”ìœ„ ë‚´ ê°’ë§Œ ìœ ì§€
        filtered = [num for num in numbers if lower_bound <= num <= upper_bound]
        
        return filtered if filtered else numbers  # ëª¨ë‘ ì œê±°ë˜ë©´ ì›ë³¸ ë°˜í™˜
    
    def _cluster_numbers(self, numbers: List[float], tolerance: float = 0.2) -> List[List[float]]:
        """
        ìˆ«ìë“¤ì„ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§
        
        Args:
            numbers: ìˆ«ì ë¦¬ìŠ¤íŠ¸
            tolerance: í—ˆìš© ì˜¤ì°¨ (0.2 = Â±20%, ìœ ì‚¬ë„ 0.8 = 1-0.2)
        
        Returns:
            í´ëŸ¬ìŠ¤í„° ë¦¬ìŠ¤íŠ¸
        """
        if not numbers:
            return []
        
        sorted_nums = sorted(numbers)
        clusters = []
        current_cluster = [sorted_nums[0]]
        
        for num in sorted_nums[1:]:
            # í˜„ì¬ í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì•™ê°’
            cluster_median = current_cluster[len(current_cluster) // 2]
            
            # ìœ ì‚¬ë„ ê³„ì‚° (0.2 tolerance = 0.8 similarity)
            similarity = 1 - abs(num - cluster_median) / max(num, cluster_median)
            
            # ìœ ì‚¬ë„ ì„ê³„ê°’ (ì„¤ì •ì—ì„œ ë¡œë“œ)
            consensus_config = self.config_loader.get_consensus_config()
            similarity_config = consensus_config.get('similarity_based', {})
            threshold = similarity_config.get('threshold', 0.7)  # ê¸°ë³¸ 0.7
            
            # ìœ ì‚¬ë„ê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ ê°™ì€ í´ëŸ¬ìŠ¤í„°
            if similarity >= threshold:
                current_cluster.append(num)
            else:
                clusters.append(current_cluster)
                current_cluster = [num]
        
        clusters.append(current_cluster)
        return clusters
    
    def _calculate_web_confidence(self, count: int) -> float:
        """
        ì›¹ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ì— ë”°ë¥¸ ì‹ ë¢°ë„
        
        3-5ê°œ: 0.6
        6-10ê°œ: 0.75
        11ê°œ ì´ìƒ: 0.8
        """
        consensus_config = self.config_loader.get_consensus_config()
        confidence_config = self.config_loader.get_layer_config('layer_3').get('confidence', {})
        
        if count >= 11:
            return confidence_config.get('consensus_high', 0.8)
        elif count >= 6:
            return 0.75
        else:
            return confidence_config.get('consensus_low', 0.6)
    
    def get_layer_sequence(self) -> List[str]:
        """í™œì„±í™”ëœ ë ˆì´ì–´ ìˆœì„œ ë°˜í™˜"""
        sequence = []
        for source in DataSource:
            if self.layer_enabled[source]:
                sequence.append(f"{source.value}. {source.name}")
        return sequence
    
    def estimate_with_trace(
        self,
        question: str,
        target_profile: Optional[BenchmarkCandidate] = None,
        rag_candidates: Optional[List[BenchmarkCandidate]] = None,
        verbose: bool = True
    ) -> EstimationResult:
        """
        ì¶”ì • + ì „ì²´ ë ˆì´ì–´ ì‹œë„ ê³¼ì • ì¶”ì 
        
        verbose=True ì‹œ ëª¨ë“  ë ˆì´ì–´ ì‹œë„ ê¸°ë¡
        """
        result = self.estimate(question, target_profile, rag_candidates)
        
        if verbose:
            print("=" * 80)
            print(f"ğŸ¯ ì§ˆë¬¸: {question}")
            print("=" * 80)
            print()
            print("ğŸ“Š ë ˆì´ì–´ ì‹œë„ ê³¼ì •:")
            for step in result.logic_steps:
                print(f"   {step}")
            print()
            
            if result.is_successful():
                print("âœ… ì¶”ì • ì„±ê³µ!")
                print(f"   ì¶œì²˜: {result.source_layer.name}")
                print(f"   ê°’: {result.get_display_value()}")
                print(f"   ì‹ ë¢°ë„: {result.confidence:.0%}")
            else:
                print("âŒ ì¶”ì • ì‹¤íŒ¨")
                print("   â†’ ëª¨ë“  ë ˆì´ì–´ì—ì„œ ë°ì´í„° ì—†ìŒ")
            print("=" * 80)
        
        return result


# ===========================================
# í¸ì˜ í•¨ìˆ˜
# ===========================================

def quick_estimate(
    question: str,
    project_data: Optional[Dict] = None,
    rag_candidates: Optional[List[BenchmarkCandidate]] = None
) -> float:
    """
    ë¹ ë¥¸ ì¶”ì • (ë‹¨ì¼ ê°’ ë°˜í™˜)
    
    Usage:
        value = quick_estimate("í•œêµ­ ìŒì‹ì  ì¬ë°©ë¬¸ ì£¼ê¸°ëŠ”?")
    """
    estimator = MultiLayerGuestimation(project_context=project_data or {})
    result = estimator.estimate(question, rag_candidates=rag_candidates)
    
    if result.value is not None:
        return result.value
    elif result.value_range:
        # ë²”ìœ„ì˜ ì¤‘ê°„ê°’ ë°˜í™˜
        return (result.value_range[0] + result.value_range[1]) / 2
    else:
        return None


def estimate_with_details(
    question: str,
    project_data: Optional[Dict] = None,
    target_profile: Optional[BenchmarkCandidate] = None,
    rag_candidates: Optional[List[BenchmarkCandidate]] = None
) -> Dict[str, Any]:
    """
    ìƒì„¸ ì¶”ì • (ë¬¸ì„œí™”ìš©)
    
    Returns:
        Estimation Details 7ê°œ ì„¹ì…˜ í˜¸í™˜ í˜•ì‹
    """
    estimator = MultiLayerGuestimation(project_context=project_data or {})
    result = estimator.estimate(question, target_profile, rag_candidates)
    
    return {
        'id': f'EST_{question[:20]}',
        'description': question,
        'value': result.value or result.get_display_value(),
        'confidence': f"{result.confidence:.0%}",
        'error_range': result.error_range,
        'used_in': '',
        
        # 7ê°œ ì„¹ì…˜
        'reason': 'ì§ì ‘ ë°ì´í„° ì—†ìŒ',
        'base_data': result.used_data,
        'logic_steps': result.logic_steps,
        'calculation': f"ìµœì¢…: {result.get_display_value()}",
        'verification': f"ì¶œì²˜: {result.source_layer.name if result.source_layer else 'None'}",
        'alternatives': [f"{r['name']}: {r['reason']}" for r in result.rejected_data[:3]],
        
        # ë©”íƒ€ë°ì´í„°
        'source_layer': result.source_layer.name if result.source_layer else None,
        'layer_sequence': result.logic_steps,
    }

