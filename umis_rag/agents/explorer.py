"""
Explorer RAG Agent Module

Explorer (Explorer) ì—ì´ì „íŠ¸ì˜ RAG ê¸°ë°˜ ê¸°íšŒ ë°œêµ´ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

í•µì‹¬ ê°œë…:
-----------
1. **Pattern Matching**: Observer ê´€ì°° â†’ ì‚¬ì—…ëª¨ë¸ íŒ¨í„´ ë§¤ì¹­
2. **Case Retrieval**: ìœ ì‚¬ ì‚°ì—… ì„±ê³µ ì‚¬ë¡€ ê²€ìƒ‰
3. **Multi-Stage Search**: ë‹¨ê³„ë³„ ì •ë°€ ê²€ìƒ‰
4. **Agent Collaboration**: Quantifier/Validatorê³¼ ìì—°ìŠ¤ëŸ¬ìš´ í˜‘ì—…

Explorerì˜ 7ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤:
-----------------------
Phase 1: íŠ¸ë¦¬ê±° ì¸ì‹ (Observer ê´€ì°°ì—ì„œ ì‹œê·¸ë„ ì¶”ì¶œ)
Phase 2: íŒ¨í„´ ë§¤ì¹­ (ì‚¬ì—…ëª¨ë¸ + Disruption)
Phase 3: ì‚¬ë¡€ ê²€ìƒ‰ (ìœ ì‚¬ ì‚°ì—…/êµ¬ì¡°)
Phase 4: ì •ëŸ‰ ê²€ì¦ (Quantifier í˜‘ì—…)
Phase 5: ë°ì´í„° ê²€ì¦ (Validator í˜‘ì—…)
Phase 6: ê°€ì„¤ ìƒì„±
Phase 7: Guardian ê²€ì¦
"""

from typing import List, Dict, Any, Optional
from pathlib import Path

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

import sys
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from umis_rag.core.config import settings
from umis_rag.core.llm_provider import LLMProvider
from umis_rag.utils.logger import logger
from umis_rag.graph.hybrid_search import HybridSearch, HybridResult


class ExplorerRAG:
    """
    Explorer (Explorer) RAG Agent
    
    ì—­í• :
    -----
    - ì‹œì¥ ê¸°íšŒ ë°œêµ´
    - ì‚¬ì—…ëª¨ë¸ íŒ¨í„´ ì¸ì‹
    - ê²€ì¦ëœ ê°€ì„¤ ìƒì„±
    
    í•µì‹¬ ë©”ì„œë“œ:
    -----------
    - search_patterns(): íŠ¸ë¦¬ê±° â†’ íŒ¨í„´ ë§¤ì¹­
    - search_cases(): ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰  
    - generate_hypothesis(): LLMìœ¼ë¡œ ê°€ì„¤ ìƒì„±
    - validate_with_framework(): ê²€ì¦ í”„ë ˆì„ì›Œí¬ ì ìš©
    
    í˜‘ì—…:
    -----
    - Quantifier: ì •ëŸ‰ ë°ì´í„° ìš”ì²­
    - Validator: ì¶œì²˜ ê²€ì¦ ìš”ì²­
    - Guardian: ìµœì¢… ê²€ì¦
    """
    
    def __init__(self, use_projected=False):
        """
        Explorer RAG ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        
        Args:
            use_projected: True = projected_index (v3.0 Dual-Index)
                          False = explorer_knowledge_base (ê¸°ì¡´, ê¸°ë³¸)
        """
        logger.info("Explorer RAG ì—ì´ì „íŠ¸ ì´ˆê¸°í™”")
        
        # Embeddings ì´ˆê¸°í™”
        self.embeddings = OpenAIEmbeddings(
            model=settings.embedding_model,
            openai_api_key=settings.openai_api_key
        )
        
        # ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ (v3.0 Dual-Index ì§€ì›!)
        collection_name = "projected_index" if use_projected else "explorer_knowledge_base"
        
        self.vectorstore = Chroma(
            collection_name=collection_name,
            embedding_function=self.embeddings,
            persist_directory=str(settings.chroma_persist_dir)
        )
        
        self.use_projected = use_projected
        
        # LLM ì´ˆê¸°í™” (ê°€ì„¤ ìƒì„±ìš©) - v7.7.0: Native/External ëª¨ë“œ ì§€ì›
        self.llm = LLMProvider.create_llm()
        self.mode = settings.umis_mode
        
        logger.info(f"  âœ… ë²¡í„° ìŠ¤í† ì–´: {collection_name}")
        logger.info(f"  âœ… ì²­í¬ ìˆ˜: {self.vectorstore._collection.count()}ê°œ")
        logger.info(f"  ğŸ¯ UMIS ëª¨ë“œ: {self.mode}")
        
        # Hybrid Search ì´ˆê¸°í™” (ì„ íƒì )
        self.hybrid_search = None
        try:
            from umis_rag.graph.connection import Neo4jConnection
            # Neo4j ì—°ê²° í…ŒìŠ¤íŠ¸
            test_conn = Neo4jConnection()
            if test_conn.verify_connection():
                self.hybrid_search = HybridSearch(graph_connection=test_conn)
                logger.info(f"  âœ… Hybrid Search í™œì„±í™” (Vector + Graph)")
            else:
                logger.warning(f"  âš ï¸  Neo4j ì—°ê²° ì‹¤íŒ¨ - Vectorë§Œ ì‚¬ìš©")
        except Exception as e:
            logger.warning(f"  âš ï¸  Hybrid Search ë¹„í™œì„± - Vectorë§Œ ì‚¬ìš©: {e}")
        logger.info(f"  âœ… LLM ëª¨ë¸: {settings.llm_model}")
    
    def search_patterns(
        self, 
        trigger_signals: str | List[str],
        top_k: int = 3,
        use_graph: bool = True  # v7.1.0: ê¸°ë³¸ê°’ True (Hybrid Search)
    ) -> List[tuple[Document, float]] | HybridResult:
        """
        v3.0: Projected Index ì§€ì›
        - use_projected=True â†’ agent_view í•„í„° ìë™
        """
        """
        íŠ¸ë¦¬ê±° ì‹œê·¸ë„ â†’ ì‚¬ì—…ëª¨ë¸ íŒ¨í„´ ë§¤ì¹­
        
        ì‚¬ìš© ì‹œì :
        ----------
        Observerê°€ ì‹œì¥ ê´€ì°°ì„ ì™„ë£Œí•˜ê³  íŠ¸ë¦¬ê±° ì‹œê·¸ë„ì„ ë°œê²¬í–ˆì„ ë•Œ
        
        ì˜ˆì‹œ:
        -----
        Input: "íŒŒí¸í™”ëœ ê³µê¸‰-ìˆ˜ìš”, ë†’ì€ ì¤‘ê°œ ë¹„ìš©"
        Output: [platform_business_model, ...]
        
        Parameters:
        -----------
        trigger_signals: íŠ¸ë¦¬ê±° ì‹œê·¸ë„ (ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)
        top_k: ë°˜í™˜í•  íŒ¨í„´ ìˆ˜
        
        Returns:
        --------
        List of (Document, similarity_score)
        """
        logger.info(f"[Explorer] íŒ¨í„´ ë§¤ì¹­ ê²€ìƒ‰ ì‹œì‘")
        
        # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        if isinstance(trigger_signals, list):
            query = ", ".join(trigger_signals)
        else:
            query = trigger_signals
        
        logger.info(f"  íŠ¸ë¦¬ê±°: {query[:100]}...")
        
        # v7.1.0: Hybrid Search ìš°ì„  (Knowledge Graph)
        if use_graph and self.hybrid_search:
            logger.info("  ğŸ” Hybrid Search (Vector + Graph)")
            hybrid_result = self.search_patterns_with_graph(query, top_k=top_k)
            
            # HybridResult â†’ List[tuple] ë³€í™˜ (ì¼ê´€ì„±)
            if hybrid_result and hasattr(hybrid_result, 'direct_matches'):
                # PatternMatch ê°ì²´ â†’ (Document, score) tuple ë³€í™˜
                converted = []
                for match in hybrid_result.direct_matches:
                    if hasattr(match, 'document') and hasattr(match, 'similarity'):
                        converted.append((match.document, match.similarity))
                    elif hasattr(match, 'doc') and hasattr(match, 'score'):
                        converted.append((match.doc, match.score))
                
                if converted:
                    logger.info(f"  âœ… Hybrid ê²°ê³¼ ë³€í™˜: {len(converted)}ê°œ")
                    return converted
            
            # Fallback to vector if conversion failed
            logger.warning("  âš ï¸ Hybrid ê²°ê³¼ ë³€í™˜ ì‹¤íŒ¨ â†’ Vectorë¡œ í´ë°±")
            use_graph = False
        
        # Fallback: Vectorë§Œ
        logger.info("  ğŸ” Vector Search")
        
        # íŒ¨í„´ ê°œìš”ë§Œ ê²€ìƒ‰ (íŠ¸ë¦¬ê±° ì‹œê·¸ë„ í¬í•¨ëœ ì²­í¬)
        results = self.vectorstore.similarity_search_with_score(
            query,
            k=top_k,
            filter={"chunk_type": "pattern_overview"}
        )
        
        logger.info(f"  âœ… {len(results)}ê°œ íŒ¨í„´ ë§¤ì¹­")
        for i, (doc, score) in enumerate(results, 1):
            pattern_id = doc.metadata.get("pattern_id", "N/A")
            logger.info(f"    #{i} {pattern_id} (ìœ ì‚¬ë„: {score:.4f})")
        
        return results
    
    def get_pattern_details(self, results: List[tuple]) -> List[Dict[str, Any]]:
        """
        ê²€ìƒ‰ ê²°ê³¼ tupleì„ ì‚¬ìš©í•˜ê¸° ì‰¬ìš´ dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Parameters:
        -----------
        results: search_patterns() ê²°ê³¼ List[(Document, score)]
        
        Returns:
        --------
        List[Dict] with keys: pattern_id, pattern_name, score, description, triggers, etc.
        """
        pattern_details = []
        
        for doc, score in results:
            metadata = doc.metadata
            detail = {
                'pattern_id': metadata.get('pattern_id', 'Unknown'),
                'pattern_name': metadata.get('pattern_name', 'Unknown'),
                'category': metadata.get('category', 'Unknown'),
                'score': float(score),
                'description': doc.page_content[:200] if doc.page_content else '',
                'metadata': metadata
            }
            pattern_details.append(detail)
        
        return pattern_details
    
    def search_patterns_with_graph(
        self,
        trigger_observation: str,
        top_k: int = 5,
        max_combinations: int = 10
    ) -> Optional[HybridResult]:
        """
        Hybrid Search: Vector + Graph í†µí•© ê²€ìƒ‰
        
        ì‚¬ìš© ì‹œì :
        ----------
        íŒ¨í„´ ë§¤ì¹­ê³¼ í•¨ê»˜ ê´€ë ¨ ì¡°í•©ê¹Œì§€ ë°œê²¬í•˜ê³  ì‹¶ì„ ë•Œ
        
        ì˜ˆì‹œ:
        -----
        Input: "ìŒì•… ìŠ¤íŠ¸ë¦¬ë° êµ¬ë… ì„œë¹„ìŠ¤"
        Output:
          Direct: [subscription_model, platform_model, ...]
          Combinations: [
            subscription + platform (Amazon Prime),
            subscription + licensing (Spotify),
            subscription + freemium (YouTube Premium)
          ]
        
        Parameters:
        -----------
        trigger_observation: Observer ê´€ì°° ë˜ëŠ” ì‹œì¥ ì„¤ëª…
        top_k: Vector ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
        max_combinations: ìµœëŒ€ ì¡°í•© ìˆ˜
        
        Returns:
        --------
        HybridResult ë˜ëŠ” None (Hybrid Search ë¹„í™œì„± ì‹œ)
        """
        if not self.hybrid_search:
            logger.warning("  âš ï¸  Hybrid Search ë¹„í™œì„± - Vector ê²€ìƒ‰ë§Œ ì‚¬ìš©í•˜ì„¸ìš”")
            return None
        
        logger.info(f"[Explorer] Hybrid Search ì‹œì‘")
        logger.info(f"  ê´€ì°°: {trigger_observation[:100]}")
        
        # 1. Vector ê²€ìƒ‰ (use_graph=Falseë¡œ ì¬ê·€ ë°©ì§€!)
        vector_results = self.search_patterns(trigger_observation, top_k, use_graph=False)
        
        # 2. Hybrid ê²€ìƒ‰
        hybrid_result = self.hybrid_search.search(
            vector_results,
            max_combinations=max_combinations
        )
        
        # 3. ê²°ê³¼ ë¡œê¹…
        logger.info(f"  âœ… Direct matches: {len(hybrid_result.direct_matches)}")
        logger.info(f"  âœ… Combinations: {len(hybrid_result.combinations)}")
        logger.info(f"  âœ… Insights: {len(hybrid_result.insights)}")
        
        for insight in hybrid_result.insights:
            logger.info(f"    {insight}")
        
        return hybrid_result
    
    def search_cases(
        self,
        industry_or_pattern: str,
        pattern_id: Optional[str] = None,
        top_k: int = 5
    ) -> List[tuple[Document, float]]:
        """
        ìœ ì‚¬ ì‚°ì—…/êµ¬ì¡° ì„±ê³µ ì‚¬ë¡€ ê²€ìƒ‰
        
        ì‚¬ìš© ì‹œì :
        ----------
        íŒ¨í„´ ë§¤ì¹­ í›„, ì‹¤ì œ ì„±ê³µ ì‚¬ë¡€ë¥¼ ì°¾ì„ ë•Œ
        
        ì˜ˆì‹œ:
        -----
        Input: "ìŒì•… ìŠ¤íŠ¸ë¦¬ë°", pattern_id="subscription_model"
        Output: [ë„·í”Œë¦­ìŠ¤, ë©œë¡ , ìŠ¤í¬í‹°íŒŒì´, ...]
        
        Parameters:
        -----------
        industry_or_pattern: ì‚°ì—…ëª… ë˜ëŠ” ìœ ì‚¬ì„± ì„¤ëª…
        pattern_id: íŠ¹ì • íŒ¨í„´ì˜ ì‚¬ë¡€ë§Œ ê²€ìƒ‰ (ì„ íƒ)
        top_k: ë°˜í™˜í•  ì‚¬ë¡€ ìˆ˜
        """
        logger.info(f"[Explorer] ì‚¬ë¡€ ê²€ìƒ‰ ì‹œì‘")
        logger.info(f"  ì‚°ì—…/íŒ¨í„´: {industry_or_pattern[:100]}")
        
        # í•„í„° êµ¬ì„± (Chroma DB ë¬¸ë²•: AND ì—°ì‚°ì ì‚¬ìš©)
        if pattern_id:
            filter_dict = {
                "$and": [
                    {"chunk_type": "success_case"},
                    {"pattern_id": pattern_id}
                ]
            }
            logger.info(f"  í•„í„°: {pattern_id} íŒ¨í„´ì˜ ì‚¬ë¡€ë§Œ")
        else:
            filter_dict = {"chunk_type": "success_case"}
        
        results = self.vectorstore.similarity_search_with_score(
            industry_or_pattern,
            k=top_k,
            filter=filter_dict
        )
        
        logger.info(f"  âœ… {len(results)}ê°œ ì‚¬ë¡€ ë°œê²¬")
        for i, (doc, score) in enumerate(results, 1):
            company = doc.metadata.get("company", "N/A")
            logger.info(f"    #{i} {company} (ìœ ì‚¬ë„: {score:.4f})")
        
        return results
    
    def get_validation_framework(
        self,
        pattern_id: str
    ) -> Optional[Document]:
        """
        íŠ¹ì • íŒ¨í„´ì˜ ê²€ì¦ í”„ë ˆì„ì›Œí¬ ê°€ì ¸ì˜¤ê¸°
        
        ì‚¬ìš© ì‹œì :
        ----------
        ê°€ì„¤ ìƒì„± í›„, ì–´ë–»ê²Œ ê²€ì¦í• ì§€ í”„ë ˆì„ì›Œí¬ í•„ìš”í•  ë•Œ
        
        ì˜ˆì‹œ:
        -----
        Input: "subscription_model"
        Output: Quantifier/Validator/Observerì—ê²Œ ë¬¼ì–´ë³¼ ì²´í¬ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"[Explorer] ê²€ì¦ í”„ë ˆì„ì›Œí¬ ê²€ìƒ‰: {pattern_id}")
        
        results = self.vectorstore.similarity_search(
            f"{pattern_id} validation",
            k=1,
            filter={
                "$and": [
                    {"pattern_id": pattern_id},
                    {"chunk_type": "validation_framework"}
                ]
            }
        )
        
        if results:
            logger.info(f"  âœ… ê²€ì¦ í”„ë ˆì„ì›Œí¬ ë°œê²¬")
            return results[0]
        else:
            logger.warning(f"  âš ï¸  ê²€ì¦ í”„ë ˆì„ì›Œí¬ ì—†ìŒ")
            return None
    
    def generate_opportunity_hypothesis(
        self,
        observer_observation: str,
        matched_patterns: List[Document],
        success_cases: List[Document]
    ) -> str | Dict[str, Any]:
        """
        ê¸°íšŒ ê°€ì„¤ ìƒì„± (v7.7.0: Native/External ëª¨ë“œ ì§€ì›)
        
        ê°œë…:
        -----
        RAGì˜ í•µì‹¬! ê²€ìƒ‰ëœ ì •ë³´ + LLMì˜ ì¶”ë¡ 
        
        ëª¨ë“œë³„ ë™ì‘:
        -----------
        Native Mode (umis_mode='native'):
            - RAG ê²€ìƒ‰ ê²°ê³¼ë§Œ ì¤€ë¹„
            - Cursor LLMì´ ì§ì ‘ ë¶„ì„í•˜ë„ë¡ ê²°ê³¼ ë°˜í™˜
            - ë¹„ìš©: $0
        
        External Mode (umis_mode='external'):
            - RAG ê²€ìƒ‰ + OpenAI API í˜¸ì¶œ
            - ì™„ì„±ëœ ê°€ì„¤ ë°˜í™˜
            - ë¹„ìš©: ~$0.10/ìš”ì²­
        
        Parameters:
        -----------
        observer_observation: Observerì˜ ì‹œì¥ ê´€ì°° ë‚´ìš©
        matched_patterns: ë§¤ì¹­ëœ íŒ¨í„´ë“¤
        success_cases: ìœ ì‚¬ ì„±ê³µ ì‚¬ë¡€ë“¤
        
        Returns:
        --------
        Native ëª¨ë“œ: Dict (RAG ê²°ê³¼ + ì§€ì‹œì‚¬í•­)
        External ëª¨ë“œ: str (ì™„ì„±ëœ ê°€ì„¤ Markdown)
        """
        logger.info(f"[Explorer] ê°€ì„¤ ìƒì„± ì‹œì‘ (ëª¨ë“œ: {self.mode})")
        
        # ì»¨í…ìŠ¤íŠ¸ ì¡°ë¦½ (ëª¨ë“  ëª¨ë“œ ê³µí†µ)
        context = self._assemble_context(matched_patterns, success_cases)
        
        # ========================================
        # Native ëª¨ë“œ: RAG ê²°ê³¼ë§Œ ë°˜í™˜
        # ========================================
        if self.mode == "native":
            logger.info("  ğŸ¯ Native ëª¨ë“œ: RAG ê²°ê³¼ë§Œ ì¤€ë¹„ (Cursor LLMì´ ì²˜ë¦¬)")
            
            return {
                "mode": "native",
                "observer_observation": observer_observation,
                "rag_context": context,
                "matched_patterns_count": len(matched_patterns),
                "success_cases_count": len(success_cases),
                "instruction": (
                    "ìœ„ RAG ê²€ìƒ‰ ê²°ê³¼(rag_context)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¸°íšŒ ê°€ì„¤ì„ ìƒì„±í•´ì£¼ì„¸ìš”.\n\n"
                    "í¬í•¨í•  ë‚´ìš©:\n"
                    "1. Observer ê´€ì°° ìš”ì•½\n"
                    "2. ë§¤ì¹­ëœ íŒ¨í„´ ë¶„ì„\n"
                    "3. ìœ ì‚¬ ì„±ê³µ ì‚¬ë¡€ ì‹œì‚¬ì \n"
                    "4. ê¸°íšŒ ê°€ì„¤ 3-5ê°œ (êµ¬ì¡°í™”)\n"
                    "5. ê° ê°€ì„¤ì˜ ê²€ì¦ ë°©í–¥"
                ),
                "next_step": "Cursor Composer/Chatì—ì„œ ìœ„ instructionì„ ë”°ë¼ ë¶„ì„í•˜ì„¸ìš”."
            }
        
        # ========================================
        # External ëª¨ë“œ: API í˜¸ì¶œ
        # ========================================
        else:
            logger.info("  ğŸŒ External ëª¨ë“œ: OpenAI API í˜¸ì¶œ")
            
            # Prompt êµ¬ì„±
            prompt = ChatPromptTemplate.from_messages([
                ("system", self._get_explorer_system_prompt()),
                ("user", self._get_hypothesis_generation_prompt())
            ])
            
            # LLM ì²´ì¸ êµ¬ì„±
            chain = prompt | self.llm | StrOutputParser()
            
            # ì‹¤í–‰
            logger.info("  â³ LLM ì¶”ë¡  ì¤‘...")
            hypothesis = chain.invoke({
                "observer_observation": observer_observation,
                "context": context
            })
            
            logger.info("  âœ… ê°€ì„¤ ìƒì„± ì™„ë£Œ")
            return hypothesis
    
    def _assemble_context(
        self,
        patterns: List[Document],
        cases: List[Document]
    ) -> str:
        """
        ê²€ìƒ‰ëœ ì •ë³´ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ë¡œ ì¡°ë¦½
        
        ê°œë…:
        -----
        RAG = Retrieval + Augmented Generation
        
        Retrieval (ê²€ìƒ‰):
          - ê´€ë ¨ íŒ¨í„´ 3ê°œ
          - ìœ ì‚¬ ì‚¬ë¡€ 5ê°œ
        
        Augmented (ì¦ê°•):
          - ì´ ì •ë³´ë¥¼ LLMì—ê²Œ ì»¨í…ìŠ¤íŠ¸ë¡œ ì œê³µ
          - LLMì´ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ 
        """
        context = "# ê²€ìƒ‰ëœ íŒ¨í„´\n\n"
        
        for i, doc in enumerate(patterns, 1):
            pattern_id = doc.metadata.get("pattern_id", "N/A")
            context += f"## íŒ¨í„´ {i}: {pattern_id}\n"
            context += doc.page_content[:500] + "...\n\n"
        
        context += "# ìœ ì‚¬ ì„±ê³µ ì‚¬ë¡€\n\n"
        
        for i, doc in enumerate(cases, 1):
            company = doc.metadata.get("company", "N/A")
            context += f"## ì‚¬ë¡€ {i}: {company}\n"
            context += doc.page_content[:500] + "...\n\n"
        
        return context
    
    def _get_explorer_system_prompt(self) -> str:
        """Explorer ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸"""
        return """ë‹¹ì‹ ì€ Explorerì…ë‹ˆë‹¤. UMISì˜ Explorer ì—ì´ì „íŠ¸ë¡œì„œ ì‹œì¥ ê¸°íšŒë¥¼ ë°œêµ´í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì—­í• :
- Observerì˜ ì‹œì¥ ê´€ì°°ì„ ë°›ì•„ ê¸°íšŒ íŒ¨í„´ ì¸ì‹
- ê²€ì¦ëœ ì‚¬ì—…ëª¨ë¸ íŒ¨í„´ 7ê°œ ë³´ìœ 
- 1ë“± ì¶”ì›” íŒ¨í„´ 5ê°œ ë³´ìœ 
- 30+ ì„±ê³µ ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤ í™œìš©

ë‹¹ì‹ ì˜ ê°•ì :
- êµ¬ì¡°ì  ì‚¬ê³  (íŒ¨í„´ ì¸ì‹)
- ì°½ì˜ì  ì‘ìš© (íŒ¨í„´ â†’ ìš°ë¦¬ ì‹œì¥ ì ìš©)
- ê²€ì¦ ì¤‘ì‹¬ (ê·¼ê±° ì—†ëŠ” ê°€ì„¤ ì•ˆ ë§Œë“¦)

ì‘ì—… ë°©ì‹:
1. Observer ê´€ì°°ì—ì„œ íŠ¸ë¦¬ê±° ì‹œê·¸ë„ ì¶”ì¶œ
2. ë§¤ì¹­ë˜ëŠ” íŒ¨í„´ ì°¾ê¸° (RAG ê²€ìƒ‰ë¨)
3. ìœ ì‚¬ ì‚¬ë¡€ì—ì„œ í•™ìŠµ (RAG ê²€ìƒ‰ë¨)
4. ìš°ë¦¬ ì‹œì¥ì— ë§ê²Œ ì¡°ì •
5. ê²€ì¦ ê°€ëŠ¥í•œ ê°€ì„¤ ìƒì„±

ì¤‘ìš”: 
- ëª¨ë“  ì£¼ì¥ì— ê·¼ê±° í•„ìš” (íŒ¨í„´/ì‚¬ë¡€ ì¸ìš©)
- ì¶”ì •ì¹˜ëŠ” ëª…í™•íˆ í‘œì‹œ
- Quantifier/Validator í˜‘ì—… ëª…ì‹œ
"""
    
    def _get_hypothesis_generation_prompt(self) -> str:
        """ê°€ì„¤ ìƒì„± í”„ë¡¬í”„íŠ¸"""
        return """# ì„ë¬´: ê¸°íšŒ ê°€ì„¤ ìƒì„±

## Observerì˜ ì‹œì¥ ê´€ì°°
{observer_observation}

## ê²€ìƒ‰ëœ ì •ë³´ (RAG)
{context}

## ì§€ì‹œì‚¬í•­

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ê²€ì¦ ê°€ëŠ¥í•œ ê¸°íšŒ ê°€ì„¤**ì„ ìƒì„±í•˜ì„¸ìš”.

êµ¬ì¡°:
1. **íŒ¨í„´ ë§¤ì¹­**: ì–´ë–¤ íŒ¨í„´ì´ ì ìš© ê°€ëŠ¥í•œê°€?
2. **ê¸°íšŒ ë…¼ë¦¬**: 
   - ë¬¸ì œ (Observer ê´€ì°°)
   - í•´ê²° ë°©ì•ˆ (íŒ¨í„´ ì ìš©)
   - ê°€ì¹˜ ì œì•ˆ
3. **ìœ ì‚¬ ì‚¬ë¡€ í•™ìŠµ**: ì„±ê³µ ì‚¬ë¡€ì—ì„œ ë°°ìš¸ ì 
4. **ì‹œì¥ ê·œëª¨ ì¶”ì •** (Quantifierì—ê²Œ ìš”ì²­í•  ë‚´ìš© ëª…ì‹œ)
5. **ë°ì´í„° ê²€ì¦** (Validatorì—ê²Œ í™•ì¸í•  ë‚´ìš© ëª…ì‹œ)
6. **ì‹¤í–‰ ê°€ëŠ¥ì„±**: CSF, ë‚œì´ë„, ë¦¬ìŠ¤í¬

ë°˜ë“œì‹œ:
- íŒ¨í„´/ì‚¬ë¡€ ì¸ìš© (chunk_id ëª…ì‹œ)
- ì¶”ì •ì¹˜ í‘œì‹œ
- ê²€ì¦ í•„ìš” í•­ëª© ëª…í™•íˆ
"""


class ExplorerAgenticRAG(ExplorerRAG):
    """
    Explorer Agentic RAG (ììœ¨ ì‹¤í–‰)
    
    ê°œë…:
    -----
    Agentê°€ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ë©° Toolì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Tools:
    ------
    1. search_patterns: íŒ¨í„´ ê²€ìƒ‰
    2. search_cases: ì‚¬ë¡€ ê²€ìƒ‰
    3. get_validation: ê²€ì¦ í”„ë ˆì„ì›Œí¬
    4. ask_quantifier: Quantifierì—ê²Œ ì§ˆë¬¸
    5. ask_validator: Validatorì—ê²Œ ì§ˆë¬¸
    
    ììœ¨ì„±:
    -------
    Explorerê°€ í•„ìš”í•œ Toolì„ ì„ íƒí•˜ì—¬ ì‹¤í–‰
    "Quantifierì—ê²Œ ë­˜ ë¬¼ì–´ë³¼ê¹Œ?" ìŠ¤ìŠ¤ë¡œ íŒë‹¨
    """
    
    def __init__(self):
        super().__init__()
        
        # Agent Tools ì •ì˜ (í–¥í›„ êµ¬í˜„)
        # TODO: LangChain Agent + Tools í†µí•©
        logger.info("  â†’ Agentic ëª¨ë“œ: í–¥í›„ êµ¬í˜„ ì˜ˆì •")
    
    def autonomous_discovery(
        self,
        observer_report: str
    ) -> Dict[str, Any]:
        """
        ì™„ì „ ììœ¨ ê¸°íšŒ ë°œêµ´
        
        ê°œë…:
        -----
        Explorerê°€ Observer ë¦¬í¬íŠ¸ë§Œ ë°›ê³ 
        ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ë©°:
        1. í•„ìš”í•œ íŒ¨í„´ ê²€ìƒ‰
        2. í•„ìš”í•œ ì‚¬ë¡€ ê²€ìƒ‰
        3. Quantifier/Validatorì—ê²Œ ì§ˆë¬¸
        4. ê°€ì„¤ ìƒì„±
        
        í˜„ì¬:
        -----
        ê¸°ë³¸ ì›Œí¬í”Œë¡œìš° êµ¬í˜„
        í–¥í›„ LangChain Agentë¡œ í™•ì¥
        """
        logger.info("[Explorer] ììœ¨ ê¸°íšŒ ë°œêµ´ ì‹œì‘")
        
        # Phase 1-3: íŒ¨í„´ ë° ì‚¬ë¡€ ê²€ìƒ‰ (ê¸°ë³¸ ì›Œí¬í”Œë¡œìš°)
        patterns = self.search_patterns(observer_report, top_k=2)
        
        # ê°€ì¥ ë§¤ì¹­ëœ íŒ¨í„´ìœ¼ë¡œ ì‚¬ë¡€ ê²€ìƒ‰
        best_pattern_id = patterns[0][0].metadata.get("pattern_id")
        cases = self.search_cases(
            observer_report,
            pattern_id=best_pattern_id,
            top_k=3
        )
        
        # Phase 4-6: ê°€ì„¤ ìƒì„±
        hypothesis = self.generate_opportunity_hypothesis(
            observer_observation=observer_report,
            matched_patterns=[p[0] for p in patterns],
            success_cases=[c[0] for c in cases]
        )
        
        return {
            "matched_patterns": patterns,
            "success_cases": cases,
            "hypothesis": hypothesis
        }


# í¸ì˜ í•¨ìˆ˜
def create_explorer_agent() -> ExplorerRAG:
    """Explorer RAG ì—ì´ì „íŠ¸ ìƒì„± (Factory)"""
    return ExplorerRAG()


def create_explorer_agentic() -> ExplorerAgenticRAG:
    """Explorer Agentic RAG ìƒì„± (í–¥í›„ ììœ¨ ì‹¤í–‰)"""
    return ExplorerAgenticRAG()

