"""
Value Sources

êµ¬ì²´ì  ê°’ ì œì‹œ
- í™•ì • ë°ì´í„°
- LLM ì¶”ì •
- ì›¹ ê²€ìƒ‰
- RAG ë²¤ì¹˜ë§ˆí¬
- í†µê³„ íŒ¨í„´ ê°’
"""

from typing import Optional, List, Dict, Any
import os
import requests
from bs4 import BeautifulSoup

from umis_rag.utils.logger import logger
from ..models import ValueEstimate, SourceType, Context, DistributionType, SoftGuide


class ValueSourceBase:
    """Value Source Base Class"""
    
    def collect(self, question: str, context: Optional[Context] = None) -> List[ValueEstimate]:
        """ê°’ ìˆ˜ì§‘"""
        raise NotImplementedError


class DefiniteDataSource(ValueSourceBase):
    """
    í™•ì • ë°ì´í„°
    
    ì—­í• :
    -----
    - í”„ë¡œì íŠ¸ ë°ì´í„°ì—ì„œ í™•ì •ê°’
    - confidence 0.95-1.0
    """
    
    def collect(self, question: str, context: Optional[Context] = None) -> List[ValueEstimate]:
        """í™•ì • ë°ì´í„° ìˆ˜ì§‘"""
        
        if not context or not context.project_data:
            return []
        
        estimates = []
        
        # í‚¤ì›Œë“œ ë§¤ì¹­ (ê°„ë‹¨íˆ)
        keywords = self._extract_keywords(question)
        
        for key, value in context.project_data.items():
            # í‚¤ ë§¤ì¹­
            if any(kw in key.lower() for kw in keywords):
                estimate = ValueEstimate(
                    source_type=SourceType.DEFINITE_DATA,
                    value=float(value) if isinstance(value, (int, float)) else 0.0,
                    confidence=0.98,  # ì™„ì „ í™•ì •ì€ ë“œë¬¾
                    reasoning=f"í”„ë¡œì íŠ¸ í™•ì • ë°ì´í„°: {key}",
                    source_detail=f"project_data.{key}",
                    raw_data=value
                )
                
                estimates.append(estimate)
        
        return estimates
    
    def _extract_keywords(self, question: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨íˆ)"""
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ë¥¼', 'ì˜', 'ì—', 'ì™€'}
        words = question.split()
        keywords = [w.lower() for w in words if w not in stopwords and len(w) >= 2]
        return keywords


class AIAugmentedEstimationSource(ValueSourceBase):
    """
    AI ì¦ê°• ì¶”ì • (v7.8.0)
    
    ì—­í• :
    -----
    - LLM + Web í†µí•© (ê¸°ì¡´ LLMEstimationSource + WebSearchSource)
    - LLM ì§€ì‹ ìš°ì„  â†’ ë¶ˆí™•ì‹¤í•˜ë©´ ì›¹ ê²€ìƒ‰
    - Cursor: instruction ë°˜í™˜ (AIê°€ ì‹¤í–‰)
    - API: External LLM API í˜¸ì¶œ (ìë™ ì‹¤í–‰)
    - confidence 0.55-0.90
    
    í†µí•© ì´ìœ :
    ----------
    - LLMê³¼ Web ëª¨ë‘ "ì™¸ë¶€ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°"
    - ì›¹ ê²€ìƒ‰ì€ LLMì´ ë¶ˆí™•ì‹¤í•  ë•Œ ë³´ì¡° ìˆ˜ë‹¨
    - Cursor ëª¨ë“œì—ì„œ LLM Source í™œìš©ë„ 0% ë¬¸ì œ í•´ê²° (v7.8.1)
    """
    
    def __init__(self, llm_mode: str = "native"):
        self.llm_mode = llm_mode
        
        from umis_rag.core.config import settings
        self.web_search_enabled = settings.web_search_enabled
    
    def collect(self, question: str, context: Optional[Context] = None) -> List[ValueEstimate]:
        """AI ì¦ê°• ì¶”ì •"""
        
        if self.llm_mode == "skip":
            return []
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Cursor AI: instruction ìƒì„± (Phase 3ì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€)
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        if self.llm_mode == "cursor":  # v7.8.1: cursor = Cursor AI
            logger.info(f"  [AI+Web] Cursor AI: instruction ìƒì„± (Phase 3 ìŠ¤í‚µ)")
            
            instruction = self._build_native_instruction(question, context)
            
            # v7.8.1: Cursor AIì—ì„œëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
            # ì´ìœ : value=0.0ì€ Falseë¡œ í‰ê°€ë˜ì–´ íŒë‹¨ ì‹¤íŒ¨ ë°œìƒ
            # instructionì€ Phase 4ì—ì„œë§Œ ì‚¬ìš©
            logger.info(f"  [AI+Web] Cursor AI: Phase 3ì—ì„œ ì‚¬ìš© ë¶ˆê°€ â†’ ë¹ˆ ê°’ ë°˜í™˜")
            return []
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # API Mode: External LLM API í˜¸ì¶œ (v7.8.1)
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        else:  # External LLM
            logger.info(f"  [AI+Web] API Mode (ëª¨ë¸: {self.llm_mode})")
            
            try:
                # Instruction ìƒì„± (Native ë¡œì§ ì¬ì‚¬ìš©)
                instruction = self._build_native_instruction(question, context)
                
                # LLM API í˜¸ì¶œ
                from umis_rag.core.model_configs import get_model_config
                from openai import OpenAI
                
                model_config = get_model_config(self.llm_mode)
                api_params = model_config.build_api_params(instruction)
                
                # OpenAI í´ë¼ì´ì–¸íŠ¸
                import os
                client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
                
                # API í˜¸ì¶œ (api_typeì— ë”°ë¼ ë¶„ê¸°)
                if model_config.api_type == 'responses':
                    response = client.responses.create(**api_params)
                    # ì‘ë‹µ íŒŒì‹±
                    llm_output = response.output_text if hasattr(response, 'output_text') else str(response.output[0].content[0].text)
                
                elif model_config.api_type == 'chat':
                    # System message ì¶”ê°€
                    if 'messages' in api_params:
                        api_params['messages'].insert(0, {
                            "role": "system",
                            "content": "ë‹¹ì‹ ì€ ì‹œì¥ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•­ìƒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."
                        })
                    response = client.chat.completions.create(**api_params)
                    llm_output = response.choices[0].message.content
                
                else:
                    logger.warning(f"  [AI+Web] ì§€ì›í•˜ì§€ ì•ŠëŠ” api_type: {model_config.api_type}")
                    return []
                
                logger.info(f"  [AI+Web] LLM ì‘ë‹µ ìˆ˜ì‹  ({len(llm_output)}ì)")
                
                # JSON íŒŒì‹± (ë²¤ì¹˜ë§ˆí¬ íŒ¨í„´ í™œìš©)
                parsed_data = self._parse_llm_json_response(llm_output)
                
                if not parsed_data:
                    logger.warning(f"  [AI+Web] JSON íŒŒì‹± ì‹¤íŒ¨")
                    return []
                
                # ValueEstimate ìƒì„±
                if 'value' not in parsed_data:
                    logger.warning(f"  [AI+Web] 'value' í‚¤ ì—†ìŒ")
                    return []
                
                estimate = ValueEstimate(
                    source_type=SourceType.AI_AUGMENTED,
                    value=float(parsed_data['value']),
                    confidence=parsed_data.get('confidence', 0.70),
                    reasoning=parsed_data.get('reasoning', 'AI ì¦ê°• ì¶”ì •'),
                    source_detail=f"LLM: {self.llm_mode}",
                    raw_data=parsed_data
                )
                
                logger.info(f"  [AI+Web] ì¶”ì • ì™„ë£Œ: {estimate.value} (ì‹ ë¢°ë„: {estimate.confidence:.2f})")
                
                return [estimate]
            
            except Exception as e:
                logger.error(f"  [AI+Web] API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                import traceback
                logger.debug(traceback.format_exc())
                return []
    
    def _parse_llm_json_response(self, llm_output: str) -> Optional[Dict]:
        """
        LLM ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ ë° íŒŒì‹±
        
        ë²¤ì¹˜ë§ˆí¬ íŒ¨í„´ ì ìš©:
        1. ```json ... ``` ë¸”ë¡ ì¶”ì¶œ
        2. ``` ... ``` ì¼ë°˜ ë¸”ë¡ ì¶”ì¶œ
        3. Raw JSON íŒŒì‹±
        
        Args:
            llm_output: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        
        Returns:
            íŒŒì‹±ëœ Dict ë˜ëŠ” None
        """
        import json
        
        try:
            content = llm_output
            
            # 1. JSON ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ (```json ... ```)
            if '```json' in content:
                json_start = content.find('```json') + 7
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
                logger.debug("  [Parser] JSON ë¸”ë¡ ê°ì§€ (```json)")
            
            # 2. ì¼ë°˜ ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ (``` ... ```)
            elif '```' in content:
                json_start = content.find('```') + 3
                json_end = content.find('```', json_start)
                content = content[json_start:json_end].strip()
                logger.debug("  [Parser] ì½”ë“œ ë¸”ë¡ ê°ì§€ (```)")
            
            else:
                logger.debug("  [Parser] ì½”ë“œ ë¸”ë¡ ì—†ìŒ, Raw JSON íŒŒì‹± ì‹œë„")
            
            # 3. JSON íŒŒì‹±
            parsed = json.loads(content)
            logger.debug(f"  [Parser] JSON íŒŒì‹± ì„±ê³µ")
            
            return parsed
        
        except json.JSONDecodeError as e:
            logger.debug(f"  [Parser] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.debug(f"  [Parser] ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {llm_output[:200]}...")
            return None
        
        except Exception as e:
            logger.debug(f"  [Parser] ì˜ˆì™¸ ë°œìƒ: {e}")
            return None
    
    def _build_native_instruction(
        self,
        question: str,
        context: Optional[Context]
    ) -> str:
        """
        Cursor AI instruction ìƒì„± (v7.8.1)
        
        AIì—ê²Œ ì œê³µí•  ìƒì„¸í•œ ë¡œì§
        """
        
        # Context ì •ë³´
        domain_info = f"ë„ë©”ì¸: {context.domain}" if context and context.domain else ""
        region_info = f"ì§€ì—­: {context.region}" if context and context.region else ""
        time_info = f"ì‹œì : {context.time_period}" if context and context.time_period else ""
        
        context_block = "\n".join([info for info in [domain_info, region_info, time_info] if info])
        
        instruction = f"""# AI Augmented Estimation

**ì§ˆë¬¸**: {question}
{context_block}

---

## ğŸ“‹ ì„ë¬´

ê°’ì„ ì¶”ì •í•˜ì„¸ìš”. ë‹¤ìŒ í”„ë¡œì„¸ìŠ¤ë¥¼ ë”°ë¥´ì„¸ìš”:

### Step 1: ì§€ì‹ ê¸°ë°˜ ì¶”ì • (ìš°ì„ )

ë¨¼ì € **ë‹¹ì‹ ì˜ ì§€ì‹**(í•™ìŠµ ë°ì´í„°)ìœ¼ë¡œ ë‹µë³€ì„ ì‹œë„í•˜ì„¸ìš”.

**ìê°€ í‰ê°€**:
- í™•ì‹ ë„ **â‰¥ 80%**: ì¦‰ì‹œ ê°’ ë°˜í™˜ (Step 2 ìŠ¤í‚µ) âœ…
- í™•ì‹ ë„ **< 80%**: Step 2ë¡œ ì§„í–‰ (ì›¹ ê²€ìƒ‰ í•„ìš”)

**ë°˜í™˜ í˜•ì‹** (í™•ì‹ ë„ â‰¥ 80%):
```json
{{
    "value": ì¶”ì •ê°’,
    "confidence": 0.80,
    "reasoning": "ì§€ì‹ ê¸°ë°˜ ì¶”ì • (ì¶œì²˜: ...)",
    "web_searched": false
}}
```

---

### Step 2: ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ (í™•ì‹ ë„ < 80%ì¸ ê²½ìš°ë§Œ)

êµ¬ê¸€ ë˜ëŠ” ë„¤ì´ë²„ì—ì„œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì„¸ìš”.

**ê²€ìƒ‰ì–´ êµ¬ì„±**:
```
ê¸°ë³¸: "{question}"
"""
        
        if context:
            if context.region:
                instruction += f'\nì§€ì—­ ì¶”ê°€: "{context.region} {question}"'
            if context.time_period:
                instruction += f'\nì‹œì  ì¶”ê°€: "{question} {context.time_period}"'
        
        instruction += """
í†µê³„/ë°ì´í„° í‚¤ì›Œë“œ ì¶”ê°€: "statistics", "data", "í†µê³„"
```

**ê²€ìƒ‰ ë²”ìœ„**:
- ìƒìœ„ **5-10ê°œ** ê²°ê³¼ í™•ì¸
- ì‹ ë¢° ì¶œì²˜ ìš°ì„  (ì •ë¶€, í†µê³„ì²­, ìœ„í‚¤í”¼ë””ì•„, í•™ìˆ  ë…¼ë¬¸)

---

### Step 3: ìˆ«ì ì¶”ì¶œ ë° ë³€í™˜

ê° ê²€ìƒ‰ ê²°ê³¼ì—ì„œ **ê´€ë ¨ ìˆ«ì**ë¥¼ ì°¾ìœ¼ì„¸ìš”.

**ë‹¨ìœ„ ë³€í™˜ ê·œì¹™**:
```
ì˜ì–´ ì•½ì:
  51.7M â†’ 51,700,000
  2.3B â†’ 2,300,000,000
  850K â†’ 850,000

í•œêµ­ì–´ ë‹¨ìœ„:
  5170ë§Œ â†’ 51,700,000
  2ì¡° 3000ì–µ â†’ 2,300,000,000,000
  85ë§Œ â†’ 850,000

ë¹„ìœ¨:
  5.2% â†’ 0.052
  6-8% â†’ 0.07 (ì¤‘ê°„ê°’)
```

**ê´€ë ¨ì„± í•„í„°ë§**:
- ì§ˆë¬¸ê³¼ ê´€ë ¨ ìˆëŠ” ìˆ«ìë§Œ ì¶”ì¶œ
- ì˜ˆ: "ì¸êµ¬" ì§ˆë¬¸ì— "GDP" ìˆ«ìëŠ” ì œì™¸

---

### Step 4: Consensus ê³„ì‚°

ì¶”ì¶œëœ ìˆ«ìë“¤ì˜ **í•©ì˜ê°’**ì„ ê³„ì‚°í•˜ì„¸ìš”.

**ì´ìƒì¹˜ ì œê±°**:
1. ëª¨ë“  ìˆ«ìì˜ **ì¤‘ì•™ê°’(median)** ê³„ì‚°
2. ì¤‘ì•™ê°’ì˜ **Â±50% ë²”ìœ„** ë²—ì–´ë‚œ ê°’ ì œê±°
3. ë‚¨ì€ ìˆ«ìë“¤ì˜ **í‰ê· ** ê³„ì‚°

**ì˜ˆì‹œ**:
```
ì¶”ì¶œ: [51.7M, 51.5M, 52.1M, 120M, 51.8M]
      â†“
ì¤‘ì•™ê°’: 51.8M
Â±50% ë²”ìœ„: [25.9M, 77.7M]
      â†“
ì´ìƒì¹˜: 120M (ë²”ìœ„ ë²—ì–´ë‚¨) â†’ ì œê±°
      â†“
ìµœì¢… í‰ê· : (51.7 + 51.5 + 52.1 + 51.8) / 4 = 51.775M
```

**Confidence ê·œì¹™**:
```
ì¼ì¹˜ ì¶œì²˜ ê°œìˆ˜ì— ë”°ë¼:
- 5ê°œ ì´ìƒ: 0.80
- 4ê°œ: 0.75
- 3ê°œ: 0.70
- 2ê°œ: 0.65
- 1ê°œë§Œ: 0.55

ì‹ ë¢° ì¶œì²˜ ë³´ë„ˆìŠ¤:
- ì •ë¶€/í†µê³„ì²­: +0.05
- ìµœì‹  ë°ì´í„°(2024): +0.03
```

---

### Step 5: ê²°ê³¼ ë°˜í™˜

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:

```json
{{
    "value": 51775000,
    "confidence": 0.75,
    "reasoning": "ì›¹ ê²€ìƒ‰ 4ê°œ ì¶œì²˜ í‰ê·  (Wikipedia 51.7M, í†µê³„ì²­ 51.5M, ë„¤ì´ë²„ 52.1M, CIA 51.8M). ì´ìƒì¹˜ 1ê°œ(120M) ì œê±°.",
    "sources_count": 4,
    "source_detail": "Google ê²€ìƒ‰",
    "web_searched": true,
    "extracted_numbers": [
        {{"value": 51700000, "source": "Wikipedia"}},
        {{"value": 51500000, "source": "í†µê³„ì²­"}},
        {{"value": 52100000, "source": "ë„¤ì´ë²„"}},
        {{"value": 51800000, "source": "CIA"}}
    ]
}}
```

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Step 1: ì§€ì‹ ê¸°ë°˜ ì¶”ì • (í™•ì‹ ë„ í‰ê°€)
- [ ] Step 2: ì›¹ ê²€ìƒ‰ (í•„ìš”ì‹œë§Œ)
- [ ] Step 3: ìˆ«ì ì¶”ì¶œ ë° ë‹¨ìœ„ ë³€í™˜
- [ ] Step 4: Consensus ê³„ì‚° (ì´ìƒì¹˜ ì œê±°)
- [ ] Step 5: ê²°ê³¼ ë°˜í™˜ (JSON í˜•ì‹)

**ì¤‘ìš”**: 
- ì›¹ ê²€ìƒ‰ì€ **ì„ íƒì ** (LLMì´ ë¶ˆí™•ì‹¤í•  ë•Œë§Œ)
- í™•ì‹¤í•˜ë©´ ì§€ì‹ë§Œìœ¼ë¡œ ë‹µë³€ (ë¹ ë¦„, $0)
- ë¶ˆí™•ì‹¤í•  ë•Œë§Œ ì›¹ ê²€ìƒ‰ (ëŠë¦¼, but ì •í™•)
"""
        
        return instruction


class LLMEstimationSource(ValueSourceBase):
    """
    âš ï¸ DEPRECATED (v7.8.0)
    
    â†’ AIAugmentedEstimationSourceë¡œ í†µí•©ë¨
    
    LLM ì¶”ì •
    
    ì—­í• :
    -----
    - LLMì—ê²Œ ì§ì ‘ ì§ˆë¬¸
    - Cursor Mode (Cursor AI) or API Mode (External LLM)
    - confidence 0.60-0.90
    """
    
    def __init__(self, llm_mode: str = "native"):
        self.llm_mode = llm_mode
        logger.warning("âš ï¸ LLMEstimationSourceëŠ” deprecated. AIAugmentedEstimationSource ì‚¬ìš© ê¶Œì¥")
    
    def collect(self, question: str, context: Optional[Context] = None) -> List[ValueEstimate]:
        """LLM ì¶”ì • (deprecated)"""
        
        if self.llm_mode == "skip":
            return []
        
        # ê°„ë‹¨í•œ ì‚¬ì‹¤ ì§ˆë¬¸ë§Œ (ë³µì¡í•œ ê±´ Tier 2ì—ì„œ)
        if not self._is_simple_factual(question):
            return []
        
        # TODO: ì‹¤ì œ LLM í˜¸ì¶œ
        # í˜„ì¬ëŠ” ìŠ¤í‚µ
        logger.info(f"  [LLM] ìŠ¤í‚µ (deprecated â†’ AIAugmented ì‚¬ìš©)")
        
        return []
    
    def _is_simple_factual(self, question: str) -> bool:
        """ê°„ë‹¨í•œ ì‚¬ì‹¤ ì§ˆë¬¸ì¸ê°€?"""
        factual_keywords = ['ì¸êµ¬', 'ë©´ì ', 'gdp', 'ìˆ˜ë„']
        return any(kw in question.lower() for kw in factual_keywords)


class WebSearchSource(ValueSourceBase):
    """
    âš ï¸ DEPRECATED (v7.8.0)
    
    â†’ AIAugmentedEstimationSourceë¡œ í†µí•©ë¨
    
    ì›¹ ê²€ìƒ‰ (v7.6.2)
    
    ì—­í• :
    -----
    - ì›¹ì—ì„œ ìµœì‹  ë°ì´í„° ê²€ìƒ‰
    - ì—¬ëŸ¬ ê²°ê³¼ì—ì„œ ìˆ«ì ì¶”ì¶œ
    - consensus ì•Œê³ ë¦¬ì¦˜ (ë‹¤ìˆ˜ ì¼ì¹˜)
    - confidence 0.60-0.80
    
    êµ¬í˜„:
    -----
    - DuckDuckGo (ë¬´ë£Œ, API í‚¤ ë¶ˆí•„ìš”)
    - Google Custom Search (ìœ ë£Œ, ê³ í’ˆì§ˆ)
    - í˜ì´ì§€ í¬ë¡¤ë§ (v7.7.0)
    
    v7.8.0: AIAugmentedEstimationSource ì‚¬ìš© ê¶Œì¥
    """
    
    def __init__(self):
        """
        ì´ˆê¸°í™” (v7.6.2 - ë™ì  ì—”ì§„ ì„ íƒ)
        
        .env ì„¤ì •:
          WEB_SEARCH_ENGINE=duckduckgo (ê¸°ë³¸, ë¬´ë£Œ)
          ë˜ëŠ”
          WEB_SEARCH_ENGINE=google
          GOOGLE_API_KEY=your-key
          GOOGLE_SEARCH_ENGINE_ID=your-id
          WEB_SEARCH_FETCH_FULL_PAGE=true (í˜ì´ì§€ í¬ë¡¤ë§, v7.7.0+)
        """
        from umis_rag.core.config import settings
        
        self.enabled = settings.web_search_enabled
        self.engine = settings.web_search_engine.lower()
        self.fetch_full_page = settings.web_search_fetch_full_page
        self.max_chars = settings.web_search_max_chars
        self.timeout = settings.web_search_timeout
        
        # ê²€ìƒ‰ ì—”ì§„ë³„ ì´ˆê¸°í™”
        if self.engine == "google":
            self._init_google()
        else:  # duckduckgo (ê¸°ë³¸)
            self._init_duckduckgo()
    
    def _init_duckduckgo(self):
        """DuckDuckGo ì´ˆê¸°í™”"""
        try:
            from duckduckgo_search import DDGS
            self.ddgs = DDGS()
            self.has_search = True
            fetch_status = "í¬ë¡¤ë§ í™œì„±í™”" if self.fetch_full_page else "snippetë§Œ"
            logger.info(f"  [Web] DuckDuckGo ì¤€ë¹„ (ë¬´ë£Œ, {fetch_status})")
        except ImportError:
            logger.warning("  [Web] duckduckgo-search íŒ¨í‚¤ì§€ ì—†ìŒ (pip install ddgs)")
            self.has_search = False
    
    def _init_google(self):
        """Google Custom Search ì´ˆê¸°í™”"""
        from umis_rag.core.config import settings
        
        try:
            from googleapiclient.discovery import build
            
            if not settings.google_api_key or not settings.google_search_engine_id:
                logger.warning("  [Web] Google API í‚¤ ë˜ëŠ” Search Engine ID ì—†ìŒ")
                logger.warning("  [Web] .envì— GOOGLE_API_KEY, GOOGLE_SEARCH_ENGINE_ID ì„¤ì • í•„ìš”")
                self.has_search = False
                return
            
            self.google_service = build(
                "customsearch",
                "v1",
                developerKey=settings.google_api_key
            )
            self.google_engine_id = settings.google_search_engine_id
            self.has_search = True
            
            fetch_status = "í¬ë¡¤ë§ í™œì„±í™”" if self.fetch_full_page else "snippetë§Œ"
            logger.info(f"  [Web] Google Custom Search ì¤€ë¹„ (ìœ ë£Œ, ê³ í’ˆì§ˆ, {fetch_status})")
        
        except ImportError:
            logger.warning("  [Web] google-api-python-client íŒ¨í‚¤ì§€ ì—†ìŒ")
            logger.warning("  [Web] pip install google-api-python-client")
            self.has_search = False
        
        except Exception as e:
            logger.warning(f"  [Web] Google ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.has_search = False
    
    def collect(self, question: str, context: Optional[Context] = None) -> List[ValueEstimate]:
        """
        ì›¹ ê²€ìƒ‰
        
        í”„ë¡œì„¸ìŠ¤:
        1. ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        2. DuckDuckGo ê²€ìƒ‰ (top 5)
        3. ê²°ê³¼ì—ì„œ ìˆ«ì ì¶”ì¶œ
        4. consensus í™•ì¸ (ì—¬ëŸ¬ ì¶œì²˜ ì¼ì¹˜)
        5. ValueEstimate ë°˜í™˜
        """
        if not self.has_search or not self.enabled:
            logger.info(f"  [Web] ë¹„í™œì„±í™”")
            return []
        
        # ì‚¬ì‹¤ ì§ˆë¬¸ë§Œ (ìˆ˜ì¹˜ ì§ˆë¬¸)
        if not self._is_numerical_question(question):
            logger.info(f"  [Web] ìˆ˜ì¹˜ ì§ˆë¬¸ ì•„ë‹˜ â†’ ìŠ¤í‚µ")
            return []
        
        logger.info(f"  [Web] ê²€ìƒ‰ ì‹œì‘ (ì—”ì§„: {self.engine})")
        
        try:
            # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
            search_query = self._build_search_query(question, context)
            logger.info(f"    ì¿¼ë¦¬: {search_query}")
            
            # ì—”ì§„ë³„ ê²€ìƒ‰ ì‹¤í–‰
            if self.engine == "google":
                results = self._search_google(search_query)
            else:  # duckduckgo
                results = self._search_duckduckgo(search_query)
            
            if not results:
                logger.info(f"    ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                return []
            
            logger.info(f"    {len(results)}ê°œ ê²°ê³¼ ë°œê²¬")
            
            # ìˆ«ì ì¶”ì¶œ
            extracted_numbers = self._extract_numbers_from_results(
                results, question
            )
            
            if not extracted_numbers:
                logger.info(f"    ìˆ«ì ì¶”ì¶œ ì‹¤íŒ¨ (íŒ¨í„´ ë§¤ì¹­ ì•ˆë¨)")
                # ë””ë²„ê¹…: ê²°ê³¼ ìƒ˜í”Œ ì¶œë ¥
                if results:
                    sample = results[0]
                    logger.info(f"    ìƒ˜í”Œ: {sample.get('title', '')[:50]}...")
                return []
            
            logger.info(f"    {len(extracted_numbers)}ê°œ ìˆ«ì ì¶”ì¶œë¨")
            
            # Consensus í™•ì¸ (ì—¬ëŸ¬ ì¶œì²˜ì—ì„œ ìœ ì‚¬í•œ ê°’)
            consensus = self._find_consensus(extracted_numbers, question)
            
            if consensus:
                logger.info(f"    Consensus: {consensus['value']} (ì‹ ë¢°ë„: {consensus['confidence']:.2f})")
                
                return [ValueEstimate(
                    source_type=SourceType.AI_AUGMENTED,  # v7.8.1: WEB_SEARCH deprecated
                    value=consensus['value'],
                    confidence=consensus['confidence'],
                    reasoning=f"ì›¹ ê²€ìƒ‰ consensus ({consensus['count']}ê°œ ì¶œì²˜ ì¼ì¹˜)",
                    source_detail=f"DuckDuckGo: {search_query}",
                    raw_data={'sources': consensus['sources']}
                )]
            else:
                logger.info(f"    Consensus ì—†ìŒ (ê°’ ë¶„ì‚°)")
                return []
        
        except Exception as e:
            logger.warning(f"  [Web] ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _fetch_page_content(self, url: str) -> Optional[str]:
        """
        ì›¹ í˜ì´ì§€ í¬ë¡¤ë§ (v7.7.0+)

        Args:
            url: í¬ë¡¤ë§í•  URL

        Returns:
            í˜ì´ì§€ í…ìŠ¤íŠ¸ (ìµœëŒ€ max_chars), ì‹¤íŒ¨ ì‹œ None
        """
        try:
            # User-Agent í—¤ë” (ì¼ë¶€ ì‚¬ì´íŠ¸ëŠ” ë´‡ ì°¨ë‹¨)
            headers = {
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }

            # í˜ì´ì§€ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ ì ìš©)
            response = requests.get(url, headers=headers, timeout=self.timeout)
            response.raise_for_status()

            # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
            soup = BeautifulSoup(response.content, 'html.parser')

            # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±° (ìŠ¤í¬ë¦½íŠ¸, ìŠ¤íƒ€ì¼, ë„¤ë¹„ê²Œì´ì…˜ ë“±)
            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'iframe']):
                tag.decompose()

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = soup.get_text(separator=' ', strip=True)

            # ê³µë°± ì •ë¦¬
            text = ' '.join(text.split())

            # ìµœëŒ€ ë¬¸ì ìˆ˜ ì œí•œ
            if len(text) > self.max_chars:
                text = text[:self.max_chars]

            logger.debug(f"    í¬ë¡¤ë§ ì„±ê³µ: {url[:50]}... ({len(text)}ì)")
            return text

        except requests.Timeout:
            logger.debug(f"    íƒ€ì„ì•„ì›ƒ: {url[:50]}...")
            return None

        except requests.RequestException as e:
            logger.debug(f"    ìš”ì²­ ì‹¤íŒ¨: {url[:50]}... ({e})")
            return None

        except Exception as e:
            logger.debug(f"    íŒŒì‹± ì‹¤íŒ¨: {url[:50]}... ({e})")
            return None

    def _search_duckduckgo(self, query: str) -> list:
        """
        DuckDuckGo ê²€ìƒ‰ ì‹¤í–‰

        Returns:
            [{'title': str, 'body': str, 'href': str}, ...]
        """
        try:
            results = self.ddgs.text(
                keywords=query,
                max_results=5
            )

            if not results:
                return []

            # í˜ì´ì§€ í¬ë¡¤ë§ í™œì„±í™”ëœ ê²½ìš°
            if self.fetch_full_page:
                logger.info(f"    í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘ ({len(results)}ê°œ)")

                enriched_results = []
                for result in results:
                    url = result.get('href', '')

                    if url:
                        # í˜ì´ì§€ í¬ë¡¤ë§ ì‹œë„
                        full_content = self._fetch_page_content(url)

                        if full_content:
                            # í¬ë¡¤ë§ ì„±ê³µ: snippet ëŒ€ì‹  ì „ì²´ ë‚´ìš© ì‚¬ìš©
                            result['body'] = full_content
                        # í¬ë¡¤ë§ ì‹¤íŒ¨: ê¸°ì¡´ snippet ìœ ì§€

                    enriched_results.append(result)

                return enriched_results
            else:
                # snippetë§Œ ì‚¬ìš©
                return results

        except Exception as e:
            logger.warning(f"    DuckDuckGo ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _search_google(self, query: str) -> list:
        """
        Google Custom Search ì‹¤í–‰

        Returns:
            [{'title': str, 'body': str, 'href': str}, ...]
            (DuckDuckGoì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜)
        """
        try:
            response = self.google_service.cse().list(
                q=query,
                cx=self.google_engine_id,
                num=5
            ).execute()

            items = response.get('items', [])

            # DuckDuckGo í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            results = []
            for item in items:
                result = {
                    'title': item.get('title', ''),
                    'body': item.get('snippet', ''),
                    'href': item.get('link', '')
                }
                results.append(result)

            # í˜ì´ì§€ í¬ë¡¤ë§ í™œì„±í™”ëœ ê²½ìš°
            if self.fetch_full_page and results:
                logger.info(f"    í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘ ({len(results)}ê°œ)")

                enriched_results = []
                for result in results:
                    url = result.get('href', '')

                    if url:
                        # í˜ì´ì§€ í¬ë¡¤ë§ ì‹œë„
                        full_content = self._fetch_page_content(url)

                        if full_content:
                            # í¬ë¡¤ë§ ì„±ê³µ: snippet ëŒ€ì‹  ì „ì²´ ë‚´ìš© ì‚¬ìš©
                            result['body'] = full_content
                            logger.debug(f"    âœ“ {url[:40]}... â†’ {len(full_content)}ì")
                        else:
                            # í¬ë¡¤ë§ ì‹¤íŒ¨: snippet ìœ ì§€
                            logger.debug(f"    âœ— {url[:40]}... â†’ snippet ìœ ì§€")

                    enriched_results.append(result)

                return enriched_results
            else:
                # snippetë§Œ ì‚¬ìš©
                return results

        except Exception as e:
            logger.warning(f"    Google ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _is_numerical_question(self, question: str) -> bool:
        """ìˆ˜ì¹˜ ì§ˆë¬¸ì¸ì§€ í™•ì¸"""
        numerical_keywords = [
            'ìˆ˜', 'ê°œìˆ˜', 'ëª‡', 'ì–¼ë§ˆ', 'í‰ê· ', 'ë¹„ìœ¨', 'ë¥ ', 'ê·œëª¨', 'ì¸êµ¬',
            'count', 'how many', 'average', 'rate', 'size', 'population'
        ]
        
        # "ì–¼ë§ˆì¸ê°€", "ëª‡ì¸ê°€" ë“± ì§ˆë¬¸ í˜•íƒœë„ í¬í•¨
        if '?' in question or 'ì¸ê°€' in question:
            return True
        
        return any(kw in question.lower() for kw in numerical_keywords)
    
    def _build_search_query(
        self,
        question: str,
        context: Optional[Context]
    ) -> str:
        """ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±"""
        
        # Context ì¶”ê°€ (ì¤‘ë³µ ë°©ì§€)
        if context:
            parts = []
            
            # Regionì´ ì´ë¯¸ ì§ˆë¬¸ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ ì¶”ê°€
            if context.region and context.region.lower() not in question.lower():
                parts.append(context.region)
            
            # Domainë„ ì¤‘ë³µ ì²´í¬
            if context.domain and context.domain != "General":
                domain_text = context.domain.replace('_', ' ')
                if domain_text.lower() not in question.lower():
                    parts.append(domain_text)
            
            parts.append(question)
            
            query = " ".join(parts)
        else:
            query = question
        
        # "statistics" ì¶”ê°€ (ì˜ì–´ ì¿¼ë¦¬ë§Œ, ì •í™•ë„ í–¥ìƒ)
        # í•œêµ­ì–´ ì¿¼ë¦¬ì—ëŠ” ì¶”ê°€í•˜ì§€ ì•ŠìŒ (ì˜ì–´ ê²€ìƒ‰ ì—”ì§„ì—ì„œ í˜¼ë€)
        has_korean = any(ord(c) >= 0xAC00 and ord(c) <= 0xD7A3 for c in query)
        
        if not has_korean and 'statistics' not in query.lower():
            query += " statistics"
        
        return query
    
    def _extract_numbers_from_results(
        self,
        results: list,
        question: str
    ) -> list:
        """
        ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìˆ«ì ì¶”ì¶œ (ê°œì„ )
        
        Returns:
            [{'value': float, 'source': str, 'context': str}, ...]
        """
        import re
        
        extracted = []
        
        for result in results:
            title = result.get('title', '')
            body = result.get('body', '')
            text = f"{title} {body}"
            source = result.get('href', 'unknown')
            
            # ìˆ«ì íŒ¨í„´ (ê°œì„  - ì˜ì–´ ë‹¨ìœ„ ì•½ì ì¶”ê°€)
            patterns = [
                # ì˜ì–´ ë‹¨ìœ„ ì•½ì (51.7M, 3.5B, 100K) - ìµœìš°ì„ !
                (r'(\d+(?:\.\d+)?)\s*([MBK])\b', 'english_abbreviation'),
                
                # í•œêµ­ì–´ í° ìˆ«ì (51,740,000ëª…)
                (r'(\d{1,3}(?:,\d{3})+)', r'([ì¡°ì–µë§Œì²œë°±ì‹­]?[ì›ëª…ê°œê°‘ì í˜¸ëŒ€%]|ëª…|ê°œ|ì›|ì¡°|ì–µ|ë§Œ)'),
                
                # ì¼ë°˜ ìˆ«ì + ë‹¨ìœ„
                (r'(\d+(?:\.\d+)?)', r'\s*([ì¡°ì–µë§Œì²œ]?[ì›ëª…ê°œê°‘ì í˜¸ëŒ€%]|%)'),
                
                # ë°±ë¶„ìœ¨
                (r'(\d+(?:\.\d+)?)', r'%'),
            ]
            
            for num_pattern, unit_pattern in patterns:
                # ì˜ì–´ ì•½ìëŠ” íŠ¹ë³„ ì²˜ë¦¬
                if unit_pattern == 'english_abbreviation':
                    matches = re.findall(num_pattern, text, re.IGNORECASE)
                else:
                    # ìˆ«ìì™€ ë‹¨ìœ„ë¥¼ í•¨ê»˜ ì°¾ê¸°
                    combined_pattern = num_pattern + r'\s*' + unit_pattern
                    matches = re.findall(combined_pattern, text)
                
                for match in matches:
                    if isinstance(match, tuple) and len(match) >= 2:
                        num_str = match[0]
                        unit = match[1] if len(match) > 1 else ""
                    else:
                        num_str = str(match)
                        unit = ""
                    
                    try:
                        # ì‰¼í‘œ ì œê±°
                        num_str = num_str.replace(',', '')
                        
                        # ìˆ«ì ë³€í™˜
                        value = float(num_str)
                        
                        # ì˜ì–´ ë‹¨ìœ„ ì•½ì ë³€í™˜
                        if unit.upper() == 'M':
                            value *= 1_000_000
                        elif unit.upper() == 'B':
                            value *= 1_000_000_000
                        elif unit.upper() == 'K':
                            value *= 1_000
                        
                        # í•œêµ­ì–´ ë‹¨ìœ„ ë³€í™˜
                        elif 'ì¡°' in unit and 'ì–µ' not in unit:  # ì¡° ë‹¨ë…
                            value *= 1_000_000_000_000
                        elif 'ì–µ' in unit and 'ì¡°' not in unit:  # ì–µ ë‹¨ë…
                            value *= 100_000_000
                        elif 'ë§Œ' in unit and 'ì–µ' not in unit:  # ë§Œ ë‹¨ë…
                            value *= 10_000
                        
                        # ë°±ë¶„ìœ¨ â†’ ë¹„ìœ¨
                        if '%' in unit or '%' in text[text.find(num_str):text.find(num_str)+20]:
                            if value > 1:  # ë°±ë¶„ìœ¨ í˜•íƒœ
                                value = value / 100
                        
                        # ë„ˆë¬´ ì‘ê±°ë‚˜ ë„ˆë¬´ í° ê°’ í•„í„°ë§
                        if value <= 0 or value > 1e18:
                            continue
                        
                        # ë§¥ë½ ì¶”ì¶œ
                        num_pos = text.find(num_str)
                        if num_pos >= 0:
                            context_start = max(0, num_pos - 50)
                            context_end = min(len(text), num_pos + 100)
                            context_text = text[context_start:context_end]
                        else:
                            context_text = title[:100] if title else body[:100]
                        
                        extracted.append({
                            'value': value,
                            'unit': unit,
                            'source': source,
                            'context': context_text,
                            'original': f"{num_str} {unit}"
                        })
                    
                    except Exception as e:
                        # ìˆ«ì ë³€í™˜ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
                        continue
        
        # ì¤‘ë³µ ì œê±° (ê°™ì€ ê°’)
        unique = []
        seen_values = set()
        
        for item in extracted:
            val = item['value']
            # Â±5% ë²”ìœ„ë¡œ ì¤‘ë³µ ì²´í¬ (division by zero ë°©ì§€)
            is_duplicate = False
            for seen in seen_values:
                if seen == 0 and val == 0:
                    is_duplicate = True
                    break
                max_val = max(abs(seen), abs(val))
                if max_val > 0 and abs(val - seen) / max_val < 0.05:
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                unique.append(item)
                seen_values.add(val)
        
        return unique
    
    def _find_consensus(self, extracted_numbers: list, question: str = "") -> Optional[Dict]:
        """
        Consensus ì°¾ê¸° (ì—¬ëŸ¬ ì¶œì²˜ì—ì„œ ìœ ì‚¬í•œ ê°’)
        
        Args:
            extracted_numbers: [{'value': ..., 'source': ...}, ...]
            question: ì§ˆë¬¸ (ê´€ë ¨ì„± í•„í„°ë§ìš©)
        
        Returns:
            {
                'value': float,
                'confidence': float,
                'count': int,
                'sources': [...]
            } or None
        """
        if len(extracted_numbers) < 1:
            return None
        
        # ê´€ë ¨ì„± í•„í„°ë§: ê°’ë“¤ì„ í¬ê¸°ë³„ë¡œ ê·¸ë£¹í™”
        # ì˜ˆ: ì¸êµ¬(51M)ì™€ ì„±ì¥ë¥ (2.4%)ì´ ì„ì´ë©´ ë¶„ë¦¬
        if len(extracted_numbers) > 1:
            values = [item['value'] for item in extracted_numbers]
            max_val = max(values)
            min_val = min([v for v in values if v > 0], default=0)
            
            # ìµœëŒ€ê°’ê³¼ ìµœì†Œê°’ì˜ ì°¨ì´ê°€ 1000ë°° ì´ìƒì´ë©´
            # í° ê°’ë“¤ë§Œ ì‚¬ìš© (ì¸êµ¬ ê°™ì€ ì ˆëŒ€ê°’ ì§ˆë¬¸ìœ¼ë¡œ ì¶”ì •)
            if max_val / max(min_val, 0.001) > 1000:
                extracted_numbers = [item for item in extracted_numbers if item['value'] > max_val / 100]
        
        if len(extracted_numbers) < 2:
            # ê°’ì´ 1ê°œë¿ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ì‹ ë¢°ë„ ë‚®ì¶¤)
            if len(extracted_numbers) == 1:
                return {
                    'value': extracted_numbers[0]['value'],
                    'confidence': 0.50,  # ë‚®ì€ ì‹ ë¢°ë„
                    'count': 1,
                    'sources': [extracted_numbers[0]['source']]
                }
            return None
        
        # ê°’ë“¤ì„ ê·¸ë£¹í™” (Â±30% ë²”ìœ„ ë‚´ë©´ ê°™ì€ ê·¸ë£¹)
        groups = []
        
        for item in extracted_numbers:
            value = item['value']
            
            # ê¸°ì¡´ ê·¸ë£¹ì— ì†í•˜ëŠ”ì§€ í™•ì¸
            found_group = False
            
            for group in groups:
                group_avg = sum(g['value'] for g in group) / len(group)
                
                # Â±30% ë²”ìœ„ ë‚´
                if abs(value - group_avg) / group_avg < 0.30:
                    group.append(item)
                    found_group = True
                    break
            
            if not found_group:
                groups.append([item])
        
        # ê°€ì¥ í° ê·¸ë£¹ ì°¾ê¸°
        if not groups:
            return None
        
        largest_group = max(groups, key=len)
        
        # 2ê°œ ì´ìƒ ì¼ì¹˜í•´ì•¼ consensus
        if len(largest_group) < 2:
            return None
        
        # í‰ê·  ê³„ì‚°
        avg_value = sum(item['value'] for item in largest_group) / len(largest_group)
        
        # Confidence: ì¼ì¹˜í•˜ëŠ” ì¶œì²˜ ê°œìˆ˜ì— ë¹„ë¡€
        # 2ê°œ: 0.60, 3ê°œ: 0.70, 4ê°œ+: 0.80
        confidence_map = {2: 0.60, 3: 0.70, 4: 0.80, 5: 0.85}
        confidence = confidence_map.get(len(largest_group), 0.85)
        
        return {
            'value': avg_value,
            'confidence': confidence,
            'count': len(largest_group),
            'sources': [item['source'] for item in largest_group]
        }


class RAGBenchmarkSource(ValueSourceBase):
    """
    RAG ë²¤ì¹˜ë§ˆí¬
    
    ì—­í• :
    -----
    - Quantifier.market_benchmarks í™œìš©
    - ë„ë©”ì¸ ì§€í‘œ ê²€ìƒ‰
    - confidence 0.50-0.80
    """
    
    def __init__(self):
        """ì´ˆê¸°í™” (Lazy)"""
        self.quantifier = None
        self._initialized = False
    
    def _initialize(self):
        """Lazy ì´ˆê¸°í™”"""
        if self._initialized:
            return
        
        try:
            from umis_rag.agents.quantifier import QuantifierRAG
            self.quantifier = QuantifierRAG()
            logger.info(f"  [RAG] QuantifierRAG ì—°ê²° ì™„ë£Œ")
            self._initialized = True
        except Exception as e:
            logger.warning(f"  [RAG] QuantifierRAG ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._initialized = True
    
    def collect(self, question: str, context: Optional[Context] = None) -> List[ValueEstimate]:
        """RAG ë²¤ì¹˜ë§ˆí¬ ê²€ìƒ‰"""
        
        self._initialize()
        
        if not self.quantifier:
            return []
        
        # ë„ë©”ì¸ ì§€í‘œ ì§ˆë¬¸ë§Œ
        if not self._is_domain_metric(question):
            return []
        
        logger.info(f"  [RAG] Quantifier ë²¤ì¹˜ë§ˆí¬ ê²€ìƒ‰")
        
        try:
            # Quantifier.search_benchmark() í˜¸ì¶œ
            results = self.quantifier.search_benchmark(
                market=question,
                top_k=3
            )
            
            if not results:
                return []
            
            estimates = []
            
            for doc, score in results:
                # ë©”íƒ€ë°ì´í„°ì—ì„œ ê°’ ì¶”ì¶œ (ë‹¤ì–‘í•œ í•„ë“œ ì‹œë„)
                value = self._extract_value_from_metadata(doc.metadata, doc.page_content)
                
                if value:
                    estimate = ValueEstimate(
                        source_type=SourceType.RAG_BENCHMARK,
                        value=value,
                        confidence=score * 0.8,  # ìœ ì‚¬ë„ ê¸°ë°˜, ì•½ê°„ í• ì¸
                        reasoning=f"RAG ë²¤ì¹˜ë§ˆí¬ (ìœ ì‚¬ë„ {score:.2f})",
                        source_detail=doc.metadata.get('metric', 'market_benchmarks'),
                        raw_data=doc.metadata
                    )
                    
                    estimates.append(estimate)
            
            logger.info(f"  [RAG] {len(estimates)}ê°œ ë²¤ì¹˜ë§ˆí¬ ë°œê²¬")
            return estimates
            
        except Exception as e:
            logger.error(f"  [RAG] ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _is_domain_metric(self, question: str) -> bool:
        """ë„ë©”ì¸ ì§€í‘œ ì§ˆë¬¸ì¸ê°€?"""
        # SaaS, ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ í‚¤ì›Œë“œ
        domain_metrics = [
            'churn', 'ltv', 'cac', 'arpu', 'mrr', 'arr',
            'í•´ì§€ìœ¨', 'ì´íƒˆë¥ ', 'ì „í™˜ìœ¨', 'conversion',
            'ì ìœ ìœ¨', 'ì„±ì¥ë¥ ', 'ë§ˆì§„'
        ]
        
        question_lower = question.lower()
        return any(metric in question_lower for metric in domain_metrics)
    
    def _extract_value_from_metadata(self, metadata: Dict, content: str) -> Optional[float]:
        """ë©”íƒ€ë°ì´í„°ì—ì„œ ê°’ ì¶”ì¶œ"""
        
        # ì‹œë„ 1: global_benchmark.median
        if 'global_benchmark' in metadata:
            global_bench = metadata['global_benchmark']
            if isinstance(global_bench, dict):
                median = global_bench.get('median')
                if median:
                    return self._parse_value(median)
        
        # ì‹œë„ 2: value í•„ë“œ
        if 'value' in metadata:
            return self._parse_value(metadata['value'])
        
        # ì‹œë„ 3: contentì—ì„œ ì¶”ì¶œ (ê°„ë‹¨íˆ)
        # "5-7%" ê°™ì€ íŒ¨í„´
        import re
        patterns = [
            r'(\d+(?:\.\d+)?)\s*-\s*(\d+(?:\.\d+)?)\s*%',  # "5-7%"
            r'(\d+(?:\.\d+)?)\s*%',  # "6%"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                if len(match.groups()) == 2:  # range
                    min_val = float(match.group(1))
                    max_val = float(match.group(2))
                    return (min_val + max_val) / 2 / 100  # % â†’ ì†Œìˆ˜
                else:  # single value
                    return float(match.group(1)) / 100
        
        return None
    
    def _parse_value(self, value_raw) -> Optional[float]:
        """ê°’ íŒŒì‹±"""
        # ìˆ«ìë©´ ê·¸ëŒ€ë¡œ
        if isinstance(value_raw, (int, float)):
            return float(value_raw)
        
        # ë¬¸ìì—´ì´ë©´ íŒŒì‹± ì‹œë„
        if isinstance(value_raw, str):
            # "5-7%" â†’ ì¤‘ì•™ê°’ 6
            if '-' in value_raw:
                parts = value_raw.replace('%', '').split('-')
                try:
                    min_val = float(parts[0])
                    max_val = float(parts[1])
                    return (min_val + max_val) / 2 / 100  # % â†’ ì†Œìˆ˜
                except:
                    pass
            
            # "6%" â†’ 0.06
            try:
                val_str = value_raw.replace('%', '').replace(',', '').strip()
                val = float(val_str)
                # % í˜•íƒœë©´ 100ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                if '%' in value_raw:
                    return val / 100
                return val
            except:
                pass
        
        return None


class StatisticalValueSource(ValueSourceBase):
    """
    í†µê³„ íŒ¨í„´ ê°’
    
    ì—­í• :
    -----
    - í†µê³„ íŒ¨í„´ì˜ ëŒ€í‘œê°’ (median or mean)
    - ë‹¤ë¥¸ Value ì—†ì„ ë•Œë§Œ ì‚¬ìš©
    - confidence 0.50-0.65
    """
    
    def collect(
        self,
        question: str,
        context: Optional[Context] = None,
        statistical_guide: Optional['SoftGuide'] = None
    ) -> List[ValueEstimate]:
        """í†µê³„ê°’ ì¶”ì¶œ"""
        
        if not statistical_guide or not statistical_guide.distribution:
            return []
        
        estimates = []
        
        dist = statistical_guide.distribution
        
        # ë¶„í¬ íƒ€ì…ë³„ ëŒ€í‘œê°’ ì„ íƒ
        if dist.distribution_type == DistributionType.NORMAL:
            # ì •ê·œë¶„í¬ â†’ mean
            if dist.mean:
                estimate = ValueEstimate(
                    source_type=SourceType.STATISTICAL_VALUE,
                    value=dist.mean,
                    confidence=0.70 if (dist.cv and dist.cv < 0.20) else 0.60,
                    reasoning="ì •ê·œë¶„í¬ í‰ê· ê°’"
                )
                estimates.append(estimate)
        
        elif dist.distribution_type == DistributionType.POWER_LAW:
            # Power Law â†’ median (í‰ê·  ê¸ˆì§€!)
            if dist.percentiles and 'p50' in dist.percentiles:
                estimate = ValueEstimate(
                    source_type=SourceType.STATISTICAL_VALUE,
                    value=dist.percentiles['p50'],
                    confidence=0.60,
                    reasoning="Power Law ì¤‘ì•™ê°’ (í‰ê·  ì‚¬ìš© ê¸ˆì§€)"
                )
                estimates.append(estimate)
        
        elif dist.distribution_type == DistributionType.EXPONENTIAL:
            # ì§€ìˆ˜ë¶„í¬ â†’ median
            if dist.percentiles and 'p50' in dist.percentiles:
                estimate = ValueEstimate(
                    source_type=SourceType.STATISTICAL_VALUE,
                    value=dist.percentiles['p50'],
                    confidence=0.65,
                    reasoning="ì§€ìˆ˜ë¶„í¬ ì¤‘ì•™ê°’"
                )
                estimates.append(estimate)
        
        elif dist.distribution_type == DistributionType.BIMODAL:
            # ì´ë´‰ë¶„í¬ â†’ ê°’ ì œì‹œ ëª»í•¨
            logger.info("  [í†µê³„ê°’] ì´ë´‰ë¶„í¬ â†’ ì„¸ë¶„í™” í•„ìš”")
            return []
        
        return estimates


        
        
        for pattern in patterns:
            match = re.search(pattern, content)
            if match:
                if len(match.groups()) == 2:  # range
                    min_val = float(match.group(1))
                    max_val = float(match.group(2))
                    return (min_val + max_val) / 2 / 100  # % â†’ ì†Œìˆ˜
                else:  # single value
                    return float(match.group(1)) / 100
        
        return None
    
    def _parse_value(self, value_raw) -> Optional[float]:
        """ê°’ íŒŒì‹±"""
        # ìˆ«ìë©´ ê·¸ëŒ€ë¡œ
        if isinstance(value_raw, (int, float)):
            return float(value_raw)
        
        # ë¬¸ìì—´ì´ë©´ íŒŒì‹± ì‹œë„
        if isinstance(value_raw, str):
            # "5-7%" â†’ ì¤‘ì•™ê°’ 6
            if '-' in value_raw:
                parts = value_raw.replace('%', '').split('-')
                try:
                    min_val = float(parts[0])
                    max_val = float(parts[1])
                    return (min_val + max_val) / 2 / 100  # % â†’ ì†Œìˆ˜
                except:
                    pass
            
            # "6%" â†’ 0.06
            try:
                val_str = value_raw.replace('%', '').replace(',', '').strip()
                val = float(val_str)
                # % í˜•íƒœë©´ 100ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                if '%' in value_raw:
                    return val / 100
                return val
            except:
                pass
        
        return None


class StatisticalValueSource(ValueSourceBase):
    """
    í†µê³„ íŒ¨í„´ ê°’
    
    ì—­í• :
    -----
    - í†µê³„ íŒ¨í„´ì˜ ëŒ€í‘œê°’ (median or mean)
    - ë‹¤ë¥¸ Value ì—†ì„ ë•Œë§Œ ì‚¬ìš©
    - confidence 0.50-0.65
    """
    
    def collect(
        self,
        question: str,
        context: Optional[Context] = None,
        statistical_guide: Optional['SoftGuide'] = None
    ) -> List[ValueEstimate]:
        """í†µê³„ê°’ ì¶”ì¶œ"""
        
        if not statistical_guide or not statistical_guide.distribution:
            return []
        
        estimates = []
        
        dist = statistical_guide.distribution
        
        # ë¶„í¬ íƒ€ì…ë³„ ëŒ€í‘œê°’ ì„ íƒ
        if dist.distribution_type == DistributionType.NORMAL:
            # ì •ê·œë¶„í¬ â†’ mean
            if dist.mean:
                estimate = ValueEstimate(
                    source_type=SourceType.STATISTICAL_VALUE,
                    value=dist.mean,
                    confidence=0.70 if (dist.cv and dist.cv < 0.20) else 0.60,
                    reasoning="ì •ê·œë¶„í¬ í‰ê· ê°’"
                )
                estimates.append(estimate)
        
        elif dist.distribution_type == DistributionType.POWER_LAW:
            # Power Law â†’ median (í‰ê·  ê¸ˆì§€!)
            if dist.percentiles and 'p50' in dist.percentiles:
                estimate = ValueEstimate(
                    source_type=SourceType.STATISTICAL_VALUE,
                    value=dist.percentiles['p50'],
                    confidence=0.60,
                    reasoning="Power Law ì¤‘ì•™ê°’ (í‰ê·  ì‚¬ìš© ê¸ˆì§€)"
                )
                estimates.append(estimate)
        
        elif dist.distribution_type == DistributionType.EXPONENTIAL:
            # ì§€ìˆ˜ë¶„í¬ â†’ median
            if dist.percentiles and 'p50' in dist.percentiles:
                estimate = ValueEstimate(
                    source_type=SourceType.STATISTICAL_VALUE,
                    value=dist.percentiles['p50'],
                    confidence=0.65,
                    reasoning="ì§€ìˆ˜ë¶„í¬ ì¤‘ì•™ê°’"
                )
                estimates.append(estimate)
        
        elif dist.distribution_type == DistributionType.BIMODAL:
            # ì´ë´‰ë¶„í¬ â†’ ê°’ ì œì‹œ ëª»í•¨
            logger.info("  [í†µê³„ê°’] ì´ë´‰ë¶„í¬ â†’ ì„¸ë¶„í™” í•„ìš”")
            return []
        
        return estimates

