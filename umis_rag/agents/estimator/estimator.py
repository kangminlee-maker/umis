"""
Estimator (Fermi) RAG Agent

6ë²ˆì§¸ Agent - ê°’ ì¶”ì • ë° ì§€ëŠ¥ì  íŒë‹¨ ì „ë¬¸ê°€
"""

from typing import Optional, Dict, Any
from pathlib import Path

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

import sys
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from umis_rag.core.config import settings
from umis_rag.utils.logger import logger

from .tier1 import Tier1FastPath
from .tier2 import Tier2JudgmentPath
from .learning_writer import LearningWriter, UserContribution
from .models import Context, EstimationResult


class EstimatorRAG:
    """
    Estimator (Fermi) RAG Agent
    
    ì—­í• :
    -----
    - ê°’ ì¶”ì • ë° ì§€ëŠ¥ì  íŒë‹¨
    - 11ê°œ Source í†µí•© (Physical, Soft, Value)
    - í•™ìŠµí•˜ëŠ” ì‹œìŠ¤í…œ (ì‚¬ìš©í• ìˆ˜ë¡ 6-16ë°° ë¹¨ë¼ì§)
    
    3-Tier ì•„í‚¤í…ì²˜:
    ---------------
    - Tier 1: Built-in + í•™ìŠµ ê·œì¹™ (<0.5ì´ˆ)
    - Tier 2: 11ê°œ Source ìˆ˜ì§‘ + ì¢…í•© íŒë‹¨ (3-8ì´ˆ)
    - Tier 3: Fermi Decomposition (ë¯¸ë˜)
    
    í˜‘ì—…:
    -----
    - Observer: ë¹„ìœ¨ ì¶”ì •
    - Explorer: ì‹œì¥ í¬ê¸° ê° ì¡ê¸°  
    - Quantifier: ë°ì´í„° ë¶€ì¡± ì‹œ
    - Validator: ì¶”ì •ì¹˜ ê²€ì¦
    
    Usage:
        >>> from umis_rag.agents.estimator import EstimatorRAG
        >>> estimator = EstimatorRAG()
        >>> result = estimator.estimate(
        ...     "B2B SaaS Churn RateëŠ”?",
        ...     domain="B2B_SaaS"
        ... )
        >>> print(f"{result.value} (Tier {result.tier})")
    """
    
    def __init__(self):
        """Estimator RAG Agent ì´ˆê¸°í™”"""
        logger.info("[Estimator] Fermi Agent ì´ˆê¸°í™”")
        
        # Tier 1: Fast Path
        self.tier1 = Tier1FastPath()
        logger.info("  âœ… Tier 1 (Built-in + í•™ìŠµ)")
        
        # Tier 2: Judgment Path (Lazy ì´ˆê¸°í™”)
        self.tier2 = None
        self.learning_writer = None
        
        # Tier 3: Fermi Decomposition (ë¯¸ë˜)
        self.tier3 = None
        
        # RAG Collections (Lazy)
        self.canonical_store = None
        self.projected_store = None
        
        logger.info("  âœ… Estimator Agent ì¤€ë¹„ ì™„ë£Œ")
    
    def estimate(
        self,
        question: str,
        context: Optional[Context] = None,
        domain: Optional[str] = None,
        region: Optional[str] = None,
        time_period: Optional[str] = None,
        project_data: Optional[Dict] = None
    ) -> Optional[EstimationResult]:
        """
        í†µí•© ì¶”ì • ë©”ì„œë“œ
        
        ìë™ìœ¼ë¡œ Tier 1 â†’ 2 â†’ 3 ì‹œë„
        
        Args:
            question: ì§ˆë¬¸ (ì˜ˆ: "B2B SaaS Churn RateëŠ”?")
            context: Context ê°ì²´ (ì„ íƒ)
            domain: ë„ë©”ì¸ (ì˜ˆ: "B2B_SaaS", "Food_Service")
            region: ì§€ì—­ (ì˜ˆ: "í•œêµ­", "ì„œìš¸")
            time_period: ì‹œì  (ì˜ˆ: "2024")
            project_data: í”„ë¡œì íŠ¸ í™•ì • ë°ì´í„°
        
        Returns:
            EstimationResult or None
        
        Example:
            >>> estimator = EstimatorRAG()
            >>> result = estimator.estimate(
            ...     "B2B SaaS Churn RateëŠ”?",
            ...     domain="B2B_SaaS"
            ... )
            >>> print(f"ê°’: {result.value}")
            >>> print(f"Tier: {result.tier} (1=ë¹ ë¦„, 2=ì •í™•)")
            >>> print(f"ì‹ ë¢°ë„: {result.confidence:.0%}")
        """
        # Context ìƒì„±
        if context is None:
            context = Context(
                domain=domain or "General",
                region=region,
                time_period=time_period or "2024",
                project_data=project_data or {}
            )
        
        logger.info(f"[Estimator] ì¶”ì •: {question}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Tier 1: Fast Path (Built-in + í•™ìŠµ)
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        result = self.tier1.estimate(question, context)
        
        if result:
            logger.info(f"  âš¡ Tier 1 ì„±ê³µ: {result.value} ({result.execution_time:.2f}ì´ˆ)")
            return result
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Tier 2: Judgment Path (11ê°œ Source)
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        self._ensure_tier2_initialized()
        result = self.tier2.estimate(question, context)
        
        if result:
            logger.info(f"  ğŸ§  Tier 2 ì™„ë£Œ: {result.value} ({result.execution_time:.2f}ì´ˆ)")
            
            if result.should_learn:
                logger.info(f"  ğŸ“š í•™ìŠµë¨ (ë‹¤ìŒì—” Tier 1ë¡œ ë¹ ë¦„!)")
            
            return result
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # Tier 3: Fermi Decomposition (ë¯¸ë˜)
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # TODO: Fermi Model Search í†µí•©
        
        logger.warning("  âŒ ì¶”ì • ì‹¤íŒ¨")
        return None
    
    def contribute(
        self,
        question: str,
        value: float,
        unit: str = "",
        context: Optional[Context] = None,
        contribution_type: str = "definite_fact"
    ) -> str:
        """
        ì‚¬ìš©ì ê¸°ì—¬ (í™•ì • ì‚¬ì‹¤, ì—…ê³„ ìƒì‹ ë“±)
        
        Args:
            question: ì§ˆë¬¸
            value: ê°’
            unit: ë‹¨ìœ„
            context: ë§¥ë½
            contribution_type: ê¸°ì—¬ íƒ€ì…
                - "definite_fact": í™•ì • ì‚¬ì‹¤ (confidence=1.0)
                - "domain_knowledge": ì—…ê³„ ìƒì‹ (confidence=0.90)
                - "personal_experience": ê°œì¸ ê²½í—˜ (confidence=0.40)
        
        Returns:
            rule_id: ì €ì¥ëœ ê·œì¹™ ID
        
        Example:
            >>> estimator = EstimatorRAG()
            >>> rule_id = estimator.contribute(
            ...     question="ìš°ë¦¬ íšŒì‚¬ ì§ì› ìˆ˜ëŠ”?",
            ...     value=150,
            ...     unit="ëª…"
            ... )
            >>> # ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥!
            >>> result = estimator.estimate("ìš°ë¦¬ íšŒì‚¬ ì§ì› ìˆ˜ëŠ”?")
            >>> # â†’ Tier 1ì—ì„œ ì¦‰ì‹œ ë¦¬í„´ (<0.5ì´ˆ)
        """
        self._ensure_tier2_initialized()
        
        contribution = UserContribution(self.learning_writer)
        
        if contribution_type == "definite_fact":
            return contribution.add_definite_fact(
                question=question,
                value=value,
                unit=unit,
                context=context
            )
        elif contribution_type == "domain_knowledge":
            return contribution.add_domain_knowledge(
                question=question,
                value=value,
                context=context or Context()
            )
        elif contribution_type == "personal_experience":
            return contribution.add_personal_experience(
                question=question,
                value=value,
                context_description=str(context) if context else ""
            )
        else:
            raise ValueError(f"Unknown contribution_type: {contribution_type}")
    
    def get_learning_stats(self) -> Dict[str, Any]:
        """
        í•™ìŠµ í†µê³„ ì¡°íšŒ
        
        Returns:
            {
                'total_rules': int,
                'by_domain': dict,
                'avg_confidence': float
            }
        """
        if self.learning_writer:
            return self.learning_writer.get_learning_stats()
        return {
            'total_rules': 0,
            'by_domain': {},
            'avg_confidence': 0.0
        }
    
    def _ensure_tier2_initialized(self):
        """Tier 2 Lazy ì´ˆê¸°í™”"""
        if self.tier2 is not None:
            return
        
        # Learning Writer ì´ˆê¸°í™”
        if self.learning_writer is None:
            # Canonical Collection ë¡œë“œ (Lazy)
            try:
                embeddings = OpenAIEmbeddings(
                    model=settings.embedding_model,
                    openai_api_key=settings.openai_api_key
                )
                
                canonical_store = Chroma(
                    collection_name="canonical_index",
                    embedding_function=embeddings,
                    persist_directory=str(settings.chroma_persist_dir)
                )
                
                self.learning_writer = LearningWriter(
                    canonical_collection=canonical_store._collection
                )
                logger.info("  âœ… Learning Writer ì´ˆê¸°í™”")
                
            except Exception as e:
                logger.warning(f"  âš ï¸  Learning Writer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.learning_writer = None
        
        # Tier 2 ì´ˆê¸°í™”
        self.tier2 = Tier2JudgmentPath(
            learning_writer=self.learning_writer
        )
        logger.info("  âœ… Tier 2 ì´ˆê¸°í™”")


# ================================================================
# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
# ================================================================

_estimator_rag_instance = None


def get_estimator_rag() -> EstimatorRAG:
    """
    Estimator RAG ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜
    
    Returns:
        EstimatorRAG ì¸ìŠ¤í„´ìŠ¤
    
    Example:
        >>> estimator = get_estimator_rag()
        >>> result = estimator.estimate("Churn RateëŠ”?")
    """
    global _estimator_rag_instance
    if _estimator_rag_instance is None:
        _estimator_rag_instance = EstimatorRAG()
    return _estimator_rag_instance

