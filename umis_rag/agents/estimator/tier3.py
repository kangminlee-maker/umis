"""
Tier 3: Fermi Model Search

ì¬ê·€ ë¶„í•´ ì¶”ì • - ë…¼ë¦¬ì˜ í¼ì¦ ë§ì¶”ê¸°

ì„¤ê³„: config/fermi_model_search.yaml (1,269ì¤„)
ì›ë¦¬: ê°€ìš© ë°ì´í„°(Bottom-up) + ê°œë… ë¶„í•´(Top-down) ë°˜ë³µ
"""

from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
import time
import math
import copy
from datetime import datetime

import sys
from pathlib import Path
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

from umis_rag.agents.estimator.models import (
    Context, EstimationResult, DecompositionTrace,
    ComponentEstimation, Tier3Config
)
from umis_rag.agents.estimator.tier2 import Tier2JudgmentPath
from umis_rag.utils.logger import logger
from umis_rag.core.config import settings

# LLM API
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    logger.warning("OpenAI íŒ¨í‚¤ì§€ ì—†ìŒ (pip install openai)")

import yaml
import re


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ í…œí”Œë¦¿ (12ê°œ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BUSINESS_METRIC_TEMPLATES = {
    # Unit Economics (ìš°ì„  - "ltv/cac" ì •í™• ë§¤ì¹­)
    "unit_economics": {
        "keywords": ["unit economics", "ltv/cac", "ë¹„ìœ¨", "ratio", "ê²½ì œì„±"],
        "models": [
            {
                "id": "UE_001",
                "formula": "ratio = ltv / cac",
                "description": "LTV/CAC ë¹„ìœ¨",
                "variables": ["ltv", "cac"]
            }
        ]
    },
    
    # ì‹œì¥ ê·œëª¨
    "market_sizing": {
        "keywords": ["ì‹œì¥", "ê·œëª¨", "TAM", "SAM", "market size"],
        "models": [
            {
                "id": "MARKET_001",
                "formula": "market = customers Ã— adoption_rate Ã— arpu Ã— 12",
                "description": "ê¸°ì—…/ê³ ê° ìˆ˜ ê¸°ë°˜ ì‹œì¥ ê·œëª¨",
                "variables": ["customers", "adoption_rate", "arpu"]
            },
            {
                "id": "MARKET_002",
                "formula": "market = population Ã— digital_rate Ã— conversion_rate Ã— arpu Ã— 12",
                "description": "ì¸êµ¬ ê¸°ë°˜ ë””ì§€í„¸ ì „í™˜ ì‹œì¥",
                "variables": ["population", "digital_rate", "conversion_rate", "arpu"]
            }
        ]
    },
    
    # ê³ ê° ìƒì•  ê°€ì¹˜
    "ltv": {
        "keywords": ["ltv", "LTV", "ìƒì• ê°€ì¹˜", "lifetime value"],
        "models": [
            {
                "id": "LTV_001",
                "formula": "ltv = arpu / churn_rate",
                "description": "ARPUë¥¼ Churnìœ¼ë¡œ ë‚˜ëˆˆ LTV",
                "variables": ["arpu", "churn_rate"]
            },
            {
                "id": "LTV_002",
                "formula": "ltv = arpu Ã— average_lifetime_months",
                "description": "í‰ê·  ìƒì•  ê¸°ê°„ ê¸°ë°˜ LTV",
                "variables": ["arpu", "average_lifetime_months"]
            }
        ]
    },
    
    # ê³ ê° íšë“ ë¹„ìš©
    "cac": {
        "keywords": ["cac", "CAC", "ê³ ê°íšë“", "customer acquisition"],
        "models": [
            {
                "id": "CAC_001",
                "formula": "cac = marketing_cost / new_customers",
                "description": "ë§ˆì¼€íŒ… ë¹„ìš©ì„ ì‹ ê·œ ê³ ê°ìœ¼ë¡œ ë‚˜ëˆ”",
                "variables": ["marketing_cost", "new_customers"]
            },
            {
                "id": "CAC_002",
                "formula": "cac = cpc / conversion_rate",
                "description": "CPCë¥¼ ì „í™˜ìœ¨ë¡œ ë‚˜ëˆ”",
                "variables": ["cpc", "conversion_rate"]
            }
        ]
    },
    
    # ì „í™˜ìœ¨
    "conversion": {
        "keywords": ["ì „í™˜ìœ¨", "conversion", "CVR"],
        "models": [
            {
                "id": "CVR_001",
                "formula": "conversion = paid_users / free_users",
                "description": "ìœ ë£Œ ì „í™˜ìœ¨ (Freemium)",
                "variables": ["paid_users", "free_users"]
            },
            {
                "id": "CVR_002",
                "formula": "conversion = industry_avg Ã— product_quality_factor",
                "description": "ì—…ê³„ í‰ê·  ì¡°ì •",
                "variables": ["industry_avg", "product_quality_factor"]
            }
        ]
    },
    
    # í•´ì§€ìœ¨
    "churn": {
        "keywords": ["churn", "í•´ì§€ìœ¨", "ì´íƒˆìœ¨"],
        "models": [
            {
                "id": "CHURN_001",
                "formula": "churn = churned_customers / total_customers",
                "description": "í•´ì§€ ê³ ê° ë¹„ìœ¨",
                "variables": ["churned_customers", "total_customers"]
            },
            {
                "id": "CHURN_002",
                "formula": "churn = 1 - retention_rate",
                "description": "ìœ ì§€ìœ¨ì˜ ì—­ìˆ˜",
                "variables": ["retention_rate"]
            }
        ]
    },
    
    # ARPU
    "arpu": {
        "keywords": ["arpu", "ARPU", "í‰ê· ë§¤ì¶œ", "average revenue"],
        "models": [
            {
                "id": "ARPU_001",
                "formula": "arpu = base_fee",
                "description": "ê¸°ë³¸ë£Œë§Œ",
                "variables": ["base_fee"]
            },
            {
                "id": "ARPU_002",
                "formula": "arpu = base_fee + overage_fee",
                "description": "ê¸°ë³¸ë£Œ + ì´ˆê³¼ë£Œ",
                "variables": ["base_fee", "overage_fee"]
            },
            {
                "id": "ARPU_003",
                "formula": "arpu = base_fee + usage_fee + addon_fee",
                "description": "ê¸°ë³¸ë£Œ + ì‚¬ìš©ëŸ‰ë£Œ + ì¶”ê°€ê¸°ëŠ¥ë£Œ",
                "variables": ["base_fee", "usage_fee", "addon_fee"]
            }
        ]
    },
    
    # ì„±ì¥ë¥ 
    "growth": {
        "keywords": ["ì„±ì¥ë¥ ", "growth rate", "CAGR"],
        "models": [
            {
                "id": "GROWTH_001",
                "formula": "growth = (current_year - last_year) / last_year",
                "description": "YoY ì„±ì¥ë¥ ",
                "variables": ["current_year", "last_year"]
            },
            {
                "id": "GROWTH_002",
                "formula": "growth = market_growth + market_share_change",
                "description": "ì‹œì¥ ì„±ì¥ + ì ìœ ìœ¨ ë³€í™”",
                "variables": ["market_growth", "market_share_change"]
            }
        ]
    },
    
    # Payback Period (v7.5.0)
    "payback": {
        "keywords": ["payback", "íšŒìˆ˜ê¸°ê°„", "íˆ¬ìíšŒìˆ˜"],
        "models": [
            {
                "id": "PAYBACK_001",
                "formula": "payback = cac / (arpu Ã— gross_margin)",
                "description": "CACë¥¼ ì›” ê¸°ì—¬ì´ìµìœ¼ë¡œ ë‚˜ëˆ”",
                "variables": ["cac", "arpu", "gross_margin"]
            },
            {
                "id": "PAYBACK_002",
                "formula": "payback = initial_investment / monthly_profit",
                "description": "ì´ˆê¸° íˆ¬ìë¥¼ ì›” ìˆ˜ìµìœ¼ë¡œ ë‚˜ëˆ”",
                "variables": ["initial_investment", "monthly_profit"]
            }
        ]
    },
    
    # Rule of 40 (v7.5.0)
    "rule_of_40": {
        "keywords": ["rule of 40", "40 ë²•ì¹™"],
        "models": [
            {
                "id": "R40_001",
                "formula": "rule_40 = growth_rate + profit_margin",
                "description": "ì„±ì¥ë¥  + ì´ìµë¥  (40% ì´ìƒì´ ê±´ê°•)",
                "variables": ["growth_rate", "profit_margin"]
            }
        ]
    },
    
    # Net Revenue Retention (v7.5.0)
    "nrr": {
        "keywords": ["nrr", "net revenue retention", "ìˆœë§¤ì¶œìœ ì§€ìœ¨"],
        "models": [
            {
                "id": "NRR_001",
                "formula": "nrr = (beginning_mrr + expansion - contraction - churn) / beginning_mrr",
                "description": "ìˆœë§¤ì¶œ ìœ ì§€ìœ¨ (100% ì´ìƒì´ ê±´ê°•)",
                "variables": ["beginning_mrr", "expansion", "contraction", "churn"]
            },
            {
                "id": "NRR_002",
                "formula": "nrr = 1 + expansion_rate - churn_rate",
                "description": "í™•ì¥ë¥  - í•´ì§€ìœ¨ + 1",
                "variables": ["expansion_rate", "churn_rate"]
            }
        ]
    },
    
    # Gross Margin (v7.5.0)
    "gross_margin": {
        "keywords": ["gross margin", "ë§¤ì¶œì´ì´ìµë¥ ", "gross profit"],
        "models": [
            {
                "id": "GM_001",
                "formula": "gross_margin = (revenue - cogs) / revenue",
                "description": "ë§¤ì¶œì´ì´ìµë¥ ",
                "variables": ["revenue", "cogs"]
            },
            {
                "id": "GM_002",
                "formula": "gross_margin = 1 - (cogs / revenue)",
                "description": "1 - COGS ë¹„ìœ¨",
                "variables": ["cogs", "revenue"]
            }
        ]
    }
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë°ì´í„° ëª¨ë¸ (Tier 3 ì „ìš©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class FermiVariable:
    """
    Fermi ëª¨í˜•ì˜ ë³€ìˆ˜
    
    Attributes:
        name: ë³€ìˆ˜ ì´ë¦„ (ì˜ˆ: "restaurants", "arpu")
        available: ê°€ìš© ì—¬ë¶€
        value: ê°’ (ì±„ì›Œì§„ ê²½ìš°)
        source: ì¶œì²˜ ("project_data", "tier2", "recursive")
        confidence: ì‹ ë¢°ë„
        need_estimate: ì¶”ì • í•„ìš” ì—¬ë¶€
        estimation_result: ì¶”ì • ê²°ê³¼ (ì¬ê·€ë¡œ ì±„ìš´ ê²½ìš°)
    """
    name: str
    available: bool
    value: Optional[float] = None
    source: str = ""
    confidence: float = 0.0
    need_estimate: bool = False
    uncertainty: float = 0.3
    
    # ì¬ê·€ ì¶”ì • ê²°ê³¼
    estimation_result: Optional[EstimationResult] = None


@dataclass
class FermiModel:
    """
    Fermi ì¶”ì • ëª¨í˜•
    
    ì˜ˆ: "ì‹œì¥ = ìŒì‹ì  Ã— ë””ì§€í„¸ìœ¨ Ã— ì „í™˜ìœ¨ Ã— ARPU Ã— 12"
    
    Attributes:
        model_id: ëª¨í˜• ID (MODEL_001, MODEL_002, ...)
        name: ëª¨í˜• ì´ë¦„
        formula: ìˆ˜ì‹ (ë¬¸ìì—´)
        description: ì„¤ëª…
        variables: ë³€ìˆ˜ ë”•ì…”ë„ˆë¦¬
        total_variables: ì´ ë³€ìˆ˜ ê°œìˆ˜
        unknown_count: Unknown ë³€ìˆ˜ ê°œìˆ˜
        feasibility_score: ì‹¤í–‰ ê°€ëŠ¥ì„± ì ìˆ˜
    """
    model_id: str
    name: str
    formula: str
    description: str
    variables: Dict[str, FermiVariable] = field(default_factory=dict)
    
    # í†µê³„
    total_variables: int = 0
    unknown_count: int = 0
    available_count: int = 0
    
    # í‰ê°€
    feasibility_score: float = 0.0
    unknown_filled: bool = False
    
    # ì„ íƒ
    selection_reason: str = ""
    is_alternative: bool = False
    why_not_selected: str = ""


@dataclass
class RankedModel:
    """
    ì ìˆ˜í™”ëœ ëª¨í˜•
    
    ëª¨í˜• ì„ íƒ ê¸°ì¤€ 4ê°œ:
    - Unknown count (50%)
    - Confidence (30%)
    - Complexity (20%)
    - Depth (10% bonus)
    """
    rank: int
    model: FermiModel
    score: float
    
    # ì ìˆ˜ ë¶„í•´
    unknown_score: float = 0.0
    confidence_score: float = 0.0
    complexity_score: float = 0.0
    depth_score: float = 0.0
    
    # ìƒíƒœ
    status: str = "feasible"  # feasible/partial/infeasible
    missing: List[str] = field(default_factory=list)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë³€ìˆ˜ ìˆ˜ë ´ ì •ì±… (Simple ë°©ì‹)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SimpleVariablePolicy:
    """
    ë‹¨ìˆœ ë³€ìˆ˜ ì •ì±… (ì‹¤ìš©ì )
    
    ì›ì¹™:
    - 6ê°œ: ê¶Œì¥ (Occam's Razor)
    - 7-10ê°œ: í—ˆìš© (ê²½ê³ )
    - 10ê°œ+: ê¸ˆì§€ (Miller's Law)
    
    íš¨ê³¼: 98% (Hybrid ëŒ€ë¹„ 2% ì°¨ì´)
    ì½”ë“œ: 20ì¤„ (Hybrid ëŒ€ë¹„ 15ë°° ê°„ë‹¨)
    """
    
    def __init__(self):
        self.recommended_max = 6   # Occam's Razor
        self.absolute_max = 10     # Miller's Law (7Â±2)
    
    def check(self, variable_count: int) -> Tuple[bool, Optional[str]]:
        """
        ë³€ìˆ˜ ê°œìˆ˜ ì²´í¬
        
        Args:
            variable_count: í˜„ì¬ ë³€ìˆ˜ ê°œìˆ˜
        
        Returns:
            (allowed, warning)
                allowed: True/False
                warning: None ë˜ëŠ” ê²½ê³  ë©”ì‹œì§€
        """
        # ì ˆëŒ€ ìƒí•œ
        if variable_count > self.absolute_max:
            return False, f"ğŸ›‘ ì ˆëŒ€ ìƒí•œ {self.absolute_max}ê°œ ì´ˆê³¼ (ì¸ì§€ í•œê³„)"
        
        # ê¶Œì¥ ìƒí•œ (ê²½ê³ ë§Œ)
        if variable_count > self.recommended_max:
            return True, f"âš ï¸  ê¶Œì¥ ìƒí•œ {self.recommended_max}ê°œ ì´ˆê³¼ (ë³µì¡ë„â†‘)"
        
        # ì •ìƒ
        return True, None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Tier 3 ë©”ì¸ í´ë˜ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Tier3FermiPath:
    """
    Tier 3: Fermi Model Search
    
    ì¬ê·€ ë¶„í•´ ì¶”ì • - ë…¼ë¦¬ì˜ í¼ì¦ ë§ì¶”ê¸°
    
    í”„ë¡œì„¸ìŠ¤:
    ---------
    Phase 1: ì´ˆê¸° ìŠ¤ìº” (ê°€ìš© ë°ì´í„° íŒŒì•…, Bottom-up)
    Phase 2: ëª¨í˜• ìƒì„± (LLM 3-5ê°œ í›„ë³´, Top-down)
    Phase 3: ì‹¤í–‰ ê°€ëŠ¥ì„± ì²´í¬ (ì¬ê·€ ì¶”ì •ìœ¼ë¡œ í¼ì¦ ë§ì¶”ê¸°)
    Phase 4: ëª¨í˜• ì‹¤í–‰ (Backtrackingìœ¼ë¡œ ì¬ì¡°ë¦½)
    
    ì•ˆì „ ì¥ì¹˜:
    ----------
    - Max depth: 4 (ë¬´í•œ ì¬ê·€ ë°©ì§€)
    - ìˆœí™˜ ê°ì§€: Call stack ì¶”ì 
    - ë³€ìˆ˜ ì œí•œ: 6ê°œ ê¶Œì¥, 10ê°œ ì ˆëŒ€
    
    Usage:
        >>> tier3 = Tier3FermiPath()
        >>> result = tier3.estimate(
        ...     "ìŒì‹ì  SaaS ì‹œì¥ì€?",
        ...     context=Context(domain="Food_Service")
        ... )
        >>> result.decomposition.depth  # 2
        >>> result.value  # 20,160,000,000
    """
    
    def __init__(self, config: Tier3Config = None):
        """ì´ˆê¸°í™”"""
        self.config = config or Tier3Config()
        
        # Tier 2 ì˜ì¡´ì„±
        self.tier2 = Tier2JudgmentPath()
        
        # ì¬ê·€ ì¶”ì 
        self.call_stack: List[str] = []
        self.max_depth = self.config.max_depth  # 4
        
        # ë³€ìˆ˜ ì •ì±…
        self.variable_policy = SimpleVariablePolicy()
        
        # LLM ëª¨ë“œ (config/llm_mode.yaml ì¤€ìˆ˜)
        self.llm_mode = getattr(settings, 'llm_mode', 'native')  # ê¸°ë³¸: native
        self.llm_client = None
        
        # External modeì¼ ë•Œë§Œ API ì´ˆê¸°í™”
        if self.llm_mode == 'external':
            if HAS_OPENAI and settings.openai_api_key:
                self.llm_client = OpenAI(api_key=settings.openai_api_key)
                logger.info("  âœ… External LLM (OpenAI API) ì¤€ë¹„")
            else:
                logger.warning("  âš ï¸  External modeì§€ë§Œ OpenAI API í‚¤ ì—†ìŒ (Fallback: í…œí”Œë¦¿ë§Œ)")
        else:
            logger.info("  âœ… Native Mode (Cursor LLM, ë¹„ìš© $0)")
            logger.info("     LLM ëª¨í˜• ìƒì„±: í…œí”Œë¦¿ë§Œ ì‚¬ìš© (80-90% ì»¤ë²„)")
        
        logger.info("[Tier 3] Fermi Model Search ì´ˆê¸°í™”")
        logger.info(f"  Max depth: {self.max_depth}")
        logger.info(f"  ë³€ìˆ˜ ì •ì±…: ê¶Œì¥ 6ê°œ, ì ˆëŒ€ 10ê°œ")
        logger.info(f"  LLM ëª¨ë“œ: {self.llm_mode}")
    
    def estimate(
        self,
        question: str,
        context: Context = None,
        available_data: Dict = None,
        depth: int = 0,
        parent_data: Dict = None
    ) -> Optional[EstimationResult]:
        """
        Fermi Decomposition ì¶”ì •
        
        Args:
            question: ì§ˆë¬¸ (ì˜ˆ: "ìŒì‹ì  SaaS ì‹œì¥ì€?")
            context: ë§¥ë½ (domain, region, time)
            available_data: ê°€ìš© ë°ì´í„° (í”„ë¡œì íŠ¸ ì œê³µ)
            depth: í˜„ì¬ ì¬ê·€ ê¹Šì´
            parent_data: ë¶€ëª¨ ë°ì´í„° (ì¬ê·€ ì‹œ ìƒì†) v7.5.0+
        
        Returns:
            EstimationResult (decomposition í¬í•¨) ë˜ëŠ” None
        """
        start_time = time.time()
        
        logger.info(f"\n{'  ' * depth}[Tier 3] Fermi Estimation (depth {depth})")
        logger.info(f"{'  ' * depth}  ì§ˆë¬¸: {question}")
        
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        # ì•ˆì „ ì²´í¬
        # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        # 1. Max depth ì²´í¬
        if depth >= self.max_depth:
            logger.warning(f"{'  ' * depth}  âš ï¸  Max depth {self.max_depth} ë„ë‹¬ â†’ Tier 2 Fallback")
            # Fallback to Tier 2
            return self.tier2.estimate(question, context or Context())
        
        # 2. ìˆœí™˜ ê°ì§€
        if self._detect_circular(question):
            logger.warning(f"{'  ' * depth}  âš ï¸  ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€ (Aâ†’Bâ†’A) â†’ ì¤‘ë‹¨")
            return None
        
        # 3. Call stack ì¶”ê°€
        self.call_stack.append(question)
        
        try:
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            # Phase 1: ì´ˆê¸° ìŠ¤ìº” (ë°ì´í„° ìƒì† v7.5.0)
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            scan_result = self._phase1_scan(question, context, available_data, depth, parent_data)
            
            if not scan_result:
                logger.warning(f"{'  ' * depth}  âŒ Phase 1 ì‹¤íŒ¨")
                return None
            
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            # Phase 2: ëª¨í˜• ìƒì„±
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            candidate_models = self._phase2_generate_models(
                question,
                scan_result['available'],
                scan_result['unknown'],
                depth
            )
            
            if not candidate_models:
                logger.warning(f"{'  ' * depth}  âŒ Phase 2 ì‹¤íŒ¨ (ëª¨í˜• ì—†ìŒ)")
                return None
            
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            # Phase 3: ì‹¤í–‰ ê°€ëŠ¥ì„± ì²´í¬ (ì¬ê·€!)
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            ranked_models = self._phase3_check_feasibility(
                candidate_models,
                context or Context(),
                depth
            )
            
            if not ranked_models:
                logger.warning(f"{'  ' * depth}  âŒ Phase 3 ì‹¤íŒ¨ (ì‹¤í–‰ ë¶ˆê°€ëŠ¥)")
                return None
            
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            # Phase 4: ìµœì„  ëª¨í˜• ì‹¤í–‰
            # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
            result = self._phase4_execute(ranked_models[0], depth, context or Context())
            
            if result:
                execution_time = time.time() - start_time
                logger.info(f"{'  ' * depth}  âœ… Tier 3 ì™„ë£Œ: {result.value} ({execution_time:.2f}ì´ˆ)")
            
            return result
        
        except Exception as e:
            logger.error(f"{'  ' * depth}  âŒ Tier 3 ì—ëŸ¬: {e}")
            return None
        
        finally:
            # Call stackì—ì„œ ì œê±° (ì¤‘ìš”!)
            if self.call_stack and self.call_stack[-1] == question:
                self.call_stack.pop()
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Phase 1: ì´ˆê¸° ìŠ¤ìº” (ê°€ìš© ë°ì´í„° íŒŒì•…)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _phase1_scan(
        self,
        question: str,
        context: Optional[Context],
        available_data: Optional[Dict],
        depth: int,
        parent_data: Optional[Dict] = None
    ) -> Optional[Dict]:
        """
        Phase 1: ì´ˆê¸° ìŠ¤ìº” (Bottom-up)
        
        ê°€ìš©í•œ ë°ì´í„° íŒŒì•…:
        1. ë¶€ëª¨ ë°ì´í„° ìƒì† (ì¬ê·€ ì‹œ) v7.5.0+
        2. í”„ë¡œì íŠ¸ ë°ì´í„° (available_data)
        3. ë§¥ë½ì—ì„œ ìëª…í•œ ë°ì´í„°
        
        Args:
            question: ì§ˆë¬¸
            context: ë§¥ë½
            available_data: í”„ë¡œì íŠ¸ ë°ì´í„°
            depth: ê¹Šì´
            parent_data: ë¶€ëª¨ ë°ì´í„° (v7.5.0+)
        
        Returns:
            {
                'available': Dict[str, FermiVariable],
                'unknown': List[str]
            }
        """
        logger.info(f"{'  ' * depth}  [Phase 1] ì´ˆê¸° ìŠ¤ìº”")
        
        available = {}
        
        # Step 0: ë¶€ëª¨ ë°ì´í„° ìƒì† (v7.5.0+)
        if parent_data:
            for key, val in parent_data.items():
                if isinstance(val, FermiVariable):
                    # ë¶€ëª¨ ë³€ìˆ˜ ê·¸ëŒ€ë¡œ ìƒì†
                    available[key] = val
                    logger.info(f"{'  ' * depth}    ë¶€ëª¨ë¡œë¶€í„° ìƒì†: {key} = {val.value}")
                elif isinstance(val, dict):
                    available[key] = FermiVariable(
                        name=key,
                        available=True,
                        value=val.get('value'),
                        source=val.get('source', 'parent_inherited'),
                        confidence=val.get('confidence', 0.8)
                    )
        
        # Step 1: í”„ë¡œì íŠ¸ ë°ì´í„°
        if available_data:
            for key, val in available_data.items():
                if isinstance(val, dict):
                    available[key] = FermiVariable(
                        name=key,
                        available=True,
                        value=val.get('value'),
                        source="project_data",
                        confidence=val.get('confidence', 1.0),
                        uncertainty=val.get('uncertainty', 0.0)
                    )
                else:
                    # ë‹¨ìˆœ ê°’
                    available[key] = FermiVariable(
                        name=key,
                        available=True,
                        value=val,
                        source="project_data",
                        confidence=1.0,
                        uncertainty=0.0
                    )
        
        # Step 2: ë§¥ë½ì—ì„œ ìëª…í•œ ë°ì´í„°
        # (ì˜ˆ: ì‹œê°„ ì œì•½ ë“±)
        if context:
            # TODO: context ê¸°ë°˜ ìëª…í•œ ë³€ìˆ˜ ì¶”ê°€
            pass
        
        logger.info(f"{'  ' * depth}    ê°€ìš© ë°ì´í„°: {len(available)}ê°œ")
        
        return {
            'available': available,
            'unknown': []  # Phase 2ì—ì„œ ëª¨í˜•ë³„ë¡œ íŒŒì•…
        }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Phase 2: ëª¨í˜• ìƒì„± (LLM)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _phase2_generate_models(
        self,
        question: str,
        available: Dict[str, FermiVariable],
        unknown: List[str],
        depth: int
    ) -> List[FermiModel]:
        """
        Phase 2: ëª¨í˜• ìƒì„± (Top-down)
        
        LLMì—ê²Œ ì—¬ëŸ¬ í›„ë³´ ëª¨í˜• ìš”ì²­
        
        í˜„ì¬: ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš© (LLM API êµ¬í˜„ ëŒ€ê¸°)
        TODO: OpenAI/Anthropic API í†µí•©
        
        Args:
            question: ì§ˆë¬¸
            available: ê°€ìš© ë³€ìˆ˜
            unknown: ë¯¸ì§€ìˆ˜ ë¦¬ìŠ¤íŠ¸
            depth: ê¹Šì´
        
        Returns:
            3-5ê°œ FermiModel í›„ë³´
        """
        logger.info(f"{'  ' * depth}  [Phase 2] ëª¨í˜• ìƒì„±")
        
        # TODO: LLM API í†µí•©
        # í˜„ì¬ëŠ” ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
        models = self._generate_default_models(question, available, depth)
        
        # ë³€ìˆ˜ ì •ì±… í•„í„°ë§
        filtered_models = []
        for model in models:
            allowed, warning = self.variable_policy.check(model.total_variables)
            
            if not allowed:
                logger.warning(f"{'  ' * depth}    ëª¨í˜• {model.model_id} ì œì™¸: {warning}")
                model.why_not_selected = warning
                continue
            
            if warning:
                logger.warning(f"{'  ' * depth}    ëª¨í˜• {model.model_id}: {warning}")
            
            filtered_models.append(model)
        
        logger.info(f"{'  ' * depth}    ìƒì„±ëœ ëª¨í˜•: {len(filtered_models)}ê°œ")
        
        return filtered_models
    
    def _generate_default_models(
        self,
        question: str,
        available: Dict[str, FermiVariable],
        depth: int
    ) -> List[FermiModel]:
        """
        ê¸°ë³¸ í…œí”Œë¦¿ ëª¨í˜• ìƒì„±
        
        1. ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ í…œí”Œë¦¿ ë§¤ì¹­
        2. LLM API ëª¨í˜• ìƒì„± (TODO)
        
        Args:
            question: ì§ˆë¬¸
            available: ê°€ìš© ë³€ìˆ˜
            depth: ê¹Šì´
        
        Returns:
            FermiModel ë¦¬ìŠ¤íŠ¸
        """
        # 1. í…œí”Œë¦¿ ë§¤ì¹­ ì‹œë„ (ìš°ì„ , Native/External ê³µí†µ)
        template_models = self._match_business_metric_template(question)
        
        if template_models:
            logger.info(f"{'  ' * depth}    í…œí”Œë¦¿ ë§¤ì¹­: {len(template_models)}ê°œ ëª¨í˜•")
            return template_models
        
        # 2. LLM ëª¨í˜• ìƒì„± (External modeë§Œ)
        if self.llm_mode == 'external' and self.llm_client:
            logger.info(f"{'  ' * depth}    í…œí”Œë¦¿ ì—†ìŒ â†’ External LLM ëª¨í˜• ìƒì„±")
            llm_models = self._generate_llm_models(question, available, depth)
            if llm_models:
                return llm_models
        elif self.llm_mode == 'native':
            logger.info(f"{'  ' * depth}    í…œí”Œë¦¿ ì—†ìŒ + Native Mode â†’ Cursorì—ê²Œ ìš”ì²­")
            logger.info(f"{'  ' * depth}    â„¹ï¸  Tier 3 ìë™ ì¤‘ë‹¨ (Native LLMì€ Cursorê°€ ì²˜ë¦¬)")
            return []  # Native modeì—ì„œëŠ” Cursorê°€ ì§ì ‘ ë¶„ì„
        
        # 3. Fallback: ê¸°ë³¸ ëª¨í˜•
        logger.warning(f"{'  ' * depth}    Fallback: ê¸°ë³¸ ëª¨í˜•")
        
        model = FermiModel(
            model_id="MODEL_DEFAULT",
            name="ê¸°ë³¸ ëª¨í˜•",
            formula="result = value",
            description="ë‹¨ìˆœ ì¶”ì • (Tier 2 í™œìš©)",
            variables={
                "value": FermiVariable(
                    name="value",
                    available=False,
                    need_estimate=True
                )
            },
            total_variables=1,
            unknown_count=1
        )
        
        return [model]
    
    def _match_business_metric_template(
        self,
        question: str
    ) -> List[FermiModel]:
        """
        ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œ í…œí”Œë¦¿ ë§¤ì¹­
        
        12ê°œ í…œí”Œë¦¿ì—ì„œ ì§ˆë¬¸ê³¼ ë§¤ì¹­ë˜ëŠ” ëª¨í˜• ì°¾ê¸°
        
        Args:
            question: ì§ˆë¬¸
        
        Returns:
            ë§¤ì¹­ëœ FermiModel ë¦¬ìŠ¤íŠ¸
        """
        question_lower = question.lower()
        
        # í…œí”Œë¦¿ ê²€ìƒ‰ (ì •í™•ë„ ìˆœ: ê¸´ í‚¤ì›Œë“œ ìš°ì„ )
        for metric_name, template in BUSINESS_METRIC_TEMPLATES.items():
            # í‚¤ì›Œë“œ ë§¤ì¹­ (ê¸´ í‚¤ì›Œë“œ ìš°ì„  - "ltv/cac"ê°€ "ltv"ë³´ë‹¤ ìš°ì„ )
            matched_keywords = [kw for kw in template['keywords'] if kw in question_lower]
            
            if matched_keywords:
                # ê°€ì¥ ê¸´ í‚¤ì›Œë“œë¡œ ë§¤ì¹­ (ë” êµ¬ì²´ì )
                best_match = max(matched_keywords, key=len)
                logger.info(f"    ğŸ“‹ í…œí”Œë¦¿ ë§¤ì¹­: {metric_name} (í‚¤ì›Œë“œ: '{best_match}')")
                
                # í…œí”Œë¦¿ ëª¨í˜• ë³€í™˜
                models = []
                for model_template in template['models']:
                    # ë³€ìˆ˜ íŒŒì‹±
                    variables = {}
                    for var_name in model_template['variables']:
                        variables[var_name] = FermiVariable(
                            name=var_name,
                            available=False,  # ê¸°ë³¸ì ìœ¼ë¡œ unknown
                            need_estimate=True
                        )
                    
                    model = FermiModel(
                        model_id=model_template['id'],
                        name=metric_name,
                        formula=model_template['formula'],
                        description=model_template['description'],
                        variables=variables,
                        total_variables=len(variables),
                        unknown_count=len(variables)
                    )
                    
                    models.append(model)
                
                return models
        
        # ë§¤ì¹­ ì‹¤íŒ¨
        return []
    
    def _generate_llm_models(
        self,
        question: str,
        available: Dict[str, FermiVariable],
        depth: int
    ) -> List[FermiModel]:
        """
        LLM APIë¡œ ëª¨í˜• ìƒì„±
        
        ì„¤ê³„: fermi_model_search.yaml Line 1158-1181
        
        Args:
            question: ì§ˆë¬¸
            available: ê°€ìš© ë³€ìˆ˜
            depth: ê¹Šì´
        
        Returns:
            LLMì´ ìƒì„±í•œ FermiModel ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"{'  ' * depth}      [LLM] ëª¨í˜• ìƒì„± ìš”ì²­")
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_llm_prompt(question, available)
        
        try:
            # OpenAI API í˜¸ì¶œ
            response = self.llm_client.chat.completions.create(
                model=self.config.llm_model,
                temperature=self.config.llm_temperature,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ Fermi Estimation ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì§ˆë¬¸ì„ ê³„ì‚° ê°€ëŠ¥í•œ ìˆ˜í•™ì  ëª¨í˜•ìœ¼ë¡œ ë¶„í•´í•˜ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            llm_output = response.choices[0].message.content
            logger.info(f"{'  ' * depth}      [LLM] ì‘ë‹µ ìˆ˜ì‹  ({len(llm_output)}ì)")
            
            # ì‘ë‹µ íŒŒì‹±
            models = self._parse_llm_models(llm_output, depth)
            
            logger.info(f"{'  ' * depth}      [LLM] íŒŒì‹± ì™„ë£Œ: {len(models)}ê°œ ëª¨í˜•")
            
            return models
        
        except Exception as e:
            logger.error(f"{'  ' * depth}      âŒ LLM API ì‹¤íŒ¨: {e}")
            return []
    
    def _build_llm_prompt(
        self,
        question: str,
        available: Dict[str, FermiVariable]
    ) -> str:
        """
        LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
        ì„¤ê³„: fermi_model_search.yaml Line 1163-1181
        """
        # ê°€ìš© ë°ì´í„° ë¬¸ìì—´
        if available:
            available_str = "\n".join([
                f"- {var.name}: {var.value} ({var.source}, confidence: {var.confidence:.0%})"
                for var in available.values()
            ])
        else:
            available_str = "(ì—†ìŒ)"
        
        prompt = f"""ì§ˆë¬¸: {question}

ê°€ìš©í•œ ë°ì´í„°:
{available_str}

ì„ë¬´:
1. ì´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•œ ê³„ì‚° ëª¨í˜•ì„ 3-5ê°œ ì œì‹œí•˜ì„¸ìš”.
2. ê° ëª¨í˜•ì€ ë‹¤ë¥¸ ë¶„í•´ ë°©ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.
3. ê°€ìš©í•œ ë°ì´í„°ë¥¼ ìµœëŒ€í•œ í™œìš©í•˜ì„¸ìš”.
4. Unknown ë³€ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ì„¸ìš”.
5. ê°„ë‹¨í• ìˆ˜ë¡ ì¢‹ìŠµë‹ˆë‹¤ (Occam's Razor, ìµœëŒ€ 6ê°œ ë³€ìˆ˜ ê¶Œì¥).

ì¶œë ¥ í˜•ì‹ (YAML):
```yaml
models:
  - id: MODEL_001
    formula: "result = A Ã— B Ã— C"
    description: "ì„¤ëª…"
    variables:
      - name: A
        description: "ìŒì‹ì  ìˆ˜"
        available: true
      - name: B
        description: "ë„ì…ë¥ "
        available: false
      - name: C
        description: "ARPU"
        available: false
  
  - id: MODEL_002
    formula: "result = A Ã— B Ã— C Ã— D"
    description: "ì„¤ëª…"
    variables:
      - name: A
        description: "ìŒì‹ì  ìˆ˜"
        available: true
      - name: B
        description: "ë””ì§€í„¸ìœ¨"
        available: true
      - name: C
        description: "ì „í™˜ìœ¨"
        available: true
      - name: D
        description: "ARPU"
        available: false
```

ì£¼ì˜: YAML í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
        
        return prompt
    
    def _parse_llm_models(
        self,
        llm_output: str,
        depth: int
    ) -> List[FermiModel]:
        """
        LLM ì‘ë‹µ íŒŒì‹± (YAML)
        
        Args:
            llm_output: LLM ì‘ë‹µ
            depth: ê¹Šì´
        
        Returns:
            FermiModel ë¦¬ìŠ¤íŠ¸
        """
        try:
            # YAML ë¸”ë¡ ì¶”ì¶œ (```yaml ... ```)
            yaml_match = re.search(r'```yaml\n(.*?)\n```', llm_output, re.DOTALL)
            
            if not yaml_match:
                # YAML ë¸”ë¡ ì—†ìœ¼ë©´ ì „ì²´ íŒŒì‹± ì‹œë„
                yaml_str = llm_output
            else:
                yaml_str = yaml_match.group(1)
            
            # YAML íŒŒì‹±
            data = yaml.safe_load(yaml_str)
            
            if not data or 'models' not in data:
                logger.warning(f"{'  ' * depth}        âš ï¸  YAML íŒŒì‹± ì‹¤íŒ¨ (models í‚¤ ì—†ìŒ)")
                return []
            
            # FermiModel ë³€í™˜
            models = []
            for model_data in data['models']:
                # ë³€ìˆ˜ íŒŒì‹±
                variables = {}
                for var_data in model_data.get('variables', []):
                    var_name = var_data.get('name', 'unknown')
                    var_available = var_data.get('available', False)
                    
                    variables[var_name] = FermiVariable(
                        name=var_name,
                        available=var_available,
                        need_estimate=not var_available,
                        source="llm_generated" if var_available else ""
                    )
                
                # FermiModel ìƒì„±
                model = FermiModel(
                    model_id=model_data.get('id', f"LLM_MODEL_{len(models)+1}"),
                    name="LLM ìƒì„± ëª¨í˜•",
                    formula=model_data.get('formula', ''),
                    description=model_data.get('description', ''),
                    variables=variables,
                    total_variables=len(variables),
                    unknown_count=sum(1 for v in variables.values() if not v.available)
                )
                
                models.append(model)
            
            return models
        
        except Exception as e:
            logger.error(f"{'  ' * depth}        âŒ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Phase 3: ì‹¤í–‰ ê°€ëŠ¥ì„± ì²´í¬ (ì¬ê·€ ì¶”ì •)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _phase3_check_feasibility(
        self,
        models: List[FermiModel],
        context: Context,
        current_depth: int
    ) -> List[RankedModel]:
        """
        Phase 3: ì‹¤í–‰ ê°€ëŠ¥ì„± ì²´í¬ + ì¬ê·€ ì¶”ì •
        
        ê° ëª¨í˜•ì˜ Unknown ë³€ìˆ˜ë¥¼ ì¬ê·€ í˜¸ì¶œë¡œ ì±„ìš°ê¸°
        
        Args:
            models: í›„ë³´ ëª¨í˜•ë“¤
            context: ë§¥ë½
            current_depth: í˜„ì¬ ê¹Šì´
        
        Returns:
            ì ìˆ˜ ìˆœ RankedModel ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"{'  ' * current_depth}  [Phase 3] ì‹¤í–‰ ê°€ëŠ¥ì„± ì²´í¬")
        
        ranked = []
        
        for model in models:
            logger.info(f"{'  ' * current_depth}    ëª¨í˜•: {model.model_id}")
            
            # Unknown ë³€ìˆ˜ ì¶”ì • (ì¬ê·€!)
            for var_name, var in model.variables.items():
                if var.need_estimate and not var.estimation_result:
                    logger.info(f"{'  ' * current_depth}      ë³€ìˆ˜ '{var_name}' ì¶”ì • í•„ìš”")
                    
                    # â­ ì¬ê·€ í˜¸ì¶œ!
                    var_result = self._estimate_variable(
                        var_name,
                        context,
                        current_depth + 1
                    )
                    
                    if var_result:
                        var.estimation_result = var_result
                        var.value = var_result.value
                        var.confidence = var_result.confidence
                        var.available = True
                        var.source = f"tier3_recursive_depth_{current_depth + 1}"
                        logger.info(f"{'  ' * current_depth}        âœ… {var.value} (conf: {var.confidence:.2f})")
                    else:
                        logger.warning(f"{'  ' * current_depth}        âŒ ì¶”ì • ì‹¤íŒ¨")
            
            # ëª¨í˜• ì ìˆ˜í™”
            score_result = self._score_model(model, current_depth)
            
            ranked.append(RankedModel(
                rank=0,  # ì •ë ¬ í›„ í• ë‹¹
                model=model,
                score=score_result['total'],
                unknown_score=score_result['unknown'],
                confidence_score=score_result['confidence'],
                complexity_score=score_result['complexity'],
                depth_score=score_result['depth'],
                status=score_result['status'],
                missing=score_result['missing']
            ))
        
        # ì ìˆ˜ ìˆœ ì •ë ¬
        ranked.sort(key=lambda x: x.score, reverse=True)
        
        # Rank í• ë‹¹
        for i, rm in enumerate(ranked, 1):
            rm.rank = i
        
        if ranked:
            logger.info(f"{'  ' * current_depth}    ìµœì„  ëª¨í˜•: {ranked[0].model.model_id} "
                       f"(ì ìˆ˜: {ranked[0].score:.3f})")
        
        return ranked
    
    def _estimate_variable(
        self,
        var_name: str,
        context: Context,
        depth: int
    ) -> Optional[EstimationResult]:
        """
        ë³€ìˆ˜ ì¶”ì • (ì¬ê·€)
        
        1. Tier 2 ë¨¼ì € ì‹œë„ (ë¹ ë¦„, ì¬ê·€ í”¼í•¨)
        2. Tier 2 ì‹¤íŒ¨ â†’ Tier 3 ì¬ê·€ í˜¸ì¶œ
        
        Args:
            var_name: ë³€ìˆ˜ ì´ë¦„
            context: ë§¥ë½
            depth: ê¹Šì´
        
        Returns:
            EstimationResult ë˜ëŠ” None
        """
        question = f"{var_name}ëŠ”?"
        
        logger.info(f"{'  ' * depth}      [Recursive] {question}")
        
        # 1. Tier 2 ë¨¼ì € ì‹œë„ (ì¬ê·€ ìµœì†Œí™”)
        tier2_result = self.tier2.estimate(question, context)
        
        if tier2_result and tier2_result.confidence >= 0.7:
            logger.info(f"{'  ' * depth}        âœ… Tier 2 ì„±ê³µ (ì¬ê·€ ë¶ˆí•„ìš”)")
            return tier2_result
        
        # 2. Tier 2 ì‹¤íŒ¨ â†’ Tier 3 ì¬ê·€
        logger.info(f"{'  ' * depth}        ğŸ”„ Tier 2 ì‹¤íŒ¨ â†’ Fermi ì¬ê·€")
        
        # ë¶€ëª¨ ë°ì´í„° ì¤€ë¹„ (v7.5.0+)
        parent_data_to_pass = {}
        # TODO: í˜„ì¬ ëª¨í˜•ì˜ available ë³€ìˆ˜ë¥¼ ë¶€ëª¨ ë°ì´í„°ë¡œ ì „ë‹¬
        
        # â­ ì¬ê·€ í˜¸ì¶œ (ë¶€ëª¨ ë°ì´í„° ìƒì†)
        return self.estimate(
            question=question,
            context=context,
            available_data=None,
            depth=depth,
            parent_data=parent_data_to_pass  # v7.5.0: ë°ì´í„° ìƒì†
        )
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Phase 4: ëª¨í˜• ì‹¤í–‰ (Backtracking)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _phase4_execute(
        self,
        ranked_model: RankedModel,
        depth: int,
        context: Context
    ) -> Optional[EstimationResult]:
        """
        Phase 4: ëª¨í˜• ì‹¤í–‰ (Backtracking)
        
        ì¬ê·€ë¡œ ì±„ìš´ ë³€ìˆ˜ë“¤ì„ backtrackingìœ¼ë¡œ ì¬ì¡°ë¦½
        
        Args:
            ranked_model: ì„ íƒëœ ëª¨í˜•
            depth: ê¹Šì´
            context: ë§¥ë½
        
        Returns:
            EstimationResult (decomposition í¬í•¨)
        """
        logger.info(f"{'  ' * depth}  [Phase 4] ëª¨í˜• ì‹¤í–‰")
        
        model = ranked_model.model
        
        # Step 1: ë³€ìˆ˜ ë°”ì¸ë”© í™•ì¸
        bindings = {}
        for name, var in model.variables.items():
            if var.available and var.value is not None:
                bindings[name] = var.value
            else:
                logger.warning(f"{'  ' * depth}    âš ï¸  ë³€ìˆ˜ '{name}' ê°’ ì—†ìŒ")
        
        if not bindings:
            logger.warning(f"{'  ' * depth}    âŒ ë°”ì¸ë”©í•  ë³€ìˆ˜ ì—†ìŒ")
            return None
        
        logger.info(f"{'  ' * depth}    ë³€ìˆ˜ ë°”ì¸ë”©: {list(bindings.keys())}")
        
        # Step 2: ê³„ì‚° ì‹¤í–‰
        # TODO: ìˆ˜ì‹ íŒŒì‹± ë° ì•ˆì „í•œ ì‹¤í–‰
        # í˜„ì¬: ê°„ë‹¨í•œ ê³±ì…ˆ ê°€ì •
        result_value = self._execute_formula_simple(model.formula, bindings)
        
        # Step 3: Confidence ì¡°í•© (Geometric Mean)
        confidences = [
            var.confidence
            for var in model.variables.values()
            if var.available and var.confidence > 0
        ]
        
        if confidences:
            combined_confidence = math.prod(confidences) ** (1 / len(confidences))
        else:
            combined_confidence = 0.5
        
        logger.info(f"{'  ' * depth}    Confidence: {combined_confidence:.2f}")
        
        # Step 4: DecompositionTrace ìƒì„±
        decomposition = DecompositionTrace(
            formula=model.formula,
            variables={
                name: var.estimation_result
                for name, var in model.variables.items()
                if var.estimation_result
            },
            calculation_logic=model.description,
            depth=depth,
            decomposition_reasoning=model.selection_reason
        )
        
        # Step 5: ComponentEstimation ìƒì„±
        components = [
            ComponentEstimation(
                component_name=name,
                component_value=var.value or 0.0,
                estimation_method=var.source,
                reasoning=f"{var.source}ì—ì„œ íšë“",
                confidence=var.confidence,
                sources=[var.source]
            )
            for name, var in model.variables.items()
            if var.available
        ]
        
        # Step 6: Estimation Trace ìƒì„±
        trace = [
            f"Step 1: ë¬¸ì œ ì •ì˜ - {model.description}",
            f"Step 2: ëª¨í˜• ì„ íƒ - {model.formula}",
            f"Step 3: ë¶„í•´ - {model.total_variables}ê°œ ë³€ìˆ˜",
            f"Step 4: ë³€ìˆ˜ ì¶”ì • - {model.available_count}ê°œ í™•ë³´",
            f"Step 5: ì¬ê·€ ê¹Šì´ - depth {depth}",
            f"Step 6: ê³„ì‚° - {model.formula}",
            f"Step 7: Confidence - {combined_confidence:.2f}",
            f"Step 8: ê²°ê³¼ - {result_value}"
        ]
        
        # Step 7: EstimationResult ìƒì„±
        result = EstimationResult(
            value=result_value,
            confidence=combined_confidence,
            tier=3,
            sources=[var.source for var in model.variables.values() if var.available],
            reasoning_detail={
                'method': 'fermi_decomposition',
                'model_id': model.model_id,
                'formula': model.formula,
                'depth': depth,
                'selection_reason': model.selection_reason,
                'why_this_method': f'Tier 1/2 ì‹¤íŒ¨, ì¬ê·€ ë¶„í•´ í•„ìš” (depth {depth})'
            },
            component_estimations=components,
            estimation_trace=trace,
            decomposition=decomposition
        )
        
        return result
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ëª¨í˜• ì ìˆ˜í™”
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _score_model(
        self,
        model: FermiModel,
        depth: int
    ) -> Dict[str, Any]:
        """
        ëª¨í˜• ì ìˆ˜í™” (4ê°œ ê¸°ì¤€)
        
        ì„¤ê³„: fermi_model_search.yaml Line 725-810
        
        ê¸°ì¤€:
        1. Unknown count (50%): ì ì„ìˆ˜ë¡ ì¢‹ìŒ
        2. Confidence (30%): ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
        3. Complexity (20%): ê°„ë‹¨í• ìˆ˜ë¡ ì¢‹ìŒ
        4. Depth (10% bonus): ì–•ì„ìˆ˜ë¡ ì¢‹ìŒ
        
        Returns:
            {
                'unknown': float,
                'confidence': float,
                'complexity': float,
                'depth': float,
                'total': float,
                'status': str,
                'missing': List[str]
            }
        """
        # 1. Unknown count (50%)
        if model.total_variables > 0:
            filled = sum(1 for v in model.variables.values() if v.available)
            model.available_count = filled
            unknown_ratio = filled / model.total_variables
        else:
            unknown_ratio = 0.0
        
        unknown_score = unknown_ratio * 0.5
        
        # 2. Confidence (30%)
        confidences = [
            v.confidence for v in model.variables.values()
            if v.available and v.confidence > 0
        ]
        
        if confidences:
            avg_confidence = math.prod(confidences) ** (1 / len(confidences))  # Geometric mean
        else:
            avg_confidence = 0.0
        
        confidence_score = avg_confidence * 0.3
        
        # 3. Complexity (20%)
        var_count = model.total_variables
        
        complexity_map = {
            1: 1.0, 2: 1.0,
            3: 0.9, 4: 0.7,
            5: 0.5, 6: 0.3,
            7: 0.2, 8: 0.15,
            9: 0.10, 10: 0.05
        }
        
        complexity = complexity_map.get(var_count, 0.0)
        complexity_score = complexity * 0.2
        
        # 4. Depth (10% bonus)
        depth_penalties = {0: 1.0, 1: 0.8, 2: 0.6, 3: 0.4, 4: 0.2}
        depth_penalty = depth_penalties.get(depth, 0.2)
        depth_score = depth_penalty * 0.1
        
        # ì´ì 
        total = unknown_score + confidence_score + complexity_score + depth_score
        
        # ìƒíƒœ íŒë‹¨
        missing = [
            name for name, var in model.variables.items()
            if not var.available
        ]
        
        if not missing:
            status = "feasible"
        elif len(missing) <= 2:
            status = "partial"
        else:
            status = "infeasible"
        
        return {
            'unknown': unknown_score,
            'confidence': confidence_score,
            'complexity': complexity_score,
            'depth': depth_score,
            'total': total,
            'status': status,
            'missing': missing
        }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ì•ˆì „ ì¥ì¹˜
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _detect_circular(self, question: str) -> bool:
        """
        ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€
        
        Call stackì— ë™ì¼ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ ìˆœí™˜
        
        ì˜ˆ:
            depth 0: "ì‹œì¥ ê·œëª¨ëŠ”?"
            depth 1: "ì ìœ ìœ¨ì€?"
            depth 2: "ì‹œì¥ ê·œëª¨ëŠ”?"  # â† ìˆœí™˜!
        
        Args:
            question: ì§ˆë¬¸
        
        Returns:
            True: ìˆœí™˜ ê°ì§€
            False: ì •ìƒ
        """
        normalized = question.lower().strip()
        
        for past_question in self.call_stack:
            if past_question.lower().strip() == normalized:
                logger.warning(f"    ìˆœí™˜ ê°ì§€: '{question}'")
                logger.warning(f"    Call stack: {self.call_stack}")
                return True
        
        return False
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ìœ í‹¸ë¦¬í‹°
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    def _execute_formula_simple(
        self,
        formula: str,
        bindings: Dict[str, float]
    ) -> float:
        """
        ìˆ˜ì‹ ì‹¤í–‰ (ì•ˆì „í•œ ë²„ì „)
        
        ì§€ì› ì—°ì‚°: +, -, *, /, ê´„í˜¸
        ê¸ˆì§€: eval() (ë³´ì•ˆ ìœ„í—˜)
        
        Args:
            formula: ìˆ˜ì‹ (ì˜ˆ: "ltv = arpu / churn_rate")
            bindings: ë³€ìˆ˜ ê°’ (ì˜ˆ: {"arpu": 80000, "churn_rate": 0.05})
        
        Returns:
            ê³„ì‚° ê²°ê³¼
        """
        try:
            # ìˆ˜ì‹ì—ì„œ ê²°ê³¼ ë³€ìˆ˜ ì œê±° (ì˜ˆ: "ltv = ..." â†’ "...")
            if '=' in formula:
                parts = formula.split('=', 1)
                if len(parts) == 2:
                    formula = parts[1].strip()
            
            # Ã— â†’ * ë³€í™˜ (ìˆ˜í•™ ê¸°í˜¸ ì •ê·œí™”)
            expr = formula.replace('Ã—', '*').replace('Ã·', '/')
            
            # ë³€ìˆ˜ ì¹˜í™˜
            for var_name, var_value in bindings.items():
                # ë³€ìˆ˜ ì´ë¦„ì„ ê°’ìœ¼ë¡œ ì¹˜í™˜
                expr = expr.replace(var_name, str(var_value))
            
            # ì•ˆì „í•œ ê³„ì‚° (í—ˆìš© ë¬¸ìë§Œ)
            allowed_chars = set('0123456789.+-*/() ')
            if not all(c in allowed_chars for c in expr):
                logger.warning(f"    âš ï¸  ìˆ˜ì‹ì— í—ˆìš©ë˜ì§€ ì•ŠëŠ” ë¬¸ì: {formula}")
                # Fallback: ê³±ì…ˆ
                return math.prod(bindings.values()) if bindings else 0.0
            
            # ê³„ì‚° ì‹¤í–‰ (ì œí•œì  eval - ìˆ«ìì™€ ì—°ì‚°ìë§Œ)
            result = eval(expr, {"__builtins__": {}}, {})
            
            return float(result)
        
        except Exception as e:
            logger.warning(f"    âš ï¸  ìˆ˜ì‹ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            logger.warning(f"    Fallback: ê³±ì…ˆ ì‚¬ìš©")
            
            # Fallback: ê³±ì…ˆ
            if bindings:
                return math.prod(bindings.values())
            return 0.0


