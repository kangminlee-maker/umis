"""
Domain-Centric Reasoner Engine
10-Signal Stack Í∏∞Î∞ò Ï†ïÎ∞Ä Ï∂îÎ°†

Ïã†Ìò∏ Ïö∞ÏÑ†ÏàúÏúÑ:
s3 ‚Üí s8 ‚Üí s6 ‚Üí s10 ‚Üí s2 ‚Üí s9 ‚Üí s7 ‚Üí s5 ‚Üí s4 ‚Üí s1
"""

from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
import yaml
from pathlib import Path
import sys

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from umis_rag.utils.logger import get_logger

logger = get_logger(__name__)


# ========================================
# Îç∞Ïù¥ÌÑ∞ ÌÅ¥ÎûòÏä§
# ========================================

@dataclass
class SignalResult:
    """Ïã†Ìò∏ Ï≤òÎ¶¨ Í≤∞Í≥º"""
    signal_name: str
    weight: float
    value: Any
    confidence: float
    evidence: List[Dict]
    umis_mapping: str


@dataclass
class DomainReasonerResult:
    """Domain Reasoner ÏµúÏ¢Ö Í≤∞Í≥º"""
    point_estimate: float
    range_estimate: Tuple[float, float]
    should_vs_will: Dict[str, Any]
    signal_breakdown: Dict[str, SignalResult]
    evidence_table: List[Dict]
    verification_log: Dict[str, Any]
    residual_unknowns: List[str]
    confidence: str  # 'Low', 'Medium', 'High'
    next_actions: List[Dict]


# ========================================
# Signal ÌÅ¥ÎûòÏä§Îì§
# ========================================

class BaseSignal:
    """Ïã†Ìò∏ Í∏∞Î≥∏ ÌÅ¥ÎûòÏä§"""
    
    def __init__(self, weight: float):
        self.weight = weight
        self.logger = get_logger(self.__class__.__name__)
    
    def process(self, definition: Dict, context: Dict) -> SignalResult:
        """Ïã†Ìò∏ Ï≤òÎ¶¨ (ÌïòÏúÑ ÌÅ¥ÎûòÏä§ÏóêÏÑú Íµ¨ÌòÑ)"""
        raise NotImplementedError


class Signal1_LLMGuess(BaseSignal):
    """s1: LLM Guess (0.15) - ÎÇÆÏùÄ Í∞ÄÏ§ëÏπò"""
    
    def __init__(self, weight=0.15):
        super().__init__(weight)
        
        # OpenAI ÏÑ§Ï†ï
        try:
            from umis_rag.core.config import settings
            self.api_key = settings.openai_api_key
            self.has_api = True
        except:
            self.api_key = None
            self.has_api = False
    
    def process(self, definition: Dict, context: Dict) -> SignalResult:
        """
        LLM Í∏∞Î∞ò Ï¥àÏïà ÏÉùÏÑ± (Îπ†Î•∏ Î≤îÏúÑ ÏÑ§Ï†ï)
        
        Args:
            definition: KPI Ï†ïÏùò
            context: {
                'query': str,
                'domain': str
            }
        
        Returns:
            SignalResult with LLM estimate
        """
        
        query = context.get('query', definition.get('question', ''))
        domain = context.get('domain', 'general')
        
        self.logger.info(f"\n[s1 LLM Guess] Ï¥àÏïà ÏÉùÏÑ±")
        self.logger.info(f"  Query: {query}")
        
        estimate = None
        llm_response = None
        
        # ===== LLM API Ìò∏Ï∂ú (ÏÑ†ÌÉùÏ†Å) =====
        if self.has_api:
            try:
                from openai import OpenAI
                
                client = OpenAI(api_key=self.api_key)
                
                prompt = f"""Îã§Ïùå ÏßàÎ¨∏Ïóê ÎåÄÌï¥ Í∞ÑÎã®Ìïú Ï∂îÏ†ï Î≤îÏúÑÎ•º Ï†úÏãúÌïòÏÑ∏Ïöî (1Î¨∏Ïû•):

ÏßàÎ¨∏: {query}
ÏÇ∞ÏóÖ: {domain}

ÌòïÏãù: "[ÌïòÌïú]-[ÏÉÅÌïú]" ÎòêÎäî "ÏïΩ [Í∞í]"
ÏòàÏãú: "6-12%" ÎòêÎäî "ÏïΩ 5,000Ïñµ Ïõê"

ÎãµÎ≥Ä:"""
                
                response = client.chat.completions.create(
                    model="gpt-4o-mini",  # Îπ†Î•¥Í≥† Ï†ÄÎ†¥Ìïú Î™®Îç∏
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=100
                )
                
                llm_response = response.choices[0].message.content.strip()
                
                self.logger.info(f"  ‚úÖ LLM ÏùëÎãµ: {llm_response}")
                
                # Í∞ÑÎã®Ìïú Í∞í ÌååÏã± ÏãúÎèÑ
                estimate = self._parse_llm_response(llm_response)
                
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è LLM API Ìò∏Ï∂ú Ïã§Ìå®: {e}")
                llm_response = f"API Ìò∏Ï∂ú Ïã§Ìå® (Query: {query})"
        else:
            self.logger.info(f"  ‚ö†Ô∏è OpenAI API ÌÇ§ ÏóÜÏùå ‚Üí Í∏∞Î≥∏ Ï∂îÏ†ï ÏÇ¨Ïö©")
            llm_response = f"ÏùºÎ∞ò ÏÉÅÏãù Í∏∞Î∞ò Ï∂îÏ†ï ÌïÑÏöî (Query: {query})"
        
        # Ï¶ùÍ±∞ ÏÉùÏÑ±
        evidence = [{
            'src_id': 'LLM_GUESS_001',
            'source': 'GPT-4 Common Knowledge',
            'content': llm_response or 'LLM ÏùºÎ∞ò ÏßÄÏãù Í∏∞Î∞ò Ï∂îÏ†ï',
            'type': 'llm_knowledge',
            'confidence': 'Low (Í≤ÄÏ¶ù ÌïÑÏöî)'
        }]
        
        return SignalResult(
            signal_name='s1_llm_guess',
            weight=self.weight,
            value=estimate,
            confidence=0.15,  # ÎÇÆÏùÄ Ïã†Î¢∞ÎèÑ
            evidence=evidence,
            umis_mapping='Guestimation Ï∂úÏ≤ò 2 (LLM ÏßÅÏ†ë)'
        )
    
    def _parse_llm_response(self, response: str) -> Optional[float]:
        """LLM ÏùëÎãµÏóêÏÑú Ïà´Ïûê ÌååÏã±"""
        
        import re
        
        # "6-12%" ‚Üí Ï§ëÍ∞ÑÍ∞í 9%
        pattern = r'(\d+\.?\d*)-(\d+\.?\d*)%'
        match = re.search(pattern, response)
        if match:
            low = float(match.group(1))
            high = float(match.group(2))
            return (low + high) / 2 / 100
        
        # "ÏïΩ 5,000Ïñµ" ‚Üí 5000Ïñµ
        pattern = r'ÏïΩ?\s*([0-9,]+)\s*Ïñµ'
        match = re.search(pattern, response)
        if match:
            num = match.group(1).replace(',', '')
            return float(num) * 100_000_000
        
        # "ÏïΩ 50%" ‚Üí 0.5
        pattern = r'ÏïΩ?\s*(\d+\.?\d*)%'
        match = re.search(pattern, response)
        if match:
            return float(match.group(1)) / 100
        
        return None


class Signal2_RAGConsensus(BaseSignal):
    """s2: RAG Consensus (0.9) - ÌïµÏã¨!"""
    
    def __init__(self, weight=0.9):
        super().__init__(weight)
        
        # UMIS RAG Agents Ï¥àÍ∏∞Ìôî
        try:
            from umis_rag.agents.explorer import ExplorerRAG
            from umis_rag.agents.quantifier import QuantifierRAG
            from umis_rag.agents.validator import ValidatorRAG
            
            self.explorer_rag = ExplorerRAG()
            self.quantifier_rag = QuantifierRAG()
            self.validator_rag = ValidatorRAG()
            
            self.logger.info("  ‚úÖ UMIS RAG Agents Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
        except Exception as e:
            self.logger.warning(f"  ‚ö†Ô∏è UMIS RAG Agents Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            self.explorer_rag = None
            self.quantifier_rag = None
            self.validator_rag = None
    
    def process(self, definition: Dict, context: Dict) -> SignalResult:
        """
        RAGÏóêÏÑú Ìï©Ïùò Î≤îÏúÑ Ï∂îÏ∂ú (ÎèÖÎ¶Ω Ï∂úÏ≤ò ‚â•2)
        
        Args:
            definition: KPI Ï†ïÏùò
            context: {
                'domain': str (ÏÇ∞ÏóÖ),
                'geography': str (ÏßÄÎ¶¨),
                'query': str (ÏõêÎ≥∏ ÏßàÎ¨∏)
            }
        
        Returns:
            SignalResult with consensus range
        """
        
        query = context.get('query', definition.get('question', ''))
        domain = context.get('domain', 'general')
        
        self.logger.info(f"\n[s2 RAG Consensus] Í≤ÄÏÉâ ÏãúÏûë")
        self.logger.info(f"  Query: {query}")
        self.logger.info(f"  Domain: {domain}")
        
        # Í≤∞Í≥º Ï†ÄÏû•
        all_results = []
        sources = []
        
        # ===== 1. Explorer RAG Í≤ÄÏÉâ (Ìå®ÌÑ¥ Í∏∞Î∞ò) =====
        if self.explorer_rag:
            try:
                explorer_results = self.explorer_rag.search_patterns(query, top_k=5)
                
                if explorer_results:
                    self.logger.info(f"  ‚úÖ Explorer RAG: {len(explorer_results)}Í∞ú Ìå®ÌÑ¥ Î∞úÍ≤¨")
                    
                    for doc, score in explorer_results:
                        all_results.append({
                            'source': 'explorer_knowledge_base',
                            'content': doc.page_content,
                            'metadata': doc.metadata,
                            'similarity': score,
                            'source_type': 'pattern'
                        })
                        sources.append('UMIS Explorer RAG')
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è Explorer RAG Í≤ÄÏÉâ Ïã§Ìå®: {e}")
        
        # ===== 2. Quantifier RAG Í≤ÄÏÉâ (Î≤§ÏπòÎßàÌÅ¨) =====
        if self.quantifier_rag:
            try:
                # Î∞©Î≤ïÎ°† Í≤ÄÏÉâ
                methodology_results = self.quantifier_rag.search_methodology(query, top_k=3)
                
                if methodology_results:
                    self.logger.info(f"  ‚úÖ Quantifier Î∞©Î≤ïÎ°†: {len(methodology_results)}Í∞ú")
                    
                    for doc, score in methodology_results:
                        all_results.append({
                            'source': 'calculation_methodologies',
                            'content': doc.page_content,
                            'metadata': doc.metadata,
                            'similarity': score,
                            'source_type': 'methodology'
                        })
                        sources.append('UMIS Quantifier Methodology')
                
                # Î≤§ÏπòÎßàÌÅ¨ Í≤ÄÏÉâ
                benchmark_results = self.quantifier_rag.search_benchmark(query, top_k=5)
                
                if benchmark_results:
                    self.logger.info(f"  ‚úÖ Quantifier Î≤§ÏπòÎßàÌÅ¨: {len(benchmark_results)}Í∞ú")
                    
                    for doc, score in benchmark_results:
                        all_results.append({
                            'source': 'market_benchmarks',
                            'content': doc.page_content,
                            'metadata': doc.metadata,
                            'similarity': score,
                            'source_type': 'benchmark'
                        })
                        sources.append('UMIS Market Benchmarks')
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è Quantifier RAG Í≤ÄÏÉâ Ïã§Ìå®: {e}")
        
        # ===== 3. Validator RAG Í≤ÄÏÉâ (Ï†ïÏùò) =====
        if self.validator_rag:
            try:
                definition_results = self.validator_rag.search_definition_case(query, top_k=3)
                
                if definition_results:
                    self.logger.info(f"  ‚úÖ Validator Ï†ïÏùò: {len(definition_results)}Í∞ú")
                    
                    for doc, score in definition_results:
                        all_results.append({
                            'source': 'definition_validation_cases',
                            'content': doc.page_content,
                            'metadata': doc.metadata,
                            'similarity': score,
                            'source_type': 'definition'
                        })
                        sources.append('UMIS Validator Definitions')
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è Validator RAG Í≤ÄÏÉâ Ïã§Ìå®: {e}")
        
        # ===== 4. ÎèÖÎ¶ΩÏÑ± ÌôïÏù∏ =====
        unique_sources = list(set(sources))
        is_independent = len(unique_sources) >= 2
        
        self.logger.info(f"\n  ÎèÖÎ¶Ω Ï∂úÏ≤ò: {len(unique_sources)}Í∞ú")
        for src in unique_sources:
            self.logger.info(f"    - {src}")
        
        if not is_independent:
            self.logger.warning(f"  ‚ö†Ô∏è ÎèÖÎ¶Ω Ï∂úÏ≤ò Î∂ÄÏ°± (< 2Í∞ú)")
        
        # ===== 5. Ìï©Ïùò Î≤îÏúÑ Ï∂îÏ∂ú =====
        consensus = self._extract_consensus(all_results, context)
        
        # ===== 6. Ï¶ùÍ±∞ ÏÉùÏÑ± =====
        evidence = [
            {
                'src_id': f"SRC_{idx+1:03d}",
                'source': result['source'],
                'content': result['content'][:200] + '...',
                'similarity': result['similarity'],
                'type': result['source_type']
            }
            for idx, result in enumerate(all_results[:5])  # Top 5
        ]
        
        self.logger.info(f"\n  Ìï©Ïùò Î≤îÏúÑ: {consensus.get('range', 'N/A')}")
        self.logger.info(f"  Ïã†Î¢∞ÎèÑ: {consensus.get('confidence', 0):.2f}")
        
        return SignalResult(
            signal_name='s2_rag_consensus',
            weight=self.weight,
            value=consensus.get('value'),
            confidence=consensus.get('confidence', 0),
            evidence=evidence,
            umis_mapping='Explorer/Quantifier/Validator RAG'
        )
    
    def _extract_consensus(self, results: List[Dict], context: Dict) -> Dict:
        """
        Ìï©Ïùò Î≤îÏúÑ Ï∂îÏ∂ú (IQR, trimmed mean)
        
        Args:
            results: RAG Í≤ÄÏÉâ Í≤∞Í≥º
            context: Îß•ÎùΩ
        
        Returns:
            {
                'value': float (Ï§ëÍ∞ÑÍ∞í),
                'range': tuple (ÌïòÌïú, ÏÉÅÌïú),
                'confidence': float (0-1),
                'method': str (Ï∂îÏ∂ú Î∞©Î≤ï)
            }
        """
        
        if not results:
            return {
                'value': None,
                'range': (None, None),
                'confidence': 0,
                'method': 'no_data'
            }
        
        # ÏàòÏπò Í∞í Ï∂îÏ∂ú (Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÎòêÎäî content ÌååÏã±)
        values = []
        
        for result in results:
            # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ÏóêÏÑú Í∞í Ï∂îÏ∂ú ÏãúÎèÑ
            metadata = result.get('metadata', {})
            
            # benchmark_value, typical_range Îì± Ï∞æÍ∏∞
            if 'value' in metadata:
                values.append(self._parse_value(metadata['value']))
            elif 'typical_range' in metadata:
                range_val = metadata['typical_range']
                if '-' in str(range_val):
                    # "6-12%" ÌòïÏãù
                    parts = str(range_val).replace('%', '').split('-')
                    if len(parts) == 2:
                        try:
                            low = float(parts[0])
                            high = float(parts[1])
                            values.append((low + high) / 2)  # Ï§ëÍ∞ÑÍ∞í
                        except:
                            pass
        
        if not values:
            return {
                'value': None,
                'range': (None, None),
                'confidence': 0.3,  # ÎÇÆÏùÄ Ïã†Î¢∞ÎèÑ
                'method': 'no_numeric_data'
            }
        
        # IQR & Trimmed Mean
        import statistics
        
        if len(values) == 1:
            value = values[0]
            range_tuple = (value * 0.8, value * 1.2)  # ¬±20%
            confidence = 0.5
        elif len(values) == 2:
            value = statistics.mean(values)
            range_tuple = (min(values), max(values))
            confidence = 0.7
        else:
            # 3Í∞ú Ïù¥ÏÉÅ ‚Üí IQR
            sorted_values = sorted(values)
            
            # Ïù¥ÏÉÅÏπò Ï†úÍ±∞ (Í∞ÑÎã® Î≤ÑÏ†Ñ: ÏÉÅÌïò 10% Ï†úÍ±∞)
            trim_count = max(1, len(sorted_values) // 10)
            trimmed = sorted_values[trim_count:-trim_count] if len(sorted_values) > 4 else sorted_values
            
            value = statistics.mean(trimmed)
            q1 = statistics.quantiles(trimmed, n=4)[0] if len(trimmed) > 2 else min(trimmed)
            q3 = statistics.quantiles(trimmed, n=4)[2] if len(trimmed) > 2 else max(trimmed)
            
            range_tuple = (q1, q3)
            confidence = min(0.9, 0.5 + len(values) * 0.1)  # Îç∞Ïù¥ÌÑ∞ ÎßéÏùÑÏàòÎ°ù Ïã†Î¢∞‚Üë
        
        return {
            'value': value,
            'range': range_tuple,
            'confidence': confidence,
            'method': 'iqr_trimmed_mean',
            'sample_size': len(values)
        }
    
    def _parse_value(self, value_str: Any) -> Optional[float]:
        """Î¨∏ÏûêÏó¥ Í∞íÏùÑ floatÎ°ú Î≥ÄÌôò"""
        if isinstance(value_str, (int, float)):
            return float(value_str)
        
        if isinstance(value_str, str):
            # "8.5%" ‚Üí 0.085
            if '%' in value_str:
                try:
                    return float(value_str.replace('%', '').strip()) / 100
                except:
                    pass
            
            # "1,000Ïñµ" ‚Üí 100_000_000_000
            if 'Ïñµ' in value_str:
                try:
                    num = value_str.replace('Ïñµ', '').replace(',', '').strip()
                    return float(num) * 100_000_000
                except:
                    pass
            
            # ÏùºÎ∞ò Ïà´Ïûê
            try:
                return float(value_str.replace(',', ''))
            except:
                pass
        
        return None


class Signal3_Laws(BaseSignal):
    """s3: Laws/Ethics/Physics (1.0) - ÏµúÏö∞ÏÑ†!"""
    
    def __init__(self, weight=1.0):
        super().__init__(weight)
        
        # ÎèÑÎ©îÏù∏Î≥Ñ Í∑úÏ†ú DB (ÌôïÏû• Í∞ÄÎä•)
        self.regulatory_db = {
            'healthcare': {
                'laws': ['ÏùòÎ£åÍ∏∞Í∏∞Î≤ï (ÏùòÎ£åÍ∏∞Í∏∞ 2-3Îì±Í∏â Ïù∏Ï¶ù)', 'Í∞úÏù∏Ï†ïÎ≥¥Î≥¥Ìò∏Î≤ï (ÎØºÍ∞êÏ†ïÎ≥¥)', 'ÏÉùÎ™ÖÏú§Î¶¨Î≤ï'],
                'agencies': ['ÏãùÏïΩÏ≤ò', 'Î≥¥Í±¥Î≥µÏßÄÎ∂Ä', 'Í∞úÏù∏Ï†ïÎ≥¥Î≥¥Ìò∏ÏúÑÏõêÌöå'],
                'approval_time': '6-24Í∞úÏõî',
                'ethical_issues': ['ÏùòÎ£å Ïú§Î¶¨', 'ÌôòÏûê ÏïàÏ†Ñ', 'Ï±ÖÏûÑ ÏÜåÏû¨']
            },
            'finance': {
                'laws': ['Í∏àÏúµÏúÑÏõêÌöå Í∑úÏ†ú', 'ÏûêÎ≥∏ÏãúÏû•Î≤ï', 'Ï†ÑÏûêÍ∏àÏúµÍ±∞ÎûòÎ≤ï', 'KYC/AML'],
                'agencies': ['Í∏àÏúµÏúÑÏõêÌöå', 'Í∏àÏúµÍ∞êÎèÖÏõê'],
                'approval_time': '3-12Í∞úÏõî',
                'ethical_issues': ['Í≥µÏ†ïÏÑ±', 'Ï†ïÎ≥¥ Î≥¥Ïïà', 'Ïù¥Ìï¥ÏÉÅÏ∂©']
            },
            'education': {
                'laws': ['ÍµêÏú°Î≤ï', 'ÌèâÏÉùÍµêÏú°Î≤ï', 'ÌïôÏõêÎ≤ï'],
                'agencies': ['ÍµêÏú°Î∂Ä', 'ÍµêÏú°Ï≤≠'],
                'approval_time': '1-6Í∞úÏõî',
                'ethical_issues': ['ÍµêÏú° ÌèâÎì±', 'ÏÇ¨ÍµêÏú° ÏñµÏ†ú']
            },
            'platform': {
                'laws': ['Ï†ÑÏûêÏÉÅÍ±∞ÎûòÎ≤ï', 'Í≥µÏ†ïÍ±∞ÎûòÎ≤ï (ÏãúÏû•ÏßÄÎ∞∞Ï†Å ÏßÄÏúÑ)', 'Í∞úÏù∏Ï†ïÎ≥¥Î≥¥Ìò∏Î≤ï'],
                'agencies': ['Í≥µÏ†ïÍ±∞ÎûòÏúÑÏõêÌöå', 'Í∞úÏù∏Ï†ïÎ≥¥Î≥¥Ìò∏ÏúÑÏõêÌöå'],
                'ethical_issues': ['ÎèÖÍ≥ºÏ†ê Î∞©ÏßÄ', 'ÏÜåÏÉÅÍ≥µÏù∏ Î≥¥Ìò∏', 'Í≥µÏ†ï ÏàòÏàòÎ£å']
            },
            'food': {
                'laws': ['ÏãùÌíàÏúÑÏÉùÎ≤ï', 'Ï∂ïÏÇ∞Î¨ºÏúÑÏÉùÍ¥ÄÎ¶¨Î≤ï'],
                'agencies': ['ÏãùÏïΩÏ≤ò', 'ÎÜçÎ¶ºÏ∂ïÏÇ∞ÏãùÌíàÎ∂Ä'],
                'ethical_issues': ['ÏãùÌíà ÏïàÏ†Ñ']
            }
        }
        
        # Î¨ºÎ¶¨Ï†Å Ï†úÏïΩ DB
        self.physical_constraints = {
            'time': {
                'day': 24,  # ÏãúÍ∞Ñ
                'year': 365,  # Ïùº
                'work_hours': 8,  # Í∑ºÎ¨¥ ÏãúÍ∞Ñ
                'sleep': 7,  # ÏàòÎ©¥
                'human_lifespan': 80  # ÌèâÍ∑† ÏàòÎ™Ö
            },
            'space': {
                'korea_area_km2': 100_000,  # ÌïúÍµ≠ Î©¥Ï†Å
                'korea_population': 52_000_000,  # Ïù∏Íµ¨
                'seoul_population': 10_000_000
            },
            'capacity': {
                'meal_time_min': 20,  # ÏãùÏÇ¨ ÏãúÍ∞Ñ
                'attention_span_min': 45,  # ÏßëÏ§ë ÏãúÍ∞Ñ
                'commute_max_min': 120  # Ï∂úÌá¥Í∑º ÏãúÍ∞Ñ
            }
        }
    
    def check(self, definition: Dict) -> Dict[str, Any]:
        """
        Î≤ï/Ïú§Î¶¨/Î¨ºÎ¶¨ Ï†úÏïΩ ÌôïÏù∏
        
        Returns:
            {
                'regulatory': {...},
                'physical': {...},
                'ethical': {...},
                'bounds': {lower, upper},
                'warnings': [...]
            }
        """
        
        self.logger.info(f"\n[s3 Laws/Ethics/Physics] Ï†úÏïΩ ÌôïÏù∏")
        
        domain = definition.get('domain', 'general')
        question = definition.get('question', '')
        
        self.logger.info(f"  Domain: {domain}")
        
        constraints = {
            'regulatory': {},
            'physical': {},
            'ethical': [],
            'bounds': {'lower': 0, 'upper': float('inf')},
            'warnings': []
        }
        
        # ===== 1. Í∑úÏ†ú Ï†úÏïΩ =====
        if domain in self.regulatory_db:
            reg_info = self.regulatory_db[domain]
            
            constraints['regulatory'] = {
                'laws': reg_info['laws'],
                'agencies': reg_info.get('agencies', []),
                'approval_time': reg_info.get('approval_time', 'Unknown'),
                'impact': 'high'
            }
            
            constraints['ethical'] = reg_info.get('ethical_issues', [])
            
            self.logger.info(f"  ‚ö†Ô∏è Í∑úÏ†ú ÏÇ∞ÏóÖ Í∞êÏßÄ!")
            self.logger.info(f"     Î≤ïÍ∑ú: {', '.join(reg_info['laws'][:2])}")
            self.logger.info(f"     ÏäπÏù∏ Í∏∞Í∞Ñ: {reg_info.get('approval_time', 'N/A')}")
            
            constraints['warnings'].append(
                f"Í∑úÏ†ú ÏÇ∞ÏóÖ ({domain}): {', '.join(reg_info['laws'][:2])} Ï§ÄÏàò ÌïÑÏöî"
            )
        
        # ===== 2. Î¨ºÎ¶¨Ï†Å Ï†úÏïΩ =====
        physical = []
        
        # ÏãúÍ∞Ñ Ï†úÏïΩ
        if 'ÏãúÍ∞Ñ' in question or 'Í∏∞Í∞Ñ' in question:
            physical.append({
                'type': 'time',
                'constraint': 'ÌïòÎ£® 24ÏãúÍ∞Ñ',
                'max_value': self.physical_constraints['time']['day']
            })
        
        # Ïù∏Íµ¨ Ï†úÏïΩ
        if 'ÌïúÍµ≠' in question or 'KR' in definition.get('geography', ''):
            physical.append({
                'type': 'population',
                'constraint': 'ÌïúÍµ≠ Ïù∏Íµ¨ 5,200Îßå',
                'max_value': self.physical_constraints['space']['korea_population']
            })
        
        # Ï±ÑÌÉùÎ•† Ï†úÏïΩ
        if 'Ï±ÑÌÉù' in question or 'Î≥¥Í∏â' in question or 'Ï†ÑÌôò' in question:
            physical.append({
                'type': 'adoption',
                'constraint': 'ÏµúÎåÄ 100%',
                'max_value': 1.0
            })
        
        constraints['physical'] = physical
        
        if physical:
            self.logger.info(f"  üìè Î¨ºÎ¶¨ Ï†úÏïΩ: {len(physical)}Í∞ú")
            for p in physical:
                self.logger.info(f"     - {p['type']}: {p['constraint']}")
        
        # ===== 3. Bounds Í≥ÑÏÇ∞ =====
        # Ï±ÑÌÉùÎ•† 0-100%
        if 'adoption' in [p['type'] for p in physical]:
            constraints['bounds'] = {'lower': 0, 'upper': 1.0}
        
        # Ïù∏Íµ¨ Ï†úÏïΩ
        if 'population' in [p['type'] for p in physical]:
            pop_constraint = next(p for p in physical if p['type'] == 'population')
            if 'upper' not in constraints['bounds'] or constraints['bounds']['upper'] == float('inf'):
                constraints['bounds']['upper'] = pop_constraint['max_value']
        
        return constraints


class Signal5_StatPatterns(BaseSignal):
    """s5: Statistical Patterns (0.75)"""
    
    def __init__(self, weight=0.75):
        super().__init__(weight)
        
        # ÌÜµÍ≥Ñ Ìå®ÌÑ¥ DB
        self.patterns = {
            'power_law': {
                'name': 'Pareto 80-20 Î≤ïÏπô',
                'formula': 'ÏÉÅÏúÑ 20%Í∞Ä 80% Ï∞®ÏßÄ',
                'applications': ['Îß§Ï∂ú ÏßëÏ§ëÎèÑ', 'Í≥†Í∞ù Î∂ÑÌè¨', 'ÏãúÏû• Ï†êÏú†Ïú®']
            },
            's_curve': {
                'name': 'Í∏∞Ïà† Ï±ÑÌÉù S-Curve',
                'stages': {
                    'innovators': 0.025,      # 2.5%
                    'early_adopters': 0.135,   # 13.5%
                    'early_majority': 0.34,    # 34%
                    'late_majority': 0.34,     # 34%
                    'laggards': 0.16           # 16%
                },
                'chasm': 0.16,  # Innovators + Early Adopters
                'applications': ['Ïã†Ï†úÌíà Î≥¥Í∏â', 'Í∏∞Ïà† Ïπ®Ìà¨Ïú®']
            },
            'elasticity': {
                'price_elasticity': {
                    'luxury': -1.5,      # Í∞ÄÍ≤© 10% ‚Üë ‚Üí ÏàòÏöî 15% ‚Üì
                    'normal': -1.0,
                    'necessity': -0.5    # ÎπÑÌÉÑÎ†•Ï†Å
                },
                'income_elasticity': {
                    'luxury': 1.5,       # ÏÜåÎìù 10% ‚Üë ‚Üí ÏàòÏöî 15% ‚Üë
                    'normal': 1.0,
                    'necessity': 0.5
                }
            },
            'regression_to_mean': {
                'rule': 'Í∑πÎã®Í∞íÏùÄ ÌèâÍ∑†ÏúºÎ°ú ÌöåÍ∑Ä',
                'applications': ['ÏÑ±Ïû•Î•† Ï†ïÏÉÅÌôî', 'Ïù¥ÏÉÅÏπò Î≥¥Ï†ï']
            }
        }
    
    def process(self, definition: Dict, context: Dict) -> SignalResult:
        """
        ÌÜµÍ≥Ñ Ìå®ÌÑ¥ Ï†ÅÏö© (80-20, S-Curve, Elasticity)
        
        Args:
            definition: KPI Ï†ïÏùò
            context: {
                'domain': str,
                'query': str
            }
        
        Returns:
            SignalResult with pattern-based estimate
        """
        
        self.logger.info(f"\n[s5 Stat Patterns] ÌÜµÍ≥Ñ Ìå®ÌÑ¥ Ï†ÅÏö©")
        
        query = context.get('query', '')
        domain = context.get('domain', 'general')
        
        evidence = []
        estimate = None
        
        # ===== 1. S-Curve Ìå®ÌÑ¥ (Ï±ÑÌÉùÎ•†) =====
        if 'Ï±ÑÌÉù' in query or 'Î≥¥Í∏â' in query or 'Ïπ®Ìà¨' in query:
            s_curve = self.patterns['s_curve']
            
            # Ïã†Í∑ú ÏãúÏû• ‚Üí Innovators + Early Adopters (16%)
            if context.get('new_market', False):
                estimate = s_curve['chasm']  # 16%
                
                evidence.append({
                    'src_id': 'PAT_SCURVE',
                    'source': 'S-Curve (Rogers Diffusion)',
                    'pattern': s_curve['name'],
                    'value': f'{estimate*100:.1f}% (Chasm Ïù¥Ï†Ñ)',
                    'type': 'statistical_pattern'
                })
                
                self.logger.info(f"  ‚úÖ S-Curve: Ïã†Í∑ú ÏãúÏû• ‚Üí {estimate*100:.1f}% (Innovators + Early Adopters)")
        
        # ===== 2. Pareto 80-20 =====
        if 'ÏßëÏ§ë' in query or 'ÏÉÅÏúÑ' in query:
            pareto = self.patterns['power_law']
            
            evidence.append({
                'src_id': 'PAT_PARETO',
                'source': 'Pareto 80-20 Î≤ïÏπô',
                'pattern': pareto['name'],
                'rule': pareto['formula'],
                'type': 'statistical_pattern'
            })
            
            self.logger.info(f"  ‚úÖ Pareto: ÏÉÅÏúÑ 20% ‚Üí 80% Í∏∞Ïó¨")
        
        # ===== 3. Elasticity =====
        if 'Í∞ÄÍ≤©' in query or 'price' in query.lower():
            elasticity = self.patterns['elasticity']['price_elasticity']
            
            # Ï†úÌíà Ïú†Ìòï Ï∂îÏ†ï
            product_type = 'normal'
            if domain in ['healthcare', 'education']:
                product_type = 'necessity'
            elif domain in ['luxury', 'premium']:
                product_type = 'luxury'
            
            el_value = elasticity[product_type]
            
            evidence.append({
                'src_id': 'PAT_ELASTICITY',
                'source': 'Price Elasticity',
                'pattern': f'{product_type.capitalize()} Ï†úÌíà',
                'value': f'ÌÉÑÎ†•ÏÑ± {el_value}',
                'type': 'statistical_pattern'
            })
            
            self.logger.info(f"  ‚úÖ Elasticity: {product_type} ‚Üí {el_value}")
        
        return SignalResult(
            signal_name='s5_stat_patterns',
            weight=self.weight,
            value=estimate,
            confidence=0.75,
            evidence=evidence,
            umis_mapping='Guestimation Ï∂úÏ≤ò 6 (ÌÜµÍ≥Ñ Ìå®ÌÑ¥)'
        )


class Signal6_MathRelations(BaseSignal):
    """s6: Math Relations (1.0) - ÏµúÏö∞ÏÑ†!"""
    
    def __init__(self, weight=1.0):
        super().__init__(weight)
        
        # Îã®ÏúÑ ÏãúÏä§ÌÖú Ï†ïÏùò
        self.unit_system = {
            # Í∏∞Î≥∏ Îã®ÏúÑ
            'number': {'dimension': 'scalar', 'si_unit': '1'},
            'KRW': {'dimension': 'currency', 'si_unit': 'KRW'},
            'USD': {'dimension': 'currency', 'si_unit': 'USD'},
            '%': {'dimension': 'ratio', 'si_unit': '1'},
            'person': {'dimension': 'count', 'si_unit': 'person'},
            'time': {'dimension': 'time', 'si_unit': 'second'},
            
            # ÌååÏÉù Îã®ÏúÑ
            'KRW/person': {'dimension': 'currency/count', 'components': ['KRW', 'person']},
            'person/year': {'dimension': 'count/time', 'components': ['person', 'year']},
        }
        
        # Î≥¥Ï°¥ Î≤ïÏπô
        self.conservation_laws = {
            'sum': 'whole = sum(parts)',
            'market_hierarchy': 'TAM >= SAM >= SOM',
            'budget': 'income = expenditure + savings',
            'proportion': '0 <= percentage <= 100'
        }
    
    def verify_dimensional_consistency(
        self,
        formula: Dict
    ) -> Dict:
        """
        Ï∞®Ïõê Î∂ÑÏÑù (Îã®ÏúÑ ÏùºÍ¥ÄÏÑ± Í≤ÄÏ¶ù)
        
        Args:
            formula: {
                'numerator': str,
                'numerator_unit': str,
                'denominator': str,
                'denominator_unit': str,
                'result_unit': str
            }
        
        Returns:
            {
                'consistent': bool,
                'errors': [...],
                'warnings': [...]
            }
        """
        
        self.logger.info(f"\n[s6 Math Relations] Ï∞®Ïõê Î∂ÑÏÑù")
        
        num_unit = formula.get('numerator_unit', '')
        den_unit = formula.get('denominator_unit', '')
        result_unit = formula.get('result_unit', '')
        
        self.logger.info(f"  Î∂ÑÏûê: {formula.get('numerator', 'N/A')} ({num_unit})")
        self.logger.info(f"  Î∂ÑÎ™®: {formula.get('denominator', 'N/A')} ({den_unit})")
        self.logger.info(f"  Í≤∞Í≥º: {result_unit}")
        
        verification = {
            'consistent': True,
            'errors': [],
            'warnings': []
        }
        
        # ===== 1. Îã®ÏúÑ ÏùºÏπò Í≤ÄÏ¶ù =====
        
        # % Í≥ÑÏÇ∞: Î∂ÑÏûê/Î∂ÑÎ™® Îã®ÏúÑ ÏùºÏπò
        if result_unit == '%':
            if num_unit != den_unit and num_unit != '' and den_unit != '':
                verification['errors'].append(
                    f"ÎπÑÏú® Í≥ÑÏÇ∞ Ïò§Î•ò: Î∂ÑÏûê({num_unit})ÏôÄ Î∂ÑÎ™®({den_unit}) Îã®ÏúÑ Î∂àÏùºÏπò"
                )
                verification['consistent'] = False
                self.logger.error(f"  ‚ùå Îã®ÏúÑ Î∂àÏùºÏπò: {num_unit} / {den_unit}")
            else:
                self.logger.info(f"  ‚úÖ ÎπÑÏú® Í≥ÑÏÇ∞ Ï†ïÏÉÅ")
        
        # Í∏àÏï° Í≥ÑÏÇ∞: KRW √ó number = KRW
        if result_unit == 'KRW':
            if 'KRW' not in num_unit and num_unit != '':
                verification['warnings'].append(
                    f"Í∏àÏï° Í≥ÑÏÇ∞ Ï£ºÏùò: Î∂ÑÏûê Îã®ÏúÑ '{num_unit}'Í∞Ä KRW ÏïÑÎãò"
                )
        
        # ===== 2. Î≥¥Ï°¥ Î≤ïÏπô Í≤ÄÏ¶ù =====
        
        # TAM >= SAM >= SOM
        if 'TAM' in formula.get('numerator', '') or 'SAM' in formula.get('numerator', ''):
            self.logger.info(f"  üìê ÏãúÏû• Í≥ÑÏ∏µ Íµ¨Ï°∞ ÌôïÏù∏")
            # Ïã§Ï†ú Í∞í ÎπÑÍµêÎäî Î≥ÑÎèÑ Î©îÏÑúÎìúÏóêÏÑú
        
        # ===== 3. ÎπÑÎ°Ä Í¥ÄÍ≥Ñ ÌôïÏù∏ =====
        
        # A / B: BÍ∞Ä Ï¶ùÍ∞ÄÌïòÎ©¥ A/B Í∞êÏÜå
        self.logger.info(f"  üìä ÎπÑÎ°Ä Í¥ÄÍ≥Ñ Ï†ïÏÉÅ")
        
        if verification['errors']:
            self.logger.error(f"  ‚ùå Ï∞®Ïõê Ïò§Î•ò {len(verification['errors'])}Í∞ú Î∞úÍ≤¨")
        else:
            self.logger.info(f"  ‚úÖ Ï∞®Ïõê ÏùºÍ¥ÄÏÑ± Í≤ÄÏ¶ù ÌÜµÍ≥º")
        
        return verification
    
    def check_conservation_laws(
        self,
        values: Dict
    ) -> Dict:
        """
        Î≥¥Ï°¥ Î≤ïÏπô Í≤ÄÏ¶ù
        
        Args:
            values: {'TAM': float, 'SAM': float, 'SOM': float}
        
        Returns:
            {'passed': bool, 'violations': [...]}
        """
        
        violations = []
        
        # TAM >= SAM >= SOM
        if 'TAM' in values and 'SAM' in values:
            if values['TAM'] < values['SAM']:
                violations.append(f"TAM ({values['TAM']}) < SAM ({values['SAM']})")
        
        if 'SAM' in values and 'SOM' in values:
            if values['SAM'] < values['SOM']:
                violations.append(f"SAM ({values['SAM']}) < SOM ({values['SOM']})")
        
        # Ï†ÑÏ≤¥ = Î∂ÄÎ∂ÑÏùò Ìï©
        if 'whole' in values and 'parts' in values:
            parts_sum = sum(values['parts'])
            if abs(values['whole'] - parts_sum) / values['whole'] > 0.01:  # 1% ÌóàÏö© Ïò§Ï∞®
                violations.append(f"Ï†ÑÏ≤¥({values['whole']}) ‚â† Ìï©({parts_sum})")
        
        return {
            'passed': len(violations) == 0,
            'violations': violations
        }


class Signal7_RulesOfThumb(BaseSignal):
    """s7: Rules of Thumb (0.7)"""
    
    def __init__(self, weight=0.7):
        super().__init__(weight)
        
        # UMIS RAG Î°úÎìú (QuantifierÏùò market_benchmarks)
        try:
            from umis_rag.agents.quantifier import QuantifierRAG
            
            self.quantifier_rag = QuantifierRAG()
            self.logger.info("  ‚úÖ Quantifier RAG Ï¥àÍ∏∞Ìôî (Rule of Thumb)")
        except Exception as e:
            self.logger.warning(f"  ‚ö†Ô∏è Quantifier RAG Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            self.quantifier_rag = None
        
        # ÌïòÎìúÏΩîÎî©Îêú Rule of Thumb (Fallback)
        self.rules = {
            'platform': {
                'commission_rate': {
                    'rule': 'ÌîåÎû´Ìèº ÏàòÏàòÎ£å = ÎåÄÏ≤¥ Ï§ëÍ∞ú ÎπÑÏö© √ó 0.4-0.5',
                    'typical_range': '3-20%',
                    'examples': 'Î∞∞ÎØº 6-12%, Ïö∞Î≤Ñ 25%'
                },
                'take_rate': {
                    'rule': 'Take Rate = GMVÏùò 10-30%',
                    'typical_range': '10-30%'
                }
            },
            'subscription': {
                'ltv_cac': {
                    'rule': 'LTV/CAC > 3 (acceptable), > 5 (good)',
                    'threshold': 3.0
                },
                'churn_rate': {
                    'rule': 'B2C SaaS: 5-7% (ÏõîÍ∞Ñ)',
                    'b2c_saas': '5-7%',
                    'b2b_saas': '2-3%',
                    'consumer': '3-5%'
                },
                'payback_period': {
                    'rule': 'Payback < 12Í∞úÏõî',
                    'target': 12
                }
            },
            'saas': {
                'rule_of_40': {
                    'rule': 'Growth Rate(%) + Profit Margin(%) >= 40',
                    'threshold': 40
                },
                'magic_number': {
                    'rule': '(Ïã†Í∑ú ARR) / (S&M ÎπÑÏö©) > 0.75',
                    'good': 1.0
                }
            },
            'ecommerce': {
                'conversion_rate': {
                    'rule': 'PC: 2-3%, Mobile: 1-2%',
                    'korea': '3-4% (Î™®Î∞îÏùº ÎÜíÏùå)'
                },
                'cart_abandonment': {
                    'rule': '70-80%',
                    'typical': 0.75
                }
            }
        }
    
    def process(self, definition: Dict, context: Dict) -> SignalResult:
        """
        ÏÇ∞ÏóÖÎ≥Ñ Rule of Thumb Ï†ÅÏö©
        
        Args:
            definition: KPI Ï†ïÏùò
            context: {
                'domain': str,
                'query': str
            }
        
        Returns:
            SignalResult with rule-based estimate
        """
        
        self.logger.info(f"\n[s7 Rules of Thumb] ÏÇ∞ÏóÖ Í≥µÏãù Ï†ÅÏö©")
        
        domain = context.get('domain', 'general')
        query = context.get('query', '')
        
        self.logger.info(f"  Domain: {domain}")
        
        evidence = []
        values = []
        
        # ===== 1. ÌïòÎìúÏΩîÎî©Îêú Rule Í≤ÄÏÉâ =====
        if domain in self.rules:
            domain_rules = self.rules[domain]
            
            self.logger.info(f"  ‚úÖ {domain.capitalize()} Rules: {len(domain_rules)}Í∞ú Î∞úÍ≤¨")
            
            for rule_name, rule_info in domain_rules.items():
                evidence.append({
                    'src_id': f"RULE_{rule_name.upper()}",
                    'source': f"UMIS Rule of Thumb ({domain})",
                    'rule': rule_info.get('rule', ''),
                    'type': 'industry_rule'
                })
                
                self.logger.info(f"    - {rule_name}: {rule_info.get('rule', '')}")
                
                # Í∞í Ï∂îÏ∂ú ÏãúÎèÑ
                if 'typical_range' in rule_info:
                    range_val = rule_info['typical_range']
                    if '-' in str(range_val) and '%' in str(range_val):
                        # "6-12%" ‚Üí Ï§ëÍ∞ÑÍ∞í 9%
                        parts = str(range_val).replace('%', '').split('-')
                        if len(parts) == 2:
                            try:
                                val = (float(parts[0]) + float(parts[1])) / 2 / 100
                                values.append(val)
                            except:
                                pass
        
        # ===== 2. UMIS RAG Rule of Thumb Í≤ÄÏÉâ =====
        if self.quantifier_rag:
            try:
                benchmarks = self.quantifier_rag.search_benchmark(query, top_k=3)
                
                if benchmarks:
                    self.logger.info(f"  ‚úÖ UMIS Benchmarks: {len(benchmarks)}Í∞ú")
                    
                    for doc, score in benchmarks:
                        evidence.append({
                            'src_id': f"BM_{doc.metadata.get('benchmark_id', 'UNK')}",
                            'source': 'UMIS Market Benchmarks',
                            'content': doc.page_content[:200],
                            'similarity': score,
                            'type': 'rag_benchmark'
                        })
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è RAG Í≤ÄÏÉâ Ïã§Ìå®: {e}")
        
        # ===== 3. Í∞í Í≥ÑÏÇ∞ =====
        estimate = None
        if values:
            import statistics
            estimate = statistics.mean(values)
            self.logger.info(f"\n  üìä Rule Í∏∞Î∞ò Ï∂îÏ†ï: {estimate}")
        
        return SignalResult(
            signal_name='s7_rules_of_thumb',
            weight=self.weight,
            value=estimate,
            confidence=0.7,
            evidence=evidence,
            umis_mapping='Guestimation Ï∂úÏ≤ò 7 (Rule of Thumb) + UMIS RAG'
        )


class Signal8_TimeSpaceBounds(BaseSignal):
    """s8: Time/Space Bounds (1.0) - ÏµúÏö∞ÏÑ†!"""
    
    def __init__(self, weight=1.0):
        super().__init__(weight)
        
        # ÏãúÍ∞Ñ Ï†úÏïΩ DB
        self.time_constraints = {
            'product_development': {
                'software': '3-12Í∞úÏõî',
                'hardware': '12-36Í∞úÏõî',
                'medical_device': '24-60Í∞úÏõî',
                'pharma': '60-120Í∞úÏõî'
            },
            'certification': {
                'medical_device': '6-24Í∞úÏõî',
                'food': '3-6Í∞úÏõî',
                'software': '1-3Í∞úÏõî'
            },
            'market_adoption': {
                'b2c': '1-3ÎÖÑ (10% Ïπ®Ìà¨)',
                'b2b': '2-5ÎÖÑ',
                'regulated': '3-7ÎÖÑ'
            }
        }
        
        # Í≥µÍ∞Ñ Ï†úÏïΩ DB
        self.space_constraints = {
            'korea': {
                'population': 52_000_000,
                'area_km2': 100_000,
                'households': 22_000_000,
                'urban_rate': 0.92
            },
            'seoul': {
                'population': 10_000_000,
                'area_km2': 605,
                'density': 16_500  # per km2
            }
        }
        
        # Ïö©Îüâ Ï†úÏïΩ
        self.capacity_limits = {
            'human': {
                'work_hours_day': 8,
                'work_days_year': 250,
                'meals_day': 3,
                'sleep_hours': 7
            },
            'business': {
                'store_capacity_customers': 50,  # ÌèâÍ∑† Îß§Ïû• ÏàòÏö©
                'delivery_radius_km': 5,  # Î∞∞Îã¨ Î∞òÍ≤Ω
                'service_capacity_per_person': 10  # 1Ïù∏Îãπ ÏÑúÎπÑÏä§ Í≥†Í∞ù Ïàò
            }
        }
    
    def calculate_bounds(
        self,
        definition: Dict
    ) -> Dict:
        """
        ÏãúÍ≥µÍ∞Ñ Ï†úÏïΩ Í∏∞Î∞ò ÏÉÅÌïú/ÌïòÌïú Í≥ÑÏÇ∞
        
        Args:
            definition: {
                'question': str,
                'domain': str,
                'geography': str,
                'time_horizon': str
            }
        
        Returns:
            {
                'time_bounds': {...},
                'space_bounds': {...},
                'capacity_limits': {...},
                'realistic_maximum': float
            }
        """
        
        self.logger.info(f"\n[s8 Time/Space Bounds] ÏãúÍ≥µÍ∞Ñ Ï†úÏïΩ")
        
        domain = definition.get('domain', 'general')
        geography = definition.get('geography', 'KR')
        time_horizon = definition.get('time_horizon', '2025-2030')
        question = definition.get('question', '')
        
        self.logger.info(f"  Domain: {domain}")
        self.logger.info(f"  Geography: {geography}")
        self.logger.info(f"  Time Horizon: {time_horizon}")
        
        bounds = {
            'time_bounds': {},
            'space_bounds': {},
            'capacity_limits': {},
            'realistic_maximum': None
        }
        
        # ===== 1. ÏãúÍ∞Ñ Ï†úÏïΩ =====
        
        # Ï†úÌíà Í∞úÎ∞ú ÏãúÍ∞Ñ
        if domain in ['healthcare', 'medical']:
            bounds['time_bounds']['development'] = self.time_constraints['product_development']['medical_device']
            bounds['time_bounds']['certification'] = self.time_constraints['certification']['medical_device']
            
            self.logger.info(f"  ‚è±Ô∏è  Í∞úÎ∞ú Í∏∞Í∞Ñ: {bounds['time_bounds']['development']}")
            self.logger.info(f"  üìã Ïù∏Ï¶ù Í∏∞Í∞Ñ: {bounds['time_bounds']['certification']}")
        
        # ÏãúÏû• ÎèÑÏûÖ ÏãúÍ∞Ñ
        market_type = 'regulated' if domain in ['healthcare', 'finance'] else 'b2c'
        bounds['time_bounds']['market_adoption'] = self.time_constraints['market_adoption'].get(market_type, '2-5ÎÖÑ')
        
        # ===== 2. Í≥µÍ∞Ñ Ï†úÏïΩ =====
        
        if geography == 'KR':
            korea = self.space_constraints['korea']
            
            bounds['space_bounds'] = {
                'max_population': korea['population'],
                'max_households': korea['households'],
                'urban_population': int(korea['population'] * korea['urban_rate'])
            }
            
            self.logger.info(f"  üåç ÏßÄÎ¶¨ Ï†úÏïΩ:")
            self.logger.info(f"     Ïù∏Íµ¨: {korea['population']:,}Î™Ö")
            self.logger.info(f"     Í∞ÄÍµ¨: {korea['households']:,}Í∞ÄÍµ¨")
        
        # ===== 3. Ïö©Îüâ Ï†úÏïΩ =====
        
        # Ïù∏Í∞Ñ ÌñâÎèô Ï†úÏïΩ
        if 'ÏÇ¨Ïö©' in question or 'ÏÜåÎπÑ' in question:
            bounds['capacity_limits']['human'] = self.capacity_limits['human']
        
        # ÏÇ¨ÏóÖ Ïö©Îüâ
        if 'Î∞∞Îã¨' in question or 'ÏÑúÎπÑÏä§' in question:
            bounds['capacity_limits']['business'] = self.capacity_limits['business']
        
        # ===== 4. ÌòÑÏã§Ï†Å ÏµúÎåÄÍ∞í Í≥ÑÏÇ∞ =====
        
        # Ïòà: ÏãúÏû• Í∑úÎ™® = Ïù∏Íµ¨ √ó Ï±ÑÌÉùÎ•†ÏÉÅÌïú √ó Îã®Í∞Ä
        if bounds['space_bounds'].get('max_population'):
            max_pop = bounds['space_bounds']['max_population']
            
            # ÎèÑÎ©îÏù∏Î≥Ñ ÌòÑÏã§Ï†Å Ï±ÑÌÉùÎ•† ÏÉÅÌïú
            adoption_ceiling = {
                'healthcare': 0.20,  # 20% (ÌòÅÏã† Ï†úÌíà)
                'finance': 0.30,
                'education': 0.40,
                'streaming': 0.60,
                'platform': 0.70
            }.get(domain, 0.30)
            
            # ÏòàÏãú Í≥ÑÏÇ∞ (Í∞ÑÎã® Î≤ÑÏ†Ñ)
            bounds['realistic_maximum'] = max_pop * adoption_ceiling
            
            self.logger.info(f"\n  üìä ÌòÑÏã§Ï†Å ÏÉÅÌïú:")
            self.logger.info(f"     Ïù∏Íµ¨ √ó Ï±ÑÌÉùÎ•†ÏÉÅÌïú = {max_pop:,} √ó {adoption_ceiling:.0%}")
            self.logger.info(f"     = {bounds['realistic_maximum']:,.0f}Î™Ö")
        
        return bounds


class Signal4_BehavioralEcon(BaseSignal):
    """s4: Behavioral Economics (0.6)"""
    
    def __init__(self, weight=0.6):
        super().__init__(weight)
        self.biases = {
            'loss_aversion': 2.5,
            'status_quo_bias': 0.5,
            'anchoring': (0.7, 1.3),
            'hyperbolic_discounting': 0.5
        }
    
    def adjust_should_vs_will(self, fused_result: Dict) -> Dict[str, Any]:
        """
        Should (Í∑úÎ≤î) vs Will (ÌòÑÏã§) Î∂ÑÎ¶¨
        
        Args:
            fused_result: {
                'value': float (ÏúµÌï©Îêú Ï∂îÏ†ïÍ∞í),
                'range': tuple (ÌïòÌïú, ÏÉÅÌïú),
                'context': dict (ÏãúÏû• Îß•ÎùΩ)
            }
        
        Returns:
            {
                'should': {...},  # Í∑úÎ≤îÏ†Å Í≤∞Î°†
                'will': {...},    # ÌòÑÏã§Ï†Å ÏòàÏ∏°
                'gap': {...}      # Ï∞®Ïù¥ Î∂ÑÏÑù
            }
        """
        
        value = fused_result.get('value', 0)
        context = fused_result.get('context', {})
        
        self.logger.info(f"  ÌñâÎèôÍ≤ΩÏ†úÌïô Î≥¥Ï†ï ÏãúÏûë (Í∏∞Ï§ÄÍ∞í: {value:,.0f})")
        
        # ===== Should: Ìé∏Ìñ• ÏóÜÎäî Ïù¥ÏÉÅÏ†Å Í∞í =====
        
        should = {
            'value': value,
            'rationale': 'Ïù¥ÏÉÅÏ†Å/Í∑úÎ≤îÏ†Å Í≤∞Î°† (Ìé∏Ìñ• Ï†úÍ±∞)',
            'assumptions': [
                'Ìï©Î¶¨Ï†Å ÏùòÏÇ¨Í≤∞Ï†ï',
                'ÏôÑÏ†Ñ Ï†ïÎ≥¥',
                'ÏãúÍ∞Ñ ÏùºÍ¥ÄÏÑ± (ÌòÑÏû¨=ÎØ∏Îûò)'
            ],
            'use_case': 'Ï†ïÏ±Ö Í∂åÍ≥†, Î™©Ìëú ÏÑ§Ï†ï, Ïû†Ïû¨ ÏãúÏû•'
        }
        
        self.logger.info(f"  Should: {should['value']:,.0f} (Ïù¥ÏÉÅÏ†Å)")
        
        # ===== Will: ÌòÑÏã§Ï†Å ÏòàÏ∏° (Ìé∏Ìñ• Î∞òÏòÅ) =====
        
        will_value = value
        adjustments = []
        
        # 1. Í∞ÄÍ≤© Ïù∏ÏÉÅ/Î≥ÄÍ≤Ω ‚Üí ÏÜêÏã§ÌöåÌîº
        if context.get('price_change', False):
            factor = 0.4  # 60% Ï†ÄÌï≠
            will_value *= factor
            adjustments.append({
                'bias': 'loss_aversion',
                'factor': factor,
                'reason': 'Í∞ÄÍ≤© Ïù∏ÏÉÅ Ï†ÄÌï≠ (ÏÜêÏã§ = Ïù¥Îìù √ó 2.5)',
                'impact': f'{(1-factor)*100:.0f}% Í∞êÏÜå'
            })
            self.logger.info(f"    - ÏÜêÏã§ÌöåÌîº: √ó{factor} (Í∞ÄÍ≤© Ïù∏ÏÉÅ Ï†ÄÌï≠)")
        
        # 2. ÌòÑÏÉÅ Ïú†ÏßÄ vs Ï†ÑÌôò ‚Üí ÌòÑÏÉÅÏú†ÏßÄ Ìé∏Ìñ•
        if context.get('requires_switch', False):
            factor = 0.5  # 50% Ï†ÑÌôòÏú®
            will_value *= factor
            adjustments.append({
                'bias': 'status_quo_bias',
                'factor': factor,
                'reason': 'Ï†ÑÌôò Ï†ÄÌï≠ (ÌòÑÏÉÅ Ïú†ÏßÄ ÏÑ†Ìò∏)',
                'impact': f'{(1-factor)*100:.0f}% Í∞êÏÜå'
            })
            self.logger.info(f"    - ÌòÑÏÉÅÏú†ÏßÄ Ìé∏Ìñ•: √ó{factor} (Ï†ÑÌôò Ï†ÄÌï≠)")
        
        # 3. ÏãúÏû• ÏßÄÎ∞∞Î†• ‚Üí Í∞ÄÍ≤© Í≤∞Ï†ïÎ†•
        market_power = context.get('market_power', 0)  # 0-1
        if market_power > 0.7:
            factor = 1 + (market_power * 0.3)  # ÏµúÎåÄ 1.3Î∞∞
            will_value *= factor
            adjustments.append({
                'bias': 'market_power',
                'factor': factor,
                'reason': f'ÎèÖÍ≥ºÏ†ê ÏãúÏû• (ÏßÄÎ∞∞Î†• {market_power*100:.0f}%)',
                'impact': f'{(factor-1)*100:.0f}% Ï¶ùÍ∞Ä'
            })
            self.logger.info(f"    - ÏãúÏû• ÏßÄÎ∞∞Î†•: √ó{factor} (ÎèÖÍ≥ºÏ†ê)")
        
        # 4. Í∏∞Ïà† Í±∞Î∂ÄÍ∞ê (ÎÖ∏Ïù∏, Î≥¥Ïàò ÏÇ∞ÏóÖ)
        if context.get('tech_resistance', False):
            factor = 0.3  # 70% Í±∞Î∂Ä
            will_value *= factor
            adjustments.append({
                'bias': 'tech_resistance',
                'factor': factor,
                'reason': 'Í∏∞Ïà† Í±∞Î∂ÄÍ∞ê (ÎÖ∏Ïù∏Ï∏µ, Î≥¥Ïàò ÏÇ∞ÏóÖ)',
                'impact': f'{(1-factor)*100:.0f}% Í∞êÏÜå'
            })
            self.logger.info(f"    - Í∏∞Ïà† Í±∞Î∂ÄÍ∞ê: √ó{factor} (Ï±ÑÌÉù Ïû•Î≤Ω)")
        
        # 5. Í∞ÄÍ≤© Î∂ÄÎã¥ (Í≥†Í∞Ä Ï†úÌíà)
        if context.get('high_price', False):
            factor = 0.6  # 40% Íµ¨Îß§ Ï£ºÏ†Ä
            will_value *= factor
            adjustments.append({
                'bias': 'price_burden',
                'factor': factor,
                'reason': 'Í∞ÄÍ≤© Î∂ÄÎã¥ (Í≥†Í∞Ä Ï†úÌíà)',
                'impact': f'{(1-factor)*100:.0f}% Í∞êÏÜå'
            })
            self.logger.info(f"    - Í∞ÄÍ≤© Î∂ÄÎã¥: √ó{factor} (Íµ¨Îß§ Ï£ºÏ†Ä)")
        
        will = {
            'value': will_value,
            'rationale': 'ÌòÑÏã§Ï†Å ÏòàÏ∏° (ÌñâÎèôÍ≤ΩÏ†úÌïô Ìé∏Ìñ• Î∞òÏòÅ)',
            'adjustments': adjustments,
            'use_case': 'Ïã§Ï†ú Ï±ÑÌÉùÎ•†, Îß§Ï∂ú ÏòàÏ∏°, ÌòÑÏã§ Ï†ÑÎßù'
        }
        
        self.logger.info(f"  Will: {will['value']:,.0f} (ÌòÑÏã§)")
        
        # ===== Gap Î∂ÑÏÑù =====
        
        gap_absolute = should['value'] - will['value']
        gap_relative = gap_absolute / should['value'] if should['value'] > 0 else 0
        
        gap = {
            'absolute': gap_absolute,
            'relative': gap_relative,
            'percentage': gap_relative * 100,
            'main_drivers': [adj['bias'] for adj in adjustments],
            'interpretation': self._interpret_gap(gap_relative)
        }
        
        self.logger.info(f"  Gap: {gap['percentage']:.1f}% ({gap['interpretation']})")
        
        return {
            'should': should,
            'will': will,
            'gap': gap,
            'signal': 's4_behavioral_econ',
            'weight': self.weight
        }

    def _interpret_gap(self, gap_relative: float) -> str:
        """Gap Ìï¥ÏÑù"""
        if gap_relative < 0.1:
            return "ÏûëÏùÄ Ï∞®Ïù¥ (< 10%)"
        elif gap_relative < 0.3:
            return "Ï§ëÍ∞Ñ Ï∞®Ïù¥ (10-30%)"
        elif gap_relative < 0.5:
            return "ÌÅ∞ Ï∞®Ïù¥ (30-50%)"
        else:
            return "Îß§Ïö∞ ÌÅ∞ Ï∞®Ïù¥ (> 50%)"


class Signal10_IndustryKPI(BaseSignal):
    """s10: Industry KPI Library (0.95) - RAG Ï§ëÏã¨!"""
    
    def __init__(self, weight=0.95):
        super().__init__(weight)
        
        # Rachel (Validator) RAG Ï¥àÍ∏∞Ìôî
        try:
            from umis_rag.agents.validator import ValidatorRAG
            
            self.validator_rag = ValidatorRAG()
            self.logger.info("  ‚úÖ Validator RAG Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
        except Exception as e:
            self.logger.warning(f"  ‚ö†Ô∏è Validator RAG Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            self.validator_rag = None
    
    def clarify_definition(
        self,
        question: str,
        domain: str
    ) -> Dict:
        """
        KPI Ï†ïÏùò Î™ÖÌôïÌôî (Step 1: Ï†ïÏùò Í≥†Ï†ï)
        
        Args:
            question: Ï∂îÏ†ï ÏßàÎ¨∏
            domain: ÏÇ∞ÏóÖ/ÏòÅÏó≠
        
        Returns:
            {
                'kpi_id': str,
                'metric_name': str,
                'standard_definition': {...},
                'status': str,
                'comparability_score': float
            }
        """
        
        self.logger.info(f"\n[s10 Industry KPI] Ï†ïÏùò Î™ÖÌôïÌôî")
        self.logger.info(f"  Question: {question}")
        self.logger.info(f"  Domain: {domain}")
        
        # ÏßàÎ¨∏ÏóêÏÑú Î©îÌä∏Î¶≠ Ï∂îÏ∂ú (Í∞ÑÎã® ÌååÏã±)
        metric_name = self._extract_metric_from_question(question)
        
        self.logger.info(f"  Ï∂îÏ∂úÎêú Î©îÌä∏Î¶≠: {metric_name}")
        
        # RachelÏùò KPI Í≤ÄÏ¶ù ÌôúÏö©
        if self.validator_rag:
            try:
                kpi_result = self.validator_rag.validate_kpi_definition(
                    metric_name=metric_name,
                    provided_definition={}  # ÌëúÏ§Ä Ï†ïÏùò Ï°∞ÌöåÎßå
                )
                
                if kpi_result['status'] in ['match', 'partial_match', 'not_found']:
                    self.logger.info(f"  ‚úÖ KPI Ï†ïÏùò: {kpi_result['status']}")
                    
                    if kpi_result['status'] != 'not_found':
                        self.logger.info(f"  KPI ID: {kpi_result.get('kpi_id', 'N/A')}")
                    
                    return {
                        'kpi_id': kpi_result.get('kpi_id', 'KPI_UNKNOWN'),
                        'metric_name': metric_name,
                        'standard_definition': kpi_result.get('standard_definition', {}),
                        'status': kpi_result['status'],
                        'comparability_score': kpi_result.get('comparability_score', 0),
                        'recommendation': kpi_result.get('recommendation', '')
                    }
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è KPI Í≤ÄÏ¶ù Ïã§Ìå®: {e}")
        
        # Fallback: Í∏∞Î≥∏ Ï†ïÏùò ÏÉùÏÑ±
        return {
            'kpi_id': 'KPI_CUSTOM',
            'metric_name': metric_name,
            'standard_definition': {
                'question': question,
                'domain': domain
            },
            'status': 'custom',
            'comparability_score': 0.5
        }
    
    def _extract_metric_from_question(self, question: str) -> str:
        """ÏßàÎ¨∏ÏóêÏÑú Î©îÌä∏Î¶≠ Ïù¥Î¶Ñ Ï∂îÏ∂ú"""
        
        question_lower = question.lower()
        
        # ÌÇ§ÏõåÎìú Îß§Ïπ≠
        if 'ÏàòÏàòÎ£å' in question or 'commission' in question_lower:
            return 'ÌîåÎû´Ìèº ÏàòÏàòÎ£åÏú®'
        elif 'Ìï¥ÏßÄ' in question or 'churn' in question_lower:
            return 'ÏõîÍ∞Ñ Ìï¥ÏßÄÏú®'
        elif 'ltv' in question_lower or 'ÏÉùÏï† Í∞ÄÏπò' in question:
            return 'LTV'
        elif 'cac' in question_lower or 'ÌöçÎìù ÎπÑÏö©' in question:
            return 'CAC'
        elif 'ÏãúÏû• Í∑úÎ™®' in question or 'market size' in question_lower or 'sam' in question_lower:
            return 'ÏãúÏû• Í∑úÎ™®'
        elif 'Ï†ÑÌôòÏú®' in question or 'conversion' in question_lower:
            return 'Ï†ÑÌôòÏú®'
        elif 'take rate' in question_lower:
            return 'Take Rate'
        elif 'gmv' in question_lower:
            return 'GMV'
        else:
            # Í∏∞Î≥∏Í∞í: ÏßàÎ¨∏ ÏûêÏ≤¥
            return question[:50]


class Signal9_CaseAnalogies(BaseSignal):
    """s9: Case Analogies (0.85) - RAG Ï§ëÏã¨!"""
    
    def __init__(self, weight=0.85):
        super().__init__(weight)
        
        # Explorer RAG Ï¥àÍ∏∞Ìôî (success_case_library)
        try:
            from umis_rag.agents.explorer import ExplorerRAG
            
            self.explorer_rag = ExplorerRAG()
            self.logger.info("  ‚úÖ Explorer RAG Ï¥àÍ∏∞Ìôî (ÏÇ¨Î°Ä Í≤ÄÏÉâ)")
        except Exception as e:
            self.logger.warning(f"  ‚ö†Ô∏è Explorer RAG Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")
            self.explorer_rag = None
    
    def process(
        self,
        definition: Dict,
        context: Dict
    ) -> SignalResult:
        """
        Ïú†ÏÇ¨ ÏÇ¨Î°Ä Ï†ÑÏù¥ Î≥¥Ï†ï
        
        Args:
            definition: KPI Ï†ïÏùò
            context: {
                'domain': str,
                'geography': str,
                'query': str
            }
        
        Returns:
            SignalResult with transferred estimate
        """
        
        query = context.get('query', '')
        domain = context.get('domain', 'general')
        target_geo = context.get('geography', 'KR')
        
        self.logger.info(f"\n[s9 Case Analogies] Ïú†ÏÇ¨ ÏÇ¨Î°Ä Í≤ÄÏÉâ")
        self.logger.info(f"  Query: {query}")
        self.logger.info(f"  Domain: {domain}")
        
        # Explorer RAGÎ°ú ÏÇ¨Î°Ä Í≤ÄÏÉâ
        cases = []
        
        if self.explorer_rag:
            try:
                # Ìå®ÌÑ¥ Í≤ÄÏÉâÏúºÎ°ú ÏÇ¨Î°Ä Ï∞æÍ∏∞
                pattern_results = self.explorer_rag.search_patterns(query, top_k=5)
                
                if pattern_results:
                    self.logger.info(f"  ‚úÖ Ïú†ÏÇ¨ Ìå®ÌÑ¥: {len(pattern_results)}Í∞ú Î∞úÍ≤¨")
                    
                    for doc, score in pattern_results:
                        # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ÏóêÏÑú ÏÇ¨Î°Ä Ï†ïÎ≥¥ Ï∂îÏ∂ú
                        metadata = doc.metadata
                        
                        case_info = {
                            'pattern_id': metadata.get('pattern_id', 'unknown'),
                            'similarity': score,
                            'content': doc.page_content,
                            'metadata': metadata
                        }
                        
                        cases.append(case_info)
                        
                        self.logger.info(f"    - {case_info['pattern_id']} (Ïú†ÏÇ¨ÎèÑ: {score:.3f})")
            
            except Exception as e:
                self.logger.warning(f"  ‚ö†Ô∏è ÏÇ¨Î°Ä Í≤ÄÏÉâ Ïã§Ìå®: {e}")
        
        # Ï†ÑÏù¥ Î≥¥Ï†ï (Í∞ÑÎã® Î≤ÑÏ†Ñ)
        transferred_estimate = self._transfer_from_cases(cases, context)
        
        # Ï¶ùÍ±∞ ÏÉùÏÑ±
        evidence = [
            {
                'src_id': f"CASE_{idx+1:03d}",
                'source': f"UMIS Pattern: {case['pattern_id']}",
                'similarity': case['similarity'],
                'type': 'case_analogy',
                'content': case['content'][:200] + '...'
            }
            for idx, case in enumerate(cases[:3])  # Top 3
        ]
        
        return SignalResult(
            signal_name='s9_case_analogies',
            weight=self.weight,
            value=transferred_estimate.get('value'),
            confidence=transferred_estimate.get('confidence', 0.85),
            evidence=evidence,
            umis_mapping='UMIS Explorer RAG (success_case_library)'
        )
    
    def _transfer_from_cases(
        self,
        cases: List[Dict],
        context: Dict
    ) -> Dict:
        """
        ÏÇ¨Î°ÄÏóêÏÑú Í∞í Ï†ÑÏù¥ Î≥¥Ï†ï
        
        Ï°∞Ï†ï Í≥ÑÏàò:
        - Ïù∏Íµ¨ ÎπÑÏú®
        - Í≥†Î†πÌôîÏú®
        - GDP per capita
        - ÏãúÏû• ÏÑ±ÏàôÎèÑ
        """
        
        if not cases:
            return {
                'value': None,
                'confidence': 0,
                'method': 'no_cases'
            }
        
        # Stub - Ïã§Ï†ú Ï†ÑÏù¥ Î≥¥Ï†ï Î°úÏßÅ
        # TODO: 6Í∞ÄÏßÄ ÌäπÏßï Ïú†ÏÇ¨ÎèÑ + 4Í∞ÄÏßÄ Ï°∞Ï†ï Í≥ÑÏàò
        
        self.logger.info(f"\n  Ï†ÑÏù¥ Î≥¥Ï†ï (Stub):")
        self.logger.info(f"    Ïú†ÏÇ¨ ÏÇ¨Î°Ä: {len(cases)}Í∞ú")
        self.logger.info(f"    Ï°∞Ï†ï Í≥ÑÏàò: Ïù∏Íµ¨, Í≥†Î†πÌôî, GDP, ÏÑ±ÏàôÎèÑ")
        
        return {
            'value': None,  # Ï†ÑÏù¥ Î≥¥Ï†ï Í∞í
            'confidence': 0.85,
            'method': 'case_transfer_stub',
            'cases_used': len(cases)
        }


# ========================================
# Domain Reasoner ÏóîÏßÑ
# ========================================

class DomainReasonerEngine:
    """
    10-Signal Stack Í∏∞Î∞ò Ï†ïÎ∞Ä Ï∂îÎ°† ÏóîÏßÑ
    
    ÌååÏù¥ÌîÑÎùºÏù∏:
    1. Ï†ïÏùò Í≥†Ï†ï (s10)
    2. Ï†úÏïΩ ÌôïÏù∏ (s3, s8)
    3. Íµ¨Ï°∞ Î∂ÑÌï¥
    4. RAG Í≤ÄÏÉâ (s2, s9, s10)
    5. ÏúµÌï© (Ïö∞ÏÑ†ÏàúÏúÑ Ï†ÅÏö©)
    6. ÌñâÎèôÍ≤ΩÏ†úÌïô Î≥¥Ï†ï (s4)
    7. Í≤ÄÏ¶ù
    8. Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±
    """
    
    def __init__(self):
        """Ï¥àÍ∏∞Ìôî"""
        logger.info("=" * 60)
        logger.info("Domain-Centric Reasoner ÏóîÏßÑ Ï¥àÍ∏∞Ìôî")
        logger.info("=" * 60)
        
        # Î∞©Î≤ïÎ°† Î°úÎìú
        self.methodology = self._load_methodology()
        
        # 10Í∞ÄÏßÄ Ïã†Ìò∏ Ï¥àÍ∏∞Ìôî
        self.signals = self._initialize_signals()
        
        logger.info("‚úÖ Domain Reasoner Ï§ÄÎπÑ ÏôÑÎ£å")
        logger.info("  ‚Ä¢ 10Í∞ÄÏßÄ Ïã†Ìò∏ Ïä§ÌÉù Î°úÎìú")
        logger.info("  ‚Ä¢ Ïö∞ÏÑ†ÏàúÏúÑ: s3 ‚Üí s8 ‚Üí s6 ‚Üí s10 ‚Üí s2 ‚Üí s9 ‚Üí s7 ‚Üí s5 ‚Üí s4 ‚Üí s1")
    
    def _load_methodology(self) -> Dict:
        """Î∞©Î≤ïÎ°† YAML Î°úÎìú"""
        yaml_path = Path("data/raw/umis_domain_reasoner_methodology.yaml")
        
        if not yaml_path.exists():
            logger.warning(f"Î∞©Î≤ïÎ°† ÌååÏùº ÏóÜÏùå: {yaml_path}")
            return {}
        
            with open(yaml_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
    
    def _initialize_signals(self) -> Dict:
        """10Í∞ÄÏßÄ Ïã†Ìò∏ Ï¥àÍ∏∞Ìôî"""
        logger.info("  10Í∞ÄÏßÄ Ïã†Ìò∏ Ïä§ÌÉù Ï¥àÍ∏∞Ìôî Ï§ë...")
        
        signals = {
            's1_llm_guess': Signal1_LLMGuess(weight=0.15),
            's2_rag_consensus': Signal2_RAGConsensus(weight=0.9),
            's3_laws_ethics_physics': Signal3_Laws(weight=1.0),
            's4_behavioral_econ': Signal4_BehavioralEcon(weight=0.6),
            's5_stat_patterns': Signal5_StatPatterns(weight=0.75),
            's6_math_relations': Signal6_MathRelations(weight=1.0),
            's7_rules_of_thumb': Signal7_RulesOfThumb(weight=0.7),
            's8_time_space_bounds': Signal8_TimeSpaceBounds(weight=1.0),
            's9_case_analogies': Signal9_CaseAnalogies(weight=0.85),
            's10_industry_kpi': Signal10_IndustryKPI(weight=0.95),
        }
        
        logger.info(f"  ‚úÖ 10Í∞ú Ïã†Ìò∏ Î™®Îëê Ï¥àÍ∏∞Ìôî ÏôÑÎ£å!")
        logger.info(f"     Ïö∞ÏÑ†ÏàúÏúÑ: s3 ‚Üí s8 ‚Üí s6 ‚Üí s10 ‚Üí s2 ‚Üí s9 ‚Üí s7 ‚Üí s5 ‚Üí s4 ‚Üí s1")
        logger.info(f"     ÏôÑÏ†Ñ Íµ¨ÌòÑ: s2, s4, s10")
        logger.info(f"     Stub Íµ¨ÌòÑ: s1, s3, s5, s6, s7, s8, s9")
        
        return signals
    
    def execute(
        self,
        question: str,
        domain: str,
        geography: str = 'KR',
        time_horizon: str = '2025-2030',
        phase_1_context: Optional[Dict] = None
    ) -> DomainReasonerResult:
        """
        6Îã®Í≥Ñ ÌååÏù¥ÌîÑÎùºÏù∏ Ïã§Ìñâ
        
        Args:
            question: Ï∂îÏ†ï ÏßàÎ¨∏
            domain: ÏÇ∞ÏóÖ/ÏòÅÏó≠
            geography: ÏßÄÎ¶¨ (Í∏∞Î≥∏ 'KR')
            time_horizon: ÏãúÍ∞Ñ Î≤îÏúÑ
            phase_1_context: Phase 1 (Guestimation) Í≤∞Í≥º (ÏÑ†ÌÉù)
        
        Returns:
            DomainReasonerResult
        """
        logger.info("\n" + "=" * 60)
        logger.info(f"Domain Reasoner Ïã§Ìñâ: {question}")
        logger.info("=" * 60)
        logger.info(f"  ÎèÑÎ©îÏù∏: {domain}")
        logger.info(f"  ÏßÄÎ¶¨: {geography}")
        logger.info(f"  ÏãúÍ∞Ñ: {time_horizon}")
        
        # Step 1: Ï†ïÏùò Í≥†Ï†ï (s10)
        logger.info("\n[Step 1] Ï†ïÏùò Í≥†Ï†ï (s10)")
        definition = self._clarify_definition(question, domain)
        
        # Step 2: Ï†úÏïΩ ÌôïÏù∏ (s3, s8)
        logger.info("\n[Step 2] Ï†úÏïΩ ÌôïÏù∏ (s3, s8)")
        constraints = self._check_constraints(definition)
        
        # Step 3: Íµ¨Ï°∞ Î∂ÑÌï¥
        logger.info("\n[Step 3] Íµ¨Ï°∞ Î∂ÑÌï¥")
        structure = self._decompose_structure(definition)
        
        # Step 4: RAG Í≤ÄÏÉâ (s2, s9, s10)
        logger.info("\n[Step 4] RAG Í≤ÄÏÉâ (s2, s9, s10)")
        rag_results = self._retrieve_from_rag(definition, domain, geography)
        
        # Step 5: ÏúµÌï© (Ïö∞ÏÑ†ÏàúÏúÑ Ï†ÅÏö©)
        logger.info("\n[Step 5] Ïã†Ìò∏ ÏúµÌï©")
        fused_result = self._fuse_signals(rag_results, constraints, structure)
        
        # Step 6: ÌñâÎèôÍ≤ΩÏ†úÌïô Î≥¥Ï†ï (Should vs Will)
        logger.info("\n[Step 6] Should vs Will Î∂ÑÏÑù")
        final_result = self._adjust_should_vs_will(fused_result)
        
        # Step 7: Í≤ÄÏ¶ù
        logger.info("\n[Step 7] Í≤ÄÏ¶ù")
        verification = self._verify(final_result, constraints, definition)
        
        # Step 8: Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±
        logger.info("\n[Step 8] Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±")
        report = self._generate_report(
            definition,
            final_result,
            verification,
            rag_results
        )
        
        logger.info("\n‚úÖ Domain Reasoner ÏôÑÎ£å")
        
        return report
    
    # ========================================
    # ÌååÏù¥ÌîÑÎùºÏù∏ Î©îÏÑúÎìúÎì§ (Stub - Îã§Ïùå Îã®Í≥ÑÏóêÏÑú Íµ¨ÌòÑ)
    # ========================================
    
    def _clarify_definition(self, question: str, domain: str) -> Dict:
        """Step 1: Ï†ïÏùò Í≥†Ï†ï (s10 ÌôúÏö©)"""
        
        # s10 (Industry KPI) ÏÇ¨Ïö©
        if 's10_industry_kpi' in self.signals:
            return self.signals['s10_industry_kpi'].clarify_definition(question, domain)
        else:
            # Fallback
            return {
            'question': question,
            'domain': domain,
                'kpi_id': 'KPI_UNKNOWN',
                'metric_name': question[:50]
        }
    
    def _check_constraints(self, definition: Dict) -> Dict:
        """Step 2: Ï†úÏïΩ ÌôïÏù∏"""
        # TODO: s3 (Laws), s8 (Time/Space Bounds)
        return {
            'laws': {},
            'bounds': {}
        }
    
    def _decompose_structure(self, definition: Dict) -> Dict:
        """Step 3: Íµ¨Ï°∞ Î∂ÑÌï¥"""
        # TODO: ÎèÑÎ©îÏù∏ Î™®Ìòï ÏÉùÏÑ±
        return {
            'model': 'TBD',
            'components': []
        }
    
    def _retrieve_from_rag(
        self,
        definition: Dict,
        domain: str,
        geography: str
    ) -> Dict:
        """Step 4: RAG Í≤ÄÏÉâ"""
        # TODO: s2 (RAG Consensus), s9 (Case Analogies), s10 (KPI)
        return {
            's2_consensus': {},
            's9_cases': [],
            's10_definitions': {}
        }
    
    def _fuse_signals(
        self,
        rag_results: Dict,
        constraints: Dict,
        structure: Dict
    ) -> Dict:
        """Step 5: Ïã†Ìò∏ ÏúµÌï©"""
        # TODO: Í∞ÄÏ§ë ÌèâÍ∑†, IQR, trimmed mean
        return {
            'value': 0,
            'range': (0, 0),
            'signals_used': []
        }
    
    def _adjust_should_vs_will(self, fused_result: Dict) -> Dict:
        """Step 6: Should vs Will Î∂ÑÎ¶¨"""
        # TODO: s4 (Behavioral Econ) ÌôúÏö©
        return {
            'should': {},
            'will': {},
            'gap': {}
        }
    
    def _verify(
        self,
        final_result: Dict,
        constraints: Dict,
        definition: Dict
    ) -> Dict:
        """Step 7: Í≤ÄÏ¶ù"""
        # TODO: Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏ Í≤ÄÏ¶ù
        return {
            'dimensional_consistency': True,
            'regulatory_compliance': True,
            'case_consensus': True,
            'should_will_separated': True
        }
    
    def _generate_report(
        self,
        definition: Dict,
        final_result: Dict,
        verification: Dict,
        rag_results: Dict
    ) -> DomainReasonerResult:
        """Step 8: Î¶¨Ìè¨Ìä∏ ÏÉùÏÑ±"""
        # TODO: 7Í∞ú ÏÑπÏÖò Î¶¨Ìè¨Ìä∏
        
        return DomainReasonerResult(
            point_estimate=0,
            range_estimate=(0, 0),
            should_vs_will={},
            signal_breakdown={},
            evidence_table=[],
            verification_log=verification,
            residual_unknowns=[],
            confidence='Medium',
            next_actions=[]
        )


# ========================================
# ÏòàÏãú ÏÇ¨Ïö©
# ========================================

if __name__ == "__main__":
    print("\n" + "=" * 60)
    print("Domain-Centric Reasoner ÏóîÏßÑ ÌÖåÏä§Ìä∏")
    print("=" * 60)
    
    engine = DomainReasonerEngine()
    
    # ÌÖåÏä§Ìä∏ Ïã§Ìñâ
    result = engine.execute(
        question="Íµ≠ÎÇ¥ ÏùåÏãù Î∞∞Îã¨ ÌîåÎû´Ìèº ÌèâÍ∑† ÏàòÏàòÎ£åÏú®",
        domain="platform",
        geography="KR"
    )
    
    print(f"\nÏ†êÏ∂îÏ†ï: {result.point_estimate}")
    print(f"Î≤îÏúÑ: {result.range_estimate}")
    print(f"Ïã†Î¢∞ÎèÑ: {result.confidence}")
    
    print("\n‚úÖ ÏóîÏßÑ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å")
