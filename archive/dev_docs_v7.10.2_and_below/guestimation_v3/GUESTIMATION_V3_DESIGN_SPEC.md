# UMIS Guestimation System v3.0 - Design Specification

**Document Version**: 1.0  
**Date**: 2025-11-06  
**Status**: Draft  
**Author**: UMIS Development Team

---

## ğŸ“‹ Document Information

### Purpose
ì´ ë¬¸ì„œëŠ” UMIS Guestimation System v3.0ì˜ ì „ì²´ ì„¤ê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. v2.1ì˜ ê·¼ë³¸ì  í•œê³„ë¥¼ í•´ê²°í•˜ê³ , "Context-Aware Judgment" ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ê¸° ìœ„í•œ ì™„ì „í•œ ì•„í‚¤í…ì²˜ ë° êµ¬í˜„ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### Scope
- **In Scope**: Guestimation System v3.0 ì „ì²´ ì„¤ê³„ (ì•„í‚¤í…ì²˜, ì»´í¬ë„ŒíŠ¸, API, ë°ì´í„° ëª¨ë¸)
- **Out of Scope**: Fermi Model Search ì¬ì„¤ê³„ (ê¸°ì¡´ ìœ ì§€, ì¼ë¶€ ìˆ˜ì •ë§Œ), RAG ì‹œìŠ¤í…œ ë³€ê²½

### Audience
- AI Developer (Cursor Agent)
- System Architect
- Future Maintainers

### References
- `SESSION_SUMMARY_20251106_FERMI_COMPLETE.md` - v2.1 ì™„ì„± ê¸°ë¡
- `CURRENT_STATUS.md` - í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœ
- `GUESTIMATION_FLOWCHART.md` - v2.1 í”Œë¡œìš°ì°¨íŠ¸
- `umis_rag/utils/multilayer_guestimation.py` - v2.1 êµ¬í˜„
- `umis_rag/utils/fermi_model_search.py` - Fermi êµ¬í˜„

---

## ğŸ¯ Executive Summary

### Problem Statement

**v2.1ì˜ ê·¼ë³¸ì  ë¬¸ì œ**:
```yaml
í˜„ì¬ Multi-Layer Guestimation:
  êµ¬ì¡°: Sequential Fallback with Early Return
  ë™ì‘: Layer 1 â†’ Layer 2 â†’ ... â†’ ì²« ì„±ê³µ ì‹œ ì¦‰ì‹œ ë¦¬í„´
  
  ë¬¸ì œì :
    âŒ "íŒë‹¨" ì—†ìŒ (ë‹¨ìˆœ if-else ì²´ì¸)
    âŒ ì •ë³´ ì¢…í•© ì—†ìŒ (ì²« ì„±ê³µë§Œ ì‚¬ìš©)
    âŒ ë§¥ë½ ê³ ë ¤ ì—†ìŒ
    âŒ íŠ¸ë ˆì´ë“œì˜¤í”„ í‰ê°€ ì—†ìŒ
```

**ì‹¤ì œ í•„ìš”**:
```yaml
ì§„ì§œ íŒë‹¨ ì‹œìŠ¤í…œ:
  1. ë§¥ë½ íŒŒì•…: ì§ˆë¬¸ ì˜ë„, ë„ë©”ì¸, ì„¸ë¶„í™”
  2. ì •ë³´ ìˆ˜ì§‘: ëª¨ë“  ê´€ë ¨ ì¶œì²˜
  3. ì¦ê±° í‰ê°€: ë§¥ë½ì— ë¹„ì¶”ì–´ ê° ì¦ê±° í‰ê°€
  4. ì¢…í•© íŒë‹¨: ê°€ì¤‘ì¹˜ ê³ ë ¤í•œ ìµœì¢… íŒë‹¨
```

### Solution Overview

**v3.0 ì„¤ê³„**:

```
Context-Aware Judgment System
  = 3-Tier Architecture + Judgment Components

3-Tier:
  Tier 1: Fast Path (90% ì¼€ì´ìŠ¤, <1ì´ˆ, $0)
  Tier 2: Judgment Path (8% ì¼€ì´ìŠ¤, 2-5ì´ˆ, $0.01-0.05)
  Tier 3: Fermi Recursion (2% ì¼€ì´ìŠ¤, 10-30ì´ˆ, $0.1-1)

4 Core Components:
  1. ComplexityAnalyzer - ì–´ëŠ Tier?
  2. ContextAnalyzer - ë§¥ë½ íŒŒì•…
  3. EvidenceCollector - ì¦ê±° ìˆ˜ì§‘
  4. JudgmentSynthesizer - ì¢…í•© íŒë‹¨
```

### Key Benefits

```yaml
ê¸°ìˆ ì  ê°œì„ :
  âœ… Sequential Fallback â†’ Context-Aware Judgment
  âœ… ì²« ì„±ê³µë§Œ ì‚¬ìš© â†’ ëª¨ë“  ì¦ê±° ì¢…í•©
  âœ… ë§¥ë½ ë¬´ì‹œ â†’ ë§¥ë½ ê¸°ë°˜ í‰ê°€
  âœ… ê³ ì • ì „ëµ â†’ ì ì‘ì  ì „ëµ

ì„±ëŠ¥ ê°œì„ :
  âœ… í™•ì‹¤í•  ë•Œ ë¹ ë¦„ (Tier 1, 90%)
  âœ… ë³µì¡í•  ë•Œ ì •í™• (Tier 2-3)
  âœ… ë¹„ìš© ìµœì í™” (í‰ê·  <$0.01)

ì‚¬ìš©ì„± ê°œì„ :
  âœ… ì¶”ë¡  íˆ¬ëª…ì„± (ëª¨ë“  ì¦ê±° + í‰ê°€ ê³¼ì •)
  âœ… ì‹ ë¢°ë„ ì •ëŸ‰í™”
  âœ… ë¶ˆí™•ì‹¤ì„± ëª…ì‹œ
```

### Migration Path

```yaml
v2.1 â†’ v3.0:
  Phase 1: v3.0 êµ¬í˜„ (ë³‘ë ¬)
  Phase 2: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
  Phase 3: ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜
  Phase 4: v2.1 Deprecation
  
  í•˜ìœ„ í˜¸í™˜ì„±: 
    - API ì‹œê·¸ë‹ˆì²˜ ìœ ì§€
    - ì„¤ì • íŒŒì¼ í˜¸í™˜
    - ê¸°ì¡´ í”„ë¡œì íŠ¸ ë™ì‘ ë³´ì¥
```

---

## ğŸ“ 1. System Architecture

### 1.1 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Estimation Entry Point                         â”‚
â”‚         estimate(question, context) â†’ Result                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ComplexityAnalyzer              â”‚
        â”‚   analyze() â†’ ComplexityResult    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           â”‚            â”‚
        â–¼           â–¼            â–¼
    â”Œâ”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Tier1â”‚    â”‚  Tier2  â”‚  â”‚  Tier3   â”‚
    â”‚Fast â”‚    â”‚Judgment â”‚  â”‚  Fermi   â”‚
    â””â”€â”€â”¬â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚            â”‚            â”‚
       â”‚       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”       â”‚
       â”‚       â”‚Context  â”‚       â”‚
       â”‚       â”‚Analyzer â”‚       â”‚
       â”‚       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜       â”‚
       â”‚            â”‚            â”‚
       â”‚       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
       â”‚       â”‚Evidence     â”‚   â”‚
       â”‚       â”‚Collector    â”‚   â”‚
       â”‚       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
       â”‚            â”‚            â”‚
       â”‚       â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
       â”‚       â”‚Judgment     â”‚   â”‚
       â”‚       â”‚Synthesizer  â”‚   â”‚
       â”‚       â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
       â”‚            â”‚            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Final Result â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Component Interaction

```
User Request
    â†“
[Entry Point]
    â†“
[ComplexityAnalyzer]
    â”œâ†’ score < 0.25 â†’ [Tier 1 Fast]
    â”œâ†’ score < 0.60 â†’ [Tier 2 Judgment]
    â”‚                     â†“
    â”‚                 [ContextAnalyzer]
    â”‚                     â†“
    â”‚                 [EvidenceCollector] (ë³‘ë ¬ ìˆ˜ì§‘)
    â”‚                     â†“
    â”‚                 [JudgmentSynthesizer]
    â”‚
    â””â†’ score >= 0.60 â†’ [Tier 3 Fermi]
                           â†“
                       [Fermi Model Search]
                           â†“
                       ì¬ê·€: estimate() í˜¸ì¶œ
```

---

## ğŸ“¦ 2. Core Components Specification

### 2.1 ComplexityAnalyzer

**Responsibility**: ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„ ë° Tier ì¶”ì²œ

**Input**:
```python
question: str          # "í•œêµ­ ìŒì‹ì  ì›”í‰ê·  ë§¤ì¶œì€?"
context: Context       # ë§¥ë½ ì •ë³´ (optional)
```

**Output**:
```python
ComplexityResult:
    score: float                    # 0.0 ~ 1.0
    recommended_tier: int           # 1, 2, or 3
    strategy: str                   # "fast_path", "judgment", "fermi"
    signals: Dict[str, Any]         # íŒë‹¨ ê·¼ê±°
    reasoning: List[str]            # ì¶”ë¡  ê³¼ì •
```

**Algorithm**:
```python
score = (
    question_type_score * 0.30 +      # ì§ˆë¬¸ ìœ í˜•
    data_availability_score * 0.25 +  # ë°ì´í„° ê°€ìš©ì„±
    variable_count_score * 0.25 +     # ì˜ˆìƒ ë³€ìˆ˜ ê°œìˆ˜
    domain_specificity_score * 0.20   # ë„ë©”ì¸ íŠ¹ìˆ˜ì„±
)

if score < 0.25:
    tier = 1, strategy = "fast_path"
elif score < 0.60:
    tier = 2, strategy = "judgment_synthesis"
else:
    tier = 3, strategy = "fermi_decomposition"
```

**Detailed Scoring Logic**:

**Design Philosophy**: 

```yaml
ë¬¸ì œ: í•˜ë“œì½”ë”©ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ëŠ” í™•ì¥ì„± ì—†ìŒ
  - "í”¼ì ë°°ë‹¬ ì‹œì¥", "ìœ ì•„ìš© ì¥ë‚œê°", "í˜¸í…” ê°ì‹¤ íšŒì „ìœ¨" ë“± ë¬´í•œí•œ ì§ˆë¬¸ ê°€ëŠ¥
  - í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¡œ ëª¨ë“  ê²½ìš° ì»¤ë²„ ë¶ˆê°€ëŠ¥
  - ì‹¤ì œ ì„¸ê³„ëŠ” ë„ˆë¬´ ë‹¤ì–‘í•¨

í•´ê²°ì±…: Hybrid Approach (ê·œì¹™ + LLM + ì„ë² ë”©)
  
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Layer 1: ë¹ ë¥¸ íŒ¨í„´ ì²´í¬ (90% ì¼€ì´ìŠ¤)            â”‚
  â”‚   - ë¬¸ë²• êµ¬ì¡° ë¶„ì„ (ì •ê·œì‹)                     â”‚
  â”‚   - íŠ¹ì • íŒ¨í„´ ë§¤ì¹­ (ì‹œê°„, ë³µí•© ì§€í‘œ ë“±)         â”‚
  â”‚   - LLM ì—†ì´ 0.001ì´ˆ                            â”‚
  â”‚   - Confidence >= 0.8 â†’ ì‚¬ìš©                    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ Confidence < 0.8
                    â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Layer 2: LLM ë¶„ë¥˜ (10% ì¼€ì´ìŠ¤)                  â”‚
  â”‚   - Native Mode: Cursor LLM ($0, 1-2ì´ˆ)        â”‚
  â”‚   - ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ (100-200 í† í°)              â”‚
  â”‚   - JSON ì‘ë‹µ                                    â”‚
  â”‚   - ìºì‹± ë¶ˆí•„ìš” (ë¹„ìš© $0, ì†ë„ ì¶©ë¶„)            â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Layer 3: ì„ë² ë”© ìœ ì‚¬ë„ (íŠ¹ì • ì¼€ì´ìŠ¤)            â”‚
  â”‚   - ì „ë¬¸ ìš©ì–´ ìœ ì‚¬ë„ ì²´í¬                       â”‚
  â”‚   - RAG ë²¤ì¹˜ë§ˆí¬ ê²€ìƒ‰                           â”‚
  â”‚   - í”„ë¡œì íŠ¸ ë°ì´í„° ë§¤ì¹­                        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

í•µì‹¬ ì›ì¹™:
  1. í™•ì‹¤í•  ë• ê·œì¹™ (ë¹ ë¦„, ë¹„ìš© ì—†ìŒ)
  2. ë¶ˆí™•ì‹¤í•  ë• LLM (ì •í™•í•¨, Native Mode $0)
  3. ë‹¨ìˆœí•˜ê²Œ ìœ ì§€ (ìºì‹± ê°™ì€ ë¶ˆí•„ìš”í•œ ë³µì¡ë„ ì œê±°)
  4. ì„ë² ë”© í™œìš© (ì˜ë¯¸ ê¸°ë°˜ ë§¤ì¹­)

ìºì‹± ì œê±° ì´ìœ :
  âŒ ë³µì¡ë„ ì¦ê°€ (Redis/íŒŒì¼/ë©”ëª¨ë¦¬ êµ¬í˜„ í•„ìš”)
  âŒ íš¨ìµ ë¯¸ë¯¸ (Native Mode ë¹„ìš© $0, ì†ë„ 1-2ì´ˆ ì¶©ë¶„)
  âŒ ì¼ê´€ì„± ë¬¸ì œ (Stale data ê°€ëŠ¥ì„±)
  âœ… YAGNI ì›ì¹™ (You Aren't Gonna Need It)
```

**4ê°€ì§€ ì ìˆ˜ ë³€ìˆ˜ë³„ ì „ëµ**:

```yaml
1. question_type_score:
   - ë¹ ë¥¸ íŒ¨í„´: ë¬¸ë²• êµ¬ì¡° (ì •ê·œì‹)
   - ë¶ˆí™•ì‹¤ ì‹œ: LLM ë¶„ë¥˜
   - í™•ì¥ì„±: ë¬´í•œí•œ ì§ˆë¬¸ ì»¤ë²„ ê°€ëŠ¥

2. data_availability_score:
   - í”„ë¡œì íŠ¸ ë°ì´í„°: ì„ë² ë”© ìœ ì‚¬ë„ ë§¤ì¹­
   - ê³µê°œ ë°ì´í„°: LLM íŒë‹¨
   - RAG: ë²¤ì¹˜ë§ˆí¬ ê²€ìƒ‰
   - í™•ì¥ì„±: ìƒˆë¡œìš´ ë°ì´í„° ì†ŒìŠ¤ ìë™ íŒë‹¨

3. variable_count_score:
   - LLM ë¶„í•´ êµ¬ì¡° ë¶„ì„
   - íœ´ë¦¬ìŠ¤í‹± ë³´ì¡° (ìˆ˜ì‹ì–´ ì¹´ìš´íŠ¸)
   - í™•ì¥ì„±: ë³µì¡í•œ ì§ˆë¬¸ë„ ë¶„í•´ ê°€ëŠ¥

4. domain_specificity_score:
   - ì„ë² ë”©: ì „ë¬¸ ìš©ì–´ ìœ ì‚¬ë„
   - LLM: ë„ë©”ì¸ ìˆ˜ì¤€ íŒë‹¨
   - í™•ì¥ì„±: ìƒˆë¡œìš´ ë„ë©”ì¸ ìë™ ì¸ì‹
```

**Confidence Calculation (ì‹ ë¢°ë„ ê³„ì‚°)**:

```yaml
í•µì‹¬ ì§ˆë¬¸: "ì´ íŒ¨í„´ ë§¤ì¹­ì´ ì–¼ë§ˆë‚˜ í™•ì‹¤í•œê°€?"

ë¬¸ì œ:
  - "ìŒì‹ì " í‚¤ì›Œë“œ â†’ simple_estimate
  - í•˜ì§€ë§Œ ì–¼ë§ˆë‚˜ í™•ì‹¤í•œê°€? 0.5? 0.8? 0.95?

í•´ê²°ì±…: Signal-based Confidence
  ì—¬ëŸ¬ ì‹ í˜¸ë¥¼ ì¢…í•©í•˜ì—¬ í™•ë¥ ì ìœ¼ë¡œ ê³„ì‚°
```

**Confidence ê³„ì‚° ê³µì‹**:

```python
def _calculate_pattern_confidence(
    self,
    question: str,
    matched_pattern: str
) -> float:
    """
    íŒ¨í„´ ë§¤ì¹­ ì‹ ë¢°ë„ ê³„ì‚°
    
    ì—¬ëŸ¬ ì‹ í˜¸ë¥¼ ì¢…í•©í•˜ì—¬ 0.0 ~ 1.0 ë°˜í™˜
    """
    
    signals = []
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Signal 1: íŒ¨í„´ ë§¤ì¹­ ê°•ë„ (50%)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    match_strength = self._calculate_match_strength(question, matched_pattern)
    signals.append(('match_strength', match_strength, 0.50))
    
    """
    ì˜ˆì‹œ:
      ì§ˆë¬¸: "í•œêµ­ ì¸êµ¬ëŠ”?"
      íŒ¨í„´: factual (ì •ì˜ ì§ˆë¬¸)
      
      ì²´í¬:
        - ë¬¸ë²• íŒ¨í„´ ì •í™•íˆ ì¼ì¹˜: ".+ëŠ”?$" âœ… (1.0)
        - "ì¸êµ¬" ê°™ì€ ì‚¬ì‹¤ í‚¤ì›Œë“œ í¬í•¨ âœ… (1.0)
        - ì¶”ì • í‚¤ì›Œë“œ ì—†ìŒ ("ì–¼ë§ˆ", "ëª‡") âœ… (1.0)
      
      match_strength = (1.0 + 1.0 + 1.0) / 3 = 1.0
    
    ì˜ˆì‹œ 2:
      ì§ˆë¬¸: "ìŒì‹ì  ë§¤ì¶œì€?"
      íŒ¨í„´: simple_estimate
      
      ì²´í¬:
        - "ë§¤ì¶œ" í‚¤ì›Œë“œ âœ… (0.8)
        - í•˜ì§€ë§Œ ë§¥ë½ ë¶ˆëª…í™• (0.6)
        - ìˆ˜ì‹ì–´ ì ìŒ (0.7)
      
      match_strength = (0.8 + 0.6 + 0.7) / 3 = 0.70
    """
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Signal 2: ë°˜ì¦ ì‹ í˜¸ (30%)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    counter_signals = self._check_counter_signals(question, matched_pattern)
    signals.append(('counter_signals', 1.0 - counter_signals, 0.30))
    
    """
    ë°˜ì¦ ì‹ í˜¸: íŒ¨í„´ê³¼ ëª¨ìˆœë˜ëŠ” í‚¤ì›Œë“œ
    
    ì˜ˆì‹œ:
      íŒ¨í„´: factual
      ë°˜ì¦: "ì–¼ë§ˆ", "ëª‡", "ì˜ˆì¸¡" (ì¶”ì •/ì˜ˆì¸¡ í‚¤ì›Œë“œ)
      
      ì§ˆë¬¸: "í•œêµ­ ì¸êµ¬ëŠ” ì–¼ë§ˆ?"
        â†’ factual íŒ¨í„´ ë§¤ì¹­
        â†’ í•˜ì§€ë§Œ "ì–¼ë§ˆ" ë°œê²¬ (ë°˜ì¦!)
        â†’ counter_signals = 0.5
        â†’ ì‹ ë¢°ë„ í•˜ë½
    
    ì˜ˆì‹œ 2:
      íŒ¨í„´: simple_estimate
      ë°˜ì¦: "3ë…„ í›„", "ë¯¸ë˜" (ì˜ˆì¸¡ í‚¤ì›Œë“œ)
      
      ì§ˆë¬¸: "3ë…„ í›„ ìŒì‹ì  ë§¤ì¶œì€?"
        â†’ simple_estimate ë§¤ì¹­
        â†’ "3ë…„ í›„" ë°œê²¬ (ë°˜ì¦!)
        â†’ counter_signals = 0.8
        â†’ ì‹ ë¢°ë„ í¬ê²Œ í•˜ë½
    """
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Signal 3: êµ¬ì¡° ëª…í™•ì„± (20%)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    structural_clarity = self._assess_structural_clarity(question)
    signals.append(('structural_clarity', structural_clarity, 0.20))
    
    """
    êµ¬ì¡° ëª…í™•ì„±: ì§ˆë¬¸ êµ¬ì¡°ê°€ ì–¼ë§ˆë‚˜ ëª…í™•í•œê°€?
    
    ëª…í™•:
      - "XëŠ”?" (ë‹¨ì¼ ê°œë…)
      - "Aì˜ BëŠ”?" (ëª…í™•í•œ ê´€ê³„)
    
    ëª¨í˜¸:
      - "X Y ZëŠ”?" (ì—¬ëŸ¬ ê°œë…)
      - ë³µí•© ë¬¸ì¥
    
    ì˜ˆì‹œ:
      "í•œêµ­ ì¸êµ¬ëŠ”?" â†’ 0.95 (ë§¤ìš° ëª…í™•)
      "ìŒì‹ì  í‰ê·  ë§¤ì¶œì€?" â†’ 0.80 (ëª…í™•)
      "ì˜¨ë¼ì¸ ìŒì‹ ë°°ë‹¬ ì‹œì¥ ì„±ì¥ë¥ ì€?" â†’ 0.60 (ë³µì¡)
    """
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ì¢…í•© Confidence ê³„ì‚°
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    total_confidence = sum(
        signal_value * weight 
        for (name, signal_value, weight) in signals
    )
    
    return total_confidence


def _calculate_match_strength(self, question: str, pattern: str) -> float:
    """íŒ¨í„´ ë§¤ì¹­ ê°•ë„"""
    
    if pattern == 'factual':
        score = 0.0
        
        # ë¬¸ë²• ë§¤ì¹­
        if re.match(r'.+(ì€|ëŠ”)\??$', question):
            score += 0.4
        
        # ì‚¬ì‹¤ í‚¤ì›Œë“œ
        factual_keywords = ['ì¸êµ¬', 'ë©´ì ', 'ìˆ˜ë„', 'ì‹œê°„']
        if any(kw in question for kw in factual_keywords):
            score += 0.4
        
        # ì¶”ì • í‚¤ì›Œë“œ ì—†ìŒ
        estimate_keywords = ['ì–¼ë§ˆ', 'ëª‡', 'ê·œëª¨']
        if not any(kw in question for kw in estimate_keywords):
            score += 0.2
        
        return min(score, 1.0)
    
    elif pattern == 'simple_estimate':
        score = 0.0
        
        # ì¶”ì • í‚¤ì›Œë“œ
        if any(kw in question for kw in ['í‰ê· ', 'ëŒ€ëµ', 'ì–¼ë§ˆ']):
            score += 0.3
        
        # ë‹¨ìˆœ ì§€í‘œ
        if any(kw in question for kw in ['ë§¤ì¶œ', 'ê°€ê²©', 'ë¹„ìš©']):
            score += 0.4
        
        # ë³µì¡ í‚¤ì›Œë“œ ì—†ìŒ
        if not any(kw in question for kw in ['ì‹œì¥', 'ê·œëª¨', 'TAM']):
            score += 0.3
        
        return min(score, 1.0)
    
    # ... ë‹¤ë¥¸ íŒ¨í„´ë“¤

def _check_counter_signals(self, question: str, pattern: str) -> float:
    """ë°˜ì¦ ì‹ í˜¸ ì²´í¬ (0.0 = ë°˜ì¦ ì—†ìŒ, 1.0 = ê°•í•œ ë°˜ì¦)"""
    
    counter_patterns = {
        'factual': ['ì–¼ë§ˆ', 'ëª‡', 'ê·œëª¨', 'ì˜ˆì¸¡'],
        'simple_estimate': ['3ë…„ í›„', 'ë¯¸ë˜', 'ì‹œì¥ ê·œëª¨'],
        'complex_estimate': ['ë‹¨ìˆœíˆ', 'ê·¸ëƒ¥'],
        'prediction': ['ê³¼ê±°', 'í˜„ì¬']
    }
    
    if pattern in counter_patterns:
        counter_keywords = counter_patterns[pattern]
        matched_counters = [kw for kw in counter_keywords if kw in question]
        
        # ë°˜ì¦ ê°•ë„
        counter_strength = len(matched_counters) * 0.3
        return min(counter_strength, 1.0)
    
    return 0.0

def _assess_structural_clarity(self, question: str) -> float:
    """êµ¬ì¡° ëª…í™•ì„±"""
    
    # ê¸¸ì´ (ì§§ì„ìˆ˜ë¡ ëª…í™•)
    length_score = max(1.0 - len(question) / 50, 0.5)
    
    # ìˆ˜ì‹ì–´ ê°œìˆ˜ (ì ì„ìˆ˜ë¡ ëª…í™•)
    modifier_count = len(self._extract_modifiers(question))
    modifier_score = max(1.0 - modifier_count * 0.1, 0.5)
    
    # ë³µí•© ë¬¸ì¥ (ë‹¨ì¼ ë¬¸ì¥ì´ ëª…í™•)
    is_compound = ',' in question or 'ê·¸ë¦¬ê³ ' in question
    compound_score = 0.7 if is_compound else 1.0
    
    return (length_score + modifier_score + compound_score) / 3
```

**ì‹¤ì œ ê³„ì‚° ì˜ˆì‹œ**:

```python
# ì˜ˆì œ 1: "í•œêµ­ ì¸êµ¬ëŠ”?"
pattern = 'factual'

match_strength:
  - ë¬¸ë²• ë§¤ì¹­ ".+ëŠ”?$": 0.4
  - "ì¸êµ¬" í‚¤ì›Œë“œ: 0.4
  - ì¶”ì • í‚¤ì›Œë“œ ì—†ìŒ: 0.2
  = 1.0

counter_signals:
  - ë°˜ì¦ í‚¤ì›Œë“œ ì—†ìŒ
  = 0.0 â†’ 1.0 (ë°˜ì „)

structural_clarity:
  - ê¸¸ì´ 8ì: 1.0
  - ìˆ˜ì‹ì–´ 1ê°œ ("í•œêµ­"): 0.9
  - ë‹¨ì¼ ë¬¸ì¥: 1.0
  = 0.97

confidence = 1.0Ã—0.5 + 1.0Ã—0.3 + 0.97Ã—0.2 = 0.994 âœ…
â†’ 0.994 >= 0.95 â†’ Tier 1 ì²˜ë¦¬!


# ì˜ˆì œ 2: "ìŒì‹ì  ì°½ì—… ì˜ˆìƒ ë§¤ì¶œì€?"
pattern = 'simple_estimate'

match_strength:
  - "ë§¤ì¶œ" í‚¤ì›Œë“œ: 0.4
  - ë³µì¡ í‚¤ì›Œë“œ ì—†ìŒ: 0.3
  = 0.7

counter_signals:
  - "ì°½ì—…" (ì˜ì‚¬ê²°ì • ë§¥ë½, ë¯¸ë¬˜í•¨): 0.3
  = 0.7 (ë°˜ì „)

structural_clarity:
  - ê¸¸ì´ 15ì: 0.7
  - ìˆ˜ì‹ì–´ 2ê°œ ("ìŒì‹ì ", "ì°½ì—…"): 0.8
  - ë‹¨ì¼ ë¬¸ì¥: 1.0
  = 0.83

confidence = 0.7Ã—0.5 + 0.7Ã—0.3 + 0.83Ã—0.2 = 0.726
â†’ 0.726 < 0.95 â†’ Tier 2ë¡œ ë„˜ê¹€! âœ…


# ì˜ˆì œ 3: "3ë…„ í›„ ìŒì‹ì  ë§¤ì¶œì€?"
pattern = 'simple_estimate' (ì˜ëª»ëœ ë§¤ì¹­!)

match_strength:
  - "ë§¤ì¶œ" í‚¤ì›Œë“œ: 0.4
  = 0.4 (ë‚®ìŒ)

counter_signals:
  - "3ë…„ í›„" (prediction ë°˜ì¦!): 0.8
  = 0.2 (ë°˜ì „, ë‚®ìŒ!)

structural_clarity:
  - 0.80

confidence = 0.4Ã—0.5 + 0.2Ã—0.3 + 0.8Ã—0.2 = 0.42
â†’ 0.42 < 0.95 â†’ Tier 2ë¡œ ë„˜ê¹€! âœ…
â†’ Tier 2ì—ì„œ LLMì´ 'prediction' ì •í™•íˆ íŒë‹¨
```

---

**1. question_type_score (30% ê°€ì¤‘ì¹˜)**

```python
def _classify_question_type(self, question: str) -> Tuple[str, float]:
    """
    ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ ë° ì ìˆ˜ ê³„ì‚°
    
    Strategy:
      1. ë¹ ë¥¸ íŒ¨í„´ ì²´í¬ (ë¬¸ë²• êµ¬ì¡° ê¸°ë°˜)
      2. ë¶ˆí™•ì‹¤í•˜ë©´ LLM ë¶„ë¥˜ (Native Mode $0)
    
    Returns:
        (type_name, score): ìœ í˜•ê³¼ ì ìˆ˜ (0.0 ~ 1.0)
    
    Note: ìºì‹± ë¶ˆí•„ìš”
      - Native Mode ë¹„ìš©: $0
      - ì‘ë‹µ ì‹œê°„: 1-2ì´ˆ (ì¶©ë¶„íˆ ë¹ ë¦„)
      - ë³µì¡ë„ ì¦ê°€ vs íš¨ìµ ë¯¸ë¯¸
    """
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Step 1: ë¹ ë¥¸ íŒ¨í„´ ì²´í¬ (ê·œì¹™ ê¸°ë°˜, LLM ì—†ì´)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    pattern_result = self._check_question_patterns(question)
    
    if pattern_result['confidence'] >= 0.8:
        # ì¶©ë¶„íˆ í™•ì‹¤í•¨ â†’ ê·œì¹™ ê²°ê³¼ ì‚¬ìš©
        return (pattern_result['type'], pattern_result['score'])
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Step 2: LLM ë¶„ë¥˜ (ë¶ˆí™•ì‹¤í•œ ê²½ìš°)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    return self._classify_with_llm(question)


def _check_question_patterns(self, question: str) -> Dict:
    """
    ë¬¸ë²• íŒ¨í„´ ê¸°ë°˜ ë¹ ë¥¸ ì²´í¬ (LLM ì—†ì´)
    
    í•µì‹¬ ì•„ì´ë””ì–´:
      - í‚¤ì›Œë“œ ë§¤ì¹­ âŒ â†’ ë¬¸ë²• êµ¬ì¡° ë¶„ì„ âœ…
      - "ë¬´ì—‡ì´ ì–¼ë§ˆì¸ê°€?" í˜•íƒœ ë¶„ì„
    """
    question_lower = question.lower()
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Pattern 1: Factual (ì •ì˜ ì§ˆë¬¸)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # "XëŠ”?" "Xë€?" "XëŠ” ë¬´ì—‡?"
    if re.match(r'.+(ì€|ëŠ”|ì´ë€|ë€)\??$', question_lower):
        # í•˜ì§€ë§Œ "ì–¼ë§ˆ", "ëª‡" ìˆìœ¼ë©´ ì¶”ì • ì§ˆë¬¸
        if not any(word in question_lower for word in ['ì–¼ë§ˆ', 'ëª‡', 'ê·œëª¨']):
            return {
                'type': 'factual',
                'score': 0.0,
                'confidence': 0.9,
                'reason': 'ì •ì˜ ì§ˆë¬¸ íŒ¨í„´'
            }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Pattern 2: Prediction (ì‹œê°„ í‘œí˜„)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # "Në…„ í›„", "ë¯¸ë˜", "ì˜ˆì¸¡", "ì „ë§"
    time_future_patterns = [
        r'\d+ë…„\s*í›„',
        r'\d+ê°œì›”\s*í›„',
        r'ë¯¸ë˜',
        r'ì˜ˆì¸¡',
        r'ì „ë§',
    ]
    
    if any(re.search(pattern, question) for pattern in time_future_patterns):
        return {
            'type': 'prediction',
            'score': 0.9,
            'confidence': 0.95,
            'reason': 'ë¯¸ë˜ ì‹œì  íŒ¨í„´'
        }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Pattern 3: Complex (ë³µí•© ê°œë…)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # "ì‹œì¥ ê·œëª¨", "TAM", "SAM", ì „ë¬¸ ì§€í‘œ
    complex_patterns = [
        r'ì‹œì¥\s*(ê·œëª¨|í¬ê¸°)',
        r'TAM|SAM|SOM',
        r'unit\s*economics',
        r'LTV|CAC',
    ]
    
    if any(re.search(pattern, question, re.IGNORECASE) for pattern in complex_patterns):
        return {
            'type': 'complex_estimate',
            'score': 0.7,
            'confidence': 0.9,
            'reason': 'ë³µí•© ì§€í‘œ íŒ¨í„´'
        }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Pattern 4: Simple vs Complex êµ¬ë¶„
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ìˆ«ì ì§ˆë¬¸ì´ì§€ë§Œ í‚¤ì›Œë“œ ëª¨í˜¸í•œ ê²½ìš°
    
    # "ì–¼ë§ˆ", "ëª‡" ìˆìœ¼ë©´ ìˆ«ì ì§ˆë¬¸
    if any(word in question_lower for word in ['ì–¼ë§ˆ', 'ëª‡', 'ê°€ê²©', 'ë¹„ìš©']):
        # ìˆ˜ì‹ì–´ ê°œìˆ˜ë¡œ ë³µì¡ë„ íŒë‹¨
        modifier_count = len(re.findall(r'[ê°€-í£]+\s+', question))
        
        if modifier_count >= 3:
            # ìˆ˜ì‹ì–´ ë§ìŒ â†’ ë³µì¡
            return {
                'type': 'complex_estimate',
                'score': 0.7,
                'confidence': 0.7,
                'reason': f'ìˆ˜ì‹ì–´ {modifier_count}ê°œ (ë³µì¡)'
            }
        else:
            # ìˆ˜ì‹ì–´ ì ìŒ â†’ ë‹¨ìˆœ
            return {
                'type': 'simple_estimate',
                'score': 0.3,
                'confidence': 0.7,
                'reason': f'ìˆ˜ì‹ì–´ {modifier_count}ê°œ (ë‹¨ìˆœ)'
            }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ë¶ˆí™•ì‹¤ â†’ LLM í•„ìš”
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    return {
        'type': 'simple_estimate',
        'score': 0.3,
        'confidence': 0.4,  # ë‚®ì€ ì‹ ë¢°ë„ â†’ LLM í˜¸ì¶œ
        'reason': 'íŒ¨í„´ ë¶ˆëª…í™•'
    }


def _classify_with_llm(self, question: str) -> Tuple[str, float]:
    """
    LLMì„ ì‚¬ìš©í•œ ì§ˆë¬¸ ë¶„ë¥˜
    
    Native Mode ì‚¬ìš© ì‹œ ë¹„ìš© $0
    ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë¹ ë¥´ê²Œ ë¶„ë¥˜
    """
    
    prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì„ 4ê°€ì§€ ìœ í˜• ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

ì§ˆë¬¸: "{question}"

ìœ í˜•:
1. factual: ì‚¬ì‹¤ í™•ì¸ ì§ˆë¬¸ (ì˜ˆ: "í•œêµ­ ì¸êµ¬ëŠ”?", "ì„œìš¸ ë©´ì ì€?")
2. simple_estimate: ë‹¨ìˆœ ì¶”ì • (ì˜ˆ: "ì¹´í˜ í‰ê·  ê°€ê²©ì€?", "ìŒì‹ì  ê³ ê°ìˆ˜ëŠ”?")
3. complex_estimate: ë³µì¡í•œ ì¶”ì • (ì˜ˆ: "ì‹œì¥ ê·œëª¨ëŠ”?", "LTVëŠ”?")
4. prediction: ë¯¸ë˜ ì˜ˆì¸¡ (ì˜ˆ: "3ë…„ í›„ ì‹œì¥ì€?")

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”:
{{"type": "...", "confidence": 0.0-1.0, "reason": "..."}}"""

    # LLM í˜¸ì¶œ (Native Mode: Cursor LLM)
    response = self._call_llm(prompt, max_tokens=100)
    
    # JSON íŒŒì‹±
    try:
        result = json.loads(response)
        
        # ì ìˆ˜ ë§¤í•‘
        score_mapping = {
            'factual': 0.0,
            'simple_estimate': 0.3,
            'complex_estimate': 0.7,
            'prediction': 0.9
        }
        
        return (result['type'], score_mapping[result['type']])
    
    except Exception as e:
        # LLM ì‹¤íŒ¨ â†’ ê¸°ë³¸ê°’
        logger.warning(f"LLM classification failed: {e}")
        return ('simple_estimate', 0.3)
```

**2. data_availability_score (25% ê°€ì¤‘ì¹˜)**

```python
def _check_data_availability(
    self, 
    question: str, 
    context: Optional[Context]
) -> float:
    """
    ë°ì´í„° ê°€ìš©ì„± ì²´í¬
    
    Strategy:
      1. í”„ë¡œì íŠ¸ ë°ì´í„° ì²´í¬ (í‚¤ì›Œë“œ ì¶”ì¶œ + ìœ ì‚¬ë„)
      2. ê³µê°œ ë°ì´í„° ê°€ëŠ¥ì„± íŒë‹¨ (LLM)
      3. RAG ë²¤ì¹˜ë§ˆí¬ ì²´í¬ (ì„ë² ë”© ê²€ìƒ‰)
    
    Returns:
        score (0.0 ~ 1.0): ë†’ì„ìˆ˜ë¡ ë°ì´í„° ì—†ìŒ (ë³µì¡í•¨)
    """
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Check 1: í”„ë¡œì íŠ¸ ë°ì´í„° (ê°€ì¥ í™•ì‹¤)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    if context and context.project_data:
        # í‚¤ì›Œë“œ ì¶”ì¶œ (NLP ê¸°ë°˜)
        keywords = self._extract_keywords_nlp(question)
        
        # ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (ì„ë² ë”©)
        for key, value in context.project_data.items():
            similarity = self._calculate_similarity(question, key)
            if similarity >= 0.7:  # 70% ì´ìƒ ìœ ì‚¬
                return 0.0  # ë°ì´í„° ìˆìŒ!
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Check 2: ê³µê°œ ë°ì´í„° ê°€ëŠ¥ì„± (LLM íŒë‹¨)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    public_data_availability = self._check_public_data_with_llm(question)
    
    if public_data_availability['available']:
        return public_data_availability['score']
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Check 3: RAG ë²¤ì¹˜ë§ˆí¬ ì²´í¬ (ì„ë² ë”© ê²€ìƒ‰)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    rag_similarity = self._check_rag_benchmarks(question)
    
    if rag_similarity >= 0.6:
        return 0.4  # RAGì— ìœ ì‚¬ ë°ì´í„° ìˆìŒ
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Check 4: ì™„ì „íˆ ìƒˆë¡œìš´ ì§ˆë¬¸
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    return 1.0


def _extract_keywords_nlp(self, question: str) -> List[str]:
    """NLP ê¸°ë°˜ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    # ê°„ë‹¨í•œ êµ¬í˜„: ëª…ì‚¬ ì¶”ì¶œ
    # ì‹¤ì œë¡œëŠ” konlpy, spacy ë“± ì‚¬ìš© ê°€ëŠ¥
    
    # ë¶ˆìš©ì–´ ì œê±°
    stopwords = {'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ë¥¼', 'ì˜', 'ì—', 'ì™€', 'ê³¼'}
    
    words = question.split()
    keywords = [w for w in words if w not in stopwords and len(w) >= 2]
    
    return keywords


def _check_public_data_with_llm(self, question: str) -> Dict:
    """LLMì—ê²Œ ê³µê°œ ë°ì´í„° ê°€ëŠ¥ì„± ì§ˆë¬¸"""
    
    prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ê³µê°œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

ì§ˆë¬¸: "{question}"

ë‹¤ìŒì„ íŒë‹¨í•˜ì„¸ìš”:
1. ê³µì‹ í†µê³„ (í†µê³„ì²­, ì •ë¶€ ê¸°ê´€) ê°€ëŠ¥ì„±
2. ì‚°ì—… ë³´ê³ ì„œ (ë¦¬ì„œì¹˜ ê¸°ê´€) ê°€ëŠ¥ì„±
3. í•™ìˆ  ë…¼ë¬¸/ì—°êµ¬ ê°€ëŠ¥ì„±

JSON í˜•ì‹ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”:
{{
  "available": true/false,
  "source_type": "official_stat" | "industry_report" | "academic" | "none",
  "score": 0.0-1.0,
  "reason": "..."
}}"""

    response = self._call_llm(prompt, max_tokens=150)
    
    try:
        result = json.loads(response)
        
        # ì ìˆ˜ ë§¤í•‘
        score_mapping = {
            'official_stat': 0.1,   # ë§¤ìš° í™•ì‹¤
            'industry_report': 0.3,  # ì°¾ì„ ê°€ëŠ¥ì„±
            'academic': 0.5,        # ê³„ì‚° í•„ìš”
            'none': 1.0             # ì—†ìŒ
        }
        
        return {
            'available': result['available'],
            'score': score_mapping.get(result['source_type'], 1.0),
            'reason': result['reason']
        }
    
    except Exception as e:
        # ì‹¤íŒ¨ ì‹œ ë³´ìˆ˜ì  íŒë‹¨
        return {'available': False, 'score': 1.0}


def _check_rag_benchmarks(self, question: str) -> float:
    """RAGì—ì„œ ìœ ì‚¬ ë²¤ì¹˜ë§ˆí¬ ê²€ìƒ‰"""
    
    # ì§ˆë¬¸ ì„ë² ë”©
    question_embedding = self._get_embedding(question)
    
    # RAG ê²€ìƒ‰ (ë²¤ì¹˜ë§ˆí¬ Collection)
    from umis_rag.agents.quantifier import QuantifierRAG
    
    quantifier = QuantifierRAG()
    results = quantifier.search_benchmarks(
        query_embedding=question_embedding,
        top_k=3
    )
    
    if not results:
        return 0.0
    
    # ìµœê³  ìœ ì‚¬ë„ ë°˜í™˜
    max_similarity = max(r['similarity'] for r in results)
    return max_similarity
```

**3. variable_count_score (25% ê°€ì¤‘ì¹˜)**

```python
def _estimate_variable_count(self, question: str) -> Tuple[int, float]:
    """
    ì˜ˆìƒ ë³€ìˆ˜ ê°œìˆ˜ ì¶”ì •
    
    Strategy:
      1. ì§ˆë¬¸ ë¶„í•´ êµ¬ì¡° ë¶„ì„ (LLM)
      2. ìˆ˜ì‹ì–´/í•œì •ì–´ ê°œìˆ˜ ì¹´ìš´íŠ¸
      3. ì¢…í•© íŒë‹¨
    
    Returns:
        (count, score): ê°œìˆ˜ì™€ ì ìˆ˜ (0.0 ~ 1.0)
    """
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Method 1: LLMì—ê²Œ ë¶„í•´ êµ¬ì¡° ì§ˆë¬¸
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    decomposition = self._ask_llm_decomposition(question)
    
    if decomposition['confidence'] >= 0.7:
        estimated_count = decomposition['variable_count']
    else:
        # LLM ë¶ˆí™•ì‹¤ â†’ íœ´ë¦¬ìŠ¤í‹± ì‚¬ìš©
        estimated_count = self._estimate_variables_heuristic(question)
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Score ê³„ì‚° (0.0 ~ 1.0)
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    if estimated_count == 0:
        score = 0.0
    elif estimated_count <= 2:
        score = 0.3
    elif estimated_count <= 5:
        score = 0.6
    else:
        score = 1.0
    
    return (estimated_count, score)


def _ask_llm_decomposition(self, question: str) -> Dict:
    """LLMì—ê²Œ ì§ˆë¬¸ ë¶„í•´ êµ¬ì¡° ì§ˆë¬¸"""
    
    prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì„ ë‹µí•˜ë ¤ë©´ ëª‡ ê°œì˜ ë³€ìˆ˜ê°€ í•„ìš”í•œì§€ ë¶„ì„í•˜ì„¸ìš”.

ì§ˆë¬¸: "{question}"

ì˜ˆì‹œ:
- "í•œêµ­ ì¸êµ¬ëŠ”?" â†’ 0ê°œ ë³€ìˆ˜ (ì‚¬ì‹¤)
- "ì¹´í˜ í‰ê·  ê°€ê²©ì€?" â†’ 1ê°œ ë³€ìˆ˜ (ê°€ê²©)
- "ìŒì‹ì  ì›”ë§¤ì¶œì€?" â†’ 3ê°œ ë³€ìˆ˜ (ê³ ê°ìˆ˜ Ã— ê°ë‹¨ê°€ Ã— ë°©ë¬¸ë¹ˆë„)
- "SaaS ì‹œì¥ ê·œëª¨ëŠ”?" â†’ 5ê°œ ë³€ìˆ˜ (ê¸°ì—…ìˆ˜ Ã— ë„ì…ë¥  Ã— ARPU Ã— ì„¸ê·¸ë¨¼íŠ¸ Ã— ì§€ì—­)

JSONìœ¼ë¡œ ë‹µí•˜ì„¸ìš”:
{{
  "variable_count": 0-10,
  "decomposition": "ë¶„í•´ êµ¬ì¡° ì„¤ëª…",
  "confidence": 0.0-1.0
}}"""

    response = self._call_llm(prompt, max_tokens=200)
    
    try:
        result = json.loads(response)
        return result
    except:
        return {'variable_count': 3, 'confidence': 0.3}


def _estimate_variables_heuristic(self, question: str) -> int:
    """íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ë³€ìˆ˜ ê°œìˆ˜ ì¶”ì • (LLM ì‹¤íŒ¨ ì‹œ)"""
    
    estimated_count = 0
    
    # ê³±ì…ˆ ê¸°í˜¸
    estimated_count += question.count('Ã—') + question.count('*')
    
    # ìˆ˜ì‹ì–´ ê°œìˆ˜ (NER)
    modifiers = self._extract_modifiers(question)
    estimated_count += len(modifiers) // 2
    
    # ê¸°ë³¸ê°’
    if estimated_count == 0:
        # ë³µì¡ë„ ë‹¨ì–´ë¡œ ì¶”ì •
        if any(w in question for w in ['ì‹œì¥', 'ê·œëª¨', 'TAM']):
            estimated_count = 4
        else:
            estimated_count = 1
    
    return estimated_count


def _extract_modifiers(self, question: str) -> List[str]:
    """ìˆ˜ì‹ì–´/í•œì •ì–´ ì¶”ì¶œ"""
    
    # íŒ¨í„´: "í˜•ìš©ì‚¬ + ëª…ì‚¬"
    # ì˜ˆ: "í•œêµ­", "ì˜¨ë¼ì¸", "B2B", "ì¤‘ì†Œê¸°ì—…"
    
    # ê°„ë‹¨í•œ êµ¬í˜„: íŠ¹ì • ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ
    modifier_categories = {
        'region': ['í•œêµ­', 'ë¯¸êµ­', 'ì„œìš¸', 'ê¸€ë¡œë²Œ', 'ì•„ì‹œì•„'],
        'channel': ['ì˜¨ë¼ì¸', 'ì˜¤í”„ë¼ì¸', 'ëª¨ë°”ì¼', 'ì›¹'],
        'target': ['B2B', 'B2C', 'B2G', 'ê¸°ì—…', 'ê°œì¸'],
        'size': ['ëŒ€ê¸°ì—…', 'ì¤‘ì†Œê¸°ì—…', 'ìŠ¤íƒ€íŠ¸ì—…'],
        'model': ['êµ¬ë…', 'ì¼íšŒì„±', 'í”„ë¦¬ë¯¸ì—„', 'ë¬´ë£Œ'],
    }
    
    modifiers = []
    for category, keywords in modifier_categories.items():
        for keyword in keywords:
            if keyword in question:
                modifiers.append(keyword)
    
    return modifiers
```

**4. domain_specificity_score (20% ê°€ì¤‘ì¹˜)**

```python
def _assess_domain_specificity(self, question: str) -> Tuple[str, float]:
    """
    ë„ë©”ì¸ íŠ¹ìˆ˜ì„± í‰ê°€
    
    Strategy:
      1. ì „ë¬¸ ìš©ì–´ ì„ë² ë”© ìœ ì‚¬ë„ ì²´í¬
      2. LLMì—ê²Œ ë„ë©”ì¸ íŒë‹¨ ì§ˆë¬¸
      3. ì¢…í•© í‰ê°€
    
    Returns:
        (domain_level, score): ìˆ˜ì¤€ê³¼ ì ìˆ˜ (0.0 ~ 1.0)
    """
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Method 1: ì „ë¬¸ ìš©ì–´ ì„ë² ë”© ìœ ì‚¬ë„
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    expert_similarity = self._check_expert_term_similarity(question)
    
    if expert_similarity >= 0.8:
        return ('expert', 1.0)
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # Method 2: LLM íŒë‹¨
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    llm_assessment = self._assess_domain_with_llm(question)
    
    return (llm_assessment['level'], llm_assessment['score'])


def _check_expert_term_similarity(self, question: str) -> float:
    """ì „ë¬¸ ìš©ì–´ì™€ì˜ ì„ë² ë”© ìœ ì‚¬ë„ ì²´í¬"""
    
    # ì „ë¬¸ ìš©ì–´ DB (ì„ë² ë”© ë¯¸ë¦¬ ê³„ì‚°)
    expert_terms = [
        'Churn', 'MRR', 'ARR', 'CAC Payback', 'Rule of 40',
        'Unit Economics', 'Cohort Analysis', 'EBITDA', 'Burn Rate'
    ]
    
    # ì§ˆë¬¸ ì„ë² ë”©
    q_embedding = self._get_embedding(question)
    
    # ê° ì „ë¬¸ ìš©ì–´ì™€ ìœ ì‚¬ë„ ê³„ì‚°
    similarities = []
    for term in expert_terms:
        term_embedding = self._get_embedding(term)
        similarity = self._cosine_similarity(q_embedding, term_embedding)
        similarities.append(similarity)
    
    # ìµœëŒ€ ìœ ì‚¬ë„ ë°˜í™˜
    return max(similarities) if similarities else 0.0


def _assess_domain_with_llm(self, question: str) -> Dict:
    """LLMì—ê²Œ ë„ë©”ì¸ ìˆ˜ì¤€ íŒë‹¨ ì§ˆë¬¸"""
    
    prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì§€ì‹ ìˆ˜ì¤€ì„ íŒë‹¨í•˜ì„¸ìš”.

ì§ˆë¬¸: "{question}"

ìˆ˜ì¤€:
1. general: ì¼ë°˜ ìƒì‹ (ì˜ˆ: "ì¸êµ¬", "ë©´ì ", "ë‚ ì”¨")
2. industry: ì‚°ì—… ì§€ì‹ (ì˜ˆ: "ë§¤ì¶œ", "ê³ ê°", "ì‹œì¥")
3. expert: ì „ë¬¸ê°€ ì§€ì‹ (ì˜ˆ: "Churn Rate", "Unit Economics", "EBITDA")

JSONìœ¼ë¡œ ë‹µí•˜ì„¸ìš”:
{{
  "level": "general" | "industry" | "expert",
  "score": 0.0-1.0,
  "domain": "êµ¬ì²´ì  ë„ë©”ì¸ (ì˜ˆ: B2B_SaaS, E-commerce)",
  "reason": "..."
}}"""

    response = self._call_llm(prompt, max_tokens=150)
    
    try:
        result = json.loads(response)
        
        # ì ìˆ˜ ë§¤í•‘
        score_mapping = {
            'general': 0.0,
            'industry': 0.5,
            'expert': 1.0
        }
        
        return {
            'level': result['level'],
            'score': score_mapping.get(result['level'], 0.5),
            'domain': result.get('domain', 'Unknown'),
            'reason': result.get('reason', '')
        }
    
    except:
        # ì‹¤íŒ¨ ì‹œ ì¤‘ê°„ê°’
        return {'level': 'industry', 'score': 0.5}
```

**Complete Example**:

```python
def analyze(self, question: str, context: Optional[Context] = None) -> ComplexityResult:
    """ì™„ì „í•œ ë³µì¡ë„ ë¶„ì„ ì˜ˆì œ"""
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ì˜ˆì œ 1: "í•œêµ­ ì¸êµ¬ëŠ”?"
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    question = "í•œêµ­ ì¸êµ¬ëŠ”?"
    
    # 1. ì§ˆë¬¸ ìœ í˜•: factual
    q_type, q_score = self._classify_question_type(question)
    # â†’ ('factual', 0.0)
    
    # 2. ë°ì´í„° ê°€ìš©ì„±: ê³µì‹ í†µê³„
    d_score = self._check_data_availability(question, context)
    # â†’ 0.1 (í†µê³„ì²­ ë°ì´í„° ìˆìŒ)
    
    # 3. ë³€ìˆ˜ ê°œìˆ˜: 0ê°œ
    v_count, v_score = self._estimate_variable_count(question)
    # â†’ (0, 0.0)
    
    # 4. ë„ë©”ì¸ íŠ¹ìˆ˜ì„±: general
    domain, domain_score = self._assess_domain_specificity(question)
    # â†’ ('general', 0.0)
    
    # ì¢…í•© ì ìˆ˜
    total_score = (
        0.0 * 0.30 +   # question_type
        0.1 * 0.25 +   # data_availability
        0.0 * 0.25 +   # variable_count
        0.0 * 0.20     # domain_specificity
    ) = 0.025
    
    # ê²°ê³¼: 0.025 < 0.25 â†’ Tier 1 âœ…
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ì˜ˆì œ 2: "í•œêµ­ ìŒì‹ì  ì›”í‰ê·  ë§¤ì¶œì€?"
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    question = "í•œêµ­ ìŒì‹ì  ì›”í‰ê·  ë§¤ì¶œì€?"
    
    # 1. ì§ˆë¬¸ ìœ í˜•: simple_estimate
    # â†’ ('simple_estimate', 0.3)
    
    # 2. ë°ì´í„° ê°€ìš©ì„±: ì‚°ì—… ë³´ê³ ì„œ ê°€ëŠ¥
    # â†’ 0.3
    
    # 3. ë³€ìˆ˜ ê°œìˆ˜: 3ê°œ (ì¢Œì„ Ã— íšŒì „ Ã— ê°ë‹¨ê°€)
    # â†’ (3, 0.6)
    
    # 4. ë„ë©”ì¸ íŠ¹ìˆ˜ì„±: industry
    # â†’ ('industry', 0.5)
    
    # ì¢…í•© ì ìˆ˜
    total_score = (
        0.3 * 0.30 +   # 0.09
        0.3 * 0.25 +   # 0.075
        0.6 * 0.25 +   # 0.15
        0.5 * 0.20     # 0.10
    ) = 0.415
    
    # ê²°ê³¼: 0.25 < 0.415 < 0.60 â†’ Tier 2 âœ…
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ì˜ˆì œ 3: "í•œêµ­ B2B SaaS ì‹œì¥ ê·œëª¨ëŠ”?"
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    question = "í•œêµ­ B2B SaaS ì‹œì¥ ê·œëª¨ëŠ”?"
    
    # 1. ì§ˆë¬¸ ìœ í˜•: complex_estimate
    # â†’ ('complex_estimate', 0.7)
    
    # 2. ë°ì´í„° ê°€ìš©ì„±: ë³´ê³ ì„œ ìˆì§€ë§Œ ê³„ì‚° í•„ìš”
    # â†’ 0.5
    
    # 3. ë³€ìˆ˜ ê°œìˆ˜: 5ê°œ ì´ìƒ
    # â†’ (5, 0.6)
    
    # 4. ë„ë©”ì¸ íŠ¹ìˆ˜ì„±: industry
    # â†’ ('industry', 0.5)
    
    # ì¢…í•© ì ìˆ˜
    total_score = (
        0.7 * 0.30 +   # 0.21
        0.5 * 0.25 +   # 0.125
        0.6 * 0.25 +   # 0.15
        0.5 * 0.20     # 0.10
    ) = 0.585
    
    # ê²°ê³¼: 0.25 < 0.585 < 0.60 â†’ Tier 2 (ê²½ê³„ì„ )
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ì˜ˆì œ 4: "3ë…„ í›„ AI ì‹œì¥ Unit EconomicsëŠ”?"
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    question = "3ë…„ í›„ AI ì‹œì¥ Unit EconomicsëŠ”?"
    
    # 1. ì§ˆë¬¸ ìœ í˜•: prediction
    # â†’ ('prediction', 0.9)
    
    # 2. ë°ì´í„° ê°€ìš©ì„±: ë°ì´í„° ì—†ìŒ
    # â†’ 1.0
    
    # 3. ë³€ìˆ˜ ê°œìˆ˜: 5ê°œ+
    # â†’ (5, 1.0)
    
    # 4. ë„ë©”ì¸ íŠ¹ìˆ˜ì„±: expert
    # â†’ ('expert', 1.0)
    
    # ì¢…í•© ì ìˆ˜
    total_score = (
        0.9 * 0.30 +   # 0.27
        1.0 * 0.25 +   # 0.25
        1.0 * 0.25 +   # 0.25
        1.0 * 0.20     # 0.20
    ) = 0.97
    
    # ê²°ê³¼: 0.97 >= 0.60 â†’ Tier 3 âœ…
    
    return ComplexityResult(
        score=total_score,
        recommended_tier=3,
        strategy="fermi_decomposition",
        signals={
            'question_type': ('prediction', 0.9),
            'data_availability': 1.0,
            'estimated_variables': (5, 1.0),
            'domain_specificity': ('expert', 1.0)
        },
        reasoning=[
            "ì§ˆë¬¸ ìœ í˜•: prediction (ì ìˆ˜ 0.9)",
            "ë°ì´í„° ê°€ìš©ì„±: ì—†ìŒ (ì ìˆ˜ 1.0)",
            "ì˜ˆìƒ ë³€ìˆ˜: 5ê°œ (ì ìˆ˜ 1.0)",
            "ë„ë©”ì¸ íŠ¹ìˆ˜ì„±: expert (ì ìˆ˜ 1.0)",
            "ì¢…í•© ì ìˆ˜: 0.97 â†’ Tier 3 ì¶”ì²œ (Fermi Decomposition)"
        ]
    )
```

---

### 2.2 ContextAnalyzer

**Responsibility**: ì§ˆë¬¸ ë§¥ë½ íŒŒì•… (ì˜ë„, ë„ë©”ì¸, ì„¸ë¶„í™” ë“±)

**Input**:
```python
question: str              # ì§ˆë¬¸
external_context: Dict     # ì™¸ë¶€ ë§¥ë½ (Fermi ì¬ê·€ ì‹œ ë¶€ëª¨ ì •ë³´)
```

**Output**:
```python
Context:
    intent: str                    # "get_value", "understand_market", etc.
    domain: str                    # "B2B_SaaS", "Consumer", etc.
    granularity: str               # "macro", "segment", "micro"
    spatiotemporal: Dict           # {region, time_period}
    parent_model: Optional[Model]  # Fermi ì¬ê·€ ì‹œ ë¶€ëª¨ ëª¨í˜•
    variable_role: Optional[str]   # ë³€ìˆ˜ ì—­í• 
    constraints: List[Constraint]  # ì œì•½ì¡°ê±´
    project_data: Dict             # í”„ë¡œì íŠ¸ ë°ì´í„°
```

**Implementation Strategy**:

```yaml
Hybrid Approach (ê·œì¹™ + LLM):

1. Intent ì¶”ë¡ :
   ê·œì¹™ (90%):
     - "ì°½ì—…", "ê³ ë ¤" â†’ make_decision
     - "ë¶„ì„", "ì´í•´" â†’ understand_market
     - "vs", "ë¹„êµ" â†’ compare
     - "ì˜ˆì¸¡", "ë…„ í›„" â†’ prediction
   
   LLM (10%):
     - ëª¨í˜¸í•œ ê²½ìš° LLMì—ê²Œ ì§ˆë¬¸
     - Native Mode $0

2. Domain ì¶”ë¡ :
   ê·œì¹™ (95%):
     - "SaaS", "êµ¬ë…" â†’ B2B_SaaS
     - "ìŒì‹ì ", "ì¹´í˜" â†’ Food_Service
     - í‚¤ì›Œë“œ ë§¤ì¹­
   
   LLM (5%):
     - ìƒˆë¡œìš´ ì‚°ì—…/ë„ë©”ì¸
     - "í”¼ì ë°°ë‹¬", "ìœ ì•„ìš© ì¥ë‚œê°" ë“±

3. Spatiotemporal ì¶”ì¶œ:
   ê·œì¹™ (100%):
     - ì •ê·œì‹: "í•œêµ­", "2024ë…„", "3ë…„ í›„"
     - NER (Named Entity Recognition)
   
   LLM: ë¶ˆí•„ìš” (ê·œì¹™ìœ¼ë¡œ ì¶©ë¶„)

4. Granularity:
   ê·œì¹™ (100%):
     - ìˆ˜ì‹ì–´ ê°œìˆ˜ ì¹´ìš´íŠ¸
     - 0-1ê°œ: macro
     - 2-3ê°œ: segment
     - 4ê°œ+: micro
   
   LLM: ë¶ˆí•„ìš”
```

**Key Methods**:
```python
def _infer_intent(question: str) -> str:
    """
    ì˜ë„ ì¶”ë¡ 
    
    Strategy:
      1. í‚¤ì›Œë“œ íŒ¨í„´ ì²´í¬ (ê·œì¹™)
      2. ëª¨í˜¸í•˜ë©´ LLM
    """
    # ê·œì¹™ ì²´í¬
    if any(word in question for word in ['ì°½ì—…', 'ê³ ë ¤', 'ì‹œì‘']):
        return 'make_decision'
    
    if any(word in question for word in ['ë¶„ì„', 'ì´í•´', 'íŒŒì•…']):
        return 'understand_market'
    
    # ... ë” ë§ì€ ê·œì¹™
    
    # ëª¨í˜¸í•¨ â†’ LLM
    return _infer_intent_with_llm(question)

def _infer_domain(question: str) -> str:
    """
    ë„ë©”ì¸ ì¶”ë¡ 
    
    Strategy:
      1. í‚¤ì›Œë“œ ë§¤ì¹­ (ê·œì¹™)
      2. ì—†ìœ¼ë©´ LLM
    """
    # ê·œì¹™ ì²´í¬
    domain_keywords = {
        'B2B_SaaS': ['SaaS', 'êµ¬ë…', 'B2B', 'í´ë¼ìš°ë“œ'],
        'Food_Service': ['ìŒì‹ì ', 'ì¹´í˜', 'ë ˆìŠ¤í† ë‘'],
        'E-commerce': ['ì»¤ë¨¸ìŠ¤', 'ì‡¼í•‘ëª°', 'ì˜¨ë¼ì¸ëª°'],
        # ...
    }
    
    for domain, keywords in domain_keywords.items():
        if any(kw in question for kw in keywords):
            return domain
    
    # ìƒˆë¡œìš´ ë„ë©”ì¸ â†’ LLM
    return _infer_domain_with_llm(question)

def _extract_spatiotemporal(question: str) -> Dict:
    """
    ì‹œê³µê°„ ì¶”ì¶œ
    
    Strategy:
      ì •ê·œì‹ë§Œ ì‚¬ìš© (LLM ë¶ˆí•„ìš”)
    """
    # ì§€ì—­ ì¶”ì¶œ
    region_patterns = {
        'í•œêµ­': r'í•œêµ­|ëŒ€í•œë¯¼êµ­|Korea',
        'ì„œìš¸': r'ì„œìš¸',
        'ë¯¸êµ­': r'ë¯¸êµ­|US|USA',
        # ...
    }
    
    # ì‹œê°„ ì¶”ì¶œ
    time_patterns = {
        'future': r'(\d+)ë…„\s*í›„',
        'year': r'(\d{4})ë…„',
        # ...
    }
    
    return {
        'region': extract_region(question, region_patterns),
        'time_period': extract_time(question, time_patterns)
    }

def _infer_granularity(question: str) -> str:
    """
    ì„¸ë¶„í™” ìˆ˜ì¤€
    
    Strategy:
      ìˆ˜ì‹ì–´ ê°œìˆ˜ë§Œ ì¹´ìš´íŠ¸ (LLM ë¶ˆí•„ìš”)
    """
    modifiers = extract_modifiers(question)
    count = len(modifiers)
    
    if count <= 1:
        return 'macro'
    elif count <= 3:
        return 'segment'
    else:
        return 'micro'
```

**LLM ì‚¬ìš© ë¹„ìœ¨**:
```yaml
Intent: 10% (ëŒ€ë¶€ë¶„ ê·œì¹™ìœ¼ë¡œ ì»¤ë²„)
Domain: 5% (ìƒˆë¡œìš´ ì‚°ì—…ë§Œ)
Spatiotemporal: 0% (ì •ê·œì‹ ì¶©ë¶„)
Granularity: 0% (ì¹´ìš´íŠ¸ë§Œ)

ì „ì²´: ~5% LLM ì‚¬ìš©
     95% ê·œì¹™ ê¸°ë°˜ (ë¹ ë¥´ê³  ë¹„ìš© ì—†ìŒ)
```

---

### 2.3 EvidenceCollector

**Responsibility**: 8ê°œ Layerì—ì„œ ì¦ê±° ìˆ˜ì§‘

**Input**:
```python
question: str
context: Context
layers: List[str]          # ìˆ˜ì§‘í•  Layer ë¦¬ìŠ¤íŠ¸
mode: str = "parallel"     # "parallel" or "sequential"
```

**Output**:
```python
List[Evidence]:
    Evidence:
        success: bool
        value: Optional[float]
        confidence: float          # 0.0 ~ 1.0
        source: str                # Layer ì´ë¦„
        source_detail: str         # ìƒì„¸ ì¶œì²˜
        reasoning: str             # ê·¼ê±°
        raw_data: Any              # ì›ë³¸ ë°ì´í„°
        metadata: Dict             # ë©”íƒ€ë°ì´í„°
```

**8 Layers**:
```python
1. project_data      # í”„ë¡œì íŠ¸ ë°ì´í„°
2. llm_direct        # LLM ì§ì ‘ ë‹µë³€
3. web_search        # ì›¹ ê²€ìƒ‰
4. law               # ë¬¼ë¦¬/ë²•ë¥  ë²•ì¹™
5. behavioral        # í–‰ë™ê²½ì œí•™
6. statistical       # í†µê³„ íŒ¨í„´
7. rag_benchmark     # RAG ë²¤ì¹˜ë§ˆí¬
8. constraint        # ì œì•½ì¡°ê±´
```

**Key Features**:
- ë³‘ë ¬ ìˆ˜ì§‘ ì§€ì› (ThreadPoolExecutor)
- ì‹¤íŒ¨ í—ˆìš© (ì¼ë¶€ Layer ì‹¤íŒ¨í•´ë„ ê³„ì†)
- íƒ€ì„ì•„ì›ƒ ì„¤ì • (Layerë³„)

---

### 2.4 JudgmentSynthesizer

**Responsibility**: ì—¬ëŸ¬ ì¦ê±°ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… íŒë‹¨

**Input**:
```python
evidence_list: List[Evidence]
context: Context
```

**Output**:
```python
JudgmentResult:
    value: float                   # ìµœì¢… ê°’
    confidence: float              # ì‹ ë¢°ë„ (0.0 ~ 1.0)
    uncertainty: float             # ë¶ˆí™•ì‹¤ì„± (Â±%)
    strategy: str                  # ì‚¬ìš©í•œ ì¢…í•© ì „ëµ
    all_evidence: List[Dict]       # í‰ê°€ëœ ëª¨ë“  ì¦ê±°
    reasoning: str                 # íŒë‹¨ ê·¼ê±°
    value_range: Optional[Tuple]   # ë²”ìœ„ (ì „ëµì´ "range"ì¼ ë•Œ)
```

**Synthesis Strategies**:
```python
1. single_best:
   - ì¡°ê±´: ìµœê³  ê°€ì¤‘ì¹˜ â‰¥ 0.9 && ë‹¤ë¥¸ ì¦ê±°ì™€ ì°¨ì´ â‰¥ 0.3
   - ë°©ë²•: ê°€ì¥ ì¢‹ì€ ì¦ê±° í•˜ë‚˜ë§Œ ì‚¬ìš©

2. weighted_average:
   - ì¡°ê±´: ì—¬ëŸ¬ ì¦ê±°ê°€ ë¹„ìŠ·í•œ ê°€ì¤‘ì¹˜
   - ë°©ë²•: ê°€ì¤‘ í‰ê· 

3. conservative:
   - ì¡°ê±´: context.intent == "make_decision"
   - ë°©ë²•: ë³´ìˆ˜ì  í•˜í•œ

4. range:
   - ì¡°ê±´: ì¦ê±°ë“¤ì´ í¬ê²Œ ë‹¤ë¦„
   - ë°©ë²•: ë²”ìœ„ ì œì‹œ (min ~ max)
```

**Evidence Evaluation**:
```python
EvaluationScore:
    relevance: float      # ë§¥ë½ ì í•©ë„ (0.0 ~ 1.0)
    reliability: float    # ì‹ ë¢°ì„± (0.0 ~ 1.0)
    recency: float        # ìµœì‹ ì„± (0.0 ~ 1.0)
    overall: float        # ì¢…í•© ê°€ì¤‘ì¹˜
    
overall = relevance * 0.5 + reliability * 0.3 + recency * 0.2
```

---

## ğŸ”„ 3. Tier Specifications

### 3.1 Tier 1: Fast Path

**Target**: 90% of cases
**Goal**: í™•ì‹¤í•œ ë‹µì´ ìˆì„ ë•Œ ì¦‰ì‹œ ë¦¬í„´

**Flow**:
```
1. Check project_data (confidence â‰¥ 0.95)
   â†“ not found
2. Check physical/legal laws (confidence = 1.0)
   â†“ not applicable
3. Check simple factual LLM (confidence â‰¥ 0.9)
   â†“ not simple or low confidence
4. Return None â†’ Go to Tier 2
```

**Performance**:
- Time: <1 second
- Cost: $0 ~ $0.001
- Confidence: â‰¥ 0.9

---

### 3.2 Tier 2: Judgment Path

**Target**: 8% of cases
**Goal**: ì¤‘ê°„ ë³µì¡ë„, ì—¬ëŸ¬ ì¦ê±° ì¢…í•©

**Flow**:
```
1. ContextAnalyzer.analyze()
   â†“
2. Select relevant layers (3-5 layers)
   â†“
3. EvidenceCollector.collect(parallel=True)
   â†“
4. JudgmentSynthesizer.synthesize()
   â†“
5. If confidence â‰¥ 0.6: Return
   Else: Go to Tier 3
```

**Performance**:
- Time: 2-5 seconds
- Cost: $0.01 ~ $0.05
- Confidence: 0.6 ~ 0.9

---

### 3.3 Tier 3: Fermi Recursion

**Target**: 2% of cases
**Goal**: ë§¤ìš° ë³µì¡, Decomposition í•„ìš”

**Flow**:
```
1. Check depth limit (max 4)
   â†“
2. Generate Fermi model (LLM)
   â†“
3. For each variable:
      - Create child context
      - Recursive call: estimate(variable, child_context, depth+1)
      - Result goes through Tier 1-2-3 again
   â†“
4. Calculate final value from model
   â†“
5. Propagate uncertainty
   â†“
6. Return result
```

**Recursion Escape**:
```python
if depth >= MAX_DEPTH:
    # Force judgment
    result = tier2_judgment_path(question, context)
    if result:
        return result
    else:
        # Last resort: constraint-based range
        return estimate_by_constraints(question, context)
```

**Performance**:
- Time: 10-30 seconds
- Cost: $0.1 ~ $1
- Confidence: 0.5 ~ 0.8

---

## ğŸ“Š 4. Data Models

### 4.1 Core Data Classes

**ComplexityResult**:
```python
@dataclass
class ComplexityResult:
    """ë³µì¡ë„ ë¶„ì„ ê²°ê³¼"""
    score: float                    # 0.0 ~ 1.0
    recommended_tier: int           # 1, 2, 3
    strategy: str                   # "fast_path" | "judgment" | "fermi"
    
    signals: Dict[str, Any]         # íŒë‹¨ ê·¼ê±°
    # {
    #   'question_type': ('simple_estimate', 0.3),
    #   'data_availability': 0.4,
    #   'estimated_variables': (3, 0.6),
    #   'domain_specificity': 0.5
    # }
    
    reasoning: List[str]            # ì¶”ë¡  ê³¼ì •
    # [
    #   "ì§ˆë¬¸ ìœ í˜•: simple_estimate (ì ìˆ˜ 0.3)",
    #   "ë°ì´í„° ê°€ìš©ì„±: ì¤‘ê°„ (ì ìˆ˜ 0.4)",
    #   "ì˜ˆìƒ ë³€ìˆ˜: 3ê°œ (ì ìˆ˜ 0.6)",
    #   "ì¢…í•© ì ìˆ˜: 0.45 â†’ Tier 2 ì¶”ì²œ"
    # ]
    
    metadata: Dict[str, Any] = field(default_factory=dict)
```

**Context**:
```python
@dataclass
class Context:
    """ì§ˆë¬¸ ë§¥ë½"""
    intent: str                     # "get_value" | "understand_market" | "make_decision" | "compare" | "predict"
    domain: str                     # "B2B_SaaS" | "Consumer" | "FinTech" | "HealthTech" | "General"
    granularity: str                # "macro" | "segment" | "micro"
    
    spatiotemporal: Dict[str, str]  # {region: "í•œêµ­", time_period: "2024"}
    
    # Fermi ì¬ê·€ ê´€ë ¨
    parent_model: Optional['FermiModel'] = None
    variable_role: Optional[str] = None      # "ARPU", "customer_count" etc.
    
    # ì œì•½ì¡°ê±´
    constraints: List['Constraint'] = field(default_factory=list)
    
    # í”„ë¡œì íŠ¸ ë°ì´í„°
    project_data: Dict[str, Any] = field(default_factory=dict)
    
    # ë©”íƒ€ë°ì´í„°
    depth: int = 0                  # ì¬ê·€ ê¹Šì´
    parent_question: Optional[str] = None
```

**Evidence**:
```python
@dataclass
class Evidence:
    """ì¦ê±° (í•˜ë‚˜ì˜ Layer ê²°ê³¼)"""
    success: bool
    
    # ê°’
    value: Optional[float] = None
    value_range: Optional[Tuple[float, float]] = None
    
    # ì‹ ë¢°ë„
    confidence: float = 0.0         # Layer ìì²´ ì‹ ë¢°ë„
    
    # ì¶œì²˜
    source: str = ""                # "project_data" | "llm_direct" | "web_search" | ...
    source_detail: str = ""         # ìƒì„¸ ì¶œì²˜ ("í†µê³„ì²­ 2023ë…„ ë°ì´í„°")
    
    # ê·¼ê±°
    reasoning: str = ""
    raw_data: Any = None            # ì›ë³¸ ë°ì´í„°
    
    # ë©”íƒ€ë°ì´í„°
    metadata: Dict[str, Any] = field(default_factory=dict)
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
```

**EvaluationScore**:
```python
@dataclass
class EvaluationScore:
    """ì¦ê±° í‰ê°€ ì ìˆ˜"""
    relevance: float                # ë§¥ë½ ì í•©ë„ (0.0 ~ 1.0)
    reliability: float              # ì‹ ë¢°ì„± (0.0 ~ 1.0)
    recency: float                  # ìµœì‹ ì„± (0.0 ~ 1.0)
    overall: float                  # ì¢…í•© ê°€ì¤‘ì¹˜
    
    details: Dict[str, Any] = field(default_factory=dict)
    # {
    #   'relevance_factors': {
    #       'region_match': 0.7,
    #       'time_match': 1.0,
    #       'granularity_match': 0.9
    #   },
    #   'reliability_factors': {
    #       'source_base': 0.7,
    #       'confidence_adjusted': 0.49
    #   }
    # }
```

**JudgmentResult**:
```python
@dataclass
class JudgmentResult:
    """íŒë‹¨ ê²°ê³¼"""
    value: float                    # ìµœì¢… íŒë‹¨ ê°’
    confidence: float               # ì‹ ë¢°ë„ (0.0 ~ 1.0)
    uncertainty: float              # ë¶ˆí™•ì‹¤ì„± (Â±%)
    
    strategy: str                   # "single_best" | "weighted_average" | "conservative" | "range"
    
    all_evidence: List[Dict]        # í‰ê°€ëœ ëª¨ë“  ì¦ê±°
    # [
    #   {
    #       'evidence': Evidence(...),
    #       'evaluation': EvaluationScore(...),
    #       'weight': 0.8
    #   },
    #   ...
    # ]
    
    reasoning: str                  # íŒë‹¨ ê·¼ê±°
    value_range: Optional[Tuple[float, float]] = None  # ì „ëµì´ "range"ì¼ ë•Œ
    
    metadata: Dict[str, Any] = field(default_factory=dict)
```

**EstimationResult** (ìµœì¢… ë¦¬í„´):
```python
@dataclass
class EstimationResult:
    """ìµœì¢… ì¶”ì • ê²°ê³¼"""
    question: str
    
    # ê°’
    value: Optional[float] = None
    value_range: Optional[Tuple[float, float]] = None
    
    # ë©”íƒ€ ì •ë³´
    tier: int = 0                   # 1, 2, 3
    source: str = ""                # "fast_path" | "judgment" | "fermi"
    confidence: float = 0.0
    uncertainty: float = 0.0
    
    # ì¶”ë¡  ê³¼ì •
    reasoning: str = ""
    logic_steps: List[str] = field(default_factory=list)
    
    # Tier 2 ì „ìš©
    judgment_result: Optional[JudgmentResult] = None
    
    # Tier 3 ì „ìš©
    fermi_model: Optional['FermiModel'] = None
    variable_results: Dict[str, 'EstimationResult'] = field(default_factory=dict)
    
    # ë©”íƒ€ë°ì´í„°
    complexity: Optional[ComplexityResult] = None
    context: Optional[Context] = None
    execution_time: float = 0.0     # seconds
    cost: float = 0.0               # dollars
    
    def is_successful(self) -> bool:
        return self.value is not None or self.value_range is not None
    
    def get_display_value(self) -> str:
        if self.value is not None:
            return f"{self.value:,.0f}"
        elif self.value_range:
            return f"{self.value_range[0]:,.0f} ~ {self.value_range[1]:,.0f}"
        return "ì¶”ì • ë¶ˆê°€"
```

### 4.2 Constraint Models

```python
@dataclass
class Constraint:
    """ì œì•½ì¡°ê±´"""
    type: str                       # "physical" | "legal" | "logical" | "temporal"
    description: str
    
    # ìˆ˜ì¹˜ ì œì•½
    min_value: Optional[float] = None
    max_value: Optional[float] = None
    
    # ê´€ê³„ ì œì•½
    relationship: Optional[str] = None  # "X < Y", "X + Y = Z"
    
    # ë©”íƒ€
    source: str = ""                # ì œì•½ì˜ ì¶œì²˜
    confidence: float = 1.0         # ì œì•½ì˜ í™•ì‹¤ì„±
```

### 4.3 Configuration Models

```python
@dataclass
class Tier1Config:
    """Tier 1 ì„¤ì •"""
    enabled: bool = True
    
    min_confidence_project_data: float = 0.95
    min_confidence_law: float = 1.0
    min_confidence_llm_factual: float = 0.9
    
    timeout_seconds: float = 1.0

@dataclass
class Tier2Config:
    """Tier 2 ì„¤ì •"""
    enabled: bool = True
    
    min_confidence: float = 0.6
    min_evidence_count: int = 2
    max_evidence_count: int = 5
    
    collection_mode: str = "parallel"  # "parallel" | "sequential"
    timeout_seconds: float = 5.0
    
    synthesis_strategy: str = "auto"   # "auto" | "single_best" | "weighted_average" | ...

@dataclass
class Tier3Config:
    """Tier 3 ì„¤ì •"""
    enabled: bool = True
    
    max_depth: int = 4
    timeout_seconds: float = 30.0
    
    force_judgment_at_max_depth: bool = True

@dataclass
class GuestimationConfig:
    """ì „ì²´ ì‹œìŠ¤í…œ ì„¤ì •"""
    tier1: Tier1Config = field(default_factory=Tier1Config)
    tier2: Tier2Config = field(default_factory=Tier2Config)
    tier3: Tier3Config = field(default_factory=Tier3Config)
    
    # LLM ëª¨ë“œ (ì „ì—­)
    llm_mode: str = "native"        # "native" | "external" | "skip"
    
    # ì›¹ ê²€ìƒ‰ ëª¨ë“œ (Guestimation ì „ìš©)
    web_search_mode: str = "native" # "native" | "external" | "skip"
    
    # ì¸í„°ë™í‹°ë¸Œ ëª¨ë“œ
    interactive_mode: bool = False
    
    # ë¡œê¹…
    verbose: bool = False
    log_all_evidence: bool = True
```

---

## ğŸ”Œ 5. API Definitions

### 5.1 Main Entry Point

```python
def estimate(
    question: str,
    context: Optional[Union[Dict, Context]] = None,
    depth: int = 0,
    config: Optional[GuestimationConfig] = None
) -> EstimationResult:
    """
    ë©”ì¸ ì¶”ì • í•¨ìˆ˜
    
    Args:
        question: ì¶”ì • ì§ˆë¬¸
            ì˜ˆ: "í•œêµ­ ìŒì‹ì  ì›”í‰ê·  ë§¤ì¶œì€?"
        
        context: ë§¥ë½ ì •ë³´ (optional)
            - Dict: ìë™ìœ¼ë¡œ Context ê°ì²´ë¡œ ë³€í™˜
            - Context: ì§ì ‘ ì œê³µ
            - None: ë¹ˆ Context ìƒì„±
        
        depth: ì¬ê·€ ê¹Šì´ (ë‚´ë¶€ ì‚¬ìš©, ì¼ë°˜ ì‚¬ìš©ìëŠ” 0)
        
        config: ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ (optional)
            - None: ì „ì—­ ì„¤ì • ì‚¬ìš© (multilayer_config.yaml + .env)
    
    Returns:
        EstimationResult: ì¶”ì • ê²°ê³¼
    
    Example:
        >>> result = estimate("í•œêµ­ ìŒì‹ì  ì›”í‰ê·  ë§¤ì¶œì€?")
        >>> print(f"ê°’: {result.value:,.0f}ì›")
        >>> print(f"ì‹ ë¢°ë„: {result.confidence:.1%}")
        >>> print(f"Tier: {result.tier}")
        
        ê°’: 2,700,000ì›
        ì‹ ë¢°ë„: 75.0%
        Tier: 2
    """
```

### 5.2 ComplexityAnalyzer API

```python
class ComplexityAnalyzer:
    def analyze(
        self, 
        question: str, 
        context: Optional[Context] = None
    ) -> ComplexityResult:
        """
        ë³µì¡ë„ ë¶„ì„
        
        Args:
            question: ì§ˆë¬¸
            context: ë§¥ë½ (optional)
        
        Returns:
            ComplexityResult
        """
    
    # Private methods (êµ¬í˜„ ì°¸ì¡°ìš©)
    def _classify_question_type(self, question: str) -> str:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜"""
    
    def _check_data_availability(
        self, 
        question: str, 
        context: Optional[Context]
    ) -> float:
        """ë°ì´í„° ê°€ìš©ì„± ì²´í¬"""
    
    def _estimate_variable_count(self, question: str) -> int:
        """ì˜ˆìƒ ë³€ìˆ˜ ê°œìˆ˜ ì¶”ì •"""
    
    def _assess_domain_specificity(self, question: str) -> float:
        """ë„ë©”ì¸ íŠ¹ìˆ˜ì„± í‰ê°€"""
```

### 5.3 ContextAnalyzer API

```python
class ContextAnalyzer:
    def analyze(
        self, 
        question: str, 
        external_context: Optional[Dict] = None
    ) -> Context:
        """
        ë§¥ë½ ë¶„ì„
        
        Args:
            question: ì§ˆë¬¸
            external_context: ì™¸ë¶€ ë§¥ë½
                - project_data: Dict
                - parent_model: FermiModel
                - constraints: List[Constraint]
        
        Returns:
            Context
        """
    
    # Private methods
    def _parse_question(self, question: str) -> Dict:
        """ì§ˆë¬¸ íŒŒì‹±"""
    
    def _infer_intent(self, question: str, parsed: Dict) -> str:
        """ì˜ë„ ì¶”ë¡ """
    
    def _infer_domain(self, question: str, parsed: Dict) -> str:
        """ë„ë©”ì¸ ì¶”ë¡ """
    
    def _infer_granularity(self, question: str) -> str:
        """ì„¸ë¶„í™” ìˆ˜ì¤€ ì¶”ë¡ """
    
    def _extract_spatiotemporal(self, question: str) -> Dict:
        """ì‹œê³µê°„ ë§¥ë½ ì¶”ì¶œ"""
```

### 5.4 EvidenceCollector API

```python
class EvidenceCollector:
    def collect(
        self,
        question: str,
        context: Context,
        layers: Optional[List[str]] = None,
        mode: str = "parallel"
    ) -> List[Evidence]:
        """
        ì¦ê±° ìˆ˜ì§‘
        
        Args:
            question: ì§ˆë¬¸
            context: ë§¥ë½
            layers: ìˆ˜ì§‘í•  Layer ë¦¬ìŠ¤íŠ¸
                - None: ë§¥ë½ì— ë”°ë¼ ìë™ ì„ íƒ
                - List: ì§€ì •ëœ Layerë§Œ
            mode: "parallel" or "sequential"
        
        Returns:
            List[Evidence]: ì„±ê³µí•œ ì¦ê±°ë“¤
        """
    
    def select_relevant_layers(
        self,
        question: str,
        context: Context
    ) -> List[str]:
        """
        ê´€ë ¨ Layer ìë™ ì„ íƒ
        
        Returns:
            List[str]: ["llm_direct", "web_search", "rag_benchmark"]
        """
    
    # Layer methods
    def try_layer(
        self,
        layer_name: str,
        question: str,
        context: Context
    ) -> Evidence:
        """ê°œë³„ Layer ì‹œë„"""
```

### 5.5 JudgmentSynthesizer API

```python
class JudgmentSynthesizer:
    def synthesize(
        self,
        evidence_list: List[Evidence],
        context: Context,
        strategy: str = "auto"
    ) -> JudgmentResult:
        """
        ì¦ê±° ì¢…í•© íŒë‹¨
        
        Args:
            evidence_list: ì¦ê±° ë¦¬ìŠ¤íŠ¸
            context: ë§¥ë½
            strategy: ì¢…í•© ì „ëµ
                - "auto": ìë™ ì„ íƒ
                - "single_best": ìµœê³  ì¦ê±°ë§Œ
                - "weighted_average": ê°€ì¤‘ í‰ê· 
                - "conservative": ë³´ìˆ˜ì  í•˜í•œ
                - "range": ë²”ìœ„ ì œì‹œ
        
        Returns:
            JudgmentResult
        """
    
    def evaluate_evidence(
        self,
        evidence: Evidence,
        context: Context
    ) -> EvaluationScore:
        """ê°œë³„ ì¦ê±° í‰ê°€"""
    
    def select_synthesis_strategy(
        self,
        evaluated_evidence: List[Dict],
        context: Context
    ) -> str:
        """ì¢…í•© ì „ëµ ìë™ ì„ íƒ"""
```

### 5.6 Tier Functions

```python
def tier1_fast_path(
    question: str,
    context: Context,
    config: Tier1Config
) -> Optional[EstimationResult]:
    """Tier 1 ì‹¤í–‰"""

def tier2_judgment_path(
    question: str,
    context: Context,
    config: Tier2Config
) -> Optional[EstimationResult]:
    """Tier 2 ì‹¤í–‰"""

def tier3_fermi_recursion(
    question: str,
    context: Context,
    depth: int,
    config: Tier3Config
) -> EstimationResult:
    """Tier 3 ì‹¤í–‰"""
```

---

## ğŸ› ï¸ 6. Implementation Guide

### 6.1 File Structure

```
umis_rag/
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ guestimation_v3/              # ì‹ ê·œ í´ë”
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ core.py                   # ë©”ì¸ Entry Point
â”‚   â”‚   â”œâ”€â”€ complexity.py             # ComplexityAnalyzer
â”‚   â”‚   â”œâ”€â”€ context.py                # ContextAnalyzer
â”‚   â”‚   â”œâ”€â”€ evidence.py               # EvidenceCollector
â”‚   â”‚   â”œâ”€â”€ judgment.py               # JudgmentSynthesizer
â”‚   â”‚   â”œâ”€â”€ tiers.py                  # Tier 1-2-3 Functions
â”‚   â”‚   â”œâ”€â”€ models.py                 # Data Models (All @dataclass)
â”‚   â”‚   â”œâ”€â”€ config.py                 # Configuration
â”‚   â”‚   â””â”€â”€ layers/                   # Layer êµ¬í˜„ (ì¬ì‚¬ìš©)
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ project_data.py
â”‚   â”‚       â”œâ”€â”€ llm_direct.py
â”‚   â”‚       â”œâ”€â”€ web_search.py
â”‚   â”‚       â”œâ”€â”€ law.py
â”‚   â”‚       â”œâ”€â”€ behavioral.py
â”‚   â”‚       â”œâ”€â”€ statistical.py
â”‚   â”‚       â”œâ”€â”€ rag_benchmark.py
â”‚   â”‚       â””â”€â”€ constraint.py
â”‚   â”‚
â”‚   â”œâ”€â”€ fermi_model_search.py         # ê¸°ì¡´ (ì¼ë¶€ ìˆ˜ì •)
â”‚   â”œâ”€â”€ guestimation.py               # v2.1 (ì¬ì‚¬ìš© ê°€ëŠ¥)
â”‚   â””â”€â”€ multilayer_guestimation.py    # v2.1 (Deprecated ì˜ˆì •)
â”‚
config/
â”œâ”€â”€ guestimation_v3_config.yaml       # ì‹ ê·œ ì„¤ì • íŒŒì¼
â””â”€â”€ multilayer_config.yaml            # v2.1 (í˜¸í™˜ ìœ ì§€)
```

### 6.2 Implementation Phases

**Phase 1: Data Models & Config (Day 1)**

```yaml
íŒŒì¼: umis_rag/utils/guestimation_v3/models.py
ì‘ì—…:
  - ComplexityResult
  - Context
  - Evidence
  - EvaluationScore
  - JudgmentResult
  - EstimationResult
  - Constraint
  - All Config classes

ì˜ˆìƒ: 300ì¤„
```

**Phase 2: Core Components (Day 1-2)**

```yaml
íŒŒì¼: umis_rag/utils/guestimation_v3/complexity.py
í´ë˜ìŠ¤: ComplexityAnalyzer
ë©”ì„œë“œ:
  - analyze()
  - _classify_question_type()
  - _check_data_availability()
  - _estimate_variable_count()
  - _assess_domain_specificity()
ì˜ˆìƒ: 250ì¤„

íŒŒì¼: umis_rag/utils/guestimation_v3/context.py
í´ë˜ìŠ¤: ContextAnalyzer
ë©”ì„œë“œ:
  - analyze()
  - _parse_question()
  - _infer_intent()
  - _infer_domain()
  - _infer_granularity()
  - _extract_spatiotemporal()
  - _extract_parent_info()
ì˜ˆìƒ: 300ì¤„
```

**Phase 3: Evidence & Judgment (Day 2-3)**

```yaml
íŒŒì¼: umis_rag/utils/guestimation_v3/evidence.py
í´ë˜ìŠ¤: EvidenceCollector
ë©”ì„œë“œ:
  - collect()
  - select_relevant_layers()
  - try_layer()
  - _collect_parallel()
  - _collect_sequential()
  - 8ê°œ Layer ë©”ì„œë“œ (ê¸°ì¡´ ì¬ì‚¬ìš©)
ì˜ˆìƒ: 400ì¤„ (ì¬ì‚¬ìš© 50%)

íŒŒì¼: umis_rag/utils/guestimation_v3/judgment.py
í´ë˜ìŠ¤: JudgmentSynthesizer
ë©”ì„œë“œ:
  - synthesize()
  - evaluate_evidence()
  - select_synthesis_strategy()
  - _score_relevance()
  - _score_reliability()
  - _score_recency()
  - _calculate_uncertainty()
  - 4ê°œ ì „ëµ ë©”ì„œë“œ
ì˜ˆìƒ: 350ì¤„
```

**Phase 4: Tier Functions (Day 3-4)**

```yaml
íŒŒì¼: umis_rag/utils/guestimation_v3/tiers.py
í•¨ìˆ˜:
  - tier1_fast_path()
  - tier2_judgment_path()
  - tier3_fermi_recursion()
ì˜ˆìƒ: 300ì¤„
```

**Phase 5: Main Entry & Integration (Day 4)**

```yaml
íŒŒì¼: umis_rag/utils/guestimation_v3/core.py
í•¨ìˆ˜:
  - estimate() (ë©”ì¸ Entry Point)
í´ë˜ìŠ¤:
  - GuestimationSystemV3
ì˜ˆìƒ: 200ì¤„
```

**Phase 6: Fermi Integration (Day 5)**

```yaml
íŒŒì¼: umis_rag/utils/fermi_model_search.py (ìˆ˜ì •)
ìˆ˜ì • ë‚´ìš©:
  - fermi_estimate() â†’ guestimation_v3.estimate() í˜¸ì¶œ
  - ë³€ìˆ˜ ì¶”ì • ë¡œì§ êµì²´
  - ì¬ê·€ íƒˆì¶œ ì¡°ê±´ ê°œì„ 
ì˜ˆìƒ: 50ì¤„ ìˆ˜ì •
```

**Phase 7: Testing & Debugging (Day 5-6)**

```yaml
íŒŒì¼: scripts/test_guestimation_v3.py
í…ŒìŠ¤íŠ¸:
  - Tier 1-2-3 ê°ê°
  - End-to-End
  - Fermi í†µí•©
ì˜ˆìƒ: 400ì¤„
```

### 6.3 Code Reuse Strategy

**ì¬ì‚¬ìš© ê°€ëŠ¥ (from v2.1)**:

```python
# umis_rag/utils/multilayer_guestimation.pyì—ì„œ ì¬ì‚¬ìš©

# Layer êµ¬í˜„ë“¤
def _try_project_data(question, context):
    # 200ì¤„ â†’ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©

def _try_law_based(question, context):
    # 150ì¤„ â†’ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©

def _try_behavioral(question, context, target_profile):
    # 180ì¤„ â†’ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©

def _try_statistical(question):
    # 120ì¤„ â†’ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©

def _try_constraint_boundary(question):
    # 100ì¤„ â†’ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©

# ì´ 750ì¤„ ì¬ì‚¬ìš© ê°€ëŠ¥!
```

**ì¬ì‘ì„± í•„ìš”**:

```python
# Sequential Fallback ë¡œì§ â†’ ì™„ì „ ì¬ì‘ì„±
def estimate(question, ...):
    # v2.1: Layer 1 â†’ ì„±ê³µ ì‹œ ì¦‰ì‹œ ë¦¬í„´
    # v3.0: Complexity ë¶„ì„ â†’ Tier ì„ íƒ â†’ ...
    
# ì•½ 500ì¤„ ì¬ì‘ì„±
```

### 6.4 Implementation Priorities

**P0 (Must Have - MVP)**:
```yaml
1. ComplexityAnalyzer (ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜)
2. ContextAnalyzer (ê¸°ë³¸ ë§¥ë½)
3. EvidenceCollector (3ê°œ Layerë§Œ: project_data, llm, law)
4. JudgmentSynthesizer (weighted_average ì „ëµë§Œ)
5. Tier 1-2 êµ¬í˜„
6. Main Entry Point
```

**P1 (Should Have - v3.0)**:
```yaml
1. ëª¨ë“  Layer êµ¬í˜„ (8ê°œ)
2. ëª¨ë“  ì¢…í•© ì „ëµ (4ê°œ)
3. Tier 3 (Fermi í†µí•©)
4. ê³ ê¸‰ ë§¥ë½ ë¶„ì„
```

**P2 (Nice to Have - v3.1+)**:
```yaml
1. ì„±ëŠ¥ ìµœì í™”
2. ìºì‹±
3. ì›¹ UI
4. í•™ìŠµ ê¸°ëŠ¥
```

### 6.5 Key Implementation Notes

**Note 1: LLM í˜¸ì¶œ ìµœì†Œí™”**

```python
# ë³µì¡ë„ ë¶„ì„ì—ì„œ LLM ì‚¬ìš© ìµœì†Œí™”
class ComplexityAnalyzer:
    def analyze(self, question, context):
        # âŒ LLMì— "ì´ ì§ˆë¬¸ì€ ì–¼ë§ˆë‚˜ ë³µì¡í•œê°€?" ë¬¼ì–´ë³´ê¸°
        # âœ… ê·œì¹™ ê¸°ë°˜ + íœ´ë¦¬ìŠ¤í‹±
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        if any(kw in question for kw in ['ì¸êµ¬', 'ë©´ì ', 'ì‹œê°„']):
            return simple
        
        # ë³€ìˆ˜ ê°œìˆ˜ ì¶”ì • (LLM ì—†ì´)
        estimated_vars = question.count('Ã—') + question.count('*')
        
        # ...
```

**Note 2: ë³‘ë ¬ ì²˜ë¦¬ ì£¼ì˜**

```python
# ThreadPoolExecutor ì‚¬ìš© ì‹œ íƒ€ì„ì•„ì›ƒ í•„ìˆ˜
def _collect_parallel(self, question, context, layers):
    with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
        futures = {
            executor.submit(
                self._try_layer_with_timeout,  # íƒ€ì„ì•„ì›ƒ ë˜í¼!
                layer, question, context
            ): layer
            for layer in layers
        }
        
        # as_completedë¡œ ë¹ ë¥¸ ê²ƒë¶€í„° ìˆ˜ì§‘
        for future in concurrent.futures.as_completed(futures, timeout=10):
            # ...
```

**Note 3: ì—ëŸ¬ í•¸ë“¤ë§**

```python
# ê°œë³„ Layer ì‹¤íŒ¨ëŠ” í—ˆìš©
def try_layer(self, layer_name, question, context):
    try:
        return self._layer_methods[layer_name](question, context)
    except Exception as e:
        logger.warning(f"Layer {layer_name} failed: {e}")
        return Evidence(success=False, error=str(e))

# í•˜ì§€ë§Œ ëª¨ë“  Layer ì‹¤íŒ¨ëŠ” ì—ëŸ¬
def collect(self, ...):
    evidence_list = [...]
    
    if not evidence_list:
        raise NoEvidenceFoundError("ëª¨ë“  Layer ì‹¤íŒ¨")
```

---

## âœ… 7. Testing Strategy

### 7.1 Unit Tests

**ComplexityAnalyzer Tests**:

```python
# scripts/test_complexity_analyzer.py

def test_simple_question():
    """ê°„ë‹¨í•œ ì‚¬ì‹¤ ì§ˆë¬¸ â†’ Tier 1"""
    analyzer = ComplexityAnalyzer()
    result = analyzer.analyze("í•œêµ­ ì¸êµ¬ëŠ”?")
    
    assert result.recommended_tier == 1
    assert result.strategy == "fast_path"
    assert result.score < 0.25

def test_moderate_question():
    """ì¤‘ê°„ ë³µì¡ë„ â†’ Tier 2"""
    result = analyzer.analyze("í•œêµ­ ìŒì‹ì  ì›”í‰ê·  ë§¤ì¶œì€?")
    
    assert result.recommended_tier == 2
    assert result.strategy == "judgment_synthesis"
    assert 0.25 <= result.score < 0.60

def test_complex_question():
    """ë³µì¡í•œ ì§ˆë¬¸ â†’ Tier 3"""
    result = analyzer.analyze("í•œêµ­ í´ë¼ìš°ë“œ SaaS ì‹œì¥ ê·œëª¨ëŠ”?")
    
    assert result.recommended_tier == 3
    assert result.strategy == "fermi_decomposition"
    assert result.score >= 0.60
```

**ContextAnalyzer Tests**:

```python
def test_intent_inference():
    """ì˜ë„ ì¶”ë¡ """
    analyzer = ContextAnalyzer()
    
    # get_value
    context = analyzer.analyze("í•œêµ­ ì¸êµ¬ëŠ”?")
    assert context.intent == "get_value"
    
    # make_decision
    context = analyzer.analyze("ìŒì‹ì  ì°½ì—…í•˜ë ¤ëŠ”ë° ì˜ˆìƒ ë§¤ì¶œì€?")
    assert context.intent == "make_decision"

def test_domain_inference():
    """ë„ë©”ì¸ ì¶”ë¡ """
    context = analyzer.analyze("SaaS Churn RateëŠ”?")
    assert context.domain == "B2B_SaaS"
    
    context = analyzer.analyze("ì»¤í”¼ìˆ ë§¤ì¶œì€?")
    assert context.domain == "Consumer"
```

**EvidenceCollector Tests**:

```python
def test_project_data_layer():
    """Layer 1: í”„ë¡œì íŠ¸ ë°ì´í„°"""
    collector = EvidenceCollector()
    context = Context(
        project_data={'customer_count': 50000}
    )
    
    evidence = collector.try_layer("project_data", "ê³ ê°ìˆ˜ëŠ”?", context)
    
    assert evidence.success == True
    assert evidence.value == 50000
    assert evidence.confidence == 1.0

def test_parallel_collection():
    """ë³‘ë ¬ ìˆ˜ì§‘"""
    evidence_list = collector.collect(
        question="í•œêµ­ ì¸êµ¬ëŠ”?",
        context=Context(),
        layers=["llm_direct", "web_search"],
        mode="parallel"
    )
    
    assert len(evidence_list) >= 1
    # ë³‘ë ¬ ì‹¤í–‰ ì‹œê°„ < ìˆœì°¨ ì‹¤í–‰ ì‹œê°„
```

**JudgmentSynthesizer Tests**:

```python
def test_single_best_strategy():
    """ë‹¨ì¼ ìµœê³  ì¦ê±° ì „ëµ"""
    synthesizer = JudgmentSynthesizer()
    
    evidence_list = [
        Evidence(success=True, value=100, confidence=0.95),  # ìµœê³ !
        Evidence(success=True, value=120, confidence=0.6),
    ]
    
    result = synthesizer.synthesize(evidence_list, Context())
    
    assert result.strategy == "single_best"
    assert result.value == 100

def test_weighted_average_strategy():
    """ê°€ì¤‘ í‰ê·  ì „ëµ"""
    evidence_list = [
        Evidence(success=True, value=100, confidence=0.7),
        Evidence(success=True, value=110, confidence=0.8),
        Evidence(success=True, value=90, confidence=0.6),
    ]
    
    result = synthesizer.synthesize(evidence_list, Context())
    
    assert result.strategy == "weighted_average"
    assert 95 <= result.value <= 110
```

### 7.2 Integration Tests

**Tier Tests**:

```python
# scripts/test_tiers.py

def test_tier1_fast_path():
    """Tier 1: Fast Path"""
    result = tier1_fast_path(
        question="í•˜ë£¨ëŠ” ëª‡ ì‹œê°„?",
        context=Context(),
        config=Tier1Config()
    )
    
    assert result is not None
    assert result.value == 24
    assert result.tier == 1
    assert result.source == "physical_law"

def test_tier2_judgment():
    """Tier 2: Judgment"""
    result = tier2_judgment_path(
        question="í•œêµ­ ìŒì‹ì  ì›”ë§¤ì¶œì€?",
        context=Context(),
        config=Tier2Config()
    )
    
    assert result is not None
    assert result.tier == 2
    assert result.judgment_result is not None
    assert len(result.judgment_result.all_evidence) >= 2

def test_tier3_fermi():
    """Tier 3: Fermi"""
    result = tier3_fermi_recursion(
        question="í•œêµ­ SaaS ì‹œì¥ ê·œëª¨ëŠ”?",
        context=Context(),
        depth=0,
        config=Tier3Config()
    )
    
    assert result.tier == 3
    assert result.fermi_model is not None
    assert len(result.variable_results) >= 2
```

### 7.3 End-to-End Tests

```python
# scripts/test_e2e_guestimation_v3.py

test_cases = [
    {
        'name': "ê°„ë‹¨í•œ ì‚¬ì‹¤",
        'question': "í•œêµ­ ì¸êµ¬ëŠ”?",
        'expected_tier': 1,
        'expected_confidence': '>0.9'
    },
    {
        'name': "ì¤‘ê°„ ë³µì¡ë„",
        'question': "í•œêµ­ ìŒì‹ì  ì›”ë§¤ì¶œì€?",
        'expected_tier': 2,
        'expected_confidence': '>0.6'
    },
    {
        'name': "Fermi í•„ìš”",
        'question': "í•œêµ­ í´ë¼ìš°ë“œ SaaS ì‹œì¥ì€?",
        'expected_tier': 3,
        'expected_confidence': '>0.5',
        'expected_model': True
    },
    {
        'name': "ì˜ì‚¬ê²°ì • ë§¥ë½",
        'question': "ìŒì‹ì  ì°½ì—… ì˜ˆìƒ ë§¤ì¶œì€?",
        'expected_tier': 2,
        'expected_strategy': 'conservative'
    }
]

def test_all_cases():
    for case in test_cases:
        result = estimate(case['question'])
        
        assert result.tier == case['expected_tier']
        # ...
```

### 7.4 Performance Tests

```python
# scripts/test_performance_v3.py

def test_tier1_speed():
    """Tier 1ì€ 1ì´ˆ ì´ë‚´"""
    start = time.time()
    result = estimate("í•œêµ­ ì¸êµ¬ëŠ”?")
    elapsed = time.time() - start
    
    assert elapsed < 1.0
    assert result.tier == 1

def test_tier2_speed():
    """Tier 2ëŠ” 5ì´ˆ ì´ë‚´"""
    start = time.time()
    result = estimate("ìŒì‹ì  ì›”ë§¤ì¶œì€?")
    elapsed = time.time() - start
    
    assert elapsed < 5.0
    assert result.tier == 2

def test_cost():
    """ë¹„ìš© ì¶”ì """
    result = estimate("SaaS ì‹œì¥ì€?")
    
    # v3.0ì€ v2.1ë³´ë‹¤ ë¹„ìš© ë‚®ì•„ì•¼ í•¨ (ì„ íƒì  ìˆ˜ì§‘)
    assert result.cost < 0.1  # $0.1 ì´í•˜
```

### 7.5 Regression Tests

```python
# v2.1 ê¸°ì¡´ ë™ì‘ ë³´ì¥

def test_backward_compatibility():
    """ê¸°ì¡´ API í˜¸í™˜ì„±"""
    # v2.1 ë°©ì‹ë„ ì—¬ì „íˆ ì‘ë™
    from umis_rag.utils.multilayer_guestimation import MultiLayerGuestimation
    
    old_estimator = MultiLayerGuestimation()
    old_result = old_estimator.estimate("í•œêµ­ ì¸êµ¬ëŠ”?")
    
    # v3.0
    new_result = estimate("í•œêµ­ ì¸êµ¬ëŠ”?")
    
    # ê²°ê³¼ ìœ ì‚¬í•´ì•¼ í•¨ (Â±10%)
    assert abs(old_result.value - new_result.value) / old_result.value < 0.1
```

---

## ğŸ”„ 8. Migration Plan

### 8.1 Migration Strategy

**ì „ëµ: Incremental Migration (ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜)**

```yaml
ì›ì¹™:
  1. v2.1ê³¼ v3.0 ë³‘ë ¬ ìš´ì˜ (1ê°œì›”)
  2. ê¸°ì¡´ API í˜¸í™˜ì„± ìœ ì§€
  3. Feature Flagë¡œ ì œì–´
  4. ë‹¨ê³„ì  ì „í™˜
```

### 8.2 Migration Phases

**Phase 1: v3.0 êµ¬í˜„ (Week 1-2)**

```yaml
ìƒíƒœ: v2.1 Active, v3.0 Development
ì‘ì—…:
  - v3.0 ì½”ë“œ êµ¬í˜„
  - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
  - í†µí•© í…ŒìŠ¤íŠ¸
  - ë¬¸ì„œ ì‘ì„±

ë¸Œëœì¹˜: feature/guestimation-v3
```

**Phase 2: A/B í…ŒìŠ¤íŠ¸ (Week 3)**

```yaml
ìƒíƒœ: v2.1 Active (90%), v3.0 Beta (10%)

Feature Flag:
  # config/guestimation_v3_config.yaml
  enabled: false  # ê¸°ë³¸ê°’: v2.1 ì‚¬ìš©
  
  rollout:
    percentage: 10  # 10%ë§Œ v3.0
    whitelist:      # íŠ¹ì • ì¿¼ë¦¬ë§Œ v3.0
      - "í•œêµ­ ì¸êµ¬ëŠ”?"
      - "ìŒì‹ì  ë§¤ì¶œì€?"

ì‘ì—…:
  - 10% íŠ¸ë˜í”½ v3.0 í…ŒìŠ¤íŠ¸
  - ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
  - ê²°ê³¼ ë¹„êµ
  - ë²„ê·¸ ìˆ˜ì •
```

**Phase 3: ì ì§„ì  í™•ëŒ€ (Week 4)**

```yaml
ìƒíƒœ: v2.1 Active (50%), v3.0 Beta (50%)

Feature Flag:
  enabled: true
  rollout:
    percentage: 50

ì‘ì—…:
  - 50% íŠ¸ë˜í”½ v3.0
  - ì„±ëŠ¥ í™•ì¸
  - ë¹„ìš© í™•ì¸
  - í”¼ë“œë°± ìˆ˜ì§‘
```

**Phase 4: ì™„ì „ ì „í™˜ (Week 5)**

```yaml
ìƒíƒœ: v2.1 Deprecated, v3.0 Active (100%)

Feature Flag:
  enabled: true
  rollout:
    percentage: 100

ì‘ì—…:
  - 100% íŠ¸ë˜í”½ v3.0
  - v2.1 Deprecation ê³µì§€
  - ë¬¸ì„œ ì—…ë°ì´íŠ¸
```

**Phase 5: v2.1 ì œê±° (Week 6+)**

```yaml
ìƒíƒœ: v3.0 Only

ì‘ì—…:
  - multilayer_guestimation.py â†’ archive/
  - v2.1 ê´€ë ¨ ì½”ë“œ ì œê±°
  - í…ŒìŠ¤íŠ¸ ì •ë¦¬
  - ìµœì¢… ë¬¸ì„œí™”
```

### 8.3 API Compatibility

**í˜„ì¬ API (v2.1)**:

```python
from umis_rag.utils.multilayer_guestimation import MultiLayerGuestimation

estimator = MultiLayerGuestimation(project_context={...})
result = estimator.estimate(
    question="...",
    target_profile=...,
    rag_candidates=...
)
```

**v3.0 API (í•˜ìœ„ í˜¸í™˜)**:

```python
# Option 1: ìƒˆë¡œìš´ ë°©ì‹ (ê¶Œì¥)
from umis_rag.utils.guestimation_v3 import estimate

result = estimate(
    question="...",
    context={
        'project_data': {...},
        'target_profile': ...,
    }
)

# Option 2: ê¸°ì¡´ ë°©ì‹ (í˜¸í™˜)
from umis_rag.utils.multilayer_guestimation import MultiLayerGuestimation

estimator = MultiLayerGuestimation()  # ë‚´ë¶€ì ìœ¼ë¡œ v3.0 í˜¸ì¶œ!
result = estimator.estimate("...")    # ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤
```

### 8.4 Feature Flag Implementation

```python
# umis_rag/utils/guestimation_v3/config.py

@dataclass
class FeatureFlags:
    """Feature Flags"""
    v3_enabled: bool = False
    rollout_percentage: int = 0
    whitelist_questions: List[str] = field(default_factory=list)
    
    def should_use_v3(self, question: str) -> bool:
        """v3.0 ì‚¬ìš© ì—¬ë¶€ íŒë‹¨"""
        if not self.v3_enabled:
            return False
        
        # Whitelist ì²´í¬
        if question in self.whitelist_questions:
            return True
        
        # í™•ë¥ ì  ë¡¤ì•„ì›ƒ
        import random
        return random.randint(1, 100) <= self.rollout_percentage

# ì‚¬ìš©
def estimate_with_version_control(question, context):
    flags = load_feature_flags()
    
    if flags.should_use_v3(question):
        return estimate_v3(question, context)
    else:
        return estimate_v2(question, context)
```

### 8.5 Rollback Plan

```yaml
ë¬¸ì œ ë°œìƒ ì‹œ:

Step 1: Feature Flag ì¦‰ì‹œ ë¹„í™œì„±
  config/guestimation_v3_config.yaml:
    enabled: false
  
  íš¨ê³¼: v2.1ë¡œ ì¦‰ì‹œ ì „í™˜ (30ì´ˆ)

Step 2: ê¸´ê¸‰ íŒ¨ì¹˜
  - ë²„ê·¸ ìˆ˜ì •
  - í•«í”½ìŠ¤ ë°°í¬
  
Step 3: ì¬ì‹œì‘
  - 10%ë¶€í„° ë‹¤ì‹œ ì‹œì‘
  - ê²€ì¦ ê°•í™”

ì¡°ê±´:
  - ì—ëŸ¬ìœ¨ >5% â†’ ì¦‰ì‹œ ë¡¤ë°±
  - ë¹„ìš© >2ë°° â†’ ë¡¤ë°± ê³ ë ¤
  - ì„±ëŠ¥ >2ë°° ëŠë¦¼ â†’ ë¡¤ë°± ê³ ë ¤
```

### 8.6 Monitoring & Metrics

```yaml
ëª¨ë‹ˆí„°ë§ ì§€í‘œ:

ì„±ëŠ¥:
  - í‰ê·  ì‘ë‹µ ì‹œê°„ (Tierë³„)
  - P95 ì‘ë‹µ ì‹œê°„
  - íƒ€ì„ì•„ì›ƒ ë¹„ìœ¨

í’ˆì§ˆ:
  - ì—ëŸ¬ìœ¨
  - ì‹ ë¢°ë„ ë¶„í¬
  - Tier ë¶„í¬ (1:2:3 ë¹„ìœ¨)

ë¹„ìš©:
  - API í˜¸ì¶œ ìˆ˜ (LLM, ì›¹)
  - í‰ê·  ë¹„ìš©/ì¿¼ë¦¬
  - ì´ ë¹„ìš©

ì •í™•ë„:
  - v2.1 vs v3.0 ê²°ê³¼ ì°¨ì´
  - ì‚¬ìš©ì í”¼ë“œë°±
  - ìˆ˜ë™ ê²€ì¦ ìƒ˜í”Œ
```

---

## ğŸ“š 9. References & Appendix

### 9.1 Related Documents

- `SESSION_SUMMARY_20251106_FERMI_COMPLETE.md` - v2.1 ê°œë°œ ê¸°ë¡
- `GUESTIMATION_FLOWCHART.md` - v2.1 í”Œë¡œìš°ì°¨íŠ¸
- `MULTILAYER_IMPLEMENTATION_STATUS.md` - v2.1 êµ¬í˜„ ìƒíƒœ
- `FERMI_IMPLEMENTATION_STATUS.md` - Fermi êµ¬í˜„ ìƒíƒœ

### 9.2 Decision Log

| Date | Decision | Rationale |
|------|----------|-----------|
| 2025-11-06 | Sequential Fallback â†’ Context-Aware Judgment | v2.1ì€ "íŒë‹¨" ì—†ìŒ, ì •ë³´ ì¢…í•© í•„ìš” |
| 2025-11-06 | 3-Tier Architecture | í™•ì‹¤í•  ë• ë¹ ë¥´ê²Œ (90%), ë³µì¡í•  ë• ì •í™•í•˜ê²Œ |
| 2025-11-06 | ë³‘ë ¬ ì¦ê±° ìˆ˜ì§‘ (Tier 2) | ëª¨ë“  ì •ë³´ í™œìš©, ì‹œê°„ ë‹¨ì¶• |
| 2025-11-06 | Incremental Migration | ë¦¬ìŠ¤í¬ ìµœì†Œí™”, ê²€ì¦ ê°€ëŠ¥ |

### 9.3 Open Questions

```yaml
Q1: Tier 2ì—ì„œ Layer ìë™ ì„ íƒ ì•Œê³ ë¦¬ì¦˜?
  í˜„ì¬: ë§¥ë½ ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹±
  ê°œì„ : LLMì´ ì„ íƒ? í•™ìŠµ ê¸°ë°˜?

Q2: ì¢…í•© ì „ëµ ìë™ ì„ íƒ ì•Œê³ ë¦¬ì¦˜?
  í˜„ì¬: ê·œì¹™ ê¸°ë°˜
  ê°œì„ : ê°•í™”í•™ìŠµ?

Q3: ë³µì¡ë„ ì ìˆ˜ ì„ê³„ê°’ (0.25, 0.60)?
  í˜„ì¬: ê²½í—˜ì  ì„¤ì •
  ê°œì„ : ë°ì´í„° ê¸°ë°˜ ìµœì í™”?

Q4: Fermi ì¬ê·€ì™€ Tier ì‹œìŠ¤í…œì˜ ì™„ì „ í†µí•©?
  í˜„ì¬: Tier 3ì—ì„œ Fermi í˜¸ì¶œ
  ê°œì„ : ë” ê¸´ë°€í•œ í†µí•©?
```

### 9.4 Future Work (v3.1+)

```yaml
ìºì‹±:
  - ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ìºì‹±
  - ì¦ê±° ìºì‹± (TTL)
  - ë¹„ìš© 50% ì ˆê° ëª©í‘œ

í•™ìŠµ:
  - ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘
  - ë³µì¡ë„ ë¶„ì„ í•™ìŠµ
  - ì¢…í•© ì „ëµ í•™ìŠµ

UI:
  - ì›¹ ì¸í„°í˜ì´ìŠ¤
  - ì‹¤ì‹œê°„ ì¶”ë¡  ê³¼ì • ì‹œê°í™”
  - ì¦ê±° íŠ¸ë¦¬ í‘œì‹œ

ê³ ê¸‰ ê¸°ëŠ¥:
  - ë¯¼ê°ë„ ë¶„ì„
  - What-if ì‹œë‚˜ë¦¬ì˜¤
  - ìë™ ê²€ì¦
```

---

## ğŸ“ Document Change Log

| Version | Date | Changes | Author |
|---------|------|---------|--------|
| 1.0 | 2025-11-06 | Initial draft - Complete specification | UMIS Dev Team |

---

**Document Complete**: All Sections (1-9) âœ…  
**Status**: Ready for Review & Implementation  
**Next Step**: Begin Phase 1 Implementation

