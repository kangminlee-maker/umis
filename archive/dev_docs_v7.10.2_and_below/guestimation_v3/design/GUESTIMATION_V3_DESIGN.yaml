# UMIS Guestimation System v3.0 - Design Document
# 자연어 기반 논리 구조 설계 (구현 독립적)

meta:
  version: "3.0-design"
  date: "2025-11-07"
  status: "draft"
  philosophy: "논리 구조에 집중, 구현은 나중에"

---

# ═══════════════════════════════════════════════════════
# PART 1: 핵심 문제 정의
# ═══════════════════════════════════════════════════════

problem_statement:
  
  v2_1_문제:
    구조: "Sequential Fallback"
    동작: "Layer 1 시도 → 성공하면 즉시 리턴 → Layer 2 시도 → ..."
    
    문제점:
      - "판단" 없음: 첫 성공만 사용
      - "정보 종합" 없음: 다른 Layer 시도 안 함
      - "맥락 고려" 없음: 모든 케이스 동일 처리
  
  실제_필요:
    - 맥락 파악: "이 질문의 의도는? 도메인은?"
    - 정보 수집: "모든 관련 출처에서 증거 수집"
    - 증거 평가: "각 증거가 맥락에 얼마나 적합한가?"
    - 종합 판단: "모든 정보를 고려한 최종 판단"

---

# ═══════════════════════════════════════════════════════
# PART 2: 핵심 설계 원칙
# ═══════════════════════════════════════════════════════

design_principles:
  
  원칙_1_False_Negative_허용:
    개념: "확실하지 않으면 넘겨라"
    
    False_Positive:
      의미: "Tier 1이 틀린 답을 확신함"
      위험도: 치명적 (복구 불가능)
      예시: "창업 매출" 질문을 "단순 추정"으로 오판 → 보수적 판단 실패
    
    False_Negative:
      의미: "Tier 1이 모르겠다고 넘김"
      위험도: 낮음 (Tier 2에서 정확히 판단)
      예시: "단순 매출" 질문을 Tier 2로 넘김 → Tier 2가 정확히 처리
    
    결론:
      - Tier 1은 명백한 것만 처리
      - 조금이라도 의심되면 Tier 2로
      - 품질 > 속도
  
  원칙_2_Tier별_목적_차별화:
    
    Tier_1_목적:
      - 명백한 케이스를 즉시 처리
      - 속도가 가장 중요
      - 대상: 40-50% 케이스만
      - 전략: 좁은 규칙
    
    Tier_2_목적:
      - 모든 정보 종합 판단
      - 정확도가 가장 중요
      - 대상: 나머지 50-60% 케이스
      - 전략: LLM 분석 + 증거 종합
    
    Tier_3_목적:
      - 재귀 분해
      - 효율성이 중요
      - 대상: 매우 복잡한 케이스
      - 전략: Fermi Model Search
  
  원칙_3_규칙과_LLM의_본질_이해:
    
    규칙의_본질:
      - IF 조건 THEN 결과
      - 매칭되면: confidence 100%
      - 안 되면: confidence 0%
      - 중간값 없음!
      - 보수적 설계 필요
    
    LLM의_본질:
      - 확률적 판단
      - 항상 confidence 0-100%
      - 맥락 이해 가능
      - 새로운 케이스 자동 처리
  
  원칙_4_단순성_우선:
    - 불필요한 복잡도 제거
    - 캐싱 불필요 (Native Mode $0)
    - YAGNI (You Aren't Gonna Need It)

---

# ═══════════════════════════════════════════════════════
# PART 3: 3-Tier 아키텍처
# ═══════════════════════════════════════════════════════

architecture:
  
  전체_흐름:
    단계:
      1. 질문 입력
      2. Tier 결정 (어느 Tier로 갈 것인가?)
      3. Tier 실행
      4. 결과 리턴
  
  tier_결정_로직:
    
    방식_A_규칙_먼저_체크:
      설명: "Tier 1 규칙 매칭 시도 → 안 되면 Tier 2"
      
      흐름:
        1. Tier 1 규칙 체크
           매칭: Tier 1 실행
           불일치: Tier 2로
        
        2. Tier 2 실행
           LLM 복잡도 분석
           simple/moderate: Tier 2 처리
           complex: Tier 3으로
        
        3. Tier 3 실행 (Fermi)
      
      장점:
        - Tier 1 매우 빠름 (40-50% 케이스)
        - False Positive 없음
      
      단점:
        - Tier 2로 많이 넘어감 (50-60%)
    
    방식_B_LLM_복잡도_먼저:
      설명: "LLM이 복잡도 판단 → Tier 결정"
      
      흐름:
        1. LLM 복잡도 분석
           매우 단순: Tier 1
           중간: Tier 2
           복잡: Tier 3
        
        2. 해당 Tier 실행
      
      장점:
        - LLM이 정확히 분류
        - Tier 분포 최적화
      
      단점:
        - 모든 케이스에 LLM 호출 (느림)
        - Tier 1도 느려짐 (모순)
    
    권장: 방식_A (규칙 먼저)
      이유:
        - Tier 1 순수성 유지
        - 40-50% 케이스 즉시 처리
        - False Positive 없음

---

# ═══════════════════════════════════════════════════════
# PART 4: Tier별 상세 설계
# ═══════════════════════════════════════════════════════

tier_1_fast_path:
  
  목적: "명백한 케이스 즉시 처리"
  
  대상_질문:
    특징:
      - 패턴이 매우 명확
      - 답이 확실함
      - 맥락 해석 불필요
    
    예시:
      - "한국 인구는?" → 공식 통계
      - "하루는 몇 시간?" → 물리 법칙
      - "최저임금은?" → 법률 상수
  
  매칭_규칙:
    설계_원칙:
      - 좁게 정의 (명백한 것만)
      - 여러 조건 AND (엄격)
      - 반증 키워드 체크
    
    규칙_예시:
      
      규칙_1_공식_통계:
        패턴: "[지역] [통계 항목]은/는?"
        조건:
          - 지역: 한국, 서울, 미국 등 (10개 주요 지역)
          - 통계 항목: 인구, 면적, GDP 등 (20개 주요 항목)
          - 문법: "은?" or "는?"
          - 반증 없음: "예측", "미래", "얼마" 등 없어야
        
        예시_매칭:
          - "한국 인구는?" ✅
          - "서울 면적은?" ✅
        
        예시_불일치:
          - "미래 한국 인구는?" ❌ (반증 "미래")
          - "한국 인구 증가율은?" ❌ (통계 항목 목록에 없음)
      
      규칙_2_물리_법칙:
        패턴: "[시간단위]는 몇 [단위]?"
        조건:
          - 시간단위: 하루, 일주일, 한달
          - 단위: 시간, 일, 달
        
        예시_매칭:
          - "하루는 몇 시간?" ✅
          - "일주일은 몇 일?" ✅
        
        예시_불일치:
          - "평균 하루는 몇 시간?" ❌ ("평균" 불필요)
      
      규칙_3_법률_상수:
        패턴: "[법률 용어]은/는?"
        조건:
          - 법률 용어 목록: 최저임금, 법정근로시간, 주휴수당 등
          - 지역/시점 한정자 없어야 (현재 한국 기준)
        
        예시_매칭:
          - "최저임금은?" ✅
        
        예시_불일치:
          - "2025년 최저임금은?" ❌ (시점 한정)
          - "미국 최저임금은?" ❌ (지역 한정)
    
    규칙_개수: 10-20개 (명백한 패턴만)
    예상_커버리지: 40-50%
  
  처리_방식:
    규칙_매칭_성공:
      - confidence: 1.0 (100%)
      - 즉시 처리
      - 데이터 소스: 프로젝트 데이터 or 상수 or 간단한 LLM 질문
    
    규칙_매칭_실패:
      - confidence: 0.0
      - Tier 2로 넘김
      - 이유: "명백한 패턴 아님"
  
  성능_목표:
    시간: "<0.5초"
    비용: "$0"
    정확도: "100% (매칭된 것은)"
    커버리지: "40-50%"

---

tier_2_judgment_path:
  
  목적: "모든 정보 종합하여 정확한 판단"
  
  대상_질문:
    - Tier 1 규칙 불일치 (50-60%)
    - 맥락 파악 필요
    - 여러 증거 종합 필요
  
  처리_단계:
    
    단계_1_맥락_파악:
      목적: "질문의 의도, 도메인, 상황 이해"
      
      파악_항목:
        
        의도_intent:
          정의: "질문자가 무엇을 원하는가?"
          
          유형:
            get_value: "단순히 값 알고 싶음"
            understand_market: "시장/현상 이해하고 싶음"
            make_decision: "의사결정 하려고 함 (창업, 투자 등)"
            compare: "비교하고 싶음"
            predict: "미래 예측하고 싶음"
          
          판단_방법:
            규칙으로_시도:
              - "창업", "시작", "고려" → make_decision
              - "분석", "이해", "조사" → understand_market
              - "vs", "비교" → compare
              - "예측", "년 후" → predict
            
            규칙_실패시:
              - LLM에게 질문
              - "이 질문의 의도는 무엇인가?"
              - LLM이 유형 + confidence 리턴
          
          중요성:
            - 같은 질문도 의도에 따라 다른 답 필요
            - "음식점 매출?" 
              → get_value: 평균 (2,700만원)
              → make_decision: 보수적 하한 (2,000만원)
        
        도메인_domain:
          정의: "어떤 산업/분야인가?"
          
          유형:
            - B2B_SaaS
            - Consumer  
            - E-commerce
            - Food_Service
            - FinTech
            - HealthTech
            - General
            - 기타 (무한)
          
          판단_방법:
            규칙으로_시도:
              - "SaaS", "구독" → B2B_SaaS
              - "음식점", "카페" → Food_Service
              - 주요 10-15개 도메인만 규칙
            
            규칙_실패시:
              - LLM에게 질문
              - "피자 배달", "유아용 장난감" 등 새 도메인
              - LLM이 도메인 분류 + confidence
          
          중요성:
            - 도메인별 벤치마크 다름
            - SaaS Churn 5% vs 소비재 Churn 30%
        
        세분화_granularity:
          정의: "얼마나 구체적인가?"
          
          수준:
            macro: "전체 시장"
            segment: "특정 세그먼트"
            micro: "매우 구체적"
          
          판단_방법:
            수식어_개수_기반:
              - 0-1개: macro
              - 2-3개: segment  
              - 4개+: micro
            
            예시:
              - "SaaS 시장" → 0개 → macro
              - "한국 B2B SaaS" → 2개 → segment
              - "한국 중소기업 대상 온라인 HR SaaS" → 5개 → micro
        
        시공간_spatiotemporal:
          정의: "언제, 어디의 질문인가?"
          
          추출_항목:
            지역: "한국, 서울, 미국, 글로벌"
            시점: "2024년, 현재, 3년 후"
          
          판단_방법:
            정규식으로_충분:
              - "한국", "서울" 등 추출
              - "2024년", "3년 후" 등 추출
              - LLM 불필요
        
        부모_모형_parent_model:
          정의: "Fermi 재귀 중이면 부모 모형 정보"
          
          포함_정보:
            - 부모 질문: "시장 규모는?"
            - 부모 모형: "시장 = 기업수 × ARPU × 12"
            - 현재 변수 역할: "ARPU"
            - 제약조건: "월간 값", "기업당 값"
          
          중요성:
            - 제약조건 전달 (ARPU는 월간이어야)
            - 맥락 전파 (시장 분석 → 변수 추정)
    
    단계_2_복잡도_판단:
      목적: "이 질문을 Tier 2에서 처리할 것인가, Tier 3으로 넘길 것인가?"
      
      판단_기준:
        
        변수_개수:
          단순: "0-2개 변수"
          복잡: "3개 이상 변수"
          
          판단_방법:
            - LLM에게 질문
            - "이 질문을 답하려면 몇 개 변수 필요한가?"
            - LLM이 분해 구조 제시
          
          예시:
            - "음식점 매출?" → 3개 (좌석 × 회전 × 객단가)
            - "SaaS 시장?" → 5개 (기업 × 도입 × ARPU × ...)
        
        데이터_가용성:
          있음: "직접 답변 가능"
          없음: "분해 필요"
          
          판단_방법:
            - 프로젝트 데이터 체크
            - RAG 벤치마크 검색
            - LLM에게 "공개 데이터 있는가?" 질문
        
        결정:
          조건:
            IF (변수 0-2개) AND (데이터 가용성 있음):
              → Tier 2 처리
            
            ELSE IF (변수 3개 이상) OR (데이터 없음):
              → Tier 3으로
    
    단계_3_증거_수집:
      목적: "관련된 모든 출처에서 정보 수집"
      
      출처_선택:
        맥락_기반_선택:
          
          IF 의도 == "make_decision":
            우선_순위:
              1. 프로젝트 데이터 (확정값)
              2. RAG 벤치마크 (유사 사례)
              3. 보수적 출처 우선
            
            제외:
              - 낙관적 웹 검색 결과
          
          IF 도메인 == "B2B_SaaS":
            포함:
              - RAG 벤치마크 (SaaS 지표)
              - 행동경제학 (구독 모델)
            
            제외:
              - 일반 통계 패턴
          
          IF 시점 == "미래":
            포함:
              - 성장 트렌드
              - 예측 모델
            
            제외:
              - 과거 데이터만
        
        기본_전략:
          - 3-5개 Layer 선택
          - 병렬 수집
          - 최소 2개 증거 필요
      
      11개_Source_3_Category:
        
        설명: "역할 기반 재분류 (MECE 95%)"
        
        Category_A_Physical_Constraints:
          
          역할: "Knock-out (절대 한계)"
          빈도: "9% (드물지만 치명적)"
          적용: "boundary 제시 → 위반 시 거부"
          
          Sources:
            
            1_시공간_법칙:
              예시:
                - "광속 한계 (c = 300,000 km/s)"
                - "동시 다지점 불가"
                - "서울-부산 최소 이동 2.5시간"
              
              신뢰도: 0.99
              
              구현: "간단한 거리/속도 공식 + LLM 보조"
              
              출력:
                type: "boundary"
                min: 2.5시간
                max: null
                confidence: 0.99
            
            2_보존_법칙:
              예시:
                - "매출 = 고객수 × 객단가 × 방문"
                - "전체 >= 부분"
                - "입력 = 출력 + 손실"
              
              신뢰도: 1.0
              
              출력:
                type: "boundary"
                relationship: "part < whole"
                confidence: 1.0
            
            3_수학_정의:
              예시:
                - "확률 ∈ [0, 1]"
                - "백분율 ∈ [0, 100]"
              
              신뢰도: 1.0
              
              출력:
                type: "boundary"
                range: [0, 1]
                confidence: 1.0
        
        Category_B_Soft_Constraints:
          
          역할: "Range 제시, 검증, 통찰"
          빈도: "60%"
          적용: "범위 제안 → 위반 시 경고 (거부 아님)"
          
          Sources:
            
            4_법률_규범:
              
              포함: "명시법 + 규제 + 시장구조 + 산업 룰"
              
              예시:
                - "최저임금 9,860원"
                - "주 52시간"
                - "통신 규제"
                - "진입장벽"
              
              신뢰도: 0.80-0.95
              
              출력:
                type: "range"
                
                base_rule:
                  value: 9860
                  range: [9860, ∞]
                
                exceptions:
                  - condition: "수습"
                    multiplier: 0.90
                
                typical_range: [9860, 15000]
                
                confidence: 0.90
            
            5_통계_패턴:
              
              포함: "산업평균 + 경험법칙 + 사회규범 + 기술한계 + 지리제약 + 경쟁구조"
              
              예시:
                - "음식점 평균 매출"
                - "SaaS Churn 5-7%"
                - "개발자 1인당 비용"
              
              신뢰도: 0.50-0.80
              
              출력_필수:
                distribution_type: "normal | power_law | exponential | bimodal | conditional" ⭐
                
                parameters:
                  IF normal:
                    mean: 값
                    std_dev: 값
                  
                  IF power_law:
                    percentiles: {p10, p25, p50, p75, p90}
                    warning: "평균 사용 금지!"
                  
                  IF bimodal:
                    peaks: [{center, range}, {center, range}]
                    action: "세분화 요청"
                
                confidence: 0.65
              
              처리_로직:
                
                분산_기준_활용:
                  
                  IF CV < 0.20:
                    역할: Soft + Value 겸용
                    Soft: range [mean-2σ, mean+2σ]
                    Value: mean (confidence 0.75)
                  
                  IF 0.20 <= CV < 0.50:
                    역할: Soft 우선
                    Soft: range [p10, p90]
                    Value: median (다른 것 없을 때, confidence 0.60)
                  
                  IF CV >= 0.50:
                    역할: Soft만
                    Soft: range [p10, p90]
                    Value: 사용 자제
                  
                  IF type == "power_law":
                    역할: Soft + Value
                    Soft: range [p10, p90]
                    Value: median (평균 금지!)
                  
                  IF type == "bimodal":
                    역할: 세분화 요청
                    action: "초급? 고급?"
            
            6_행동경제학:
              
              예시:
                - "Loss Aversion"
                - "Hyperbolic Discounting"
                - "Power Law (20:80)"
              
              신뢰도: 0.60
              
              출력:
                type: "insight" (정량화 포기!) ⭐
                
                pattern: "Loss Aversion"
                
                implication: "가격 인상 시 Churn 증가 예상"
                
                quantitative_hint:
                  direction: "upward"
                  magnitude: "moderate"
                
                confidence: 0.60
              
              활용: "해석 보조, 불확실성 설명 (정량적 사용 안 함)"
        
        Category_C_Value_Sources:
          
          역할: "구체적 값 제시"
          빈도: "100%"
          적용: "증거 수집 → 평가 → 종합 판단"
          
          Sources:
            
            7_확정_데이터:
              예시:
                - "우리 고객 10만명"
                - "작년 매출 30억"
              
              신뢰도: 0.95-1.0
              
              주의: "완전 확정 드묾, 0.95 정도"
            
            8_LLM_추정:
              예시:
                - "한국 인구 5,200만명"
              
              신뢰도: 0.60-0.90
              
              조정: "시의성 고려 (2023 데이터면 ×0.3 페널티)" ⭐
            
            9_웹_검색:
              예시:
                - "음식점 평균 2,500만원"
              
              신뢰도: 0.70
              
              장점: "최신 데이터"
            
            10_RAG_벤치마크:
              예시:
                - "SaaS Churn 6%"
              
              신뢰도: 0.50-0.80
              
              구현: "QuantifierRAG.search_benchmark() 재사용" ⭐
            
            11_통계_패턴_값:
              예시:
                - median 2,000만원
              
              신뢰도: 0.50-0.65
              
              조건: "다른 Value 없을 때만" ⭐
              
              주의: "분산 고려, 분포 타입 체크"
    
    단계_4_증거_평가:
      목적: "각 증거가 맥락에 얼마나 적합한가?"
      
      평가_기준:
        
        맥락_적합도_relevance:
          정의: "이 증거가 질문 맥락에 맞는가?"
          
          평가_요소:
            지역_일치:
              - 질문: "한국 음식점"
              - 증거: "서울 음식점 데이터"
              - 일치도: 0.7 (서울 ≠ 한국 전체)
            
            시점_일치:
              - 질문: "2024년"
              - 증거: "2023년 데이터"
              - 일치도: 0.8 (1년 차이)
            
            세분화_일치:
              - 질문: "HR SaaS"
              - 증거: "전체 SaaS"
              - 일치도: 0.6 (세분화 불일치)
          
          종합:
            relevance = (지역_일치 + 시점_일치 + 세분화_일치) / 3
        
        신뢰성_reliability:
          정의: "이 증거를 얼마나 신뢰할 수 있는가?"
          
          평가_요소:
            출처_신뢰도:
              - 프로젝트 데이터: 1.0
              - 물리 법칙: 1.0
              - 공식 통계: 0.9
              - 산업 보고서: 0.7
              - 웹 검색: 0.5
            
            증거_자체_confidence:
              - Layer가 리턴한 confidence
              - LLM: 0.6-0.9
              - 웹 검색 consensus: 0.7
              - RAG 유사도: 0.5-0.8
          
          종합:
            reliability = 출처_신뢰도 × 증거_confidence
        
        최신성_recency:
          정의: "시간에 민감한 질문일 때 얼마나 최신인가?"
          
          평가:
            시간_민감_질문:
              - "2024년", "현재", "최근"
              → recency 중요 (가중치 높임)
            
            시간_무관_질문:
              - "일반적으로", "평균"
              → recency 덜 중요
          
          계산:
            데이터_연도_차이로_감쇠:
              - 올해 데이터: 1.0
              - 1년 전: 0.9
              - 2년 전: 0.8
              - 3년 이상: 0.6
        
        종합_가중치:
          공식: |
            overall = (
              relevance × 0.50 +
              reliability × 0.30 +
              recency × 0.20
            )
    
    단계_4A_Source_적용_순서:
      
      목적: "Physical → Value → Soft 순서로 적용"
      
      순서:
        
        Step_1_Physical_Constraints_수집:
          
          실행:
            - 모든 Physical Source 체크 (빠름)
            - 시공간, 보존, 수학
          
          결과:
            boundaries: [
              {type: "spacetime", range: [0, 24]},
              {type: "case", range: [0, 16]}
            ]
            
            final_boundary: intersection = [0, 16]
            
            confidence: 0.99
          
          목적: "불가능 영역 확정"
        
        Step_2_Value_Sources_수집:
          
          실행:
            - 맥락 기반 3-5개 선택
            - boundary 힌트 전달
            - 병렬 수집
          
          결과:
            values: [
              {source: "llm", value: 11.5, conf: 0.75},
              {source: "web", value: 12, conf: 0.70},
              {source: "rag", value: 11, conf: 0.65}
            ]
          
          목적: "값 후보 수집"
        
        Step_3_Soft_Constraints_수집:
          
          실행:
            - 맥락 기반 1-2개 선택
            - 법률, 통계, 행동
          
          결과:
            guides: [
              {type: "legal", range: [8, 10], conf: 0.85},
              {type: "statistical", range: [10, 14], conf: 0.60}
            ]
            
            suggested_range: union = [8, 14]
          
          목적: "합리성 검증"
        
        Step_4_값_검증:
          
          실행:
            각_value_체크:
              11.5 ∈ [0, 16] (Physical) ✅
              11.5 ∈ [8, 14] (Soft) ✅
              → 합리적
          
          결과:
            모든_값_통과: ✅
            
            or
            
            이상치_발견:
              value: 20
              Physical: ✅ [0, 16] 위반!
              → 거부 or 재수집
        
        Step_5_충돌_해결:
          
          충돌_유형_3가지:
            
            유형_1_Physical끼리:
              예: 제약_A [0, 10억] vs 제약_B [5억, ∞]
              
              해결:
                교집합: [5억, 10억]
                
                IF 교집합_공집합:
                  → 사용자_질문: "모순, 어느 것?"
            
            유형_2_Physical_vs_Value:
              예: boundary [197만원, ∞] vs value 180만원
              
              해결:
                1. 재확인: 웹 데이터 정확?
                2. 예외 체크: 수습? 특례?
                3. IF 예외_아님:
                     → Physical 우선 (197만원)
                     → Value 거부
                4. ELSE:
                     → 사용자_질문
            
            유형_3_Value끼리_불일치:
              예: LLM 2,000 vs 웹 5,000 (150% 차이)
              
              해결:
                1. 시의성_조정:
                   LLM confidence ×0.3
                2. 가중치_재계산
                3. 웹_우선
        
        Step_6_종합_판단:
          (다음 단계로)
    
    단계_5_종합_판단:
      목적: "평가된 증거들을 종합하여 최종 값 결정"
      
      종합_전략_선택:
        
        전략은_맥락에_따라:
          
          IF 의도 == "make_decision":
            전략: conservative
            방법: 보수적 하한 선택
            이유: 의사결정은 안전해야
          
          IF 증거들이_일치:
            조건: "모든 증거 값이 ±20% 이내"
            전략: weighted_average
            방법: 가중 평균
            이유: 일치하면 평균이 합리적
          
          IF 증거들이_불일치:
            조건: "증거 값 차이 >50%"
            전략: range
            방법: 범위 제시 (min ~ max)
            이유: 불확실성 명시
          
          IF 하나가_압도적:
            조건: "최고 가중치가 다른 것보다 2배 이상"
            전략: single_best
            방법: 최고 증거만 사용
            이유: 압도적이면 그것만으로 충분
        
        자동_선택_로직:
          입력: [평가된_증거_리스트, 맥락]
          출력: 전략_이름
          
          우선순위:
            1. 의도 체크 (make_decision → conservative)
            2. 일치도 체크 (일치 → weighted_average)
            3. 불일치 체크 (불일치 → range)
            4. 압도적 체크 (압도 → single_best)
            5. 기본값: weighted_average
      
      값_계산:
        
        weighted_average:
          공식: |
            final_value = Σ(증거값 × 가중치) / Σ(가중치)
          
          예시:
            증거_A: 2,500만원 (가중치 0.8)
            증거_B: 3,000만원 (가중치 0.6)
            증거_C: 2,700만원 (가중치 0.7)
            
            계산:
              = (2500×0.8 + 3000×0.6 + 2700×0.7) / (0.8+0.6+0.7)
              = 2,700만원
        
        conservative:
          방법: "가중치 높은 증거 중 최소값"
          
          예시:
            가중치_순으로_정렬:
              1. 2,700만원 (0.8)
              2. 3,000만원 (0.7)
              3. 2,500만원 (0.6)
            
            상위_3개_중_최소값: 2,500만원
        
        range:
          방법: "모든 증거의 min ~ max"
          
          예시:
            증거: [2,000, 2,500, 3,500, 3,000]
            범위: 2,000 ~ 3,500만원
            중앙값: 2,750만원
      
      불확실성_계산:
        정의: "최종 값이 얼마나 불확실한가? (±%)"
        
        계산_방법:
          
          방법_A_증거_분산:
            - 모든 증거 값의 표준편차
            - 평균 대비 비율
            - uncertainty = σ / μ
          
          방법_B_가중치_기반:
            - 최고 가중치 = 0.9 → uncertainty ±10%
            - 최고 가중치 = 0.7 → uncertainty ±30%
            - 최고 가중치 = 0.5 → uncertainty ±50%
          
          방법_C_증거_개수:
            - 증거 1개: ±50%
            - 증거 2-3개: ±30%
            - 증거 4개+: ±20%
          
          종합:
            uncertainty = max(방법_A, 방법_B, 방법_C)
  
  성능_목표:
    시간: "3-8초"
    비용: "$0 (Native) or $0.01-0.05 (External)"
    정확도: "95-98%"
    커버리지: "50-60% + Tier 1 실패분"

---

tier_3_fermi_recursion:
  
  목적: "복잡한 질문을 분해하여 재귀 추정"
  
  대상_질문:
    - Tier 2에서도 판단 어려움
    - 변수 3개 이상
    - 데이터 없음
  
  처리_방식:
    
    단계_1_모형_생성:
      LLM_활용:
        - "이 질문을 어떻게 분해할 수 있는가?"
        - LLM이 3-5개 후보 모형 제시
        - 가장 실행 가능한 모형 선택
    
    단계_2_변수_추정:
      각_변수마다:
        - 새로운 질문 생성
        - 부모 모형 정보 전달
        - 재귀 호출: estimate(변수_질문, 부모_맥락, depth+1)
        - 결과는 Tier 1-2-3 모두 거침!
    
    단계_3_재귀_탈출:
      
      탈출_조건:
        
        조건_1_Depth_제한:
          - depth >= 4
          - 강제 종료
          - Tier 2 판단 시스템 호출
        
        조건_2_순환_감지:
          - 같은 질문 반복
          - 강제 종료
        
        조건_3_제약_도달:
          - 물리적/논리적 한계 도달
          - 제약조건으로 범위 추정
    
    단계_4_값_계산:
      - 모형에 변수값 대입
      - 계산
      - 불확실성 전파
  
  성능_목표:
    시간: "10-30초"
    비용: "$0.1-1 (External) or $0 (Native)"
    정확도: "85-95%"
    커버리지: "100% (무조건 답)"

---

# ═══════════════════════════════════════════════════════
# PART 5: 핵심 결정 사항
# ═══════════════════════════════════════════════════════

key_decisions:
  
  결정_1_Tier_1_규칙_설계:
    
    질문: "Tier 1 규칙을 얼마나 좁게 설계할 것인가?"
    
    옵션_A_넓은_규칙:
      규칙_개수: 50-100개
      커버리지: 70-80%
      위험: False Positive 높음
    
    옵션_B_좁은_규칙:
      규칙_개수: 10-20개
      커버리지: 40-50%
      위험: False Positive 낮음
    
    선택: 옵션_B (좁은 규칙)
    
    이유:
      - False Negative는 Tier 2가 처리
      - False Positive는 복구 불가능
      - 품질 > 커버리지
  
  결정_2_규칙_vs_LLM:
    
    질문: "규칙과 LLM을 어떻게 조합할 것인가?"
    
    옵션_A_모든_Tier_동일:
      - 모든 Tier에 "규칙 먼저, 실패 시 LLM"
      - 일관성 있음
      - 하지만 Tier 목적 달성 어려움
    
    옵션_B_Tier별_최적화:
      - Tier 1: 규칙만 (속도)
      - Tier 2: LLM 중심 (정확도)
      - Tier 3: 규칙 우선 (효율)
      - 각 Tier 목적에 맞춤
    
    선택: 옵션_B (Tier별 최적화)
    
    이유:
      - Tier마다 필요한 것 다름
      - Tier 1은 속도가 핵심 → 규칙 필수
      - Tier 2는 정확도가 핵심 → LLM 유리
  
  결정_3_복잡도_분석_위치:
    
    질문: "복잡도 분석을 언제 할 것인가?"
    
    옵션_A_Entry_Point:
      - 질문 들어오자마자 복잡도 분석
      - Tier 결정 → 해당 Tier 실행
      - 깔끔하지만 모든 케이스 LLM 필요
    
    옵션_B_Tier별:
      - Tier 1 규칙 먼저 시도
      - 실패하면 Tier 2 (LLM 복잡도 분석)
      - Tier 2에서 복잡하면 Tier 3으로
      - Tier 1 빠름 유지
    
    선택: 옵션_B (Tier별)
    
    이유:
      - Tier 1 순수성 유지 (40-50% 즉시)
      - LLM 호출 최소화
  
  결정_4_신뢰도_표현:
    
    규칙_신뢰도:
      - 매칭: 1.0 (100%)
      - 불일치: 0.0
      - 중간값 없음
    
    LLM_신뢰도:
      - LLM이 자체 리턴
      - 0.0 ~ 1.0
      - 확률적
    
    혼합하지_않음:
      - 규칙은 규칙
      - LLM은 LLM
      - 각자의 본질 유지

---

# ═══════════════════════════════════════════════════════
# PART 6: 구현 가이드 (언어 독립적)
# ═══════════════════════════════════════════════════════

implementation_guide:
  
  Tier_1_구현:
    
    규칙_정의_방법:
      형식: "패턴 매칭 (정규식 or 키워드)"
      
      구현_선택지:
        - Python 정규식
        - YAML 규칙 정의 + 인터프리터
        - LLM 프롬프트 ("이 패턴에 맞는가?")
      
      권장: "구현 시 결정"
    
    데이터_소스:
      - 프로젝트 데이터 딕셔너리
      - 상수 테이블 (법칙, 법률)
      - 간단한 LLM 질문 (factual만)
  
  Tier_2_구현:
    
    맥락_파악:
      구현_선택지:
        - LLM 프롬프트 (단일 통합)
        - LLM 프롬프트 (항목별 분리)
        - 규칙 + LLM 하이브리드
      
      권장: "LLM 단일 통합 프롬프트"
      
      프롬프트_예시: |
        질문: "{question}"
        
        다음을 분석하세요:
        1. 의도 (get_value | understand_market | make_decision | ...)
        2. 도메인 (B2B_SaaS | Consumer | ...)
        3. 세분화 (macro | segment | micro)
        4. 지역/시점
        
        JSON으로 답하세요.
    
    증거_수집:
      병렬_실행: "가능하면 병렬"
      Layer_선택: "맥락 기반 (3-5개)"
    
    판단_종합:
      전략_선택: "맥락 기반 자동 선택"
      값_계산: "전략별 계산"
  
  Tier_3_구현:
    
    Fermi_Model_Search_재사용:
      - 기존 코드 대부분 유지
      - 변수 추정 부분만 수정
      - estimate() 재귀 호출

---

# ═══════════════════════════════════════════════════════
# PART 7: 성능 예측
# ═══════════════════════════════════════════════════════

performance_projection:
  
  케이스_분포:
    Tier_1: "40-50%"
    Tier_2: "45-55%"
    Tier_3: "2-5%"
  
  평균_성능:
    
    시간:
      계산: |
        0.1초 × 45% (Tier 1) +
        6초 × 50% (Tier 2) +
        20초 × 5% (Tier 3)
        = 0.045 + 3.0 + 1.0
        = 4.045초
      
      평가: "허용 가능 (목표 <5초)"
    
    비용_Native:
      Tier_1: "$0"
      Tier_2: "$0"
      Tier_3: "$0"
      총: "$0"
    
    비용_External:
      Tier_1: "$0"
      Tier_2: "$0.02"
      Tier_3: "$0.10"
      평균: "$0 + $0.01 + $0.005 = $0.015"
    
    정확도:
      Tier_1: "100% (매칭된 것은)"
      Tier_2: "95-98%"
      Tier_3: "90-95%"
      전체: "95-97%"

---

# ═══════════════════════════════════════════════════════
# PART 8: 열린 질문
# ═══════════════════════════════════════════════════════

open_questions:
  
  질문_1_Tier_1_규칙_개수:
    현재: "10-20개"
    고민: "너무 적은가? 너무 많은가?"
    검증_방법: "실제 질문 샘플 100개로 테스트"
  
  질문_2_Tier_2_LLM_프롬프트:
    현재: "맥락 파악을 단일 프롬프트로"
    고민: "항목별 분리가 더 정확한가?"
    검증_방법: "A/B 테스트"
  
  질문_3_증거_수집_Layer_선택:
    현재: "맥락 기반 3-5개 선택"
    고민: "어떻게 선택할 것인가?"
    옵션:
      - 규칙 기반 (도메인 → Layer 매핑)
      - LLM 선택
      - 모든 Layer 시도 (병렬)
  
  질문_4_종합_전략_자동_선택:
    현재: "맥락 + 증거 분포 기반"
    고민: "선택 로직이 복잡할 수 있음"
    대안: "항상 weighted_average"

---

# ═══════════════════════════════════════════════════════
# PART 9: 학습 시스템 (핵심!)
# ═══════════════════════════════════════════════════════

learning_system:
  
  핵심_아이디어:
    개념: "Tier 2/3 결과 → Tier 1 규칙으로 편입"
    
    진화_과정:
      초기:
        - Tier 1 규칙: 10-20개 (명백한 것만)
        - 커버리지: 40-50%
        - 대부분 Tier 2로 넘어감
      
      1개월_후:
        - Tier 1 규칙: 100-200개 (학습된 것 추가)
        - 커버리지: 80-85%
        - 대부분 Tier 1 처리
      
      1년_후:
        - Tier 1 규칙: 1,000-2,000개
        - RAG로 전환 (검색 기반)
        - 커버리지: 95%+
    
    효과:
      - 시스템이 사용할수록 빨라짐
      - 비용 감소 (LLM 호출 ↓)
      - 품질 유지 (검증된 것만 편입)
  
  학습_흐름:
    
    단계_1_Tier_2_3_추정:
      질문: "한국 음식점 월평균 매출은?"
      
      Tier_2_처리:
        - LLM 맥락 파악
        - 증거 수집 (5개 출처)
        - 판단 종합
        - 결과: 2,700만원 ± 30%
      
      메타데이터_생성:
        question: "한국 음식점 월평균 매출은?"
        value: 2700만원
        value_range: [1890만원, 3510만원]
        
        context:
          intent: "understand_market"
          domain: "Food_Service"
          region: "한국"
          time_period: "2024"
          granularity: "macro"
        
        confidence: 0.85
        
        evidence_sources:
          - source: "web_search"
            value: 3000만원
            weight: 0.6
          - source: "rag_benchmark"
            value: 2500만원
            weight: 0.8
          - source: "llm_direct"
            value: 2700만원
            weight: 0.7
        
        judgment_strategy: "weighted_average"
        
        timestamp: "2024-11-07T10:30:00"
        usage_count: 1
    
    단계_2_재사용_감지:
      
      조건:
        - 같은 질문 3회 이상
        OR
        - 유사한 질문 10회 이상
      
      예시:
        "한국 음식점 월매출은?"
        "한국 식당 평균 매출은?"
        "국내 음식점 매출은?"
        → 모두 유사 (유사도 >0.8)
        → 10회 누적
        → 학습 트리거!
    
    단계_3_규칙화_후보_생성:
      
      방법:
        입력:
          - 질문 패턴 추출
          - 메타데이터 일반화
        
        출력:
          규칙_후보:
            pattern: "[지역] [업종] [지표]는?"
            
            template:
              지역: "한국"
              업종: "음식점"
              지표: "월평균 매출"
            
            generalized:
              지역: [한국, 국내, 대한민국]
              업종: [음식점, 식당, 레스토랑]
              지표: [월매출, 월평균 매출, 평균 매출]
            
            결과_템플릿:
              value: 2700만원
              range: [1890만원, 3510만원]
              
              metadata:
                domain: "Food_Service"
                confidence: 0.85
                last_updated: "2024-11-07"
                usage_count: 10
                sources: ["web", "rag", "llm"]
    
    단계_4_검증:
      
      자동_검증:
        - 유사 질문들 결과 일치도 >90%
        - 증거 출처 2개 이상
        - confidence >0.8
      
      인간_검증_필요시:
        - confidence <0.8
        - 결과 분산 큼
        - 중요한 지표 (시장 규모 등)
    
    단계_5_Tier_1_편입:
      
      저장_위치:
        초기_단계:
          형식: "YAML 파일"
          파일: "data/learned_rules/food_service.yaml"
          
          구조: |
            rules:
              - id: "RULE-FOOD-001"
                pattern: "[한국|국내] [음식점|식당] [월매출|매출]"
                
                result:
                  value: 2700만원
                  range: [1890만원, 3510만원]
                
                metadata:
                  domain: "Food_Service"
                  region: "한국"
                  granularity: "macro"
                  confidence: 0.85
                  sources: ["web", "rag", "llm"]
                  evidence_count: 5
                  
                  learned_from: "tier2"
                  created_at: "2024-11-07"
                  usage_count: 10
                  last_verified: "2024-11-07"
        
        확장_단계:
          형식: "RAG (Vector DB)"
          collection: "learned_estimation_rules"
          
          이유:
            - 규칙 1,000개 이상 시
            - 패턴 매칭 → 임베딩 검색
            - 유사한 질문 자동 찾기
      
      검색_방식:
        
        YAML_단계:
          방법: "패턴 매칭"
          도구: "정규식 or 키워드 매칭"
          속도: "0.001초"
          확장성: "~100개 규칙"
        
        RAG_단계:
          방법: "임베딩 유사도 검색"
          도구: "ChromaDB 벡터 검색"
          속도: "0.01-0.1초"
          확장성: "무한"

---

# ═══════════════════════════════════════════════════════
# PART 10: 메타데이터 설계 (검색 가능성)
# ═══════════════════════════════════════════════════════

metadata_design:
  
  핵심_원칙:
    - 적을수록 좋음 (단순성)
    - 검색 커버리지 높을수록 좋음 (유사 질문 찾기)
    - 재현 가능할수록 좋음 (추적성)
  
  필수_메타데이터:
    
    1_질문_패턴:
      목적: "유사 질문 매칭"
      
      항목:
        원본_질문: "한국 음식점 월평균 매출은?"
        
        일반화_패턴: "[지역] [업종] [지표]"
        
        변수_템플릿:
          지역: [한국, 국내, 대한민국, Korea]
          업종: [음식점, 식당, 레스토랑, 요식업]
          지표: [월매출, 월평균 매출, 평균 매출, 매출]
        
        임베딩:
          vector: [0.123, -0.456, ...] (1536 dim)
          목적: "유사 질문 검색"
      
      검색_활용:
        - "국내 식당 매출은?" 입력
        - 임베딩 유사도 >0.8
        - 매칭! → Tier 1 결과 사용
    
    2_맥락_정보:
      목적: "맥락 일치 여부 판단"
      
      항목:
        intent: "understand_market | make_decision | ..."
        domain: "Food_Service | B2B_SaaS | ..."
        region: "한국 | 서울 | 미국 | ..."
        time_period: "2024 | 현재 | 3년 후 | ..."
        granularity: "macro | segment | micro"
      
      검색_활용:
        IF 질문_맥락 == 저장된_맥락:
          → 정확히 사용 가능
        
        ELSE IF 일부_다름:
          → 조정 필요
          예: 저장된 것 "2024년" / 질문 "2025년"
            → 성장률 고려하여 조정
    
    3_결과_정보:
      목적: "실제 사용할 값"
      
      항목:
        value: 2700만원
        value_range: [1890만원, 3510만원]
        unit: "원" (단위)
        
        confidence: 0.85
        uncertainty: "±30%"
      
      검색_활용:
        - 값 그대로 리턴
        - 또는 범위 리턴
    
    4_근거_추적:
      목적: "왜 이 값인가? (재현성)"
      
      항목:
        evidence_sources: ["web_search", "rag", "llm"]
        evidence_count: 5
        
        judgment_strategy: "weighted_average"
        
        tier_origin: "tier2"
        
        timestamp: "2024-11-07T10:30:00"
      
      최소화_원칙:
        포함_하지_않음:
          - 개별 증거 상세 (너무 많음)
          - LLM 프롬프트 (불필요)
          - 중간 계산 과정 (복잡)
        
        포함:
          - 출처 목록만
          - 사용 전략만
          - 생성 시점만
    
    5_사용_통계:
      목적: "얼마나 자주 사용되는가? (우선순위)"
      
      항목:
        usage_count: 10 (누적 사용 횟수)
        last_used: "2024-11-07T15:20:00"
        last_verified: "2024-11-07" (마지막 검증)
      
      활용:
        - 자주 사용 → 우선순위 높임
        - 오래된 것 → 재검증 필요
        - 안 쓰이는 것 → 제거 후보
  
  선택적_메타데이터:
    
    validation_history:
      목적: "검증 이력 (고급)"
      항목: "검증 날짜, 검증자, 결과"
      필요성: "중요한 규칙만"
    
    related_questions:
      목적: "유사 질문 링크 (고급)"
      항목: "관련 질문 ID 리스트"
      필요성: "패턴 발견 시"
  
  최소_필수_메타데이터:
    리스트:
      1. 질문 패턴 (임베딩 포함)
      2. 맥락 (intent, domain, region, time, granularity)
      3. 결과 (value, range, unit, confidence)
      4. 근거 (sources, strategy, tier)
      5. 통계 (usage_count, last_used, last_verified)
    
    총: "5개 카테고리"
    
    예상_크기: "200-300 bytes/규칙"

---

# ═══════════════════════════════════════════════════════
# PART 11: Tier 1 규칙 라이브러리 설계
# ═══════════════════════════════════════════════════════

tier1_rule_library:
  
  진화_경로:
    
    Stage_1_초기_YAML:
      규칙_개수: "10-20개"
      형식: "YAML 파일"
      검색: "순차 매칭"
      속도: "0.001초"
      
      파일_구조:
        data/tier1_rules/
          ├── built_in.yaml           # 10-20개 명백한 규칙
          └── learned/                 # 학습된 규칙
              ├── food_service.yaml
              ├── b2b_saas.yaml
              └── ...
    
    Stage_2_중기_YAML:
      규칙_개수: "100-500개"
      형식: "YAML 파일 (도메인별)"
      검색: "도메인 인덱스 + 패턴 매칭"
      속도: "0.01-0.05초"
      
      최적화:
        - 도메인별 파일 분리
        - 도메인 먼저 식별 → 해당 파일만 검색
        - 인덱스 구조 추가
    
    Stage_3_장기_RAG:
      규칙_개수: "1,000개 이상"
      형식: "Vector DB"
      검색: "임베딩 유사도"
      속도: "0.1-0.5초"
      
      전환_이유:
        - YAML 순차 매칭 느려짐
        - 유사 질문 자동 찾기
        - 확장성 무한
      
      Collection:
        이름: "tier1_learned_rules"
        
        문서_구조:
          rule_id: "RULE-FOOD-001"
          
          question_pattern:
            original: "한국 음식점 월평균 매출은?"
            template: "[지역] [업종] [지표]"
            embedding: [...]
          
          context:
            intent: "understand_market"
            domain: "Food_Service"
            region: "한국"
            time_period: "2024"
            granularity: "macro"
          
          result:
            value: 2700만원
            range: [1890만원, 3510만원]
            unit: "원"
            confidence: 0.85
            uncertainty: 0.30
          
          provenance:
            tier_origin: "tier2"
            sources: ["web", "rag", "llm"]
            strategy: "weighted_average"
            evidence_count: 5
            
            created_at: "2024-11-07"
            usage_count: 10
            last_verified: "2024-11-07"
  
  검색_로직:
    
    Stage_1_2_YAML:
      
      단계:
        1. 질문 정규화
           예: "국내 식당 매출?" → "한국 음식점 매출"
        
        2. 키워드 추출
           예: ["한국", "음식점", "매출"]
        
        3. 도메인 추정 (빠른 규칙)
           예: "음식점" → Food_Service
        
        4. 해당 도메인 YAML 로드
           파일: "learned/food_service.yaml"
        
        5. 패턴 매칭 시도
           규칙들을 순차 체크
        
        6. 매칭 성공 시
           - 맥락 일치 여부 체크
           - 시점 조정 필요 여부
           - 결과 리턴
        
        7. 매칭 실패 시
           - Tier 2로 넘김
    
    Stage_3_RAG:
      
      단계:
        1. 질문 임베딩
           embedding = embed(question)
        
        2. 유사도 검색
           results = vector_search(embedding, top_k=5)
        
        3. 맥락 필터링
           후보들 중:
             - 맥락 일치도 체크
             - 시점 일치도 체크
             - 일치하는 것만 선택
        
        4. 최고 유사도 선택
           IF 유사도 >= 0.85:
             → 규칙 사용
           ELSE:
             → Tier 2로
        
        5. 값 조정 (필요 시)
           IF 시점 다름:
             → 성장률 적용하여 조정
           
           IF 지역 다름:
             → 지역 배수 적용

---

# ═══════════════════════════════════════════════════════
# PART 12: 메타데이터 검색 시나리오
# ═══════════════════════════════════════════════════════

metadata_search_scenarios:
  
  시나리오_1_완전_일치:
    질문: "한국 음식점 월평균 매출은?"
    
    검색:
      - 질문 임베딩
      - 유사도 검색
      - 최고 유사도: 0.98 (거의 동일!)
    
    매칭된_규칙:
      question: "한국 음식점 월평균 매출은?"
      context:
        domain: "Food_Service"
        region: "한국"
        time: "2024"
    
    맥락_일치:
      - domain: ✅ 일치
      - region: ✅ 일치
      - time: ✅ 일치 (현재 = 2024)
    
    결과: "2,700만원 그대로 사용" ✅
  
  시나리오_2_유사_질문:
    질문: "국내 식당 평균 매출은?"
    
    검색:
      유사도: 0.88
    
    매칭된_규칙:
      question: "한국 음식점 월평균 매출은?"
    
    맥락_일치:
      - domain: ✅ (식당 = 음식점)
      - region: ✅ (국내 = 한국)
      - time: ✅
    
    결과: "2,700만원 사용" ✅
  
  시나리오_3_시점_다름:
    질문: "2025년 한국 음식점 매출은?"
    
    검색:
      유사도: 0.92
    
    매칭된_규칙:
      question: "한국 음식점 월평균 매출은?"
      context:
        time: "2024"
      result:
        value: 2700만원
    
    맥락_불일치:
      - time: ❌ (2025 vs 2024)
    
    조정_방법:
      
      성장률_적용_가능:
        IF RAG에 "음식점 매출 성장률" 있음:
          성장률: 5%/년
          조정값: 2700 × 1.05 = 2,835만원
          결과: "2,835만원 (2024 기준 2,700 + 5% 성장)" ✅
        
        ELSE:
          → Tier 2로 넘김 (조정 불가)
  
  시나리오_4_맥락_다름:
    질문: "음식점 창업 예상 매출은?"
    
    검색:
      유사도: 0.85
    
    매칭된_규칙:
      question: "한국 음식점 월평균 매출은?"
      context:
        intent: "understand_market"
      result:
        value: 2700만원
    
    맥락_불일치:
      - intent: ❌ (make_decision vs understand_market)
    
    처리:
      
      옵션_A_조정:
        IF 저장된_range_있음:
          range: [1890만원, 3510만원]
          보수적_선택: 1890만원 (하한)
          결과: "1,890만원 (보수적)" ✅
      
      옵션_B_Tier_2:
        맥락_중요도_높음:
          → Tier 2로 넘김
          → LLM이 정확히 판단
  
  시나리오_5_도메인_다름:
    질문: "한국 카페 월평균 매출은?"
    
    검색:
      유사도: 0.75 (낮음)
    
    매칭된_규칙:
      domain: "Food_Service"
    
    맥락_일치:
      - domain: ✅ (카페도 Food_Service)
    
    하지만:
      유사도_낮음: 0.75 < 0.85
      → Tier 2로 넘김
      → 카페는 음식점과 다를 수 있음

---

# ═══════════════════════════════════════════════════════
# PART 13: 학습 정책
# ═══════════════════════════════════════════════════════

learning_policy:
  
  편입_기준:
    
    자동_편입:
      조건:
        - 사용 횟수 >= 10회
        - confidence >= 0.85
        - 결과 일관성 >90% (여러 번 추정 시)
        - 증거 출처 >= 3개
      
      절차:
        1. 메타데이터 생성
        2. YAML 파일에 추가
        3. 인덱스 업데이트
    
    인간_검증_후_편입:
      조건:
        - 0.7 <= confidence < 0.85
        - 중요한 지표 (시장 규모 등)
        - 의사결정 관련
      
      절차:
        1. 후보로 등록
        2. 인간 검토 요청
        3. 승인 시 편입
    
    편입_금지:
      조건:
        - confidence < 0.7
        - 증거 1개만
        - 맥락 매우 특수 (재사용 불가능)
  
  유지보수_정책:
    
    주기적_검증:
      빈도: "월 1회"
      
      대상:
        - 6개월 이상 사용 안 된 규칙
        - confidence 낮은 규칙 (<0.8)
      
      방법:
        - Tier 2로 재추정
        - 결과 비교
        - 차이 >20% → 업데이트 or 제거
    
    자동_업데이트:
      트리거:
        - 같은 질문 Tier 2 추정 결과와 차이 >30%
        - 새로운 증거 발견
      
      방법:
        - 새 결과로 교체
        - 이력 보존
        - last_verified 업데이트
    
    제거_정책:
      조건:
        - 12개월 사용 없음
        - 검증 실패 3회 이상
        - 도메인 deprecated
      
      방법:
        - 아카이브로 이동
        - 활성 규칙에서 제거

---

# ═══════════════════════════════════════════════════════
# PART 14: 전체 시스템 진화
# ═══════════════════════════════════════════════════════

system_evolution:
  
  Week_1:
    Tier_1_규칙: "20개 (built-in)"
    커버리지: "45%"
    평균_속도: "2.3초"
    
    처리_분포:
      Tier_1: 45%
      Tier_2: 50%
      Tier_3: 5%
  
  Month_1:
    Tier_1_규칙: "120개 (20 + 100 learned)"
    커버리지: "75%"
    평균_속도: "1.2초"
    
    처리_분포:
      Tier_1: 75%
      Tier_2: 22%
      Tier_3: 3%
    
    학습_소스:
      - Tier_2 결과: 80개
      - Tier_3 결과: 20개
  
  Month_6:
    Tier_1_규칙: "500개"
    커버리지: "88%"
    평균_속도: "0.6초"
    
    RAG_전환_고려:
      이유: "YAML 매칭 느려지기 시작"
      임계값: "500개"
  
  Year_1:
    Tier_1_규칙: "2,000개 (RAG)"
    커버리지: "95%"
    평균_속도: "0.3초"
    
    처리_분포:
      Tier_1: 95%
      Tier_2: 4%
      Tier_3: 1%
    
    시스템_특성:
      - 대부분 Tier 1 (학습된 규칙)
      - 새 질문만 Tier 2/3
      - 매우 빠름
      - 비용 거의 없음

---

# ═══════════════════════════════════════════════════════
# PART 15: 핵심 통찰 및 설계 결정
# ═══════════════════════════════════════════════════════

key_insights:
  
  통찰_1_학습하는_시스템:
    개념: "사용할수록 똑똑해지는 시스템"
    
    메커니즘:
      - Tier 2/3는 "학습 엔진"
      - Tier 1은 "캐시 + 지식 베이스"
      - 선순환: 많이 쓸수록 → 빨라짐 → 더 많이 씀
    
    본질:
      초기: "느리지만 정확"
      진화: "빠르고 정확"
  
  통찰_2_메타데이터가_핵심:
    
    검색_가능성:
      IF 메타데이터_잘_설계:
        → 유사 질문 찾기 쉬움
        → 재사용률 높음
        → 학습 효과 극대화
      
      IF 메타데이터_부실:
        → 검색 실패
        → 재사용 안 됨
        → 학습 효과 없음
    
    최소성_vs_완결성:
      너무_적으면: 검색 정확도 ↓
      너무_많으면: 복잡도 ↑, 저장 공간 ↑
      
      균형점: "5개 카테고리" (현재 설계)
  
  통찰_3_YAML_to_RAG_진화:
    
    자연스러운_진화:
      - 초기: YAML (20개, 단순)
      - 중기: YAML (500개, 도메인 분리)
      - 장기: RAG (2,000개+, 벡터 검색)
    
    전환_시점:
      지표: "검색 속도"
      임계값: "YAML 매칭 >0.1초"
      결정: "RAG로 전환"
    
    일관성:
      - YAML과 RAG는 동일한 메타데이터
      - 검색 방식만 다름
      - 투명한 전환

---

# ═══════════════════════════════════════════════════════
# PART 16: 구현 독립적 사양
# ═══════════════════════════════════════════════════════

implementation_agnostic_spec:
  
  핵심_인터페이스:
    
    estimate_함수:
      입력:
        - 질문: "한국 음식점 월매출은?"
        - 맥락: {project_data: {...}, constraints: [...]}
        - 깊이: 0 (재귀용)
      
      출력:
        - 값: 2700만원
        - 범위: [1890, 3510]
        - 신뢰도: 0.85
        - Tier: 2
        - 근거: [증거_리스트]
        - 추론_과정: "..."
      
      동작:
        1. Tier 1 규칙 체크 (어떤 방식이든)
        2. 실패 시 Tier 2 (어떤 방식이든)
        3. 필요 시 Tier 3 (어떤 방식이든)
    
    learn_함수:
      입력:
        - 질문
        - 추정_결과
        - 메타데이터
      
      출력:
        - 규칙_생성_여부
        - 규칙_ID (생성 시)
      
      동작:
        1. 재사용 횟수 체크
        2. 편입 기준 확인
        3. 규칙 생성 및 저장
  
  데이터_스키마:
    
    LearnedRule:
      필수_필드:
        - rule_id: "고유 ID"
        - question_pattern: "질문 패턴 + 임베딩"
        - context: "맥락 정보 (5개)"
        - result: "결과 (값, 범위, 신뢰도)"
        - provenance: "근거 (출처, 전략)"
        - stats: "통계 (사용 횟수 등)"
      
      선택_필드:
        - validation_history: "검증 이력"
        - related_questions: "관련 질문"
      
      크기: "200-300 bytes"
  
  확장_포인트:
    
    규칙_저장소:
      초기: "YAML 파일"
      확장: "Vector DB"
      인터페이스: "동일"
    
    맥락_파악:
      초기: "규칙 + 간단한 LLM"
      확장: "고급 LLM + 학습"
      인터페이스: "동일"
    
    증거_수집:
      초기: "3-5개 Layer"
      확장: "10개+ Layer"
      인터페이스: "동일"

---

# ═══════════════════════════════════════════════════════
# PART 17: 사용자 기여 데이터 (User-Contributed Facts)
# ═══════════════════════════════════════════════════════

user_contributed_facts:
  
  핵심_아이디어:
    
    개념: "사용자가 제공하는 사실/경험을 시스템 지식으로 전환"
    
    사용자_입력_예시:
      - "우리 회사 고객 10만명이야"
      - "업계 평균 Churn 5%라고 들었어"
      - "경험상 음식점은 보통 2,000만원 정도"
      - "작년 우리 매출 30억"
    
    분류:
      
      확정_사실:
        예: "우리 회사 고객 10만명"
        특징: 프로젝트 특정, 검증 가능
        처리: 즉시 프로젝트 데이터로 사용
      
      업계_상식:
        예: "SaaS Churn 보통 5%"
        특징: 일반화 가능, 검증 필요
        처리: 후보로 모음 → 검증 → Tier 1 편입
      
      개인_경험:
        예: "음식점 보통 2,000만원"
        특징: 주관적, 신뢰도 낮음
        처리: 참고용으로 모음 → 다른 증거와 비교
  
  데이터_흐름:
    
    단계_1_수집:
      
      수집_시점:
        - 사용자가 명시적으로 입력
        - 대화 중 언급
        - 파일 업로드 (Excel 등)
      
      수집_형식:
        user_fact:
          fact_id: "UCF-2024110701"  # User Contributed Fact
          
          fact_type: "definite | industry_common | personal_experience"
          
          statement:
            original: "우리 회사 고객 10만명"
            normalized: "고객수 = 100,000명"
          
          value:
            metric: "고객수"
            value: 100000
            unit: "명"
            value_type: "point | range | distribution"
          
          context:
            project_id: "PROJ-20241107"
            user_id: "user123"
            session_id: "SESSION-001"
            
            scope: "project | domain | global"
            
            domain: "B2B_SaaS" (추정)
            region: "한국" (추정)
            time_period: "2024" (명시 or 추정)
          
          source_info:
            source_type: "user_stated | user_file | user_experience"
            confidence_claim: "확실 | 들었음 | 경험상"
            
            timestamp: "2024-11-07T10:30:00"
          
          verification_status: "pending"
    
    단계_2_즉시_활용:
      
      프로젝트_데이터로:
        조건:
          - fact_type == "definite"
          - scope == "project"
          - 사용자가 확정값으로 제공
        
        예시:
          "우리 회사 고객 10만명"
          → project_data['customer_count'] = 100000
          → 이 프로젝트에서 즉시 사용
          → 검증 불필요
      
      참고_데이터로:
        조건:
          - fact_type == "industry_common" or "personal_experience"
          - 검증 전
        
        활용:
          - Tier 2 증거 수집 시 추가 증거로 활용
          - 하지만 낮은 가중치 (0.3-0.5)
          - "사용자 제공" 명시
    
    단계_3_후보_큐_저장:
      
      저장_위치:
        파일: "data/user_facts/pending.jsonl"
        
        형식: |
          {"fact_id": "UCF-001", "statement": "...", "value": ..., ...}
          {"fact_id": "UCF-002", ...}
          {"fact_id": "UCF-003", ...}
      
      목적:
        - 검증 대기
        - 일괄 처리
        - 이력 보존
    
    단계_4_자동_검증:
      
      검증_방법:
        
        교차_검증:
          IF 같은_메트릭_여러_사용자:
            예:
              사용자_A: "SaaS Churn 5%"
              사용자_B: "SaaS Churn 7%"
              사용자_C: "SaaS Churn 6%"
            
            분석:
              - 평균: 6%
              - 분산: 작음
              - 일치도: 높음
            
            판단: "검증 통과" ✅
            편입: Tier 1 후보로
        
        외부_검증:
          IF 사용자_fact_있음:
            예: "음식점 평균 2,000만원"
          
          Tier_2로_재추정:
            - 웹 검색: 2,500만원
            - RAG: 2,700만원
            - LLM: 2,600만원
          
          비교:
            사용자: 2,000만원
            시스템: 2,600만원
            차이: 23%
          
          판단:
            IF 차이 <20%:
              → "검증 통과" ✅
            ELSE:
              → "재확인 필요" ⚠️
        
        신뢰도_축적:
          사용자별_신뢰도_추적:
            user_id: "user123"
            
            제공_횟수: 15
            검증_통과: 12
            검증_실패: 3
            
            신뢰도: 12/15 = 0.80
          
          활용:
            IF 사용자_신뢰도 >0.85:
              → 자동 검증 완화
              → 빠른 편입
            
            IF 사용자_신뢰도 <0.60:
              → 엄격한 검증
              → 인간 확인 필요
    
    단계_5_Tier_1_편입:
      
      편입_조건:
        자동_편입:
          - 교차 검증 통과 (3명 이상 일치)
          - 외부 검증 통과 (차이 <20%)
          - 제공자 신뢰도 >0.85
        
        인간_검증_후:
          - 외부 검증 차이 20-50%
          - 제공자 신뢰도 0.60-0.85
          - 중요한 지표
        
        편입_금지:
          - 외부 검증 차이 >50%
          - 제공자 신뢰도 <0.60
          - 검증 불가능
      
      편입_형태:
        규칙_추가:
          파일: "data/learned_rules/[domain].yaml"
          
          메타데이터_추가:
            provenance:
              tier_origin: "user_contributed"
              contributor_id: "user123"
              verification_method: "cross_check | external_verify"
              verified_at: "2024-11-08"
  
  신뢰도_계층:
    
    계층_구조:
      
      Level_1_확정값:
        예: "우리 회사 고객 10만명"
        신뢰도: 1.0
        검증: 불필요
        범위: 프로젝트만
      
      Level_2_검증된_업계_상식:
        예: "SaaS Churn 5-7%"
        신뢰도: 0.85-0.95
        검증: 교차 or 외부
        범위: 도메인 전체
      
      Level_3_미검증_정보:
        예: "경험상 음식점 2,000만원"
        신뢰도: 0.50-0.70
        검증: 대기 중
        범위: 참고용만
      
      Level_4_검증_실패:
        예: "음식점 5,000만원" (너무 높음)
        신뢰도: <0.50
        검증: 실패
        범위: 사용 안 함
    
    활용_방식:
      
      Tier_1_규칙_편입:
        - Level 1: 즉시 (프로젝트 데이터)
        - Level 2: 검증 후 편입
        - Level 3-4: 편입 안 함
      
      Tier_2_증거_활용:
        - Level 1: 1.0 가중치
        - Level 2: 0.7-0.9 가중치
        - Level 3: 0.3-0.5 가중치 (참고용)
        - Level 4: 사용 안 함

  데이터_격리:
    
    프로젝트별_격리:
      
      프로젝트_데이터:
        위치: "projects/[project_id]/user_facts.yaml"
        
        범위: 해당 프로젝트만
        
        공유_안_됨: 다른 프로젝트 접근 불가
        
        예시:
          프로젝트_A: "우리 고객 10만명"
          → 프로젝트_A에서만 사용
          → 프로젝트_B는 접근 불가
      
      도메인_지식:
        위치: "data/user_facts/[domain]/verified.yaml"
        
        범위: 같은 도메인 모든 프로젝트
        
        조건:
          - 검증 통과
          - 일반화 가능
          - 재사용 가치 있음
        
        예시:
          "SaaS Churn 5-7%" (검증됨)
          → 모든 SaaS 프로젝트에서 사용 가능
      
      전역_지식:
        위치: "data/tier1_rules/learned/[domain].yaml"
        
        범위: 모든 프로젝트
        
        조건:
          - 엄격한 검증
          - 높은 재사용률
          - 시스템 학습 완료

  피드백_루프:
    
    사용자_피드백_수집:
      
      시점:
        - 추정 결과 제시 시
        - "이 값이 맞나요?"
      
      피드백_타입:
        
        확인:
          사용자: "맞아요"
          처리: usage_count++, 신뢰도 ↑
        
        수정:
          사용자: "아니요, 실제로는 3,000만원이에요"
          처리:
            - 사용자 fact로 저장
            - 기존 규칙 신뢰도 ↓
            - 재검증 트리거
        
        보충:
          사용자: "서울은 4,000만원, 지방은 2,000만원"
          처리:
            - 세분화 필요 신호
            - 지역별 규칙 생성 트리거

---

# ═══════════════════════════════════════════════════════
# PART 18: 검증 파이프라인
# ═══════════════════════════════════════════════════════

verification_pipeline:
  
  목적: "사용자 제공 정보를 안전하게 시스템 지식으로 전환"
  
  파이프라인_단계:
    
    Stage_1_수집:
      
      입력_채널:
        
        명시적_입력:
          형태: "사용자가 직접 fact 입력"
          예시: "고객수 10만명으로 설정해줘"
          처리: fact_type = "definite"
        
        대화_추출:
          형태: "대화 중 자연스럽게 언급"
          예시: "우리 Churn이 5% 정도거든"
          처리: LLM이 fact 추출 → 사용자 확인
        
        파일_업로드:
          형태: "Excel, CSV 등"
          예시: assumptions.xlsx
          처리: 파일 파싱 → fact 리스트 생성
      
      저장_위치:
        즉시_사용:
          파일: "projects/[project_id]/.project_data.yaml"
          범위: 프로젝트만
          검증: 불필요 (사용자 확정)
        
        검증_대기:
          파일: "data/user_facts/pending/[user_id].jsonl"
          범위: 검증 후 결정
          검증: 필수
    
    Stage_2_분류:
      
      자동_분류:
        
        범위_판단:
          
          IF 프로젝트_특수:
            지표:
              - "우리", "당사", 프로젝트명 포함
              - 구체적 숫자
            
            예: "우리 회사 고객 10만명"
            
            판단: scope = "project"
            처리: 프로젝트 데이터로만 사용
          
          IF 도메인_일반:
            지표:
              - "업계", "평균", "보통"
              - 일반적 표현
            
            예: "SaaS 업계 Churn 보통 5%"
            
            판단: scope = "domain"
            처리: 검증 후 도메인 지식으로
          
          IF 전역_지식:
            지표:
              - 물리/법률 상수
              - 보편적 사실
            
            예: "최저임금 9,860원"
            
            판단: scope = "global"
            처리: 검증 후 전역 규칙으로
        
        신뢰도_초기값:
          
          사용자_진술_기반:
            "확실해요": 0.9
            "들었어요": 0.7
            "아마도": 0.5
            "경험상": 0.6
          
          사용자_이력_기반:
            신뢰도_높은_사용자: +0.1
            신뢰도_낮은_사용자: -0.2
    
    Stage_3_검증:
      
      검증_방법:
        
        방법_1_교차_검증:
          
          조건: "같은 메트릭에 여러 사용자 입력"
          
          절차:
            1. 동일_메트릭_수집:
               예: "SaaS Churn"
                 - 사용자_A: 5%
                 - 사용자_B: 7%
                 - 사용자_C: 6%
                 - 사용자_D: 5.5%
            
            2. 통계_분석:
               평균: 5.875%
               표준편차: 0.83%
               분산: 작음
            
            3. 일치도_판단:
               IF 표준편차/평균 < 0.2:
                 → 일치도 높음 ✅
               
               결과: 5.9% ± 15%
            
            4. 신뢰도_설정:
               사용자_수_기반:
                 2명: 0.60
                 3명: 0.75
                 4명: 0.85
                 5명+: 0.90
        
        방법_2_외부_검증:
          
          조건: "시스템이 독립적으로 추정 가능"
          
          절차:
            1. 사용자_fact_있음:
               "음식점 평균 2,000만원"
            
            2. Tier_2_독립_추정:
               - 웹 검색
               - RAG
               - LLM
               
               결과: 2,600만원
            
            3. 차이_계산:
               차이 = |2000 - 2600| / 2600 = 23%
            
            4. 판단:
               IF 차이 <15%:
                 → 검증 통과 ✅
                 → confidence 0.85
               
               IF 차이 15-30%:
                 → 부분 검증
                 → confidence 0.70
                 → 범위로 통합
               
               IF 차이 >30%:
                 → 검증 실패 ❌
                 → 사용자에게 재확인 요청
        
        방법_3_논리_검증:
          
          조건: "다른 fact와 논리적 일관성 체크"
          
          절차:
            사용자_facts:
              - "고객수 10만명"
              - "월간 매출 100억"
              - "ARPU 1,000원"
            
            논리_체크:
              계산: 100,000 × 1,000 = 1억 (월간)
              입력: 100억
              차이: 100배!
            
            판단:
              → 논리 모순 ❌
              → 사용자에게 재확인
        
        방법_4_시간_검증:
          
          조건: "시간이 지나면서 계속 유효한가?"
          
          절차:
            1개월_후:
              - 같은 질문 Tier 2 재추정
              - 사용자 fact와 비교
              - 여전히 일치하면 신뢰도 ↑
            
            6개월_후:
              - 자동 재검증
              - 차이 확인
              - 업데이트 or 제거
    
    Stage_4_편입:
      
      편입_대상:
        
        프로젝트_지식:
          조건:
            - scope = "project"
            - 사용자 확정값
          
          위치: "projects/[project_id]/.project_data.yaml"
          
          검증: 불필요
          
          수명: 프로젝트 종료까지
        
        도메인_지식:
          조건:
            - scope = "domain"
            - 검증 통과 (confidence >0.80)
            - 재사용 가치 있음
          
          위치: "data/user_facts/verified/[domain].yaml"
          
          검증: 필수
          
          수명: 재검증 실패까지
        
        Tier_1_규칙:
          조건:
            - 검증 통과 (confidence >0.85)
            - 사용 10회 이상 (검증 포함)
            - 일반화 가능
          
          위치: "data/learned_rules/[domain].yaml"
          
          검증: 엄격
          
          수명: 영구 (유지보수 대상)
      
      메타데이터_마킹:
        
        출처_표시:
          provenance:
            tier_origin: "user_contributed"
            
            contributors:
              - user_id: "user123"
                contribution_date: "2024-11-07"
                original_value: 2000만원
              - user_id: "user456"
                contribution_date: "2024-11-08"
                original_value: 2200만원
            
            verification:
              method: "cross_check"
              external_check_value: 2600만원
              verified_at: "2024-11-08"
              verified_by: "system_auto"
            
            final_value: 2100만원
            final_confidence: 0.82

  사용자_경험_최적화:
    
    투명성:
      
      사용자에게_알림:
        수집_시:
          메시지: "이 정보를 저장하여 향후 비슷한 질문에 활용하겠습니까?"
          선택: "예 | 아니오 | 이 프로젝트만"
        
        검증_결과:
          통과: "제공하신 정보가 검증되었습니다 (신뢰도 85%)"
          실패: "다른 데이터와 차이가 있습니다. 재확인해주시겠어요?"
        
        편입_알림:
          메시지: "제공하신 정보가 시스템 지식으로 추가되었습니다"
          혜택: "비슷한 질문이 더 빨라집니다"
    
    기여_추적:
      
      사용자별_대시보드:
        내_기여:
          - 제공한 fact 수: 15개
          - 검증 통과: 12개
          - Tier 1 편입: 8개
          - 내 신뢰도: 80%
        
        영향:
          - 내 기여로 빨라진 쿼리: 45개
          - 다른 사용자 도움: 12명
      
      인센티브:
        - 높은 신뢰도 사용자: 자동 검증 완화
        - 많은 기여: 우선 지원
        - 커뮤니티 기여도 표시

---

# ═══════════════════════════════════════════════════════
# PART 19: 통합 시스템 아키텍처
# ═══════════════════════════════════════════════════════

integrated_architecture:
  
  데이터_소스_계층:
    
    Layer_1_확정_데이터:
      출처:
        - 프로젝트 데이터 (사용자 입력)
        - 물리/법률 상수
        - 공식 통계 (검증됨)
      
      신뢰도: 1.0
      검증: 불필요
      사용: Tier 1 즉시
    
    Layer_2_학습된_규칙:
      출처:
        - Tier 2/3 추정 결과 (10회+ 사용)
        - 사용자 제공 (검증 통과)
      
      신뢰도: 0.85-0.95
      검증: 완료
      사용: Tier 1 규칙
    
    Layer_3_검증된_사용자_지식:
      출처:
        - 사용자 제공 (검증 통과)
        - 교차 검증 완료
      
      신뢰도: 0.70-0.85
      검증: 완료
      사용: Tier 2 증거
    
    Layer_4_미검증_정보:
      출처:
        - 사용자 제공 (검증 대기)
        - 1-2회 사용
      
      신뢰도: 0.50-0.70
      검증: 대기
      사용: Tier 2 참고용
  
  전체_흐름:
    
    질문_입력:
      "한국 음식점 월매출은?"
    
    Tier_1_시도:
      
      검색_순서:
        1. 프로젝트 데이터 (Layer 1)
        2. 학습된 규칙 (Layer 2)
           - YAML or RAG 검색
           - 유사도 >0.85
        3. Built-in 규칙
      
      매칭:
        IF 발견:
          → 결과 리턴 (빠름!)
        ELSE:
          → Tier 2로
    
    Tier_2_실행:
      
      맥락_파악: LLM
      
      증거_수집:
        출처:
          - 웹 검색
          - RAG 벤치마크
          - LLM 직접
          - 검증된 사용자 지식 (Layer 3)
          - 미검증 정보 (Layer 4, 낮은 가중치)
      
      판단_종합:
        - 모든 증거 평가
        - 전략 선택
        - 최종 값 결정
      
      학습:
        IF 재사용_가치_있음:
          → 메타데이터 생성
          → Tier 1 편입 후보
    
    사용자_fact_업데이트:
      
      IF 결과와_사용자_입력_다름:
        알림: "제공하신 값(2,000)과 추정값(2,600)이 다릅니다"
        선택: "제 값이 맞아요 | 추정값 사용 | 둘 다 참고"
        
        처리:
          "제 값": 사용자 fact 신뢰도 ↑
          "추정값": 사용자 fact 신뢰도 ↓
          "둘 다": 범위로 병합

---

# ═══════════════════════════════════════════════════════
# PART 20: 메타데이터 확장 (사용자 기여 포함)
# ═══════════════════════════════════════════════════════

extended_metadata:
  
  LearnedRule_확장:
    
    기존_필수_5개:
      - question_pattern
      - context
      - result
      - provenance
      - stats
    
    추가_필드:
      
      contributors:
        목적: "누가 기여했는가?"
        
        형식:
          contributors:
            - user_id: "user123"
              contribution_type: "direct_input | verification | feedback"
              contribution_date: "2024-11-07"
              original_value: 2000만원
            
            - user_id: "user456"
              contribution_type: "verification"
              contribution_date: "2024-11-08"
              original_value: 2200만원
        
        활용:
          - 기여자 추적
          - 신뢰도 계산
          - 인센티브
        
        필요성: "사용자 기여 규칙만"
      
      verification_detail:
        목적: "검증 과정 기록"
        
        형식:
          verification:
            method: "cross_check | external_verify | time_verify"
            
            cross_check:
              contributor_count: 4
              values: [2000, 2200, 2100, 2050]
              consensus: 2088만원
            
            external_check:
              tier2_value: 2600만원
              difference: 23%
              passed: false
            
            final_decision:
              value: 2100만원
              confidence: 0.75
              reasoning: "교차 검증 통과, 외부 검증 차이 있음"
        
        필요성: "검증 이력 중요한 것만"
  
  최종_메타데이터_사양:
    
    필수_항목:
      1. question_pattern (검색)
      2. context (맥락 매칭)
      3. result (값)
      4. provenance (출처)
      5. stats (사용 통계)
    
    조건부_항목:
      6. contributors (사용자 기여 시)
      7. verification_detail (검증 중요 시)
    
    크기:
      기본: 200-300 bytes
      사용자_기여: 300-400 bytes (contributors 추가)
    
    트레이드오프:
      - 크기 +50% (300 → 400 bytes)
      - 하지만 투명성 ↑↑
      - 신뢰도 계산 정확 ↑

---

# ═══════════════════════════════════════════════════════
# PART 21: 구현 가이드 (사용자 데이터)
# ═══════════════════════════════════════════════════════

implementation_guide_user_data:
  
  파일_구조:
    
    projects/[project_id]/
      .project_data.yaml:
        목적: "프로젝트 확정 데이터"
        
        예시: |
          customer_count: 100000
          monthly_revenue: 1000000000
          churn_rate: 0.05
          
          metadata:
            source: "user_input"
            confirmed: true
            timestamp: "2024-11-07"
    
    data/user_facts/
      pending/
        [user_id].jsonl:
          목적: "검증 대기 큐"
          
          예시: |
            {"fact_id": "UCF-001", "metric": "churn", "value": 0.05, ...}
            {"fact_id": "UCF-002", "metric": "arpu", "value": 50000, ...}
      
      verified/
        [domain].yaml:
          목적: "검증 완료된 도메인 지식"
          
          예시: |
            domain: "B2B_SaaS"
            
            facts:
              - fact_id: "UCF-VERIFIED-001"
                metric: "churn_rate"
                value: 0.06
                range: [0.05, 0.07]
                
                contributors: ["user123", "user456", "user789"]
                verification: "cross_check"
                confidence: 0.85
      
      rejected/
        [user_id].jsonl:
          목적: "검증 실패 기록"
          이유: "재발 방지, 패턴 학습"
  
  워크플로우:
    
    사용자_입력:
      예: "@Quantifier, 우리 고객 10만명, Churn 5%로 계산해줘"
      
      처리:
        1. LLM이 fact 추출
           facts:
             - customer_count: 100000
             - churn_rate: 0.05
        
        2. 사용자 확인
           메시지: "다음 정보를 저장하겠습니다. 맞나요?"
           
           확인: "예"
        
        3. 프로젝트 데이터 저장
           파일: .project_data.yaml
        
        4. 도메인 지식 후보 등록
           파일: data/user_facts/pending/user123.jsonl
           조건: scope 판단 결과
    
    검증_프로세스:
      
      자동_검증_예시:
        입력: "SaaS Churn 5%"
        
        1. 교차 검증 시도
           기존_입력: ["user456: 6%", "user789: 5.5%"]
           새_입력: "user123: 5%"
           
           분석:
             평균: 5.5%
             일치: 높음
           
           결과: 검증 통과 ✅
        
        2. 외부 검증
           Tier_2_추정: 6.2%
           차이: 12%
           
           결과: 허용 범위
        
        3. 편입
           파일: data/user_facts/verified/b2b_saas.yaml
           신뢰도: 0.82
        
        4. 사용자 알림
           메시지: "제공하신 정보가 검증되었습니다 (신뢰도 82%)"

---

# ═══════════════════════════════════════════════════════
# PART 22: 열린 질문 (사용자 데이터)
# ═══════════════════════════════════════════════════════

open_questions_user_data:
  
  질문_1_편입_임계값:
    현재: "사용 10회 + confidence 0.85"
    고민: "너무 높은가? 낮은가?"
    검증: "실사용 데이터로 조정"
  
  질문_2_사용자_신뢰도:
    현재: "사용자별 신뢰도 추적"
    고민: "사용자 신뢰도를 규칙 신뢰도에 반영할 것인가?"
    옵션:
      A: "반영 (사용자 0.9 → 규칙도 0.9)"
      B: "독립 (검증으로만 판단)"
  
  질문_3_검증_비용:
    현재: "외부 검증 = Tier 2 실행 (비용 발생)"
    고민: "모든 사용자 fact를 검증하면 비용 많음"
    대안:
      - 샘플링 검증
      - 중요한 것만 검증
      - 신뢰도 높은 사용자는 생략
  
  질문_4_프라이버시:
    고민: "사용자 입력을 다른 사용자와 공유하는가?"
    
    옵션_A_완전_공유:
      - 모든 검증된 fact 공유
      - 시스템 학습 빠름
      - 하지만 프라이버시 이슈
    
    옵션_B_익명화_후_공유:
      - user_id 제거
      - 메트릭만 공유
      - 프라이버시 보호
    
    옵션_C_선택적_공유:
      - 사용자가 선택
      - "이 정보를 다른 사람과 공유하시겠습니까?"

---

# ═══════════════════════════════════════════════════════
# PART 23: RAG 재사용 전략
# ═══════════════════════════════════════════════════════

rag_reuse_strategy:
  
  현재_UMIS_RAG_시스템:
    
    기존_Collections:
      
      Explorer:
        - explorer_knowledge_base: 354개 (패턴/사례)
        - 용도: 비즈니스 모델 패턴 매칭
      
      Quantifier:
        - calculation_methodologies: 30개
        - market_benchmarks: 100개 ⭐
        - 용도: 계산 방법론, 시장 벤치마크
      
      Validator:
        - data_sources_registry: 50개
        - definition_validation_cases: 84개
      
      Observer:
        - market_structure_patterns: 30개
        - value_chain_benchmarks: 50개
      
      System:
        - system_knowledge: 28개 (도구)
      
      Guardian:
        - query_memory, goal_memory, rae_index
    
    검색_방식:
      메서드: "similarity_search_with_score()"
      임베딩: "text-embedding-3-large (3072 dim)"
      DB: "ChromaDB"
  
  Guestimation_필요_RAG:
    
    필요_1_Tier_1_학습된_규칙:
      목적: "학습된 추정 결과 검색"
      
      데이터_형태:
        질문: "한국 음식점 월매출은?"
        결과: 2700만원
        맥락: {domain, region, time, ...}
      
      검색_방식:
        - 질문 임베딩 → 유사 질문 찾기
        - 맥락 필터링
      
      기존_유사:
        없음 (새로운 용도)
      
      재사용_가능:
        ❌ 별도 Collection 필요
        이유: 데이터 구조 다름
    
    필요_2_Layer_7_벤치마크:
      목적: "도메인별 지표 벤치마크 검색"
      
      데이터_형태:
        지표: "SaaS Churn Rate"
        값: 5-7%
        도메인: "B2B_SaaS"
      
      검색_방식:
        - 지표 임베딩 → 유사 벤치마크
        - 도메인 필터링
      
      기존_유사:
        Quantifier.market_benchmarks ⭐
        - 100개 시장 벤치마크
        - 동일한 검색 방식
      
      재사용_가능:
        ✅ 그대로 재사용!
        방법: QuantifierRAG.search_benchmark()
    
    필요_3_사용자_기여_검색:
      목적: "검증된 사용자 fact 검색"
      
      데이터_형태:
        동일: Tier 1 학습된 규칙
        출처만 다름: user_contributed
      
      재사용_가능:
        ✅ Tier 1 규칙과 같은 Collection
        구분: provenance.tier_origin = "user_contributed"
  
  재사용_전략:
    
    전략_1_기존_Collection_활용:
      
      Quantifier_market_benchmarks:
        
        현재_용도:
          - Method 3 (Proxy) 계산
          - 유사 시장 벤치마크
        
        Guestimation_활용:
          - Layer 7: RAG 벤치마크
          - 도메인 지표 검색
        
        재사용_방식:
          직접_호출:
            from umis_rag.agents.quantifier import QuantifierRAG
            
            quantifier = QuantifierRAG()
            benchmarks = quantifier.search_benchmark("SaaS Churn", top_k=5)
          
          통합:
            Guestimation Layer 7에서
            → QuantifierRAG 인스턴스 생성
            → search_benchmark() 호출
            → 결과 활용
        
        장점:
          ✅ 코드 재사용
          ✅ 데이터 중복 없음
          ✅ 100개 벤치마크 즉시 활용
        
        단점:
          ❌ Quantifier 의존성 (허용 가능)
    
    전략_2_신규_Collection_생성:
      
      tier1_learned_rules:
        
        목적: "학습된 추정 결과 (Tier 2/3 + 사용자 기여)"
        
        데이터_구조:
          rule_id: "RULE-FOOD-001"
          
          question_pattern:
            original: "한국 음식점 월매출은?"
            embedding: [...]
          
          context:
            intent: "understand_market"
            domain: "Food_Service"
            region: "한국"
            time_period: "2024"
          
          result:
            value: 2700만원
            range: [1890, 3510]
            confidence: 0.85
          
          provenance:
            tier_origin: "tier2 | tier3 | user_contributed"
            sources: [...]
            
          stats:
            usage_count: 10
            last_verified: "2024-11-07"
        
        검색_방식:
          질문_임베딩_검색:
            - 유사 질문 찾기
            - 맥락 필터링
            - 최고 유사도 >0.85 → 사용
        
        필요성: ✅ 필수
        
        크기:
          Week 1: 0개
          Month 1: 100개
          Month 6: 500개
          Year 1: 2,000개
  
  최종_Collection_구조:
    
    기존_유지:
      - explorer_knowledge_base: 354개
      - calculation_methodologies: 30개
      - market_benchmarks: 100개 ⭐
      - data_sources_registry: 50개
      - definition_validation_cases: 84개
      - market_structure_patterns: 30개
      - value_chain_benchmarks: 50개
      - query_memory, goal_memory, rae_index
      - system_knowledge: 28개
    
    신규_추가:
      - tier1_learned_rules: 0 → 2,000개 (진화) ⭐
    
    총_Collections: 13개 → 14개

---

# ═══════════════════════════════════════════════════════
# PART 24: Guestimation Layer 7 상세 설계
# ═══════════════════════════════════════════════════════

layer7_rag_benchmark_design:
  
  목적: "도메인 지표 벤치마크 검색"
  
  데이터_소스:
    
    소스_1_Quantifier_benchmarks:
      Collection: "market_benchmarks"
      개수: 100개
      
      데이터_예시:
        - 지표: "SaaS Churn Rate"
          값: 5-7%
          도메인: "B2B_SaaS"
          지역: "Global"
        
        - 지표: "E-commerce Conversion"
          값: 2-3%
          도메인: "E-commerce"
      
      검색_방식:
        QuantifierRAG.search_benchmark(지표명, top_k=5)
      
      활용:
        질문: "SaaS Churn은?"
        → search_benchmark("SaaS Churn")
        → 결과: 5-7% (confidence 0.75)
    
    소스_2_학습된_규칙:
      Collection: "tier1_learned_rules"
      개수: 0 → 2,000개 (진화)
      
      데이터_예시:
        질문: "한국 SaaS Churn은?"
        결과: 6%
        맥락: {domain: "B2B_SaaS", region: "한국"}
      
      검색_방식:
        질문_유사도_검색
      
      활용:
        질문: "국내 SaaS 해지율은?"
        → 유사도 0.88
        → 결과: 6% (confidence 0.85)
  
  통합_전략:
    
    병렬_검색:
      
      단계:
        1. 두_소스_모두_검색:
           - Quantifier.search_benchmark()
           - tier1_learned_rules 검색
        
        2. 결과_병합:
           소스_1: "SaaS Churn 5-7%" (Global, 0.75)
           소스_2: "한국 SaaS Churn 6%" (한국, 0.85)
        
        3. 맥락_기반_선택:
           IF 질문_지역 == "한국":
             → 소스_2 우선 (맥락 일치)
           
           IF 질문_지역 == "글로벌":
             → 소스_1 우선
        
        4. 신뢰도_가중:
           최종_신뢰도 = max(소스_1_confidence, 소스_2_confidence)
  
  구현_방식:
    
    옵션_A_래퍼_클래스:
      
      구조:
        class GuestimationRAG:
          def __init__(self):
            self.quantifier = QuantifierRAG()
            self.tier1_store = load_tier1_collection()
          
          def search_benchmark(query, context):
            # 두 소스 검색
            results_1 = self.quantifier.search_benchmark(query)
            results_2 = self.tier1_store.search(query)
            
            # 병합 및 선택
            return merge_and_select(results_1, results_2, context)
      
      장점:
        ✅ 깔끔한 인터페이스
        ✅ 내부 복잡도 숨김
      
      단점:
        ❌ 새 클래스 필요
    
    옵션_B_직접_호출:
      
      구조:
        # Layer 7에서 직접
        from umis_rag.agents.quantifier import QuantifierRAG
        
        quantifier = QuantifierRAG()
        benchmarks = quantifier.search_benchmark(query)
        
        # Tier 1도 직접 검색
        learned_rules = search_tier1_rules(query)
        
        # 병합
        final = merge(benchmarks, learned_rules)
      
      장점:
        ✅ 단순함
        ✅ 의존성 명확
      
      단점:
        ❌ Layer 7 코드 복잡해짐
    
    권장: 옵션_A (래퍼)
      이유:
        - Layer는 단순해야 함
        - 통합 로직은 별도 클래스로

---

# ═══════════════════════════════════════════════════════
# PART 25: Collection 설계 (tier1_learned_rules)
# ═══════════════════════════════════════════════════════

tier1_learned_rules_collection:
  
  목적: "학습된 추정 결과를 빠르게 검색"
  
  Collection_사양:
    
    이름: "tier1_learned_rules"
    
    DB: "ChromaDB"
    
    임베딩: "text-embedding-3-large (3072 dim)"
    
    예상_크기:
      Week 1: 0개
      Month 1: 100개
      Month 6: 500개
      Year 1: 2,000개
      Year 2: 5,000개
    
    스토리지:
      크기: 2,000개 × 400 bytes = 800KB (작음!)
      임베딩: 2,000개 × 3072 × 4 bytes = 24MB
      총: ~25MB (매우 작음)
  
  문서_스키마:
    
    Document:
      
      page_content:
        내용: "질문 텍스트 + 맥락 설명"
        
        예시: |
          질문: 한국 음식점 월평균 매출은?
          
          맥락:
          - 의도: 시장 이해
          - 도메인: Food Service
          - 지역: 한국
          - 시점: 2024년
          - 세분화: 전체 평균
        
        목적: "임베딩 품질 향상"
      
      metadata:
        
        필수_필드:
          rule_id: "RULE-FOOD-001"
          
          question:
            original: "한국 음식점 월평균 매출은?"
            normalized: "한국 음식점 월매출"
            template: "[지역] [업종] [지표]"
          
          context:
            intent: "understand_market"
            domain: "Food_Service"
            region: "한국"
            time_period: "2024"
            granularity: "macro"
          
          result:
            value: 2700만원
            value_min: 1890만원
            value_max: 3510만원
            unit: "원"
            confidence: 0.85
            uncertainty: 0.30
          
          provenance:
            tier_origin: "tier2"
            sources: ["web_search", "rag_benchmark", "llm_direct"]
            strategy: "weighted_average"
            evidence_count: 5
          
          stats:
            usage_count: 10
            created_at: "2024-11-07T10:30:00"
            last_used: "2024-11-07T15:20:00"
            last_verified: "2024-11-07"
        
        조건부_필드:
          contributors:
            - user_id: "user123"
              value: 2000만원
          
          verification:
            method: "cross_check"
            verified_at: "2024-11-08"
  
  검색_메서드:
    
    기본_검색:
      
      메서드명: "search_learned_rule()"
      
      입력:
        - question: "한국 카페 월매출은?"
        - context: {domain: "Food_Service", region: "한국"}
        - top_k: 5
      
      처리:
        1. 질문_임베딩
        2. 유사도_검색 (top_k=10)
        3. 맥락_필터링:
           IF context.domain 지정:
             → domain 일치하는 것만
           IF context.region 지정:
             → region 일치하는 것만
        4. 재정렬 (필터링 후)
        5. Top_k 리턴
      
      출력:
        results:
          - rule: RULE-FOOD-001
            similarity: 0.88
            value: 2700만원
            confidence: 0.85
            context_match: 0.95 (domain ✅, region ✅)
    
    고급_검색:
      
      메서드명: "search_with_adjustment()"
      
      입력:
        - question: "2025년 한국 음식점 매출은?"
        - context: {...}
      
      처리:
        1. 기본_검색
        2. 시점_불일치_감지:
           저장: "2024년"
           질문: "2025년"
           차이: 1년
        
        3. 조정_가능_여부:
           IF 성장률_데이터_있음:
             → 조정 가능
           ELSE:
             → 불일치로 표시
        
        4. 값_조정:
           원본: 2700만원 (2024)
           성장률: 5%/년
           조정: 2700 × 1.05 = 2835만원
      
      출력:
        result:
          value: 2835만원
          adjusted: true
          adjustment_method: "growth_rate"
          original_value: 2700만원
          original_time: "2024"
  
  기존_RAG와_차이:
    
    비교:
      
      기존_Collections:
        목적: "방법론, 패턴, 사례 검색"
        데이터: "정적 (YAML에서 빌드)"
        업데이트: "YAML 수정 → 재빌드"
        크기: "고정 (354개 등)"
      
      tier1_learned_rules:
        목적: "추정 결과 검색"
        데이터: "동적 (사용하며 축적)"
        업데이트: "실시간 (자동 학습)"
        크기: "성장 (0 → 2,000개+)"
    
    공통점:
      - ChromaDB 동일
      - 임베딩 모델 동일
      - 검색 방식 동일
      - 메타데이터 필터링 동일
    
    차이점:
      - 데이터 생성 방식 (정적 vs 동적)
      - 업데이트 빈도 (드물게 vs 자주)
      - 크기 진화 (고정 vs 성장)

---

# ═══════════════════════════════════════════════════════
# PART 26: 재사용 의존성 맵
# ═══════════════════════════════════════════════════════

dependency_map:
  
  Guestimation_시스템:
    
    의존_컴포넌트:
      
      필수_의존:
        
        1_ChromaDB_인프라:
          from: "UMIS 기존"
          용도: "Vector DB"
          재사용: "100%"
        
        2_임베딩_모델:
          from: "UMIS 기존"
          모델: "text-embedding-3-large"
          재사용: "100%"
        
        3_QuantifierRAG:
          from: "umis_rag.agents.quantifier"
          메서드: "search_benchmark()"
          용도: "Layer 7 벤치마크 검색"
          재사용: "메서드 호출"
      
      선택_의존:
        
        4_ExplorerRAG:
          from: "umis_rag.agents.explorer"
          용도: "패턴 검색 (필요 시)"
          재사용: "선택적"
        
        5_Guardian_Memory:
          from: "umis_rag.guardian"
          용도: "순환 감지 (Fermi 재귀)"
          재사용: "선택적"
    
    독립_컴포넌트:
      
      신규_개발:
        
        1_tier1_learned_rules_Collection:
          목적: "학습된 규칙 검색"
          이유: "기존에 없는 용도"
        
        2_ComplexityAnalyzer:
          목적: "복잡도 분석"
          이유: "Guestimation 특화"
        
        3_ContextAnalyzer:
          목적: "맥락 파악"
          이유: "Guestimation 특화"
        
        4_EvidenceCollector:
          목적: "8개 Layer 통합"
          이유: "Guestimation 특화"
        
        5_JudgmentSynthesizer:
          목적: "증거 종합 판단"
          이유: "Guestimation 특화"
  
  코드_재사용률:
    
    인프라_재사용: "90%"
      - ChromaDB
      - 임베딩 모델
      - 설정 시스템
      - 로깅
    
    Agent_재사용: "30%"
      - QuantifierRAG 메서드 호출
      - 선택적으로 다른 Agent도
    
    신규_개발: "70%"
      - Guestimation 특화 로직
      - 3-Tier 시스템
      - 학습 시스템
    
    총_재사용: "~50%"

---

# ═══════════════════════════════════════════════════════
# PART 27: 구현 전략 (RAG)
# ═══════════════════════════════════════════════════════

implementation_strategy_rag:
  
  Phase_1_기존_RAG_활용:
    
    단계:
      1. QuantifierRAG 통합
         - Layer 7에서 search_benchmark() 호출
         - 100개 벤치마크 즉시 활용
         - 코드 10줄
      
      2. 테스트
         - "SaaS Churn은?"
         - "E-commerce Conversion은?"
         - 벤치마크 검색 동작 확인
      
      3. Tier 2 통합
         - 증거 수집 시 포함
         - 가중치 0.6-0.8
    
    예상_시간: "1-2시간"
    
    결과:
      - Layer 7 즉시 작동
      - 100개 벤치마크 활용
      - 추가 데이터 불필요
  
  Phase_2_학습_Collection_구축:
    
    단계:
      1. Collection_생성
         - 이름: "tier1_learned_rules"
         - 스키마 정의
         - 초기 데이터: 0개
      
      2. 학습_로직_구현:
         - Tier 2 결과 → 메타데이터 생성
         - 재사용 감지 (10회+)
         - Collection 추가
      
      3. 검색_로직_구현:
         - search_learned_rule()
         - 맥락 필터링
         - 시점 조정
      
      4. Tier_1_통합:
         - Tier 1에서 검색
         - 유사도 >0.85 → 사용
    
    예상_시간: "1-2일"
    
    결과:
      - 학습 시스템 작동
      - 사용할수록 빨라짐
  
  Phase_3_사용자_기여_통합:
    
    단계:
      1. 사용자_fact_수집:
         - 입력 파싱
         - 메타데이터 생성
         - pending.jsonl 저장
      
      2. 검증_파이프라인:
         - 교차 검증
         - 외부 검증
         - 신뢰도 계산
      
      3. Collection_편입:
         - 검증 통과 → tier1_learned_rules
         - provenance.tier_origin = "user_contributed"
    
    예상_시간: "2-3일"
    
    결과:
      - 사용자 기여 활성화
      - 커뮤니티 지식 축적

---

# ═══════════════════════════════════════════════════════
# PART 28: 최종 설계 결정 (RAG)
# ═══════════════════════════════════════════════════════

final_design_decisions_rag:
  
  결정_1_기존_Collection_재사용:
    
    질문: "Quantifier market_benchmarks를 재사용할 것인가?"
    
    결정: "✅ 재사용"
    
    이유:
      - 100개 벤치마크 즉시 활용
      - 중복 없음
      - 코드 간결
      - 의존성 허용 가능
    
    방법: "QuantifierRAG.search_benchmark() 직접 호출"
  
  결정_2_신규_Collection_생성:
    
    질문: "tier1_learned_rules는 필요한가?"
    
    결정: "✅ 필수"
    
    이유:
      - 학습 시스템의 핵심
      - 기존 Collection으로 대체 불가
      - 동적 성장 (0 → 2,000개+)
    
    타이밍: "Phase 2 (1-2일 후)"
  
  결정_3_Collection_분리_vs_통합:
    
    질문: "사용자 기여를 별도 Collection으로?"
    
    옵션_A_분리:
      - tier1_learned_rules (시스템 학습)
      - tier1_user_contributed (사용자 기여)
      
      장점: 출처 명확
      단점: 검색 2번, 복잡
    
    옵션_B_통합:
      - tier1_learned_rules (모두 포함)
      - provenance.tier_origin으로 구분
      
      장점: 검색 1번, 단순
      단점: 필터링 필요
    
    결정: "✅ 옵션_B (통합)"
    
    이유:
      - 사용자 입장에서 출처 무관
      - 검색 단순
      - 메타데이터로 충분히 구분
  
  결정_4_YAML_vs_RAG_전환:
    
    질문: "언제 YAML에서 RAG로 전환?"
    
    결정: "규칙 500개 시점"
    
    이유:
      - YAML 순차 매칭: ~500개까지 0.05초 이내
      - 500개 이상: 0.1초 이상 (느려짐)
      - RAG: 규칙 수 무관 (항상 0.1-0.5초)
    
    전환_방법:
      - YAML → JSON 변환
      - Collection 빌드
      - 검색 로직 교체
      - 인터페이스 동일 유지

---

# ═══════════════════════════════════════════════════════
# END - RAG 전략 포함 완전한 설계
# ═══════════════════════════════════════════════════════




