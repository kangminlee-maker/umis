# ========================================
# âš ï¸  DEPRECATED: UMIS LLM ëª¨ë“œ ì„¤ì •
# v7.11.0+: LLM Complete Abstractionìœ¼ë¡œ ëŒ€ì²´
# ========================================
#
# ì´ íŒŒì¼ì€ v7.11.0ë¶€í„° Deprecated ë˜ì—ˆìŠµë‹ˆë‹¤.
#
# ë³€ê²½ì‚¬í•­:
#   - llm_mode íŒŒë¼ë¯¸í„° ì œê±°
#   - LLMProvider ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš© (Dependency Injection)
#   - í™˜ê²½ë³€ìˆ˜: LLM_MODE (cursor/external)
#
# ìƒˆë¡œìš´ ì‚¬ìš©ë²•:
#   from umis_rag.core.llm_provider_factory import get_default_llm_provider
#   
#   llm_provider = get_default_llm_provider()  # .envì˜ LLM_MODE ì‚¬ìš©
#   estimator = EstimatorRAG(llm_provider=llm_provider)
#
# ì°¸ê³  ë¬¸ì„œ:
#   - dev_docs/improvements/LLM_COMPLETE_ABSTRACTION_SUMMARY_v7_11_0.md
#   - umis.yaml (Estimator Agent ì„¹ì…˜)
#
# ========================================

version: "7.11.0"
status: "deprecated"
updated: "2025-11-26"
replacement: "LLMProvider (umis_rag.core.llm_provider)"

# ========================================
# ğŸ‰ v7.7.0 ì‹ ê·œ ê¸°ëŠ¥
# ========================================
#
# âœ… ì§„ì§œ Native ëª¨ë“œ êµ¬í˜„ ì™„ë£Œ!
#
# ì´ì „ (v7.4.0):
#   - Native ëª¨ë“œ "ê°œë…ë§Œ" ì¡´ì¬
#   - ì‹¤ì œë¡œëŠ” í•­ìƒ External ë™ì‘ (OpenAI API í˜¸ì¶œ)
#   - umis_mode ì„¤ì • ë¬´ìš©ì§€ë¬¼
#
# í˜„ì¬ (v7.7.0):
#   - Native ëª¨ë“œ ì‹¤ì œ êµ¬í˜„ âœ…
#   - Explorerê°€ umis_mode ì„¤ì • ë°˜ì˜
#   - RAGë§Œ ìˆ˜í–‰ â†’ Cursor LLMì´ ì²˜ë¦¬
#   - ë¹„ìš© $0!
#
# êµ¬í˜„ ë‚´ì—­:
#   1. LLMProvider í´ë˜ìŠ¤ ì¶”ê°€ (umis_rag/core/llm_provider.py)
#   2. Explorer ìˆ˜ì • (Native/External ë¶„ê¸°)
#   3. í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (scripts/test_native_mode.py)
#
# ========================================

# ========================================
# ìš©ì–´ ì •ì˜
# ========================================

terminology:
  native_llm:
    name: "Native LLM"
    definition: "Cursor Agentê°€ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸"
    examples:
      - "Claude Sonnet 4.5"
      - "Claude Opus 3.5"
      - "GPT-4o"
      - "GPT-4 Turbo"
    note: "ì‚¬ìš©ìê°€ Cursor ì„¤ì •ì—ì„œ ì„ íƒ"

  external_llm:
    name: "External LLM"
    definition: "APIë¥¼ í†µí•´ ì™¸ë¶€ í˜¸ì¶œí•˜ëŠ” ëª¨ë¸"
    examples:
      - "OpenAI API (GPT-4, GPT-4o)"
      - "Anthropic API (Claude Sonnet, Claude Haiku)"
    note: "ì¶”ê°€ API í‚¤ ë° ë¹„ìš© í•„ìš”"

# ========================================
# ëª¨ë“œ ì„¤ì •
# ========================================

default_mode: "native"  # ê¶Œì¥ ì„¤ì •

modes:

  native:
    name: "Native Mode"
    description: "Cursor Native LLM ì‚¬ìš© (ì¶”ê°€ ë¹„ìš© ì—†ìŒ)"

    llm_source: "Cursor Agent"
    cost: "Cursor êµ¬ë…ì— í¬í•¨ ($0 ì¶”ê°€)"
    performance: "ìµœê³  (ì‚¬ìš©ì ì„ íƒ ëª¨ë¸)"
    context_window: "ìµœëŒ€ 200K tokens"
    automation: false

    use_cases:
      - "ì¼íšŒì„± ì‹¬ì¸µ ë¶„ì„"
      - "íƒìƒ‰ì  ë¶„ì„"
      - "í’ˆì§ˆ ì¤‘ì‹œ"
      - "Interactive ì‘ì—…"

    workflow: |
      1. RAG íŒ¨í„´ ê²€ìƒ‰ (Python)
      2. ë¶„ì„ì€ Cursor Composer/Chatì—ì„œ ì§ì ‘
      3. Native LLMì´ RAG ê²°ê³¼ í™œìš©í•˜ì—¬ ë¶„ì„

    advantages:
      - "ìµœê³  ì„±ëŠ¥ (Sonnet 4.5 ë“±)"
      - "ì¶”ê°€ ë¹„ìš© ì—†ìŒ"
      - "ë¹ ë¥¸ ì‘ë‹µ (API ì™•ë³µ ì—†ìŒ)"
      - "í° ì»¨í…ìŠ¤íŠ¸ (200K)"
      - "ëª¨ë¸ ì„ íƒ ìœ ì—°ì„±"

    disadvantages:
      - "ìë™í™” ë¶ˆê°€ (ì‚¬ìš©ì ì°¸ì—¬ í•„ìš”)"
      - "ë°°ì¹˜ ì²˜ë¦¬ ë¶ˆê°€"

  external:
    name: "External Mode"
    description: "ì™¸ë¶€ API LLM í˜¸ì¶œ (ìë™í™” ê°€ëŠ¥)"

    llm_source: "OpenAI/Anthropic API"
    cost: "í† í°ë‹¹ ê³¼ê¸ˆ (ì¶”ê°€ ë¹„ìš©)"
    performance: "ì¤‘ìƒ"
    context_window: "128-200K tokens"
    automation: true

    use_cases:
      - "ìë™í™” í•„ìš” (cron job)"
      - "ëŒ€ëŸ‰ ë¶„ì„ (100ê°œ ì´ìƒ ì‹œì¥)"
      - "ë…ë¦½ ì‹¤í–‰ (Cursor ì—†ì´)"
      - "ë°°ì¹˜ ì²˜ë¦¬"

    workflow: |
      1. Python ìŠ¤í¬ë¦½íŠ¸ ë…ë¦½ ì‹¤í–‰
      2. RAG ê²€ìƒ‰ + LLM API í˜¸ì¶œ
      3. ê²°ê³¼ ìë™ ì €ì¥

    advantages:
      - "ì™„ì „ ìë™í™”"
      - "ë°°ì¹˜ ì²˜ë¦¬ ê°€ëŠ¥"
      - "Cursor ë…ë¦½"

    disadvantages:
      - "ì¶”ê°€ API ë¹„ìš©"
      - "Native LLMë³´ë‹¤ ì„±ëŠ¥ ë‚®ì„ ìˆ˜ ìˆìŒ"
      - "API ì œí•œ (rate limit)"

# ========================================
# ëª¨ë“œë³„ ë¹„ìš© ë¹„êµ (100ê°œ ì‹œì¥ ë¶„ì„ ê¸°ì¤€)
# ========================================

cost_comparison:
  scenario: "100ê°œ ì‹œì¥ ë¶„ì„ (ê° 600K tokens)"

  native_mode:
    tokens: "60M tokens"
    cursor_cost: "$0 (êµ¬ë…ì— í¬í•¨)"
    total_cost: "$0"
    quality: "â˜…â˜…â˜…â˜…â˜…"

  external_gpt4:
    tokens: "60M tokens"
    api_cost: "$600 (GPT-4 $10/1M)"
    total_cost: "$600"
    quality: "â˜…â˜…â˜…"

  external_sonnet:
    tokens: "60M tokens"
    api_cost: "$180 (Claude $3/1M)"
    total_cost: "$180"
    quality: "â˜…â˜…â˜…â˜…â˜…"

  external_haiku:
    tokens: "60M tokens"
    api_cost: "$15 (Haiku $0.25/1M)"
    total_cost: "$15"
    quality: "â˜…â˜…"

# ========================================
# ê¶Œì¥ì‚¬í•­
# ========================================

recommendations:

  current_use_case:
    scenario: "ì¼íšŒì„± ì‹œì¥ ë¶„ì„ (í˜„ì¬ ìƒí™©)"
    recommendation: "native"
    reason: |
      - ì¶”ê°€ ë¹„ìš© ì—†ìŒ
      - ìµœê³  í’ˆì§ˆ
      - ìë™í™” ë¶ˆí•„ìš”
    action: "External LLM í˜¸ì¶œ ì œê±°"

  future_automation:
    scenario: "ìë™í™” í•„ìš” (í–¥í›„)"
    recommendation: "external (Claude API)"
    reason: |
      - Nativeë³´ë‹¤ ì €ë ´ (Haiku)
      - ë˜ëŠ” ë™ì¼ í’ˆì§ˆ (Sonnet API)
      - ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥
    action: "í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ êµ¬í˜„"

  hybrid_strategy:
    scenario: "ìœ ì—°í•œ ì‚¬ìš©"
    recommendation: "ëª¨ë“œ ì„ íƒ ê°€ëŠ¥í•˜ê²Œ êµ¬í˜„"
    implementation: |
      explorer = ExplorerRAG(llm_mode='native')  # Cursor
      explorer = ExplorerRAG(llm_mode='external')  # API

# ========================================
# êµ¬í˜„ ê°€ì´ë“œ
# ========================================

implementation:

  current_status:
    title: "âœ… v7.7.0 êµ¬í˜„ ì™„ë£Œ!"
    
    completed:
      - "LLMProvider í´ë˜ìŠ¤ (umis_rag/core/llm_provider.py)"
      - "Explorer Native/External ëª¨ë“œ ë¶„ê¸°"
      - "í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (scripts/test_native_mode.py)"
    
    how_to_use:
      step_1:
        what: ".env íŒŒì¼ì—ì„œ ëª¨ë“œ ì„¤ì •"
        native: "UMIS_MODE=native (ê¶Œì¥)"
        external: "UMIS_MODE=external (ìë™í™” í•„ìš” ì‹œ)"
      
      step_2:
        what: "Explorer ì‚¬ìš©"
        code: |
          from umis_rag.agents.explorer import ExplorerRAG
          
          explorer = ExplorerRAG()
          result = explorer.generate_opportunity_hypothesis(...)
          
          # Native ëª¨ë“œ: Dict ë°˜í™˜ (RAG ê²°ê³¼ + ì§€ì‹œì‚¬í•­)
          # External ëª¨ë“œ: str ë°˜í™˜ (ì™„ì„±ëœ ê°€ì„¤)
      
      step_3:
        what: "í…ŒìŠ¤íŠ¸"
        command: "python scripts/test_native_mode.py"
    
    benefits:
      cost_saving: "$10 â†’ $0 (100íšŒ ë¶„ì„ ê¸°ì¤€)"
      quality: "ë™ì¼ ë˜ëŠ” ë” ìš°ìˆ˜ (Cursor LLM)"
      speed: "API ì™•ë³µ ì—†ìŒ (ë¹ ë¦„)"
      natural: "Cursorì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©"

  immediate_action:
    title: "ğŸš€ ì§€ê¸ˆ ë°”ë¡œ ì‚¬ìš©í•˜ê¸°"

    step_1_set_mode:
      what: ".env íŒŒì¼ ìˆ˜ì •"
      action: "UMIS_MODE=native"
      location: ".env íŒŒì¼ (í”„ë¡œì íŠ¸ ë£¨íŠ¸)"

    step_2_test:
      what: "í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
      command: "python scripts/test_native_mode.py"
      expected: |
        Native ëª¨ë“œ ê²°ê³¼:
        - mode: 'native'
        - rag_context: RAG ê²€ìƒ‰ ê²°ê³¼
        - instruction: Cursor LLM ì§€ì‹œì‚¬í•­

    step_3_workflow:
      what: "ì‹¤ì œ ì‚¬ìš©"
      process: |
        1. Python ìŠ¤í¬ë¦½íŠ¸: RAG ê²€ìƒ‰ ì‹¤í–‰
        2. ê²°ê³¼ í™•ì¸: RAG ì»¨í…ìŠ¤íŠ¸ + ì§€ì‹œì‚¬í•­
        3. Cursor Composer: ì§€ì‹œì‚¬í•­ ë”°ë¼ ë¶„ì„
      
      example: |
        # 1. RAG ê²€ìƒ‰
        python scripts/test_native_mode.py
        
        # ê²°ê³¼ ì¶œë ¥:
        # {
        #   'mode': 'native',
        #   'rag_context': '...íŒ¨í„´ ì •ë³´...',
        #   'instruction': 'ìœ„ íŒ¨í„´ìœ¼ë¡œ ê°€ì„¤ ìƒì„±í•´ì£¼ì„¸ìš”'
        # }
        
        # 2. Cursor Composerì—ì„œ:
        # "@Explorer ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìŒì•… ì‹œì¥ ê¸°íšŒ 3ê°œ"

  future_action:
    title: "í–¥í›„ (ìë™í™” í•„ìš” ì‹œ)"

    when: |
      - ëŒ€ëŸ‰ ë¶„ì„ (100ê°œ ì´ìƒ)
      - ë°°ì¹˜ ì²˜ë¦¬ (cron job)
      - Cursor ë…ë¦½ ì‹¤í–‰

    implementation: |
      # umis_rag/llm/provider.py ì‹ ê·œ ì‘ì„±

      class LLMProvider:
          @staticmethod
          def create(mode='native'):
              if mode == 'native':
                  return NativeLLM()  # Cursor ì—°ë™
              elif mode == 'external':
                  return ClaudeAPI()  # API í˜¸ì¶œ

      # Agentì—ì„œ ì‚¬ìš©
      class ExplorerRAG:
          def __init__(self, llm_mode='native'):
              self.llm = LLMProvider.create(llm_mode)

# ========================================
# Best Practices
# ========================================

best_practices:

  rule_1:
    title: "Native ìš°ì„  ì›ì¹™"
    rule: "ê°€ëŠ¥í•˜ë©´ í•­ìƒ Native Mode ì‚¬ìš©"
    reason: "ë¹„ìš© $0, ìµœê³  í’ˆì§ˆ, ë¹ ë¥¸ ì†ë„"

  rule_2:
    title: "Externalì€ í•„ìš”í•  ë•Œë§Œ"
    rule: "ìë™í™”ê°€ ëª…í™•íˆ í•„ìš”í•œ ê²½ìš°ì—ë§Œ"
    examples:
      - "ë§¤ì¼ ìë™ìœ¼ë¡œ 100ê°œ ì‹œì¥ ë¶„ì„"
      - "cron jobìœ¼ë¡œ ì£¼ê°„ ë¦¬í¬íŠ¸ ìƒì„±"

  rule_3:
    title: "RAGëŠ” ìœ ì§€"
    rule: "ì„ë² ë”©ì€ OpenAI API ìœ ì§€ (ì €ë ´)"
    cost: "$0.00013/1K tokens (ë¬´ì‹œ ê°€ëŠ¥)"

  rule_4:
    title: "ëª¨ë¸ ì¤‘ë¦½ì„±"
    rule: "íŠ¹ì • ëª¨ë¸ëª… í•˜ë“œì½”ë”© ê¸ˆì§€"
    code: |
      # âŒ ë‚˜ìœ ì˜ˆ
      if model == "claude-sonnet-4.5":

      # âœ… ì¢‹ì€ ì˜ˆ
      if mode == "native":

# ========================================
# FAQ
# ========================================

faq:
  q1:
    question: "Native Modeì˜ ì„±ëŠ¥ì€?"
    answer: |
      ì‚¬ìš©ìê°€ ì„ íƒí•œ Cursor Agent ëª¨ë¸ ì„±ëŠ¥.
      ì¼ë°˜ì ìœ¼ë¡œ Claude Sonnet 4.5 ë˜ëŠ” GPT-4o ì‚¬ìš© ì‹œ
      External GPT-4 Turboë³´ë‹¤ ìš°ìˆ˜.

  q2:
    question: "ì™„ì „ ì˜¤í”„ë¼ì¸ ê°€ëŠ¥?"
    answer: |
      ë¶ˆê°€ëŠ¥. RAG ì„ë² ë”©ì€ OpenAI API í•„ìš”.
      ëŒ€ì•ˆ: Local Embeddings (Sentence Transformers)
      í•˜ì§€ë§Œ í’ˆì§ˆ ì €í•˜ ê°€ëŠ¥ì„±.

  q3:
    question: "ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ëŠ”?"
    answer: |
      ì°¸ê³ ìš©ìœ¼ë¡œ ìœ ì§€ ê°€ëŠ¥.
      ì‹¤ì œ ì‚¬ìš©ì€ Native Mode ê¶Œì¥.
      ìë™í™” í•„ìš” ì‹œì—ë§Œ External Mode.

  q4:
    question: "OPENAI_API_KEYëŠ” ì—¬ì „íˆ í•„ìš”?"
    answer: |
      ë„¤, RAG ì„ë² ë”©ì— í•„ìš” (OpenAI text-embedding-3-large).
      í•˜ì§€ë§Œ LLM í˜¸ì¶œì€ ë¶ˆí•„ìš” (Native LLM ì‚¬ìš©).

  q5:
    question: "Phase 4 (Fermi)ëŠ” LLMì„ ì–´ë–»ê²Œ ì‚¬ìš©?"
    answer: |
      ëª¨ë“œì— ë”°ë¼ ë‹¤ë¦„:

      Native Mode (ê¸°ë³¸, v7.7.0):
        - Phase 4 (Fermi) ì‹¤í–‰
        - Step 1: ì´ˆê¸° ìŠ¤ìº”
        - Step 2: ëª¨í˜• ìƒì„± (Native ëª¨í˜• ì‚¬ìš©)
        - Step 3-4: ì¬ê·€ ì¶”ì • ë° ì‹¤í–‰
        - LLM API í˜¸ì¶œ ì—†ìŒ (ë¹„ìš© $0)

      External Mode (ìë™í™”):
        - Phase 4 ì‹¤í–‰
        - Step 2ì—ì„œ OpenAI API í˜¸ì¶œ
        - ëª¨í˜• ìƒì„± í”„ë¡¬í”„íŠ¸ ìë™ ì‹¤í–‰
        - ë¹„ìš© ë°œìƒ ($0.03/ì§ˆë¬¸)

# ========================================
# v7.7.0 ì—…ë°ì´íŠ¸: Phase 4 ì •ì±…
# ========================================

phase4_policy:

  native_mode:
    llm_usage: "ì‚¬ìš© ì•ˆ í•¨ (Native ëª¨í˜• ì‚¬ìš©)"
    coverage: "ì¼ë°˜ Fermi ë¶„í•´"
    cost: "$0"

    behavior:
      step_2_generate: "Native ëª¨í˜• ìƒì„± (ë‹´ë°°, ìŒì‹ì  ë“±)"
      step_3_4: "ì¬ê·€ ì¶”ì • ë° Backtracking"

    reason: |
      Native LLM (Cursor)ì´ ë” ìš°ìˆ˜í•˜ê³  ë¹„ìš© $0
      ë³µì¡í•œ ëª¨í˜• ìƒì„±ì€ Cursorê°€ ì§ì ‘ ì²˜ë¦¬í•˜ëŠ”ê²Œ ë‚˜ìŒ

  external_mode:
    llm_usage: "OpenAI API ì‚¬ìš©"
    coverage: "100% (Native + LLM)"
    cost: "~$0.03/ì§ˆë¬¸ (GPT-4o)"

    behavior:
      step_2_generate: "Native ì‹œë„ â†’ ì‹¤íŒ¨ ì‹œ OpenAI API í˜¸ì¶œ"
      step_3_4: "ì¬ê·€ ì¶”ì • ë° Backtracking"

    reason: |
      ìë™í™” í•„ìš” ì‹œ (ë°°ì¹˜ ì²˜ë¦¬, cron job)
      Cursor ì—†ì´ ë…ë¦½ ì‹¤í–‰

# ========================================
# END
# ========================================


