# ëª¨ë¸ë³„ API ìµœì í™” êµ¬ì¡° ì„¤ê³„ - ëŒ€ì•ˆ ë¶„ì„

**Version:** v1.0  
**Date:** 2025-11-23  
**Context:** Estimator Phase 4 ëª¨ë¸ë³„ API ì„¤ì • êµ¬ì¡°í™”

---

## ğŸ“‹ ëª©ì°¨

1. [í˜„ì¬ êµ¬ì¡° ë¶„ì„](#1-í˜„ì¬-êµ¬ì¡°-ë¶„ì„)
2. [í•µì‹¬ ì„¤ê³„ ì§ˆë¬¸](#2-í•µì‹¬-ì„¤ê³„-ì§ˆë¬¸)
3. [ëŒ€ì•ˆ ë¹„êµ](#3-ëŒ€ì•ˆ-ë¹„êµ)
4. [ì¶”ì²œ ì†”ë£¨ì…˜](#4-ì¶”ì²œ-ì†”ë£¨ì…˜)
5. [êµ¬í˜„ ê°€ì´ë“œ](#5-êµ¬í˜„-ê°€ì´ë“œ)
6. [ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš](#6-ë§ˆì´ê·¸ë ˆì´ì…˜-ê³„íš)

---

## 1. í˜„ì¬ êµ¬ì¡° ë¶„ì„

### 1.1 ê¸°ì¡´ ì‹œìŠ¤í…œ

**í˜„ì¬ êµ¬ì¡° (v7.7.0):**
```
.env (ëª¨ë¸ ì„ íƒ)
  â†“
umis_rag/core/config.py (Settings)
  â†“
umis_rag/core/model_router.py (Phaseë³„ ëª¨ë¸ ì„ íƒ)
  â†“
umis_rag/agents/estimator/phase4_fermi.py (LLM í˜¸ì¶œ)
```

**í˜„ì¬ ì„¤ì • ë°©ì‹:**
```python
# .env
LLM_MODEL_PHASE4=o1-mini
USE_PHASE_BASED_ROUTING=true

# umis_rag/core/config.py
llm_model_phase4: str = Field(default="o1-mini")
use_phase_based_routing: bool = Field(default=True)

# umis_rag/core/model_router.py
def select_model(self, phase: PhaseType) -> str:
    if phase == 4:
        return settings.llm_model_phase4  # "o1-mini"
```

**Phase 4ì—ì„œ ì‚¬ìš©:**
```python
# umis_rag/agents/estimator/phase4_fermi.py
from umis_rag.core.model_router import select_model

model_name = select_model(context)  # Phase ê¸°ë°˜ ìë™ ì„ íƒ
response = self._call_llm(prompt, model_name)  # ë‹¨ìˆœ í˜¸ì¶œ
```

### 1.2 ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ

**ë²¤ì¹˜ë§ˆí¬ êµ¬ì¡°:**
```python
# benchmarks/estimator/phase4/common.py

MODEL_API_CONFIGS = {
    'o1-mini': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'max_output_tokens': 16000,
        'notes': 'STEM ìµœì í™”, 80% ì €ë ´'
    },
    'gpt-5.1': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'max_output_tokens': 16000,
        'notes': 'Advanced reasoning, JSON í˜•ì‹ ì•½í•¨'
    },
    # ... 15ê°œ ëª¨ë¸
}

def get_model_config(model_name: str) -> dict:
    return MODEL_API_CONFIGS.get(model_name, DEFAULT_CONFIG)

def build_api_params(model_name: str, prompt: str, reasoning_effort='medium') -> dict:
    config = get_model_config(model_name)
    # configì— ë”°ë¼ API íŒŒë¼ë¯¸í„° êµ¬ì„±
    if config['api_type'] == 'responses':
        return {
            'model': model_name,
            'input': prompt,
            'reasoning': {'effort': reasoning_effort},
            'max_output_tokens': config['max_output_tokens']
        }
```

### 1.3 ë¬¸ì œì 

**í˜„ì¬ ì‹œìŠ¤í…œì˜ í•œê³„:**
1. **ëª¨ë¸ë³„ ìµœì í™” ë¶€ì¡±**: Phase 4ì—ì„œ ëª¨ë¸ ì´ë¦„ë§Œ ë°›ì•„ì„œ ë‹¨ìˆœ í˜¸ì¶œ
2. **API íŒŒë¼ë¯¸í„° í•˜ë“œì½”ë”©**: `reasoning_effort`, `max_output_tokens` ë“±ì´ ì½”ë“œì— ë°•í˜€ìˆìŒ
3. **ëª¨ë¸ ë³€ê²½ ì‹œ ìˆ˜ë™ ì¡°ì •**: .envì—ì„œ ëª¨ë¸ ë°”ê¾¸ë©´ API íŒŒë¼ë¯¸í„°ë„ ìˆ˜ë™ìœ¼ë¡œ ë§ì¶°ì•¼ í•¨
4. **ì¤‘ë³µ ê´€ë¦¬**: ë²¤ì¹˜ë§ˆí¬ì™€ ì‹¤ì œ ì‹œìŠ¤í…œì—ì„œ ê°ê° ëª¨ë¸ ì„¤ì • ê´€ë¦¬

---

## 2. í•µì‹¬ ì„¤ê³„ ì§ˆë¬¸

### 2.1 ì§ˆë¬¸ ëª©ë¡

**Q1: ëª¨ë¸ ì„¤ì •ì„ ì–´ë””ì— ë‘˜ ê²ƒì¸ê°€?**
- Aì•ˆ: `.env` íŒŒì¼ (ë‹¨ìˆœ, ì‚¬ìš©ì ì¹œí™”ì )
- Bì•ˆ: `config.py` (ì¤‘ì•™ ì§‘ì¤‘, íƒ€ì… ì•ˆì „)
- Cì•ˆ: `model_configs.py` (ì „ìš© ëª¨ë“ˆ, í™•ì¥ì„±)
- Dì•ˆ: YAML íŒŒì¼ (ì„¤ì • íŒŒì¼, ë²„ì „ ê´€ë¦¬)

**Q2: ëˆ„ê°€ ëª¨ë¸ ì„¤ì •ì„ ì ìš©í•  ê²ƒì¸ê°€?**
- Aì•ˆ: Phase 4ê°€ ì§ì ‘ ì½ì–´ì„œ ì ìš©
- Bì•ˆ: ModelRouterê°€ ì„¤ì •ê¹Œì§€ í¬í•¨í•˜ì—¬ ë°˜í™˜
- Cì•ˆ: ë³„ë„ ModelConfigManager ìƒì„±

**Q3: ì„¤ì • ë³€ê²½ ì‹œ ì–´ë–»ê²Œ ë°˜ì˜í•  ê²ƒì¸ê°€?**
- Aì•ˆ: ì¬ì‹œì‘ í•„ìš” (ì •ì  ë¡œë”©)
- Bì•ˆ: ì‹¤ì‹œê°„ ë¦¬ë¡œë”© (ë™ì  ë¡œë”©)
- Cì•ˆ: í•˜ì´ë¸Œë¦¬ë“œ (ìºì‹± + ì„ íƒì  ë¦¬ë¡œë”©)

**Q4: ë²¤ì¹˜ë§ˆí¬ì™€ ì‹¤ì œ ì‹œìŠ¤í…œ ì„¤ì •ì„ ì–´ë–»ê²Œ í†µí•©í•  ê²ƒì¸ê°€?**
- Aì•ˆ: ë²¤ì¹˜ë§ˆí¬ ì„¤ì •ì„ ì‹¤ì œ ì‹œìŠ¤í…œìœ¼ë¡œ ì´ë™
- Bì•ˆ: ê³µí†µ ëª¨ë“ˆ ìƒì„± (ì–‘ìª½ì—ì„œ import)
- Cì•ˆ: ì„¤ì • íŒŒì¼ë¡œ í†µí•© (YAML/JSON)

---

## 3. ëŒ€ì•ˆ ë¹„êµ

### 3.1 ëŒ€ì•ˆ 1: ìµœì†Œ ë³€ê²½ (Phase 4 ì§ì ‘ ì½ê¸°)

**êµ¬ì¡°:**
```
.env (ëª¨ë¸ ì´ë¦„ë§Œ)
  â†“
config.py (ëª¨ë¸ ì´ë¦„ ë¡œë”©)
  â†“
model_router.py (ëª¨ë¸ ì´ë¦„ ì„ íƒ)
  â†“
phase4_fermi.py (ëª¨ë¸ ì„¤ì • ì§ì ‘ ê´€ë¦¬) â† ğŸ†• MODEL_API_CONFIGS í¬í•¨
```

**ì¥ì :**
- âœ… êµ¬í˜„ ê°„ë‹¨ (2ì‹œê°„)
- âœ… ê¸°ì¡´ êµ¬ì¡° ìµœì†Œ ë³€ê²½
- âœ… Phase 4ì—ì„œ ì™„ì „í•œ ì œì–´

**ë‹¨ì :**
- âŒ Phase 4ì—ë§Œ ì ìš© (ë‹¤ë¥¸ PhaseëŠ” ë³„ë„ ì‘ì—…)
- âŒ ì„¤ì • ì¤‘ë³µ (ë²¤ì¹˜ë§ˆí¬ vs ì‹¤ì œ)
- âŒ í™•ì¥ì„± ë‚®ìŒ

**ì½”ë“œ ì˜ˆì‹œ:**
```python
# umis_rag/agents/estimator/phase4_fermi.py

MODEL_API_CONFIGS = {
    'o1-mini': {...},
    'gpt-5.1': {...},
    # ...
}

class Phase4FermiDecomposition:
    def _call_llm(self, prompt: str, model_name: str) -> str:
        config = MODEL_API_CONFIGS.get(model_name, DEFAULT_CONFIG)
        
        # config ê¸°ë°˜ API í˜¸ì¶œ
        if config['api_type'] == 'responses':
            params = {
                'model': model_name,
                'input': prompt,
                'reasoning': {'effort': 'medium'},
                'max_output_tokens': config['max_output_tokens']
            }
            response = self.client.responses.create(**params)
```

**í‰ê°€:**
- ì í•©ì„±: â­â­ (ë‹¨ê¸° í•´ê²°ì±…)
- í™•ì¥ì„±: â­ (ë‚®ìŒ)
- ìœ ì§€ë³´ìˆ˜: â­â­ (ë³´í†µ)

---

### 3.2 ëŒ€ì•ˆ 2: ModelRouter í™•ì¥ (ì„¤ì • í¬í•¨ ë°˜í™˜) â­ ì¶”ì²œ

**êµ¬ì¡°:**
```
config/model_configs.yaml (ëª¨ë¸ë³„ API ì„¤ì •) ğŸ†•
  â†“
umis_rag/core/model_configs.py (ì„¤ì • ë¡œë”©) ğŸ†•
  â†“
umis_rag/core/model_router.py (ëª¨ë¸ + ì„¤ì • ë°˜í™˜) ğŸ”§
  â†“
umis_rag/agents/estimator/phase4_fermi.py (ì„¤ì • ì‚¬ìš©) ğŸ”§
```

**ì¥ì :**
- âœ… ì¤‘ì•™ ì§‘ì¤‘ ê´€ë¦¬
- âœ… ëª¨ë“  Phaseì— ì ìš© ê°€ëŠ¥
- âœ… ë²¤ì¹˜ë§ˆí¬ì™€ ì„¤ì • í†µí•© ê°€ëŠ¥
- âœ… YAMLë¡œ ë²„ì „ ê´€ë¦¬ ìš©ì´
- âœ… í™•ì¥ì„± ë†’ìŒ

**ë‹¨ì :**
- âŒ êµ¬í˜„ ë³µì¡ (4-6ì‹œê°„)
- âŒ ìƒˆë¡œìš´ ëª¨ë“ˆ ì¶”ê°€
- âŒ ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • í•„ìš”

**ì½”ë“œ ì˜ˆì‹œ:**

**1. ì„¤ì • íŒŒì¼:**
```yaml
# config/model_configs.yaml

models:
  o1-mini:
    api_type: responses
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: medium
    max_output_tokens: 16000
    temperature_support: false
    notes: "STEM ìµœì í™”, 80% ì €ë ´"
  
  gpt-5.1:
    api_type: responses
    reasoning_effort:
      support: true
      levels: [low, medium, high]
      default: high
    max_output_tokens: 16000
    temperature_support: false
    notes: "Advanced reasoning, JSON í˜•ì‹ ì•½í•¨"
  
  gpt-4.1-nano:
    api_type: chat
    reasoning_effort:
      support: false
    max_output_tokens: 4096
    temperature_support: true
    temperature_default: 0.7
    notes: "Phase 0-2 ìµœì í™”"

defaults:
  api_type: chat
  max_output_tokens: 4096
  temperature: 0.7
```

**2. ì„¤ì • ë¡œë”:**
```python
# umis_rag/core/model_configs.py

from typing import Dict, Any, Optional
from pathlib import Path
import yaml
from dataclasses import dataclass

@dataclass
class ModelConfig:
    """ëª¨ë¸ë³„ API ì„¤ì •"""
    model_name: str
    api_type: str  # 'responses' or 'chat'
    reasoning_effort_support: bool
    reasoning_effort_levels: list[str]
    reasoning_effort_default: str
    max_output_tokens: int
    temperature_support: bool
    temperature_default: float
    notes: str
    
    def build_api_params(
        self, 
        prompt: str, 
        reasoning_effort: Optional[str] = None,
        temperature: Optional[float] = None
    ) -> Dict[str, Any]:
        """API íŒŒë¼ë¯¸í„° êµ¬ì„±"""
        
        if self.api_type == 'responses':
            params = {
                'model': self.model_name,
                'input': prompt,
                'max_output_tokens': self.max_output_tokens
            }
            
            # reasoning_effort ì ìš©
            if self.reasoning_effort_support:
                effort = reasoning_effort or self.reasoning_effort_default
                if effort in self.reasoning_effort_levels:
                    params['reasoning'] = {'effort': effort}
            
            return params
        
        else:  # chat
            params = {
                'model': self.model_name,
                'messages': [{'role': 'user', 'content': prompt}],
                'max_tokens': self.max_output_tokens
            }
            
            # temperature ì ìš©
            if self.temperature_support:
                temp = temperature or self.temperature_default
                params['temperature'] = temp
            
            return params


class ModelConfigManager:
    """ëª¨ë¸ ì„¤ì • ê´€ë¦¬ì"""
    
    _instance = None
    _configs: Dict[str, ModelConfig] = {}
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._load_configs()
        return cls._instance
    
    def _load_configs(self):
        """YAMLì—ì„œ ì„¤ì • ë¡œë“œ"""
        config_path = Path(__file__).parent.parent.parent / "config" / "model_configs.yaml"
        
        with open(config_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        defaults = data.get('defaults', {})
        
        for model_name, config in data.get('models', {}).items():
            self._configs[model_name] = ModelConfig(
                model_name=model_name,
                api_type=config.get('api_type', defaults.get('api_type', 'chat')),
                reasoning_effort_support=config.get('reasoning_effort', {}).get('support', False),
                reasoning_effort_levels=config.get('reasoning_effort', {}).get('levels', []),
                reasoning_effort_default=config.get('reasoning_effort', {}).get('default', 'medium'),
                max_output_tokens=config.get('max_output_tokens', defaults.get('max_output_tokens', 4096)),
                temperature_support=config.get('temperature_support', defaults.get('temperature_support', True)),
                temperature_default=config.get('temperature_default', defaults.get('temperature', 0.7)),
                notes=config.get('notes', '')
            )
    
    def get_config(self, model_name: str) -> ModelConfig:
        """ëª¨ë¸ ì„¤ì • ì¡°íšŒ"""
        return self._configs.get(model_name, self._get_default_config(model_name))
    
    def _get_default_config(self, model_name: str) -> ModelConfig:
        """ê¸°ë³¸ ì„¤ì • ë°˜í™˜"""
        return ModelConfig(
            model_name=model_name,
            api_type='chat',
            reasoning_effort_support=False,
            reasoning_effort_levels=[],
            reasoning_effort_default='medium',
            max_output_tokens=4096,
            temperature_support=True,
            temperature_default=0.7,
            notes='Default config'
        )
    
    def list_models(self) -> list[str]:
        """ì§€ì› ëª¨ë¸ ëª©ë¡"""
        return list(self._configs.keys())


# Singleton instance
model_config_manager = ModelConfigManager()
```

**3. ModelRouter í™•ì¥:**
```python
# umis_rag/core/model_router.py

from umis_rag.core.model_configs import model_config_manager, ModelConfig
from typing import Tuple

class ModelRouter:
    
    def select_model_with_config(self, phase: PhaseType) -> Tuple[str, ModelConfig]:
        """
        Phaseì— ë§ëŠ” ìµœì  ëª¨ë¸ê³¼ ì„¤ì • ë°˜í™˜ (v7.8.0)
        
        Returns:
            (model_name, model_config)
        """
        model_name = self.select_model(phase)  # ê¸°ì¡´ ë¡œì§
        config = model_config_manager.get_config(model_name)
        
        return model_name, config
```

**4. Phase 4ì—ì„œ ì‚¬ìš©:**
```python
# umis_rag/agents/estimator/phase4_fermi.py

from umis_rag.core.model_router import ModelRouter
from umis_rag.core.model_configs import ModelConfig

class Phase4FermiDecomposition:
    
    def __init__(self):
        self.router = ModelRouter()
        # ...
    
    def estimate(self, query: str, context: Context) -> EstimationResult:
        """Phase 4 ì¶”ì • ì‹¤í–‰"""
        
        # 1. ëª¨ë¸ + ì„¤ì • ì„ íƒ
        model_name, model_config = self.router.select_model_with_config(phase=4)
        
        # 2. í”„ë¡¬í”„íŠ¸ ìƒì„± (Fast Mode ê³ ë ¤)
        prompt = self._build_fermi_prompt(context, model_name)
        
        # 3. API íŒŒë¼ë¯¸í„° êµ¬ì„±
        api_params = model_config.build_api_params(
            prompt=prompt,
            reasoning_effort='medium'  # ë˜ëŠ” contextì—ì„œ ê°€ì ¸ì˜¤ê¸°
        )
        
        # 4. LLM í˜¸ì¶œ
        if model_config.api_type == 'responses':
            response = self.client.responses.create(**api_params)
            raw_response = response.output
        else:
            response = self.client.chat.completions.create(**api_params)
            raw_response = response.choices[0].message.content
        
        # ... ë‚˜ë¨¸ì§€ ë¡œì§
```

**í‰ê°€:**
- ì í•©ì„±: â­â­â­â­â­ (ìµœì )
- í™•ì¥ì„±: â­â­â­â­â­ (ë§¤ìš° ë†’ìŒ)
- ìœ ì§€ë³´ìˆ˜: â­â­â­â­ (ìš°ìˆ˜)

---

### 3.3 ëŒ€ì•ˆ 3: ModelConfigManager ë…ë¦½ ëª¨ë“ˆ

**êµ¬ì¡°:**
```
config/model_configs.yaml ğŸ†•
  â†“
umis_rag/core/model_config_manager.py (ì „ìš© ë§¤ë‹ˆì €) ğŸ†•
  â†“
umis_rag/core/model_router.py (ëª¨ë¸ ì„ íƒë§Œ) 
  â†“
umis_rag/agents/estimator/phase4_fermi.py (ë§¤ë‹ˆì € ì§ì ‘ ì‚¬ìš©) ğŸ”§
```

**ì¥ì :**
- âœ… ì±…ì„ ë¶„ë¦¬ ëª…í™•
- âœ… ModelRouterëŠ” ë‹¨ìˆœ ìœ ì§€
- âœ… ì„¤ì • ê´€ë¦¬ ì „ë¬¸í™”

**ë‹¨ì :**
- âŒ ëª¨ë“ˆ ê°„ ê²°í•©ë„ ì¦ê°€
- âŒ Phase 4ì—ì„œ ë‘ ê°œ ëª¨ë“ˆ import

**ì½”ë“œ ì˜ˆì‹œ:**
```python
# umis_rag/agents/estimator/phase4_fermi.py

from umis_rag.core.model_router import ModelRouter
from umis_rag.core.model_config_manager import ModelConfigManager

class Phase4FermiDecomposition:
    
    def __init__(self):
        self.router = ModelRouter()
        self.config_manager = ModelConfigManager()
    
    def estimate(self, query: str, context: Context) -> EstimationResult:
        # ëª¨ë¸ ì„ íƒ
        model_name = self.router.select_model(phase=4)
        
        # ì„¤ì • ì¡°íšŒ
        config = self.config_manager.get_config(model_name)
        
        # API í˜¸ì¶œ
        api_params = config.build_api_params(prompt)
        # ...
```

**í‰ê°€:**
- ì í•©ì„±: â­â­â­â­ (ì¢‹ìŒ)
- í™•ì¥ì„±: â­â­â­â­ (ë†’ìŒ)
- ìœ ì§€ë³´ìˆ˜: â­â­â­ (ì¢‹ìŒ)

---

### 3.4 ëŒ€ì•ˆ 4: .env í™•ì¥ (íŒŒë¼ë¯¸í„° í¬í•¨)

**êµ¬ì¡°:**
```
.env (ëª¨ë¸ + íŒŒë¼ë¯¸í„°)
  â†“
config.py (ëª¨ë¸ë³„ ì„¤ì • ë¡œë”©) ğŸ”§
  â†“
model_router.py (ì„¤ì • í¬í•¨ ë°˜í™˜) ğŸ”§
  â†“
phase4_fermi.py (ì„¤ì • ì‚¬ìš©) ğŸ”§
```

**ì¥ì :**
- âœ… ì„¤ì • íŒŒì¼ ì¶”ê°€ ë¶ˆí•„ìš”
- âœ… ì‚¬ìš©ìê°€ .envë§Œ ìˆ˜ì •

**ë‹¨ì :**
- âŒ .env ë³µì¡ë„ ê¸‰ì¦
- âŒ 15ê°œ ëª¨ë¸ Ã— 5ê°œ íŒŒë¼ë¯¸í„° = 75ê°œ í™˜ê²½ë³€ìˆ˜
- âŒ íƒ€ì… ì•ˆì „ì„± ë‚®ìŒ
- âŒ ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€

**ì½”ë“œ ì˜ˆì‹œ:**
```bash
# .env (ë³µì¡ë„ í­ë°œ)

LLM_MODEL_PHASE4=o1-mini
LLM_MODEL_PHASE4_API_TYPE=responses
LLM_MODEL_PHASE4_REASONING_EFFORT_SUPPORT=true
LLM_MODEL_PHASE4_REASONING_EFFORT_LEVELS=low,medium,high
LLM_MODEL_PHASE4_MAX_OUTPUT_TOKENS=16000

# gpt-5.1ë¡œ ë³€ê²½í•˜ë©´?
LLM_MODEL_PHASE4=gpt-5.1
LLM_MODEL_PHASE4_API_TYPE=responses  # ë‹¤ì‹œ ì„¤ì •í•´ì•¼ í•¨
LLM_MODEL_PHASE4_REASONING_EFFORT_SUPPORT=true  # ë‹¤ì‹œ ì„¤ì •í•´ì•¼ í•¨
# ...
```

**í‰ê°€:**
- ì í•©ì„±: â­ (ë¹„ì¶”ì²œ)
- í™•ì¥ì„±: â­ (ë§¤ìš° ë‚®ìŒ)
- ìœ ì§€ë³´ìˆ˜: â­ (ë§¤ìš° ì–´ë ¤ì›€)

---

## 4. ì¶”ì²œ ì†”ë£¨ì…˜

### 4.1 ìµœì¢… ì¶”ì²œ: ëŒ€ì•ˆ 2 (ModelRouter í™•ì¥) â­â­â­â­â­

**ì„ ì • ì´ìœ :**

**1. ì¤‘ì•™ ì§‘ì¤‘ ê´€ë¦¬**
- ëª¨ë“  ëª¨ë¸ ì„¤ì •ì„ í•œ ê³³ì—ì„œ ê´€ë¦¬
- ë²¤ì¹˜ë§ˆí¬ì™€ ì‹¤ì œ ì‹œìŠ¤í…œ í†µí•© ê°€ëŠ¥
- ì¼ê´€ì„± ë³´ì¥

**2. í™•ì¥ì„±**
- ìƒˆ ëª¨ë¸ ì¶”ê°€: YAMLì— í•­ëª©ë§Œ ì¶”ê°€
- ìƒˆ Phase ì¶”ê°€: ê¸°ì¡´ êµ¬ì¡° ê·¸ëŒ€ë¡œ í™œìš©
- ìƒˆ íŒŒë¼ë¯¸í„° ì¶”ê°€: YAML ìŠ¤í‚¤ë§ˆë§Œ í™•ì¥

**3. ì‚¬ìš©ì ì¹œí™”ì„±**
- `.env`ì—ì„œëŠ” ëª¨ë¸ ì´ë¦„ë§Œ ì„ íƒ (ë‹¨ìˆœ)
- ìƒì„¸ ì„¤ì •ì€ YAMLë¡œ ê´€ë¦¬ (ì „ë¬¸ê°€)
- ê¸°ë³¸ê°’ ì œê³µìœ¼ë¡œ ëŒ€ë¶€ë¶„ ìˆ˜ì • ë¶ˆí•„ìš”

**4. ë²„ì „ ê´€ë¦¬**
- YAML íŒŒì¼ì„ Gitìœ¼ë¡œ ê´€ë¦¬
- ëª¨ë¸ ì„¤ì • ë³€ê²½ ì´ë ¥ ì¶”ì 
- íŒ€ í˜‘ì—… ìš©ì´

**5. íƒ€ì… ì•ˆì „ì„±**
- `ModelConfig` dataclassë¡œ íƒ€ì… ì²´í¬
- IDE ìë™ì™„ì„± ì§€ì›
- ëŸ°íƒ€ì„ ì˜¤ë¥˜ ê°ì†Œ

### 4.2 êµ¬í˜„ ìš°ì„ ìˆœìœ„

**Phase 1 (ì¦‰ì‹œ):**
1. `config/model_configs.yaml` ìƒì„±
2. `umis_rag/core/model_configs.py` êµ¬í˜„
3. ê¸°ì¡´ Phase 4ì—ì„œ ì‚¬ìš©

**Phase 2 (ë‹¨ê³„ì ):**
4. `ModelRouter.select_model_with_config()` ì¶”ê°€
5. ë‹¤ë¥¸ Phase (0-3)ì—ë„ ì ìš©

**Phase 3 (ìµœì í™”):**
6. ë²¤ì¹˜ë§ˆí¬ ì„¤ì • í†µí•©
7. ë™ì  ë¦¬ë¡œë”© ì§€ì›

---

## 5. êµ¬í˜„ ê°€ì´ë“œ

### 5.1 Step-by-Step

**Step 1: ì„¤ì • íŒŒì¼ ìƒì„± (30ë¶„)**
```bash
# config/model_configs.yaml ìƒì„±
mkdir -p config
touch config/model_configs.yaml
```

**Step 2: ëª¨ë¸ ì„¤ì • ëª¨ë“ˆ êµ¬í˜„ (2ì‹œê°„)**
```bash
# umis_rag/core/model_configs.py êµ¬í˜„
# - ModelConfig dataclass
# - ModelConfigManager singleton
# - YAML ë¡œë”© ë¡œì§
```

**Step 3: Phase 4 í†µí•© (1.5ì‹œê°„)**
```bash
# umis_rag/agents/estimator/phase4_fermi.py ìˆ˜ì •
# - model_configs import
# - _call_llm() ë©”ì„œë“œ ìˆ˜ì •
# - API íŒŒë¼ë¯¸í„° ë™ì  êµ¬ì„±
```

**Step 4: í…ŒìŠ¤íŠ¸ (1ì‹œê°„)**
```bash
# í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„±
python -m pytest tests/test_model_configs.py
python -m pytest tests/test_estimator_phase4.py
```

**Step 5: ë¬¸ì„œí™” (30ë¶„)**
```bash
# README ì—…ë°ì´íŠ¸
# config/model_configs.yaml ì£¼ì„ ì¶”ê°€
# ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ ì‘ì„±
```

**ì´ ì†Œìš” ì‹œê°„: 5.5ì‹œê°„**

### 5.2 í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤

```python
# tests/test_model_configs.py

import pytest
from umis_rag.core.model_configs import ModelConfigManager, ModelConfig

def test_model_config_loading():
    """YAML ë¡œë”© í…ŒìŠ¤íŠ¸"""
    manager = ModelConfigManager()
    
    # o1-mini ì„¤ì • í™•ì¸
    config = manager.get_config('o1-mini')
    assert config.api_type == 'responses'
    assert config.reasoning_effort_support == True
    assert config.max_output_tokens == 16000

def test_api_params_building():
    """API íŒŒë¼ë¯¸í„° êµ¬ì„± í…ŒìŠ¤íŠ¸"""
    manager = ModelConfigManager()
    config = manager.get_config('o1-mini')
    
    params = config.build_api_params(
        prompt="Test prompt",
        reasoning_effort='medium'
    )
    
    assert params['model'] == 'o1-mini'
    assert params['input'] == "Test prompt"
    assert params['reasoning']['effort'] == 'medium'
    assert params['max_output_tokens'] == 16000

def test_unsupported_model():
    """ë¯¸ì§€ì› ëª¨ë¸ ê¸°ë³¸ê°’ í…ŒìŠ¤íŠ¸"""
    manager = ModelConfigManager()
    config = manager.get_config('unknown-model')
    
    assert config.api_type == 'chat'  # ê¸°ë³¸ê°’
    assert config.max_output_tokens == 4096  # ê¸°ë³¸ê°’
```

### 5.3 ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

**ì½”ë“œ ë³€ê²½:**
- [ ] `config/model_configs.yaml` ìƒì„± ë° 15ê°œ ëª¨ë¸ ì •ì˜
- [ ] `umis_rag/core/model_configs.py` êµ¬í˜„
- [ ] `umis_rag/agents/estimator/phase4_fermi.py` ìˆ˜ì •
- [ ] í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‘ì„± ë° ì‹¤í–‰

**ë¬¸ì„œ ì—…ë°ì´íŠ¸:**
- [ ] READMEì— ëª¨ë¸ ì„¤ì • ì¶”ê°€ ë°©ë²• ì„¤ëª…
- [ ] `model_configs.yaml` ì£¼ì„ ë° ì˜ˆì‹œ
- [ ] ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ ì‘ì„±

**ê²€ì¦:**
- [ ] ê¸°ì¡´ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ëª¨ë¸ ë³€ê²½ ì‹œ ìë™ ì„¤ì • ì ìš© í™•ì¸
- [ ] ìƒˆ ëª¨ë¸ ì¶”ê°€ í…ŒìŠ¤íŠ¸ (YAMLë§Œ ìˆ˜ì •)

---

## 6. ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

### 6.1 ë‹¨ê³„ë³„ ê³„íš

**Week 1: Phase 4 ì ìš©**
- Day 1: `model_configs.yaml` ë° `model_configs.py` êµ¬í˜„
- Day 2: Phase 4 í†µí•© ë° í…ŒìŠ¤íŠ¸
- Day 3: ë¬¸ì„œí™” ë° ê²€ì¦

**Week 2: ì „ì²´ í™•ì¥**
- Day 1-2: `ModelRouter.select_model_with_config()` êµ¬í˜„
- Day 3-4: Phase 0-3 ì ìš©
- Day 5: í†µí•© í…ŒìŠ¤íŠ¸

**Week 3: ë²¤ì¹˜ë§ˆí¬ í†µí•©**
- Day 1-2: ë²¤ì¹˜ë§ˆí¬ `MODEL_API_CONFIGS` â†’ YAML ì´ë™
- Day 3-4: ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìˆ˜ì •
- Day 5: ì „ì²´ ê²€ì¦

### 6.2 ë¡¤ë°± ê³„íš

**ë¬¸ì œ ë°œìƒ ì‹œ:**
1. Gitìœ¼ë¡œ ì´ì „ ë²„ì „ ë³µêµ¬
2. Feature flagë¡œ ê¸°ëŠ¥ ë¹„í™œì„±í™”
3. `.env`ì—ì„œ `USE_MODEL_CONFIGS=false` ì„¤ì •

---

## 7. FAQ

**Q1: .envì—ì„œ ëª¨ë¸ë§Œ ë°”ê¾¸ë©´ ìë™ìœ¼ë¡œ ì„¤ì •ì´ ì ìš©ë˜ë‚˜ìš”?**
A1: ë„¤! `LLM_MODEL_PHASE4=gpt-5.1`ë¡œ ë°”ê¾¸ë©´ `model_configs.yaml`ì˜ gpt-5.1 ì„¤ì •ì´ ìë™ ì ìš©ë©ë‹ˆë‹¤.

**Q2: ìƒˆ ëª¨ë¸ì„ ì¶”ê°€í•˜ë ¤ë©´?**
A2: `config/model_configs.yaml`ì— í•­ëª©ë§Œ ì¶”ê°€í•˜ë©´ ë©ë‹ˆë‹¤. ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš”.

**Q3: ë²¤ì¹˜ë§ˆí¬ì™€ ì‹¤ì œ ì‹œìŠ¤í…œì´ ê°™ì€ ì„¤ì •ì„ ì‚¬ìš©í•˜ë‚˜ìš”?**
A3: ë„¤! YAMLì„ ê³µìœ í•˜ë¯€ë¡œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ê²€ì¦ëœ ì„¤ì •ì´ ê·¸ëŒ€ë¡œ ì‹¤ì œ ì‹œìŠ¤í…œì— ì ìš©ë©ë‹ˆë‹¤.

**Q4: ì„±ëŠ¥ ì˜í–¥ì€?**
A4: YAML ë¡œë”©ì€ ìµœì´ˆ 1íšŒë§Œ (singleton). ì‹¤í–‰ ì¤‘ì—ëŠ” ë©”ëª¨ë¦¬ ìºì‹œ ì‚¬ìš©í•˜ë¯€ë¡œ ì˜¤ë²„í—¤ë“œ ê±°ì˜ ì—†ìŒ.

**Q5: ê¸°ì¡´ ì½”ë“œì™€ í˜¸í™˜ë˜ë‚˜ìš”?**
A5: ë„¤! ê¸°ì¡´ `select_model(phase)` ë©”ì„œë“œëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€. ìƒˆë¡œìš´ `select_model_with_config(phase)` ì¶”ê°€.

---

## 8. ì°¸ê³  ìë£Œ

### 8.1 ê´€ë ¨ íŒŒì¼

**ê¸°ì¡´ ì‹œìŠ¤í…œ:**
- `umis_rag/core/config.py` - Settings í´ë˜ìŠ¤
- `umis_rag/core/model_router.py` - Phaseë³„ ëª¨ë¸ ì„ íƒ
- `umis_rag/agents/estimator/phase4_fermi.py` - Phase 4 êµ¬í˜„

**ë²¤ì¹˜ë§ˆí¬:**
- `benchmarks/estimator/phase4/common.py` - MODEL_API_CONFIGS
- `benchmarks/estimator/phase4/tests/` - í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

### 8.2 ë¬¸ì„œ

- `benchmarks/estimator/PHASE4_IMPROVEMENT_PLAN.md` - ê°œì„  ê³„íš
- `docs/architecture/UMIS_ARCHITECTURE_BLUEPRINT.md` - ì „ì²´ êµ¬ì¡°

---

**ë¬¸ì„œ ì‘ì„±:** AI Assistant  
**ë‚ ì§œ:** 2025-11-23  
**ë²„ì „:** v1.0

