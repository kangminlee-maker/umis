#!/usr/bin/env python3
"""
ì‹¤íŒ¨í•œ ëª¨ë¸ë“¤ë§Œ ì¬í…ŒìŠ¤íŠ¸
"""
import sys
sys.path.insert(0, '/Users/kangmin/umis_main_1103/umis')

from scripts.benchmark_comprehensive_2025 import LLMBenchmark2025Comprehensive

def main():
    """ì‹¤íŒ¨/ì €í’ˆì§ˆ ëª¨ë¸ë§Œ ì¬í…ŒìŠ¤íŠ¸"""
    
    benchmark = LLMBenchmark2025Comprehensive()
    
    # ì‹¤íŒ¨í•˜ê±°ë‚˜ í’ˆì§ˆì´ ë‚®ì•˜ë˜ ëª¨ë¸ë“¤
    failed_models = {
        'openai_nano': ['gpt-5-nano'],
        'openai_mini': ['gpt-5-mini'],
        'openai_standard': ['gpt-5', 'gpt-5.1'],
        'openai_thinking': ['o1', 'o3', 'o3-mini', 'o4-mini']
    }
    
    # ëª¨ë¸ ëª©ë¡ êµì²´
    benchmark.models = failed_models
    
    print("="*100)
    print("ì‹¤íŒ¨ ëª¨ë¸ ì¬í…ŒìŠ¤íŠ¸ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ + íŒŒì‹±)")
    print("="*100)
    print()
    print("ì¬í…ŒìŠ¤íŠ¸ ëª¨ë¸:")
    for cat, models in failed_models.items():
        print(f"  {cat}: {', '.join(models)}")
    print()
    print("ê°œì„ ì‚¬í•­:")
    print("  âœ… reasoning ëª¨ë¸ í”„ë¡¬í”„íŠ¸ì— JSON ê°•ì¡° ì¶”ê°€")
    print("  âœ… ì •ê·œì‹ìœ¼ë¡œ JSON ê°ì²´ ì¶”ì¶œ")
    print("  âœ… ì¤‘ì²© êµ¬ì¡° ì§€ì›")
    print()
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    benchmark.run_benchmark()
    
    # ê²°ê³¼ ì €ì¥
    output_file = 'benchmark_failed_models_retest.json'
    benchmark.save_results(output_file)
    
    # ê°„ë‹¨í•œ ë¦¬í¬íŠ¸
    print("\n" + "="*100)
    print("ğŸ“Š ì¬í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("="*100)
    
    success = [r for r in benchmark.results if r.get('success')]
    
    # ëª¨ë¸ë³„ í‰ê·  í’ˆì§ˆ
    model_scores = {}
    for r in success:
        model = r['model']
        if model not in model_scores:
            model_scores[model] = []
        model_scores[model].append(r['quality_score']['total_score'])
    
    print("\nëª¨ë¸ë³„ í‰ê·  í’ˆì§ˆ:")
    for model, scores in sorted(model_scores.items()):
        avg = sum(scores) / len(scores) if scores else 0
        improvement = "ê°œì„ " if avg > 20 else "ì—¬ì „íˆ ë‚®ìŒ"
        print(f"  {model:15} {avg:5.1f}ì  ({len(scores)}/7 ì„±ê³µ) - {improvement}")
    
    # Phaseë³„ ë¶„ì„
    print("\nPhaseë³„ ê°œì„  í˜„í™©:")
    phase_improve = {}
    for r in success:
        phase = r['phase']
        score = r['quality_score']['total_score']
        if phase not in phase_improve:
            phase_improve[phase] = []
        phase_improve[phase].append(score)
    
    for phase in sorted(phase_improve.keys()):
        scores = phase_improve[phase]
        avg = sum(scores) / len(scores)
        print(f"  Phase {phase}: {avg:.1f}ì  (ê°œì„  ì „ ëŒ€ë¹„)")
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")
    print("ğŸ‰ ì¬í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    main()


