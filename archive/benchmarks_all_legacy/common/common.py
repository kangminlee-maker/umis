#!/usr/bin/env python3
"""
âš ï¸ DEPRECATED (v7.11.0) - Legacy Phase 4 ê³µí†µ í•¨ìˆ˜ ëª¨ë“ˆ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì´ íŒŒì¼ì€ v7.10.2ì˜ Phase ê¸°ë°˜ ë²¤ì¹˜ë§ˆí¬ë¥¼ ìœ„í•œ Legacy ì½”ë“œì…ë‹ˆë‹¤.

**v7.11.0 ë³€ê²½ì‚¬í•­**:
- Phase 5 (0-4) â†’ 4-Stage Fusion Architectureë¡œ ì¬ì„¤ê³„
- ë²¤ì¹˜ë§ˆí¬ëŠ” `tests/unit/`, `tests/integration/`, `tests/e2e/`ë¡œ ì´ë™
- ì´ íŒŒì¼ì˜ ê¸°ëŠ¥ì€ `umis_rag/core/model_configs.py`ë¡œ ëŒ€ì²´ë¨

**ê¶Œì¥ì‚¬í•­**:
- ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬: `tests/` í´ë” ì°¸ì¡°
- ëª¨ë¸ ì„¤ì •: `config/model_configs.yaml` ë° `umis_rag/core/model_configs.py`
- Legacy ë²¤ì¹˜ë§ˆí¬: `archive/benchmarks_v7.10.2/`

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Phase 4 ê³µí†µ í•¨ìˆ˜ ëª¨ë“ˆ (Legacy)
- ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ (ì—°ê²°ì„± ê°•ì œ)
- ê°œë…ì  ì¼ê´€ì„± í‰ê°€ (ì‹ ê·œ)
- Fermi ì¶”ì • í‰ê°€ ì‹œìŠ¤í…œ
- ëª¨ë¸ë³„ API ì—”ë“œí¬ì¸íŠ¸ ì²˜ë¦¬ (ëª…ì‹œì  ê´€ë¦¬)
"""

import math


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ëª¨ë¸ë³„ API ì„¤ì • (ëª…ì‹œì  ê´€ë¦¬)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

MODEL_API_CONFIGS = {
    # ===== o-series =====
    'o1-mini': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'STEM ìµœì í™”, 80% ì €ë ´'
    },
    'o1': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'ê¸°ë³¸ reasoning ëª¨ë¸, function calling ì§€ì›'
    },
    'o1-2024-12-17': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'o1ì˜ íŠ¹ì • ë²„ì „'
    },
    'o1-pro': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['high'],  # high ê³ ì •
        'reasoning_effort_fixed': 'high',
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'context_window': 200000,
        'notes': 'Responses API only, ìµœê³  ì„±ëŠ¥, ë¹„ìš© ë†’ìŒ ($150/1M input)'
    },
    'o1-pro-2025-03-19': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['high'],  # high ê³ ì •
        'reasoning_effort_fixed': 'high',
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'context_window': 200000,
        'notes': 'o1-proì˜ íŠ¹ì • ë²„ì „'
    },
    'o3': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'o3 ì‹œë¦¬ì¦ˆ'
    },
    'o3-2025-04-16': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'o3ì˜ íŠ¹ì • ë²„ì „'
    },
    'o3-mini': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'o3 mini ë²„ì „'
    },
    'o3-mini-2025-01-31': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'o3-miniì˜ íŠ¹ì • ë²„ì „'
    },
    'o4-mini': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'o4 mini ë²„ì „'
    },
    'o4-mini-2025-04-16': {
        'api_type': 'responses',
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['low', 'medium', 'high'],
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'o4-miniì˜ íŠ¹ì • ë²„ì „'
    },

    # ===== gpt-5 series =====
    'gpt-5.1': {
        'api_type': 'responses',  # Chat Completionsë„ ì§€ì›
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['none', 'low', 'medium', 'high'],
        'temperature_support': True,  # reasoning.effort=noneì¼ ë•Œë§Œ
        'temperature_condition': 'reasoning_effort_none',
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'context_window': 196000,
        'notes': 'temperature/top_pëŠ” reasoning.effort=noneì¼ ë•Œë§Œ'
    },
    'gpt-5-pro': {
        'api_type': 'responses',  # Responses API only
        'reasoning_effort_support': True,
        'reasoning_effort_levels': ['high'],  # high ê³ ì •
        'reasoning_effort_fixed': 'high',
        'temperature_support': False,
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'context_window': 400000,
        'notes': 'Responses API only, reasoning.effort=high ê³ ì •, temperature ë¯¸ì§€ì›'
    },

    # ===== gpt-4.1 series =====
    'gpt-4.1': {
        'api_type': 'responses',
        'reasoning_effort_support': False,
        'temperature_support': False,  # Responses APIì—ì„œëŠ” ë¯¸ì§€ì›
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'reasoning ë¯¸ì§€ì›'
    },
    'gpt-4.1-mini': {
        'api_type': 'responses',
        'reasoning_effort_support': False,
        'temperature_support': False,  # Responses APIì—ì„œëŠ” ë¯¸ì§€ì›
        'max_output_tokens': 16000,  # í†µì¼: ëª¨ë“  ëª¨ë¸ 16K
        'notes': 'reasoning ë¯¸ì§€ì›'
    },
}


def get_model_config(model_name):
    """
    ëª¨ë¸ ì´ë¦„ì— ë§ëŠ” API ì„¤ì • ë°˜í™˜

    Args:
        model_name: ëª¨ë¸ ì´ë¦„ (ì˜ˆ: 'o1', 'gpt-5.1')

    Returns:
        dict: ëª¨ë¸ API ì„¤ì •
    """
    # ì •í™•í•œ ì´ë¦„ ë§¤ì¹­
    if model_name in MODEL_API_CONFIGS:
        return MODEL_API_CONFIGS[model_name]

    # Prefix ê¸°ë°˜ í´ë°± (ìƒˆë¡œìš´ ë²„ì „ ëª¨ë¸ ëŒ€ë¹„)
    if model_name.startswith('o1-pro'):
        return MODEL_API_CONFIGS['o1-pro']
    elif model_name.startswith('o1-mini'):
        return MODEL_API_CONFIGS['o1-mini']
    elif model_name.startswith('o1'):
        return MODEL_API_CONFIGS['o1']
    elif model_name.startswith('o3-mini'):
        return MODEL_API_CONFIGS['o3-mini']
    elif model_name.startswith('o3'):
        return MODEL_API_CONFIGS['o3']
    elif model_name.startswith('o4-mini'):
        return MODEL_API_CONFIGS['o4-mini']
    elif model_name.startswith('gpt-5.1'):
        return MODEL_API_CONFIGS['gpt-5.1']
    elif model_name.startswith('gpt-5-pro'):
        return MODEL_API_CONFIGS['gpt-5-pro']
    elif model_name.startswith('gpt-4.1-mini'):
        return MODEL_API_CONFIGS['gpt-4.1-mini']
    elif model_name.startswith('gpt-4.1'):
        return MODEL_API_CONFIGS['gpt-4.1']

    # ê¸°ë³¸ê°’ (Chat Completions fallback)
    return {
        'api_type': 'chat',
        'reasoning_effort_support': False,
        'temperature_support': True,
        'max_output_tokens': 16000,
        'notes': 'Unknown model, using Chat Completions fallback'
    }


def build_api_params(model_name, prompt, reasoning_effort='medium'):
    """
    ëª¨ë¸ ì„¤ì •ì— ë§ëŠ” API íŒŒë¼ë¯¸í„° ìƒì„±

    Args:
        model_name: ëª¨ë¸ ì´ë¦„
        prompt: í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸
        reasoning_effort: reasoning effort ë ˆë²¨ (ê¸°ë³¸: 'medium')

    Returns:
        tuple: (api_type, api_params_dict)
    """
    config = get_model_config(model_name)

    api_params = {
        "model": model_name,
        "max_output_tokens": config['max_output_tokens']
    }

    api_type = config['api_type']

    # API íƒ€ì…ë³„ prompt í•„ë“œëª…
    if api_type == 'responses':
        api_params["input"] = prompt
    else:  # 'chat'
        api_params["messages"] = [{"role": "user", "content": prompt}]

    # Reasoning effort ì²˜ë¦¬
    if config['reasoning_effort_support']:
        # ê³ ì •ëœ effortê°€ ìˆìœ¼ë©´ ì‚¬ìš©
        if 'reasoning_effort_fixed' in config:
            effort_to_use = config['reasoning_effort_fixed']
        else:
            # ì§€ì›ë˜ëŠ” ë ˆë²¨ì¸ì§€ í™•ì¸
            if reasoning_effort in config['reasoning_effort_levels']:
                effort_to_use = reasoning_effort
            else:
                # ì§€ì› ì•ˆ ë˜ë©´ ê°€ì¥ ê°€ê¹Œìš´ ë ˆë²¨ ì„ íƒ
                effort_to_use = config['reasoning_effort_levels'][-1]  # ê¸°ë³¸ì ìœ¼ë¡œ ê°€ì¥ ë†’ì€ ë ˆë²¨

        api_params["reasoning"] = {"effort": effort_to_use}

    # Temperature ì²˜ë¦¬ (Chat Completionsì—ì„œë§Œ, ë˜ëŠ” íŠ¹ì • ì¡°ê±´)
    if api_type == 'chat' and config.get('temperature_support'):
        api_params["temperature"] = 0.3  # ì¼ê´€ì„±ì„ ìœ„í•œ ë‚®ì€ temperature

    return api_type, api_params


def call_model_api(client, api_type, api_params):
    """
    API íƒ€ì…ì— ë§ê²Œ ëª¨ë¸ í˜¸ì¶œ

    Args:
        client: OpenAI client
        api_type: 'responses' ë˜ëŠ” 'chat'
        api_params: API íŒŒë¼ë¯¸í„° dict

    Returns:
        API response object
    """
    if api_type == 'responses':
        return client.responses.create(**api_params)
    else:  # 'chat'
        return client.chat.completions.create(**api_params)


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í”„ë¡¬í”„íŠ¸ ë° ì‹œë‚˜ë¦¬ì˜¤
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def get_fast_mode_constraint():
    """pro ëª¨ë¸ìš© ì†ë„ ìµœì í™” ì œì•½ (v7.7.1)"""
    return '''
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”´ SPEED OPTIMIZATION MODE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

â±ï¸ ëª©í‘œ ì‘ë‹µ ì‹œê°„: 60ì´ˆ ì´ë‚´
ğŸ“ ìµœëŒ€ ì¶œë ¥ ê¸¸ì´: 2,000ì ì´ë‚´ (ì•½ 500 í† í°)
ğŸ“‹ decomposition: 3-5ë‹¨ê³„ë§Œ (í•„ìˆ˜ ë‹¨ê³„ë§Œ í¬í•¨)
âœ‚ï¸ reasoning: ê° ë‹¨ê³„ 15ë‹¨ì–´ ì´ë‚´

ğŸ’¡ ë¹ ë¥´ê³  ê°„ê²°í•˜ê²Œ í•µì‹¬ë§Œ ë‹µë³€í•˜ì„¸ìš”!
   ê¹Šì€ ì¶”ë¡ ë³´ë‹¤ëŠ” ì§ê´€ì  ê·¼ì‚¬ì¹˜ë¥¼ ìš°ì„ í•˜ì„¸ìš”.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
'''


def get_improved_fewshot_prompt():
    """ê°œì„ ëœ Few-shot í”„ë¡¬í”„íŠ¸ - ê³„ì‚° ì—°ê²°ì„± + concept í•„ë“œ ê°•ì œ"""
    return '''
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ”´ CRITICAL MANDATORY FIELDS (ëˆ„ë½ ì‹œ 0ì !):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. decompositionì˜ ëª¨ë“  ë‹¨ê³„ì— "concept" í•„ë“œ í•„ìˆ˜!
2. ìµœìƒìœ„ "final_calculation" í•„ë“œ í•„ìˆ˜!
3. ìµœìƒìœ„ "calculation_verification" í•„ë“œ í•„ìˆ˜!

âš ï¸ ì´ 3ê°œ í•„ë“œê°€ í•˜ë‚˜ë¼ë„ ëˆ„ë½ë˜ë©´ í‰ê°€ ì ìˆ˜ê°€ í¬ê²Œ ê°ì ë©ë‹ˆë‹¤!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ì˜¬ë°”ë¥¸ ì˜ˆì‹œ: ì„œìš¸ì‹œ íƒì‹œ ìˆ˜

{
    "value": 66667,  â† ë°˜ë“œì‹œ ë§ˆì§€ë§‰ stepì˜ valueì™€ ë™ì¼!
    "unit": "ëŒ€",
    "confidence": 0.6,
    "method": "bottom-up",
    "decomposition": [
        {
            "step": "1. ì„œìš¸ ì¸êµ¬",
            "concept": "population_seoul",  â† í•„ìˆ˜! ë„ë©”ì¸ ê°œë… ëª…ì‹œ
            "value": 10000000,
            "unit": "ëª…",
            "calculation": "1000ë§Œëª… (í†µê³„ ê¸°ë°˜)",
            "reasoning": "ì„œìš¸ì‹œ ê³µì‹ ì¸êµ¬ í†µê³„"
        },
        {
            "step": "2. 1ì¸ë‹¹ ì—°ê°„ íƒì‹œ ì´ìš©",
            "concept": "taxi_usage_per_capita",  â† í•„ìˆ˜!
            "value": 20,
            "unit": "íšŒ",
            "calculation": "ì›” 1.5íšŒ Ã— 12ê°œì›” â‰ˆ 20",
            "reasoning": "ëŒ€ì¤‘êµí†µ ì¤‘ì‹¬, ê°€ë” ì´ìš©"
        },
        {
            "step": "3. ì—°ê°„ ì´ ì´ìš© íšŸìˆ˜",
            "concept": "total_taxi_rides",  â† í•„ìˆ˜!
            "value": 200000000,
            "unit": "íšŒ",
            "calculation": "10000000 Ã— 20 = 200000000",
            "reasoning": "step1 Ã— step2"
        },
        {
            "step": "4. íƒì‹œ 1ëŒ€ë‹¹ ì—°ê°„ ìš´í–‰",
            "concept": "rides_per_taxi",  â† í•„ìˆ˜!
            "value": 3000,
            "unit": "íšŒ",
            "calculation": "ì¼ 10íšŒ Ã— 300ì¼ = 3000",
            "reasoning": "2êµëŒ€ ê¸°ì¤€"
        },
        {
            "step": "5. ìµœì¢…: í•„ìš” íƒì‹œ ìˆ˜",
            "concept": "total_taxis_needed",  â† í•„ìˆ˜! ë§ˆì§€ë§‰ ë‹¨ê³„ë„!
            "value": 66667,  â† ì´ ê°’ì´ ìµœì¢… "value"ê°€ ë¨!
            "unit": "ëŒ€",
            "calculation": "200000000 Ã· 3000 = 66667",
            "reasoning": "ì´ì´ìš© Ã· ëŒ€ë‹¹ìš´í–‰ = step3 Ã· step4"
        }
    ],
    "final_calculation": "step5 = step3 Ã· step4 = 200000000 Ã· 3000 = 66667",  â† í•„ìˆ˜!
    "calculation_verification": "âœ“ ê²€ì¦: 10,000,000ëª… Ã— 20íšŒ Ã· 3,000íšŒ = 66,667ëŒ€"  â† í•„ìˆ˜!
}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MANDATORY RULES (ì ˆëŒ€ ê·œì¹™):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. ğŸ”´ "concept" í•„ë“œ - ëª¨ë“  decomposition ë‹¨ê³„ì— í•„ìˆ˜!
   â†’ ë„ë©”ì¸ íŠ¹í™” ê°œë…ì„ ì˜ì–´ snake_caseë¡œ ëª…ì‹œ
   â†’ ì˜ˆ: "population_seoul", "taxi_usage_per_capita"
   â†’ ëˆ„ë½ ì‹œ ê°œë… ì ìˆ˜ 0ì !

2. ğŸ”´ "final_calculation" í•„ë“œ - JSON ìµœìƒìœ„ì— í•„ìˆ˜!
   â†’ decomposition ë§ˆì§€ë§‰ ë‹¨ê³„ ê³„ì‚°ì„ ì‹¤ì œ ìˆ«ìë¡œ ì¬ê²€ì¦
   â†’ ì˜ˆ: "step5 = step3 Ã· step4 = 200000000 Ã· 3000 = 66667"
   â†’ ëˆ„ë½ ì‹œ ì—°ê²°ì„± ì ìˆ˜ -10ì !

3. ğŸ”´ "calculation_verification" í•„ë“œ - JSON ìµœìƒìœ„ì— í•„ìˆ˜!
   â†’ ì „ì²´ ê³„ì‚° ê³¼ì • ì¬í™•ì¸
   â†’ ì˜ˆ: "âœ“ ê²€ì¦: 10,000,000ëª… Ã— 20íšŒ Ã· 3,000íšŒ = 66,667ëŒ€"
   â†’ ëˆ„ë½ ì‹œ ì—°ê²°ì„± ì ìˆ˜ -5ì !

4. ìµœì¢… ì¶”ì •ê°’ = decomposition ë§ˆì§€ë§‰ ë‹¨ê³„ì˜ value
   â†’ JSONì˜ "value": 66667 = decomposition[-1]["value"]: 66667

5. ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” ë°˜ë“œì‹œ ìµœì¢… ê³„ì‚° ë‹¨ê³„
   â†’ "step": "N. ìµœì¢…: [ì¶”ì • ëŒ€ìƒ]"
   â†’ ì´ ë‹¨ê³„ì˜ valueê°€ ê³§ ìµœì¢… ë‹µ

6. ê° ì¤‘ê°„ ë‹¨ê³„ëŠ” ëª…í™•í•œ ì‚¬ì¹™ì—°ì‚°ìœ¼ë¡œ ì—°ê²°
   â†’ "calculation": "step3 Ã· step4 = 200000000 Ã· 3000 = 66667"

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
'''


def get_phase4_scenarios(model_name=None):
    """Phase 4 ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    
    Args:
        model_name: ëª¨ë¸ ì´ë¦„ (pro ëª¨ë¸ì´ë©´ Fast Mode ì¶”ê°€)
    """
    fewshot_example = get_improved_fewshot_prompt()
    
    # pro ëª¨ë¸ì´ë©´ Fast Mode constraint ì¶”ê°€
    pro_models = ['gpt-5-pro', 'o1-pro', 'o1-pro-2025-03-19']
    if model_name and model_name in pro_models:
        fast_mode = get_fast_mode_constraint()
        print(f"  ğŸš€ [Fast Mode] {model_name}ì— ì†ë„ ìµœì í™” í”„ë¡¬í”„íŠ¸ ì ìš©")
    else:
        fast_mode = ""

    return [
        {
            'id': 'phase4_korean_businesses',
            'name': 'Phase 4 - í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜',
            'phase': 4,
            'prompt': f'''{fast_mode}{fewshot_example}

ì´ì œ ì‹¤ì œ ë¬¸ì œë¥¼ í’€ì–´ì£¼ì„¸ìš”:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ë¬¸ì œ: í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜ë¥¼ ì¶”ì •í•˜ì„¸ìš”.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

íŒíŠ¸:
- í•œêµ­ ì¸êµ¬, ê²½ì œí™œë™ì¸êµ¬ ê³ ë ¤
- ìì˜ì—…ì, ë²•ì¸ ì‚¬ì—…ì êµ¬ë¶„
- ë‹¤ì¤‘ ì‚¬ì—…ìë“±ë¡ ê°€ëŠ¥ì„± ê³ ë ¤

âš ï¸ CRITICAL: ë°˜ë“œì‹œ ì•„ë˜ ê·œì¹™ì„ ë”°ë¥´ì„¸ìš”!

1. decompositionì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ value = JSON ìµœìƒìœ„ "value"
2. ë§ˆì§€ë§‰ stepì˜ "step" í•„ë“œëŠ” ë°˜ë“œì‹œ "N. ìµœì¢…: í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜"
3. ë§ˆì§€ë§‰ stepì˜ "calculation"ì€ ì‹¤ì œ ì‚¬ì¹™ì—°ì‚° (ì˜ˆ: "4000000 + 3837000 = 7837000")
4. ë°˜ì˜¬ë¦¼/ê·¼ì‚¬ì¹˜ëŠ” ë§ˆì§€ë§‰ì—ë§Œ ì ìš©

JSON í˜•ì‹ (ì—„ê²©íˆ ì¤€ìˆ˜):
{{
    "value": <decomposition ë§ˆì§€ë§‰ ë‹¨ê³„ì˜ valueì™€ ì •í™•íˆ ë™ì¼!>,
    "unit": "ê°œ",
    "confidence": <0.3-0.7>,
    "method": "bottom-up",
    "decomposition": [
        {{
            "step": "1. [ì²« ë²ˆì§¸ êµ¬ì„±ìš”ì†Œ]",
            "concept": "[ë„ë©”ì¸_ê°œë…_snake_case]",  â† ğŸ”´ í•„ìˆ˜!
            "value": <ìˆ«ì>,
            "unit": "[ë‹¨ìœ„]",
            "calculation": "[ê³„ì‚° ê³¼ì •]",
            "reasoning": "[ê°€ì • ë° ê·¼ê±°]"
        }},
        {{
            "step": "2. [ë‘ ë²ˆì§¸ êµ¬ì„±ìš”ì†Œ]",
            "concept": "[ë„ë©”ì¸_ê°œë…_snake_case]",  â† ğŸ”´ í•„ìˆ˜!
            "value": <ìˆ«ì>,
            "unit": "[ë‹¨ìœ„]",
            "calculation": "[ê³„ì‚° ê³¼ì •]",
            "reasoning": "[ê°€ì • ë° ê·¼ê±°]"
        }},
        ...
        {{
            "step": "N. ìµœì¢…: í•œêµ­ ì „ì²´ ì‚¬ì—…ì ìˆ˜",
            "concept": "total_businesses_korea",  â† ğŸ”´ í•„ìˆ˜!
            "value": <ì´ ê°’ì´ ê³§ ìµœìƒìœ„ "value"!>,
            "unit": "ê°œ",
            "calculation": "step1 + step2 + ... = <ì •í™•í•œ ê³„ì‚°>",
            "reasoning": "ëª¨ë“  êµ¬ì„±ìš”ì†Œ í•©ì‚°"
        }}
    ],
    "final_calculation": "step1 + step2 + ... = <ì‹¤ì œ ìˆ«ìë¡œ ì¬ê³„ì‚°>",  â† ğŸ”´ í•„ìˆ˜!
    "calculation_verification": "âœ“ ê²€ì¦: [ì „ì²´ ê³„ì‚° ê³¼ì • ì¬í™•ì¸]"  â† ğŸ”´ í•„ìˆ˜!
}}

ğŸ”´ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ë°˜ë“œì‹œ í™•ì¸!):
â–¡ ëª¨ë“  decomposition ë‹¨ê³„ì— "concept" í•„ë“œ ìˆìŒ â† ëˆ„ë½ ì‹œ 0ì !
â–¡ ìµœìƒìœ„ì— "final_calculation" í•„ë“œ ìˆìŒ â† ëˆ„ë½ ì‹œ -10ì !
â–¡ ìµœìƒìœ„ì— "calculation_verification" í•„ë“œ ìˆìŒ â† ëˆ„ë½ ì‹œ -5ì !
â–¡ decomposition[-1]["value"] == JSON["value"] â† ë°˜ë“œì‹œ í™•ì¸!
â–¡ ë§ˆì§€ë§‰ stepì€ ìµœì¢… ê³„ì‚° ë‹¨ê³„
â–¡ ëª¨ë“  calculation í•„ë“œì— ì‹¤ì œ ìˆ«ì í¬í•¨''',
            'expected_value': 7837000,
            'expected_unit': 'ê°œ',
        },
        {
            'id': 'phase4_seoul_population',
            'name': 'Phase 4 - ì„œìš¸ì‹œ ì¸êµ¬',
            'phase': 4,
            'prompt': f'''{fast_mode}{fewshot_example}

ì´ì œ ì‹¤ì œ ë¬¸ì œ:

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ë¬¸ì œ: ì„œìš¸ì‹œ ì¸êµ¬ë¥¼ ì¶”ì •í•˜ì„¸ìš”.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

íŒíŠ¸:
- í•œêµ­ ì „ì²´ ì¸êµ¬ ëŒ€ë¹„ ì„œìš¸ ë¹„ì¤‘
- ìˆ˜ë„ê¶Œ ì§‘ì¤‘ë„ ê³ ë ¤
- ë˜ëŠ” ë©´ì  ê¸°ë°˜ ì ‘ê·¼

âš ï¸ CRITICAL: decomposition ë§ˆì§€ë§‰ ë‹¨ê³„ì˜ value = JSON ìµœìƒìœ„ "value" (ì •í™•íˆ ì¼ì¹˜!)

ë°˜ë“œì‹œ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
ë§ˆì§€ë§‰ step: "N. ìµœì¢…: ì„œìš¸ì‹œ ì¸êµ¬", valueëŠ” ì´ ë‹¨ê³„ì˜ ê³„ì‚° ê²°ê³¼''',
            'expected_value': 9668465,
            'expected_unit': 'ëª…',
        },
        {
            'id': 'phase4_coffee_shops',
            'name': 'Phase 4 - í•œêµ­ ì»¤í”¼ ì „ë¬¸ì  ìˆ˜',
            'phase': 4,
            'prompt': f'''{fast_mode}âš ï¸ CRITICAL RULE: ìµœì¢… ì¶”ì •ê°’(value)ì€ ë°˜ë“œì‹œ decompositionì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ ê°’ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤!

ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:

{{
    "value": 66667,  â† ë§ˆì§€ë§‰ stepì˜ valueì™€ ë™ì¼!
    "decomposition": [
        {{"step": "1. ì¸êµ¬", "value": 10000000, "calculation": "1000ë§Œ"}},
        {{"step": "2. ì´ìš©íšŸìˆ˜", "value": 20, "calculation": "ì›” 2íšŒ Ã— 12"}},
        {{"step": "3. ì´ì´ìš©", "value": 200000000, "calculation": "10000000 Ã— 20"}},
        {{"step": "4. íƒì‹œìš´í–‰", "value": 3000, "calculation": "ì¼ 10íšŒ Ã— 300ì¼"}},
        {{"step": "5. ìµœì¢…: íƒì‹œ ìˆ˜", "value": 66667, "calculation": "200000000 Ã· 3000 = 66667"}}
    ],
    "final_calculation": "step3 Ã· step4 = 200000000 Ã· 3000 = 66667"
}}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ë¬¸ì œ: í•œêµ­ ì»¤í”¼ ì „ë¬¸ì  ìˆ˜ë¥¼ ì¶”ì •í•˜ì„¸ìš”.
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

íŒíŠ¸:
- ì»¤í”¼ ì†Œë¹„ ì¸êµ¬
- ì í¬ë‹¹ ê³ ê° ìˆ˜
- ë¸Œëœë“œ ê²½ìŸ ë° ìƒê¶Œ ì¤‘ë³µ

âš ï¸ í•„ìˆ˜:
1. ë§ˆì§€ë§‰ step: "N. ìµœì¢…: ì»¤í”¼ ì „ë¬¸ì  ìˆ˜"
2. ì´ ë‹¨ê³„ì˜ value = JSON ìµœìƒìœ„ "value" (ì •í™•íˆ ì¼ì¹˜!)
3. calculationì— ì‹¤ì œ ì‚¬ì¹™ì—°ì‚° í¬í•¨

ë°˜ë“œì‹œ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ''',
            'expected_value': 100000,
            'expected_unit': 'ê°œ',
        }
    ]


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í‰ê°€ ì‹œìŠ¤í…œ (v7.8.0 - ë‚´ìš©/í˜•ì‹ ë¶„ë¦¬)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# í—¬í¼ í•¨ìˆ˜ë“¤
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def has_appropriate_operations(decomp):
    """ì—°ì‚° ì ì ˆì„± í‰ê°€"""
    if not decomp or len(decomp) < 2:
        return False
    
    # ê³±ì…ˆ, ë‚˜ëˆ—ì…ˆ, ë§ì…ˆ ë“±ì˜ ì—°ì‚°ì´ ìˆëŠ”ì§€ í™•ì¸
    operations = ['Ã—', 'Ã·', '+', '-', '*', '/', 'x']
    for step in decomp:
        calc = step.get('calculation', '')
        if any(op in calc for op in operations):
            return True
    return False


def has_logical_order(decomp):
    """ë…¼ë¦¬ì  ìˆœì„œ í‰ê°€"""
    if not decomp or len(decomp) < 3:
        return True  # ë‹¨ìˆœí•œ ê²½ìš° í†µê³¼
    
    # ë§ˆì§€ë§‰ ë‹¨ê³„ê°€ "ìµœì¢…" ë˜ëŠ” "í•©ê³„" í¬í•¨í•˜ëŠ”ì§€
    last_step = decomp[-1].get('step', '').lower()
    if 'ìµœì¢…' in last_step or 'í•©ê³„' in last_step or 'total' in last_step:
        return True
    
    return False


def uses_intermediate_results(decomp):
    """ì¤‘ê°„ ê²°ê³¼ í™œìš© í‰ê°€"""
    if not decomp or len(decomp) < 3:
        return False
    
    # "step1", "step2" ë“±ì˜ ì°¸ì¡°ê°€ ìˆëŠ”ì§€
    for i, step in enumerate(decomp):
        if i == 0:
            continue
        
        reasoning = step.get('reasoning', '').lower()
        calculation = step.get('calculation', '').lower()
        
        # ì´ì „ ë‹¨ê³„ ì°¸ì¡°
        if 'step' in reasoning or 'step' in calculation:
            return True
    
    return False


def auto_verify_calculation(decomp, final_value):
    """ë¶„í•´ ê°’ë“¤ë¡œ ìµœì¢…ê°’ ìë™ ê³„ì‚° ì‹œë„"""
    if not isinstance(decomp, list) or len(decomp) < 2:
        return None, "ë‹¨ê³„ ë¶€ì¡±"

    values = [step.get('value', 0) for step in decomp if isinstance(step.get('value'), (int, float))]

    if len(values) < 2:
        return None, "ìœ íš¨í•œ ê°’ ë¶€ì¡±"

    results = []

    if values[-1] > 0:
        error = abs(values[-1] - final_value) / max(final_value, 1)
        results.append(('ë§ˆì§€ë§‰ ë‹¨ê³„', values[-1], error))

    total = sum(values)
    if total > 0:
        error = abs(total - final_value) / max(final_value, 1)
        results.append(('ëª¨ë“  ë‹¨ê³„ í•©', total, error))

    if len(values) >= 2:
        last_two = sum(values[-2:])
        if last_two > 0:
            error = abs(last_two - final_value) / max(final_value, 1)
            results.append(('ë§ˆì§€ë§‰ 2ë‹¨ê³„ í•©', last_two, error))

    if results:
        best = min(results, key=lambda x: x[2])
        return best[1], f"{best[0]}: {best[1]:,.0f} (ì˜¤ì°¨ {best[2]*100:.1f}%)"

    return None, "ê³„ì‚° ë¶ˆê°€"


def evaluate_content_score(decomp, final_value):
    """ë‚´ìš© ì ìˆ˜ í‰ê°€ (45ì ) - v7.8.0
    
    ì‹¤ì œ ì¶”ë¡  ëŠ¥ë ¥ì„ í‰ê°€ (í˜•ì‹ê³¼ ë¬´ê´€)
    
    Returns:
        dict: {
            'score': float (0-45),
            'details': list of str,
            'breakdown': {
                'step_completeness': float (0-10),
                'calculation_logic': float (0-10),
                'numerical_accuracy': float (0-25)
            }
        }
    """
    score = 0
    details = []
    breakdown = {}
    
    if not isinstance(decomp, list) or len(decomp) == 0:
        return {
            'score': 0,
            'details': ['âŒ decomposition ì—†ìŒ'],
            'breakdown': {'step_completeness': 0, 'calculation_logic': 0, 'numerical_accuracy': 0}
        }
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 1. ë‹¨ê³„ë³„ ê³„ì‚° ì™„ì„±ë„ (10ì )
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    calculable_steps = 0
    for step in decomp:
        # ê³„ì‚° ê°€ëŠ¥ ì¡°ê±´: value + (calculation ë˜ëŠ” reasoningì— ì—°ì‚°)
        if (step.get('value') is not None and 
            (step.get('calculation') or 
             any(op in step.get('reasoning', '') for op in ['Ã—', 'Ã·', '+', '-', '*', '/']))):
            calculable_steps += 1
    
    completeness_score = (calculable_steps / len(decomp)) * 10
    score += completeness_score
    breakdown['step_completeness'] = round(completeness_score, 1)
    details.append(f"ë‹¨ê³„ë³„ ê³„ì‚° ì™„ì„±ë„: {calculable_steps}/{len(decomp)} ({completeness_score:.1f}ì )")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 2. ê³„ì‚° ë…¼ë¦¬ ì—°ê²° (10ì )
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    logic_score = 0
    
    # 2-1. ì—°ì‚° ì ì ˆì„± (4ì )
    if has_appropriate_operations(decomp):
        logic_score += 4
        details.append("âœ… ì—°ì‚° ì ì ˆì„± (4ì )")
    else:
        details.append("âŒ ì—°ì‚° ë¶€ì¡± (0ì )")
    
    # 2-2. ë‹¨ê³„ ìˆœì„œ (3ì )
    if has_logical_order(decomp):
        logic_score += 3
        details.append("âœ… ë…¼ë¦¬ì  ìˆœì„œ (3ì )")
    else:
        details.append("âŒ ìˆœì„œ ë¶ˆëª…í™• (0ì )")
    
    # 2-3. ì¤‘ê°„ ê²°ê³¼ í™œìš© (3ì )
    if uses_intermediate_results(decomp):
        logic_score += 3
        details.append("âœ… ì¤‘ê°„ ê²°ê³¼ í™œìš© (3ì )")
    else:
        details.append("âŒ ì¤‘ê°„ ê²°ê³¼ ë¯¸í™œìš© (0ì )")
    
    score += logic_score
    breakdown['calculation_logic'] = logic_score
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 3. ìˆ˜ì¹˜ ì •í™•ì„± (25ì )
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    if len(decomp) > 0:
        last_value = decomp[-1].get('value', 0)
        
        if isinstance(last_value, (int, float)) and last_value > 0 and final_value > 0:
            error_ratio = abs(last_value - final_value) / max(final_value, 1)
            
            if error_ratio < 0.01:
                numerical_score = 25
                details.append(f"âœ… ìˆ˜ì¹˜ ì™„ë²½ ì¼ì¹˜ (25ì )")
            elif error_ratio < 0.05:
                numerical_score = 20
                details.append(f"âœ… ìˆ˜ì¹˜ ê±°ì˜ ì¼ì¹˜ (20ì )")
            elif error_ratio < 0.10:
                numerical_score = 15
                details.append(f"âš ï¸ ìˆ˜ì¹˜ ê·¼ì ‘ (15ì )")
            elif error_ratio < 0.30:
                numerical_score = 10
                details.append(f"âš ï¸ ìˆ˜ì¹˜ ë¶€ë¶„ ì¼ì¹˜ (10ì )")
            else:
                numerical_score = 5
                details.append(f"âŒ ìˆ˜ì¹˜ ë¶ˆì¼ì¹˜ (5ì )")
        else:
            numerical_score = 0
            details.append("âŒ ìˆ˜ì¹˜ ê²€ì¦ ë¶ˆê°€ (0ì )")
    else:
        numerical_score = 0
        details.append("âŒ ë§ˆì§€ë§‰ ë‹¨ê³„ ì—†ìŒ (0ì )")
    
    score += numerical_score
    breakdown['numerical_accuracy'] = numerical_score
    
    return {
        'score': min(score, 45),
        'details': details,
        'breakdown': breakdown
    }


def evaluate_format_score(response, decomp, auto_generated_fields=None):
    """í˜•ì‹ ì ìˆ˜ í‰ê°€ (5ì ) - v7.8.0
    
    JSON ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ë„ í‰ê°€
    
    Args:
        response: ì‘ë‹µ dict
        decomp: decomposition ë¦¬ìŠ¤íŠ¸
        auto_generated_fields: ìë™ ìƒì„±ëœ í•„ë“œ ëª©ë¡ (ì„ íƒì )
    
    Returns:
        dict: {
            'score': float (0-5),
            'details': list of str,
            'breakdown': {
                'final_calculation': int (0 or 2),
                'calculation_verification': int (0 or 2),
                'concept_fields': float (0-1)
            }
        }
    """
    score = 0
    details = []
    breakdown = {}
    auto_gen = auto_generated_fields or []
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 1. final_calculation í•„ë“œ (2ì )
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    if 'final_calculation' in response:
        # ìë™ ìƒì„±ì¸ì§€ í™•ì¸
        if 'final_calculation' in auto_gen or 'Auto-generated' in str(response.get('final_calculation', '')):
            score += 0
            breakdown['final_calculation'] = 0
            details.append("âŒ final_calculation ëˆ„ë½ (ìë™ ìƒì„±, 0ì )")
        else:
            score += 2
            breakdown['final_calculation'] = 2
            details.append("âœ… final_calculation ì œê³µ (2ì )")
    else:
        score += 0
        breakdown['final_calculation'] = 0
        details.append("âŒ final_calculation ëˆ„ë½ (0ì )")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 2. calculation_verification í•„ë“œ (2ì )
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    if 'calculation_verification' in response:
        # ìë™ ìƒì„±ì¸ì§€ í™•ì¸
        if ('calculation_verification' in auto_gen or 
            'ìë™ ê²€ì¦' in str(response.get('calculation_verification', ''))):
            score += 0
            breakdown['calculation_verification'] = 0
            details.append("âŒ calculation_verification ëˆ„ë½ (ìë™ ìƒì„±, 0ì )")
        else:
            score += 2
            breakdown['calculation_verification'] = 2
            details.append("âœ… calculation_verification ì œê³µ (2ì )")
    else:
        score += 0
        breakdown['calculation_verification'] = 0
        details.append("âŒ calculation_verification ëˆ„ë½ (0ì )")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # 3. concept í•„ë“œ ì™„ì„±ë„ (1ì )
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    if decomp and len(decomp) > 0:
        with_concept = sum(1 for s in decomp if s.get('concept'))
        concept_ratio = with_concept / len(decomp)
        
        if concept_ratio >= 0.8:
            concept_score = 1.0
            score += 1.0
            breakdown['concept_fields'] = 1.0
            details.append(f"âœ… concept í•„ë“œ ì™„ì„± ({with_concept}/{len(decomp)}, 1ì )")
        elif concept_ratio >= 0.5:
            concept_score = 0.5
            score += 0.5
            breakdown['concept_fields'] = 0.5
            details.append(f"âš ï¸ concept í•„ë“œ ë¶€ë¶„ ({with_concept}/{len(decomp)}, 0.5ì )")
        else:
            concept_score = 0
            breakdown['concept_fields'] = 0
            details.append(f"âŒ concept í•„ë“œ ë¶€ì¡± ({with_concept}/{len(decomp)}, 0ì )")
    else:
        breakdown['concept_fields'] = 0
        details.append("âŒ concept í•„ë“œ ì—†ìŒ (0ì )")
    
    return {
        'score': score,
        'details': details,
        'breakdown': breakdown
    }


def evaluate_conceptual_coherence(problem_id, decomp, final_calc):
    """ê°œë…ì  ì¼ê´€ì„± í‰ê°€ (15ì )

    Pseudo-codeì˜ ë…¼ë¦¬ì  íƒ€ë‹¹ì„± í‰ê°€:
    - ê° ë‹¨ê³„ê°€ ìµœì¢… ëª©í‘œì™€ ê°œë…ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ”ì§€
    - ë„ë©”ì¸ ì§€ì‹ì— ë¶€í•©í•˜ëŠ”ì§€
    - ë¶ˆí•„ìš”í•œ ë‹¨ê³„ëŠ” ì—†ëŠ”ì§€
    """
    score = 0
    details = []

    if not isinstance(decomp, list) or len(decomp) < 2:
        return {
            'score': 0,
            'details': ['âŒ decomposition ì—†ìŒ ë˜ëŠ” ë¶€ì¡±']
        }

    # ë‹¨ê³„ë³„ ê°œë… ì¶”ì¶œ
    steps_text = ' '.join([
        f"{s.get('step', '')} {s.get('reasoning', '')} {s.get('calculation', '')}"
        for s in decomp
    ]).lower()

    # ë¬¸ì œë³„ í•µì‹¬ ê°œë… í‚¤ì›Œë“œ
    concept_keywords = {
        'phase4_korean_businesses': {
            'essential': ['ì¸êµ¬', 'ê²½ì œí™œë™', 'ìì˜ì—…', 'ë²•ì¸', 'ì‚¬ì—…ì', 'ê¸°ì—…', 'ì°½ì—…'],
            'operations': ['í•©', 'ë”í•˜', '+', 'ê³±', 'Ã—', '*', 'ë¹„ìœ¨', '%'],
            'irrelevant': ['í‚¤', 'ëª¸ë¬´ê²Œ', 'ë‚ ì”¨', 'ì˜¨ë„', 'íƒì‹œ', 'ì»¤í”¼'],
            'logic': 'ê²½ì œí™œë™ì¸êµ¬ ê¸°ë°˜ ë˜ëŠ” ì—…ì¢…ë³„ í•©ì‚°'
        },
        'phase4_seoul_population': {
            'essential': ['ì¸êµ¬', 'ì„œìš¸', 'ë¹„ì¤‘', 'ë¹„ìœ¨', 'ìˆ˜ë„ê¶Œ', 'ì „êµ­'],
            'operations': ['ê³±', 'Ã—', '*', 'ë¹„ìœ¨', '%'],
            'irrelevant': ['ì‚¬ì—…ì', 'ì»¤í”¼', 'íƒì‹œ'],
            'logic': 'ì „êµ­ ì¸êµ¬ Ã— ì„œìš¸ ë¹„ì¤‘'
        },
        'phase4_coffee_shops': {
            'essential': ['ì¸êµ¬', 'ì†Œë¹„', 'ê³ ê°', 'ì í¬', 'ì»¤í”¼', 'ë§¤ì¥', 'ìˆ˜ìš”'],
            'operations': ['ë‚˜ëˆ„', 'Ã·', '/', 'ê³±', 'Ã—'],
            'irrelevant': ['íƒì‹œ', 'ì‚¬ì—…ìë“±ë¡', 'ë²•ì¸'],
            'logic': 'ì†Œë¹„ì¸êµ¬ Ã· ì í¬ë‹¹ ê³ ê° ìˆ˜'
        }
    }

    keywords = concept_keywords.get(problem_id, concept_keywords['phase4_korean_businesses'])

    # 1. í•µì‹¬ ê°œë… í¬í•¨ ì—¬ë¶€ (5ì )
    essential_found = sum(1 for kw in keywords['essential'] if kw in steps_text)
    essential_ratio = essential_found / len(keywords['essential'])

    if essential_ratio >= 0.4:  # 40% ì´ìƒ í¬í•¨
        essential_score = 5
        details.append(f"âœ… í•µì‹¬ ê°œë… í¬í•¨ ({essential_found}/{len(keywords['essential'])}) (5ì )")
    elif essential_ratio >= 0.2:
        essential_score = 3
        details.append(f"âš ï¸ í•µì‹¬ ê°œë… ì¼ë¶€ ({essential_found}/{len(keywords['essential'])}) (3ì )")
    else:
        essential_score = 0
        details.append(f"âŒ í•µì‹¬ ê°œë… ë¶€ì¡± ({essential_found}/{len(keywords['essential'])}) (0ì )")

    score += essential_score

    # 2. ë…¼ë¦¬ì  ì—°ì‚° ì¡´ì¬ (3ì )
    operations_found = any(op in steps_text or op in final_calc.lower() for op in keywords['operations'])
    if operations_found:
        score += 3
        details.append("âœ… ë…¼ë¦¬ì  ì—°ì‚° í¬í•¨ (3ì )")
    else:
        details.append("âŒ ë…¼ë¦¬ì  ì—°ì‚° ì—†ìŒ (0ì )")

    # 3. ê´€ë ¨ ì—†ëŠ” ê°œë… ì‚¬ìš© (-3ì , ê°ì )
    irrelevant_found = [kw for kw in keywords['irrelevant'] if kw in steps_text]
    if irrelevant_found:
        penalty = min(3, len(irrelevant_found))
        score -= penalty
        details.append(f"âš ï¸ ê´€ë ¨ ì—†ëŠ” ê°œë… ì‚¬ìš© ({', '.join(irrelevant_found[:2])}) (-{penalty}ì )")
    else:
        details.append("âœ… ê´€ë ¨ ì—†ëŠ” ê°œë… ì—†ìŒ (0ì )")

    # 4. Pseudo-code ë…¼ë¦¬ êµ¬ì¡° (7ì )
    # ë§ˆì§€ë§‰ ë‹¨ê³„ê°€ ìµœì¢… ê³„ì‚° ë‹¨ê³„ì¸ì§€
    last_step = decomp[-1].get('step', '').lower()
    if 'ìµœì¢…' in last_step or 'total' in last_step or 'í•©ê³„' in last_step:
        score += 3
        details.append("âœ… ìµœì¢… ë‹¨ê³„ ëª…í™• (3ì )")
    else:
        details.append("âš ï¸ ìµœì¢… ë‹¨ê³„ ë¶ˆëª…í™• (0ì )")

    # ì¤‘ê°„ ë‹¨ê³„ë“¤ì´ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ”ì§€ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
    # calculation í•„ë“œì— ì´ì „ step ì°¸ì¡°ê°€ ìˆëŠ”ì§€
    has_step_ref = any('step' in s.get('calculation', '').lower() for s in decomp[1:])
    if has_step_ref:
        score += 4
        details.append("âœ… ë‹¨ê³„ ê°„ ì°¸ì¡° ëª…í™• (4ì )")
    else:
        # calculationì— ì‹¤ì œ ìˆ«ì ì—°ì‚°ì´ ìˆëŠ”ì§€
        has_calc = any(op in s.get('calculation', '') for s in decomp for op in ['+', '-', '*', 'Ã—', '/', 'Ã·'])
        if has_calc:
            score += 2
            details.append("âš ï¸ ì—°ì‚° ìˆìœ¼ë‚˜ ì°¸ì¡° ë¶ˆëª…í™• (2ì )")
        else:
            details.append("âŒ ë‹¨ê³„ ê°„ ì—°ê²° ë¶ˆëª…í™• (0ì )")

    return {
        'score': max(0, min(score, 15)),  # 0-15ì  ë²”ìœ„
        'details': details,
        'logic_description': keywords['logic']
    }


def evaluate_fermi_response(model_name, response, expected_value, problem_id=''):
    """Fermi ì¶”ì • í‰ê°€ (110ì ) - v7.8.0
    
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    í‰ê°€ ê¸°ì¤€ (ì´ 110ì ):
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    1. ì •í™•ë„ (25ì ): Log10 ê¸°ë°˜ ì˜¤ì°¨ìœ¨
    2. ë‚´ìš© ì ìˆ˜ (45ì ):
       - ë‹¨ê³„ë³„ ê³„ì‚° ì™„ì„±ë„ (10ì )
       - ê³„ì‚° ë…¼ë¦¬ ì—°ê²° (10ì )
       - ìˆ˜ì¹˜ ì •í™•ì„± (25ì )
    3. í˜•ì‹ ì ìˆ˜ (5ì ):
       - final_calculation (2ì )
       - calculation_verification (2ì )
       - concept í•„ë“œ (1ì )
    4. ë¶„í•´ í’ˆì§ˆ (10ì )
    5. ê°œë…ì  ì¼ê´€ì„± (15ì )
    6. ë…¼ë¦¬ (10ì )
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    âœ¨ v7.8.0 ì£¼ìš” ë³€ê²½:
    - ê³„ì‚° ì—°ê²°ì„± (50ì ) â†’ ë‚´ìš© ì ìˆ˜ (45ì ) + í˜•ì‹ ì ìˆ˜ (5ì )
    - ìë™ ìƒì„±ëœ í•„ë“œëŠ” í˜•ì‹ ì ìˆ˜ 0ì  ì²˜ë¦¬
    """
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # ğŸ”„ í›„ì²˜ë¦¬: í•„ìˆ˜ í•„ë“œ ìë™ ìƒì„±
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    decomp = response.get('decomposition', [])
    auto_generated_fields = []
    
    if not response.get('final_calculation') and decomp and len(decomp) > 0:
        # decomposition ë§ˆì§€ë§‰ ë‹¨ê³„ì˜ calculation ì‚¬ìš©
        last_step = decomp[-1]
        if last_step.get('calculation'):
            response['final_calculation'] = f"Auto-generated: {last_step['calculation']}"
            auto_generated_fields.append('final_calculation')
            print(f"  ğŸ”„ [í›„ì²˜ë¦¬] final_calculation ìë™ ìƒì„±: {last_step.get('step', 'N/A')}")
    
    if not response.get('calculation_verification'):
        # ìë™ ê²€ì¦ ê²°ê³¼ ì‚¬ìš©
        if decomp and len(decomp) > 0:
            auto_result, auto_msg = auto_verify_calculation(decomp, response.get('value', 0))
            if auto_result is not None:
                response['calculation_verification'] = f"âœ“ ìë™ ê²€ì¦: {auto_msg}"
                auto_generated_fields.append('calculation_verification')
                print(f"  ğŸ”„ [í›„ì²˜ë¦¬] calculation_verification ìë™ ìƒì„±")
    
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    # í‰ê°€ ì‹œì‘
    # â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    result = {
        'model': model_name,
        'value': response.get('value', 0),
        'unit': response.get('unit', ''),
        'expected_value': expected_value
    }

    if isinstance(result['value'], dict):
        result['value'] = 0
    elif not isinstance(result['value'], (int, float)):
        try:
            result['value'] = float(str(result['value']).replace(',', ''))
        except:
            result['value'] = 0

    # 1. ì •í™•ë„ (25ì )
    if result['value'] > 0 and expected_value > 0:
        error = abs(math.log10(result['value']) - math.log10(expected_value))

        if error < 0.05:
            accuracy_score = 25
        elif error < 0.1:
            accuracy_score = 20
        elif error < 0.3:
            accuracy_score = 15
        elif error < 0.5:
            accuracy_score = 10
        else:
            accuracy_score = 5

        error_pct = (10**error - 1) * 100
    else:
        accuracy_score = 0
        error_pct = 999

    result['accuracy'] = {
        'score': accuracy_score,
        'error_pct': round(error_pct, 1)
    }

    # 2. ë‚´ìš© ì ìˆ˜ (45ì ) - v7.8.0
    content_eval = evaluate_content_score(decomp, result['value'])
    result['content_score'] = content_eval

    # 3. í˜•ì‹ ì ìˆ˜ (5ì ) - v7.8.0
    format_eval = evaluate_format_score(response, decomp, auto_generated_fields)
    result['format_score'] = format_eval

    # 4. ë¶„í•´ í’ˆì§ˆ (10ì )
    if isinstance(decomp, list) and len(decomp) >= 3:
        decomp_score = 3
        complete = sum(1 for s in decomp
                      if all(k in s for k in ['step', 'value', 'calculation', 'reasoning']))
        decomp_score += min(7, (complete / len(decomp)) * 7)
    else:
        decomp_score = 0

    result['decomposition'] = {
        'score': decomp_score,
        'count': len(decomp) if isinstance(decomp, list) else 0
    }

    # 5. ê°œë…ì  ì¼ê´€ì„± (15ì )
    conceptual = evaluate_conceptual_coherence(
        problem_id,
        decomp,
        response.get('final_calculation', '')
    )

    result['conceptual_coherence'] = conceptual

    # 6. ë…¼ë¦¬ (10ì )
    logic_score = 0
    if response.get('method'):
        logic_score += 5
    if response.get('reasoning'):
        logic_score += 5

    result['logic'] = {'score': logic_score}

    # ì´ì  ê³„ì‚° (110ì )
    result['total_score'] = (
        accuracy_score +
        content_eval['score'] +
        format_eval['score'] +
        decomp_score +
        conceptual['score'] +
        logic_score
    )

    return result


